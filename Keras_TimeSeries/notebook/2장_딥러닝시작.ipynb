{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1~10까지 예측 모델 구하기\n",
    "1~10까지의 데이터가 주어졌을때 답이 1에서 10이 나오도록 컴퓨터를 학습시키고, 이 학습 결과로 다른 임의의 값을 주었을때 컴퓨터가 답을 예측하는 모델을 만드는 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 데이터 생성\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "y = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1을 입력하면 1이 출력되고, 2를 입력하면 2가 출력되는 공식을 컴퓨터에게 학습시키는 것.  \n",
    "머신러닝에서는 트레이닝 시킨다고 함.   \n",
    "이러한 구조를 수학식으로 풀게되면 `y = ax + b` 이라는 식으로 풀 수 있게 되는데  \n",
    "딥러닝, 인공신경망에서는 `h(x) = wx + b` 라고 표현함  \n",
    "\n",
    "`a` 는 기울기, `b` 는 `y`의 절편이라고 불렀었는데, 이를 머신러닝에서는 `w`를 `weight` 가중치, `b`를 편향이라고 읽음  \n",
    "이러한 인공신경망은 input 값인 x와 그의 결과인 출력값 y 를 가지고 컴퓨터에게 `train` 시키는 과정으로 반복됨  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# keras 불러오기\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 정의한 1차 함수의 모델은 보통 '회귀모델'이라고함. 케라스로 모델을 쌓는 과정  \n",
    "input_dim은 입력으로 들어가는 데이터의 차원을 의미함.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()  # 모델을 순차적으로 구성하겠다고 선언\n",
    "model.add(Dense(1, input_dim=1, activation='relu'))  # 순차적 구성 모델에 Dense 레이어를 추가하겠다는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인공신경망의 layer 들이 깊게 쌓인 것을 딥러닝이라고 함.  \n",
    "딥러닝을 구현하기 위해서는 신경망을 훈련시킬 x, y 값에 해당하는 데이터를 준비하고, 얼마나 많은 노드와 레이어로 모델을 구성할지 설계해야 함. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컴퓨터가 이해할 수 있도록 model을 `compile` 해주어야 함.  \n",
    "이때 인잣값으로 `loss`, `optimizer`, `metrics` 를 지정해주어야 함.  \n",
    "* `loss` : 손실함수의 종류  \n",
    "* `optimizer` : 최적화 함수\n",
    "* `metrics` : 어떤 방식으로 모델을 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fit`으로 케라스의 모델을 학습함.  \n",
    "이때 인잣값으로 `x`, `y`, `epochs`, `batch_size` 를 지정해줌  \n",
    "* `x` : 모델에 넣을 input 데이터  \n",
    "* `y` : 모델에 넣을 output 데이터  \n",
    "* `epochs` : 훈련을 반복할 횟수\n",
    "* `batch_size` : 배치사이즈, 신경망에 넘겨주는 데이터의 수  \n",
    "\n",
    "아래의 코드의 경우에는 x, y 데이터를 1개씩 쪼개어 훈련을 하겠다는 의미.  \n",
    "batch_size가 1일경우 1개의 배치사이즈로 총 10번의 step을 돌아야 1epoch 이 됨.   \n",
    "batch_size가 2일경우 2개의 배치사이즈로 총 5번의 step을 돌아야 1epoch 이 됨.  \n",
    "\n",
    "그래서 batch_size가 클수록 파라미터의 갱신(step)이 적어지게 되어서 학습이 빨라지지만 정확도가 떨어질 수 있음  \n",
    "\n",
    ">1 epoch = batch_size * step(data_size / batch_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/800\n",
      "10/10 [==============================] - 0s 630us/step - loss: 4.7918 - accuracy: 0.1087\n",
      "Epoch 2/800\n",
      "10/10 [==============================] - 0s 522us/step - loss: 4.0962 - accuracy: 0.1390\n",
      "Epoch 3/800\n",
      "10/10 [==============================] - 0s 572us/step - loss: 5.8505 - accuracy: 0.0396\n",
      "Epoch 4/800\n",
      "10/10 [==============================] - 0s 564us/step - loss: 4.9014 - accuracy: 0.2754\n",
      "Epoch 5/800\n",
      "10/10 [==============================] - 0s 608us/step - loss: 3.6786 - accuracy: 0.2754\n",
      "Epoch 6/800\n",
      "10/10 [==============================] - 0s 683us/step - loss: 2.3076 - accuracy: 0.2754\n",
      "Epoch 7/800\n",
      "10/10 [==============================] - 0s 628us/step - loss: 5.7035 - accuracy: 0.0396\n",
      "Epoch 8/800\n",
      "10/10 [==============================] - 0s 695us/step - loss: 2.5364 - accuracy: 0.1390\n",
      "Epoch 9/800\n",
      "10/10 [==============================] - 0s 652us/step - loss: 4.7150 - accuracy: 0.0182\n",
      "Epoch 10/800\n",
      "10/10 [==============================] - 0s 664us/step - loss: 4.6192 - accuracy: 0.0182\n",
      "Epoch 11/800\n",
      "10/10 [==============================] - 0s 701us/step - loss: 1.9040 - accuracy: 0.2754\n",
      "Epoch 12/800\n",
      "10/10 [==============================] - 0s 604us/step - loss: 3.1446 - accuracy: 0.0283\n",
      "Epoch 13/800\n",
      "10/10 [==============================] - 0s 702us/step - loss: 4.1630 - accuracy: 0.0283\n",
      "Epoch 14/800\n",
      "10/10 [==============================] - 0s 682us/step - loss: 1.8288 - accuracy: 0.1390\n",
      "Epoch 15/800\n",
      "10/10 [==============================] - 0s 605us/step - loss: 2.6162 - accuracy: 0.0678\n",
      "Epoch 16/800\n",
      "10/10 [==============================] - 0s 704us/step - loss: 2.7952 - accuracy: 0.0182\n",
      "Epoch 17/800\n",
      "10/10 [==============================] - 0s 672us/step - loss: 1.9596 - accuracy: 0.0182\n",
      "Epoch 18/800\n",
      "10/10 [==============================] - 0s 657us/step - loss: 2.5190 - accuracy: 0.1390\n",
      "Epoch 19/800\n",
      "10/10 [==============================] - 0s 691us/step - loss: 2.3815 - accuracy: 0.0860\n",
      "Epoch 20/800\n",
      "10/10 [==============================] - 0s 607us/step - loss: 1.9758 - accuracy: 0.0860\n",
      "Epoch 21/800\n",
      "10/10 [==============================] - 0s 613us/step - loss: 1.3347 - accuracy: 0.0283\n",
      "Epoch 22/800\n",
      "10/10 [==============================] - 0s 658us/step - loss: 1.3586 - accuracy: 0.1390\n",
      "Epoch 23/800\n",
      "10/10 [==============================] - 0s 594us/step - loss: 2.4643 - accuracy: 0.0396\n",
      "Epoch 24/800\n",
      "10/10 [==============================] - 0s 676us/step - loss: 1.5733 - accuracy: 0.1845\n",
      "Epoch 25/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 1.7797 - accuracy: 0.0283\n",
      "Epoch 26/800\n",
      "10/10 [==============================] - 0s 626us/step - loss: 1.6041 - accuracy: 0.1390\n",
      "Epoch 27/800\n",
      "10/10 [==============================] - 0s 670us/step - loss: 1.9290 - accuracy: 0.0678\n",
      "Epoch 28/800\n",
      "10/10 [==============================] - 0s 693us/step - loss: 0.7432 - accuracy: 0.2754\n",
      "Epoch 29/800\n",
      "10/10 [==============================] - 0s 696us/step - loss: 0.8888 - accuracy: 0.0678\n",
      "Epoch 30/800\n",
      "10/10 [==============================] - 0s 760us/step - loss: 1.2117 - accuracy: 0.0283\n",
      "Epoch 31/800\n",
      "10/10 [==============================] - 0s 601us/step - loss: 0.9457 - accuracy: 0.0396\n",
      "Epoch 32/800\n",
      "10/10 [==============================] - 0s 718us/step - loss: 0.9168 - accuracy: 0.1087\n",
      "Epoch 33/800\n",
      "10/10 [==============================] - 0s 624us/step - loss: 1.1654 - accuracy: 0.0283\n",
      "Epoch 34/800\n",
      "10/10 [==============================] - 0s 635us/step - loss: 0.3524 - accuracy: 0.1087\n",
      "Epoch 35/800\n",
      "10/10 [==============================] - 0s 742us/step - loss: 1.0299 - accuracy: 0.0182\n",
      "Epoch 36/800\n",
      "10/10 [==============================] - 0s 616us/step - loss: 0.9570 - accuracy: 0.0860\n",
      "Epoch 37/800\n",
      "10/10 [==============================] - 0s 651us/step - loss: 0.3906 - accuracy: 0.1845\n",
      "Epoch 38/800\n",
      "10/10 [==============================] - 0s 642us/step - loss: 0.8450 - accuracy: 0.0860\n",
      "Epoch 39/800\n",
      "10/10 [==============================] - 0s 625us/step - loss: 0.7775 - accuracy: 0.0526\n",
      "Epoch 40/800\n",
      "10/10 [==============================] - 0s 701us/step - loss: 0.4696 - accuracy: 0.0526\n",
      "Epoch 41/800\n",
      "10/10 [==============================] - 0s 614us/step - loss: 0.2484 - accuracy: 0.2754\n",
      "Epoch 42/800\n",
      "10/10 [==============================] - 0s 702us/step - loss: 0.4409 - accuracy: 0.0283\n",
      "Epoch 43/800\n",
      "10/10 [==============================] - 0s 661us/step - loss: 0.5258 - accuracy: 0.0860\n",
      "Epoch 44/800\n",
      "10/10 [==============================] - 0s 611us/step - loss: 0.2477 - accuracy: 0.1390\n",
      "Epoch 45/800\n",
      "10/10 [==============================] - 0s 635us/step - loss: 0.2968 - accuracy: 0.0860\n",
      "Epoch 46/800\n",
      "10/10 [==============================] - 0s 724us/step - loss: 0.2780 - accuracy: 0.1845\n",
      "Epoch 47/800\n",
      "10/10 [==============================] - 0s 677us/step - loss: 0.2775 - accuracy: 0.2754\n",
      "Epoch 48/800\n",
      "10/10 [==============================] - 0s 647us/step - loss: 0.2898 - accuracy: 0.1845\n",
      "Epoch 49/800\n",
      "10/10 [==============================] - 0s 678us/step - loss: 0.2879 - accuracy: 0.0182\n",
      "Epoch 50/800\n",
      "10/10 [==============================] - 0s 600us/step - loss: 0.2160 - accuracy: 0.0182\n",
      "Epoch 51/800\n",
      "10/10 [==============================] - 0s 686us/step - loss: 0.1936 - accuracy: 0.1845\n",
      "Epoch 52/800\n",
      "10/10 [==============================] - 0s 606us/step - loss: 0.1313 - accuracy: 0.1390\n",
      "Epoch 53/800\n",
      "10/10 [==============================] - 0s 702us/step - loss: 0.2779 - accuracy: 0.0182\n",
      "Epoch 54/800\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.0000e+ - 0s 676us/step - loss: 0.1238 - accuracy: 0.0860\n",
      "Epoch 55/800\n",
      "10/10 [==============================] - 0s 579us/step - loss: 0.1386 - accuracy: 0.2754\n",
      "Epoch 56/800\n",
      "10/10 [==============================] - 0s 674us/step - loss: 0.1572 - accuracy: 0.0283  \n",
      "Epoch 57/800\n",
      "10/10 [==============================] - 0s 723us/step - loss: 0.0825 - accuracy: 0.1845\n",
      "Epoch 58/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 0.1137 - accuracy: 0.1845\n",
      "Epoch 59/800\n",
      "10/10 [==============================] - 0s 718us/step - loss: 0.1205 - accuracy: 0.1087\n",
      "Epoch 60/800\n",
      "10/10 [==============================] - 0s 695us/step - loss: 0.1298 - accuracy: 0.0860  \n",
      "Epoch 61/800\n",
      "10/10 [==============================] - 0s 720us/step - loss: 0.1521 - accuracy: 0.0860\n",
      "Epoch 62/800\n",
      "10/10 [==============================] - 0s 687us/step - loss: 0.0868 - accuracy: 0.0283\n",
      "Epoch 63/800\n",
      "10/10 [==============================] - 0s 618us/step - loss: 0.1318 - accuracy: 0.0526\n",
      "Epoch 64/800\n",
      "10/10 [==============================] - 0s 623us/step - loss: 0.0686 - accuracy: 0.1087  \n",
      "Epoch 65/800\n",
      "10/10 [==============================] - 0s 688us/step - loss: 0.0973 - accuracy: 0.1390\n",
      "Epoch 66/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 0.0547 - accuracy: 0.1390\n",
      "Epoch 67/800\n",
      "10/10 [==============================] - 0s 643us/step - loss: 0.1124 - accuracy: 0.0396\n",
      "Epoch 68/800\n",
      "10/10 [==============================] - 0s 707us/step - loss: 0.0790 - accuracy: 0.0283\n",
      "Epoch 69/800\n",
      "10/10 [==============================] - 0s 650us/step - loss: 0.0558 - accuracy: 0.0396\n",
      "Epoch 70/800\n",
      "10/10 [==============================] - 0s 659us/step - loss: 0.0400 - accuracy: 0.1390\n",
      "Epoch 71/800\n",
      "10/10 [==============================] - 0s 623us/step - loss: 0.0681 - accuracy: 0.2754\n",
      "Epoch 72/800\n",
      "10/10 [==============================] - 0s 636us/step - loss: 0.0381 - accuracy: 0.1087\n",
      "Epoch 73/800\n",
      "10/10 [==============================] - 0s 697us/step - loss: 0.0398 - accuracy: 0.0182\n",
      "Epoch 74/800\n",
      "10/10 [==============================] - 0s 636us/step - loss: 0.0516 - accuracy: 0.0678\n",
      "Epoch 75/800\n",
      "10/10 [==============================] - 0s 647us/step - loss: 0.0655 - accuracy: 0.0526\n",
      "Epoch 76/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 693us/step - loss: 0.0397 - accuracy: 0.0396\n",
      "Epoch 77/800\n",
      "10/10 [==============================] - 0s 647us/step - loss: 0.0473 - accuracy: 0.2754\n",
      "Epoch 78/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 0.0372 - accuracy: 0.0182\n",
      "Epoch 79/800\n",
      "10/10 [==============================] - 0s 706us/step - loss: 0.0345 - accuracy: 0.0396\n",
      "Epoch 80/800\n",
      "10/10 [==============================] - 0s 691us/step - loss: 0.0298 - accuracy: 0.1390\n",
      "Epoch 81/800\n",
      "10/10 [==============================] - 0s 680us/step - loss: 0.0353 - accuracy: 0.1087\n",
      "Epoch 82/800\n",
      "10/10 [==============================] - 0s 608us/step - loss: 0.0403 - accuracy: 0.0678\n",
      "Epoch 83/800\n",
      "10/10 [==============================] - 0s 641us/step - loss: 0.0233 - accuracy: 0.0396\n",
      "Epoch 84/800\n",
      "10/10 [==============================] - 0s 663us/step - loss: 0.0411 - accuracy: 0.0526\n",
      "Epoch 85/800\n",
      "10/10 [==============================] - 0s 661us/step - loss: 0.0222 - accuracy: 0.0396\n",
      "Epoch 86/800\n",
      "10/10 [==============================] - 0s 674us/step - loss: 0.0330 - accuracy: 0.0283\n",
      "Epoch 87/800\n",
      "10/10 [==============================] - 0s 630us/step - loss: 0.0368 - accuracy: 0.2754\n",
      "Epoch 88/800\n",
      "10/10 [==============================] - 0s 693us/step - loss: 0.0428 - accuracy: 0.2754\n",
      "Epoch 89/800\n",
      "10/10 [==============================] - 0s 668us/step - loss: 0.0310 - accuracy: 0.0283\n",
      "Epoch 90/800\n",
      "10/10 [==============================] - 0s 612us/step - loss: 0.0469 - accuracy: 0.2754\n",
      "Epoch 91/800\n",
      "10/10 [==============================] - 0s 673us/step - loss: 0.0216 - accuracy: 0.0396\n",
      "Epoch 92/800\n",
      "10/10 [==============================] - 0s 649us/step - loss: 0.0281 - accuracy: 0.0860\n",
      "Epoch 93/800\n",
      "10/10 [==============================] - 0s 647us/step - loss: 0.0238 - accuracy: 0.0526\n",
      "Epoch 94/800\n",
      "10/10 [==============================] - 0s 660us/step - loss: 0.0324 - accuracy: 0.1390\n",
      "Epoch 95/800\n",
      "10/10 [==============================] - 0s 613us/step - loss: 0.0224 - accuracy: 0.0283\n",
      "Epoch 96/800\n",
      "10/10 [==============================] - 0s 634us/step - loss: 0.0308 - accuracy: 0.2754\n",
      "Epoch 97/800\n",
      "10/10 [==============================] - 0s 649us/step - loss: 0.0335 - accuracy: 0.1087\n",
      "Epoch 98/800\n",
      "10/10 [==============================] - 0s 650us/step - loss: 0.0163 - accuracy: 0.0526\n",
      "Epoch 99/800\n",
      "10/10 [==============================] - 0s 659us/step - loss: 0.0399 - accuracy: 0.2754\n",
      "Epoch 100/800\n",
      "10/10 [==============================] - 0s 670us/step - loss: 0.0276 - accuracy: 0.0283\n",
      "Epoch 101/800\n",
      "10/10 [==============================] - 0s 658us/step - loss: 0.0278 - accuracy: 0.0860\n",
      "Epoch 102/800\n",
      "10/10 [==============================] - 0s 668us/step - loss: 0.0244 - accuracy: 0.0283\n",
      "Epoch 103/800\n",
      "10/10 [==============================] - 0s 602us/step - loss: 0.0378 - accuracy: 0.2754\n",
      "Epoch 104/800\n",
      "10/10 [==============================] - 0s 620us/step - loss: 0.0202 - accuracy: 0.0182\n",
      "Epoch 105/800\n",
      "10/10 [==============================] - 0s 652us/step - loss: 0.0285 - accuracy: 0.1390\n",
      "Epoch 106/800\n",
      "10/10 [==============================] - 0s 621us/step - loss: 0.0189 - accuracy: 0.0396\n",
      "Epoch 107/800\n",
      "10/10 [==============================] - 0s 647us/step - loss: 0.0195 - accuracy: 0.0396\n",
      "Epoch 108/800\n",
      "10/10 [==============================] - 0s 653us/step - loss: 0.0212 - accuracy: 0.0396\n",
      "Epoch 109/800\n",
      "10/10 [==============================] - 0s 635us/step - loss: 0.0212 - accuracy: 0.1087\n",
      "Epoch 110/800\n",
      "10/10 [==============================] - 0s 669us/step - loss: 0.0338 - accuracy: 0.0860\n",
      "Epoch 111/800\n",
      "10/10 [==============================] - 0s 610us/step - loss: 0.0222 - accuracy: 0.1390\n",
      "Epoch 112/800\n",
      "10/10 [==============================] - 0s 687us/step - loss: 0.0298 - accuracy: 0.0526\n",
      "Epoch 113/800\n",
      "10/10 [==============================] - 0s 701us/step - loss: 0.0188 - accuracy: 0.0182\n",
      "Epoch 114/800\n",
      "10/10 [==============================] - 0s 663us/step - loss: 0.0244 - accuracy: 0.1845  \n",
      "Epoch 115/800\n",
      "10/10 [==============================] - 0s 652us/step - loss: 0.0262 - accuracy: 0.1390\n",
      "Epoch 116/800\n",
      "10/10 [==============================] - 0s 645us/step - loss: 0.0304 - accuracy: 0.1845\n",
      "Epoch 117/800\n",
      "10/10 [==============================] - 0s 635us/step - loss: 0.0196 - accuracy: 0.0283\n",
      "Epoch 118/800\n",
      "10/10 [==============================] - 0s 684us/step - loss: 0.0370 - accuracy: 0.2754\n",
      "Epoch 119/800\n",
      "10/10 [==============================] - 0s 662us/step - loss: 0.0233 - accuracy: 0.0283\n",
      "Epoch 120/800\n",
      "10/10 [==============================] - 0s 665us/step - loss: 0.0184 - accuracy: 0.0396\n",
      "Epoch 121/800\n",
      "10/10 [==============================] - 0s 662us/step - loss: 0.0215 - accuracy: 0.1087\n",
      "Epoch 122/800\n",
      "10/10 [==============================] - 0s 620us/step - loss: 0.0183 - accuracy: 0.0283\n",
      "Epoch 123/800\n",
      "10/10 [==============================] - 0s 694us/step - loss: 0.0202 - accuracy: 0.0526\n",
      "Epoch 124/800\n",
      "10/10 [==============================] - 0s 645us/step - loss: 0.0286 - accuracy: 0.1087\n",
      "Epoch 125/800\n",
      "10/10 [==============================] - 0s 626us/step - loss: 0.0180 - accuracy: 0.0396  \n",
      "Epoch 126/800\n",
      "10/10 [==============================] - 0s 667us/step - loss: 0.0298 - accuracy: 0.2754\n",
      "Epoch 127/800\n",
      "10/10 [==============================] - 0s 677us/step - loss: 0.0284 - accuracy: 0.0678\n",
      "Epoch 128/800\n",
      "10/10 [==============================] - 0s 618us/step - loss: 0.0131 - accuracy: 0.0396\n",
      "Epoch 129/800\n",
      "10/10 [==============================] - 0s 683us/step - loss: 0.0187 - accuracy: 0.0182\n",
      "Epoch 130/800\n",
      "10/10 [==============================] - 0s 666us/step - loss: 0.0224 - accuracy: 0.0860\n",
      "Epoch 131/800\n",
      "10/10 [==============================] - 0s 660us/step - loss: 0.0231 - accuracy: 0.1845\n",
      "Epoch 132/800\n",
      "10/10 [==============================] - 0s 689us/step - loss: 0.0226 - accuracy: 0.0678\n",
      "Epoch 133/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 0.0264 - accuracy: 0.1845\n",
      "Epoch 134/800\n",
      "10/10 [==============================] - 0s 670us/step - loss: 0.0144 - accuracy: 0.0678\n",
      "Epoch 135/800\n",
      "10/10 [==============================] - 0s 680us/step - loss: 0.0194 - accuracy: 0.1087\n",
      "Epoch 136/800\n",
      "10/10 [==============================] - 0s 661us/step - loss: 0.0102 - accuracy: 0.0182  \n",
      "Epoch 137/800\n",
      "10/10 [==============================] - 0s 696us/step - loss: 0.0181 - accuracy: 0.0283\n",
      "Epoch 138/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 0.0223 - accuracy: 0.1390\n",
      "Epoch 139/800\n",
      "10/10 [==============================] - 0s 628us/step - loss: 0.0241 - accuracy: 0.0283\n",
      "Epoch 140/800\n",
      "10/10 [==============================] - 0s 653us/step - loss: 0.0142 - accuracy: 0.0283  \n",
      "Epoch 141/800\n",
      "10/10 [==============================] - 0s 643us/step - loss: 0.0175 - accuracy: 0.0526\n",
      "Epoch 142/800\n",
      "10/10 [==============================] - 0s 675us/step - loss: 0.0295 - accuracy: 0.2754\n",
      "Epoch 143/800\n",
      "10/10 [==============================] - 0s 626us/step - loss: 0.0177 - accuracy: 0.0678\n",
      "Epoch 144/800\n",
      "10/10 [==============================] - 0s 667us/step - loss: 0.0261 - accuracy: 0.1390\n",
      "Epoch 145/800\n",
      "10/10 [==============================] - 0s 683us/step - loss: 0.0238 - accuracy: 0.0860\n",
      "Epoch 146/800\n",
      "10/10 [==============================] - 0s 659us/step - loss: 0.0173 - accuracy: 0.0678\n",
      "Epoch 147/800\n",
      "10/10 [==============================] - 0s 608us/step - loss: 0.0151 - accuracy: 0.0526\n",
      "Epoch 148/800\n",
      "10/10 [==============================] - 0s 670us/step - loss: 0.0198 - accuracy: 0.0678  \n",
      "Epoch 149/800\n",
      "10/10 [==============================] - 0s 665us/step - loss: 0.0133 - accuracy: 0.0283\n",
      "Epoch 150/800\n",
      "10/10 [==============================] - 0s 632us/step - loss: 0.0183 - accuracy: 0.0283\n",
      "Epoch 151/800\n",
      "10/10 [==============================] - 0s 706us/step - loss: 0.0159 - accuracy: 0.0396\n",
      "Epoch 152/800\n",
      "10/10 [==============================] - 0s 627us/step - loss: 0.0187 - accuracy: 0.1087\n",
      "Epoch 153/800\n",
      "10/10 [==============================] - 0s 644us/step - loss: 0.0136 - accuracy: 0.0182\n",
      "Epoch 154/800\n",
      "10/10 [==============================] - 0s 629us/step - loss: 0.0180 - accuracy: 0.0678\n",
      "Epoch 155/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 630us/step - loss: 0.0160 - accuracy: 0.1087\n",
      "Epoch 156/800\n",
      "10/10 [==============================] - 0s 706us/step - loss: 0.0116 - accuracy: 0.0283\n",
      "Epoch 157/800\n",
      "10/10 [==============================] - 0s 611us/step - loss: 0.0109 - accuracy: 0.0182  \n",
      "Epoch 158/800\n",
      "10/10 [==============================] - 0s 712us/step - loss: 0.0153 - accuracy: 0.0678  \n",
      "Epoch 159/800\n",
      "10/10 [==============================] - 0s 655us/step - loss: 0.0100 - accuracy: 0.0283\n",
      "Epoch 160/800\n",
      "10/10 [==============================] - 0s 644us/step - loss: 0.0149 - accuracy: 0.1390\n",
      "Epoch 161/800\n",
      "10/10 [==============================] - 0s 675us/step - loss: 0.0171 - accuracy: 0.0860\n",
      "Epoch 162/800\n",
      "10/10 [==============================] - 0s 614us/step - loss: 0.0183 - accuracy: 0.0860\n",
      "Epoch 163/800\n",
      "10/10 [==============================] - 0s 651us/step - loss: 0.0131 - accuracy: 0.0182\n",
      "Epoch 164/800\n",
      "10/10 [==============================] - 0s 651us/step - loss: 0.0118 - accuracy: 0.0182\n",
      "Epoch 165/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 0.0280 - accuracy: 0.2754\n",
      "Epoch 166/800\n",
      "10/10 [==============================] - 0s 721us/step - loss: 0.0109 - accuracy: 0.0526\n",
      "Epoch 167/800\n",
      "10/10 [==============================] - 0s 648us/step - loss: 0.0122 - accuracy: 0.0283\n",
      "Epoch 168/800\n",
      "10/10 [==============================] - 0s 628us/step - loss: 0.0142 - accuracy: 0.0182  \n",
      "Epoch 169/800\n",
      "10/10 [==============================] - 0s 643us/step - loss: 0.0164 - accuracy: 0.0182\n",
      "Epoch 170/800\n",
      "10/10 [==============================] - 0s 615us/step - loss: 0.0199 - accuracy: 0.1390\n",
      "Epoch 171/800\n",
      "10/10 [==============================] - 0s 665us/step - loss: 0.0173 - accuracy: 0.1390\n",
      "Epoch 172/800\n",
      "10/10 [==============================] - 0s 650us/step - loss: 0.0157 - accuracy: 0.0860\n",
      "Epoch 173/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 0.0217 - accuracy: 0.1390\n",
      "Epoch 174/800\n",
      "10/10 [==============================] - 0s 642us/step - loss: 0.0156 - accuracy: 0.1845  \n",
      "Epoch 175/800\n",
      "10/10 [==============================] - 0s 588us/step - loss: 0.0209 - accuracy: 0.1390\n",
      "Epoch 176/800\n",
      "10/10 [==============================] - 0s 677us/step - loss: 0.0156 - accuracy: 0.1390\n",
      "Epoch 177/800\n",
      "10/10 [==============================] - 0s 688us/step - loss: 0.0268 - accuracy: 0.2754\n",
      "Epoch 178/800\n",
      "10/10 [==============================] - 0s 618us/step - loss: 0.0173 - accuracy: 0.0283\n",
      "Epoch 179/800\n",
      "10/10 [==============================] - 0s 686us/step - loss: 0.0238 - accuracy: 0.2754\n",
      "Epoch 180/800\n",
      "10/10 [==============================] - 0s 625us/step - loss: 0.0262 - accuracy: 0.2754\n",
      "Epoch 181/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 0.0130 - accuracy: 0.0526\n",
      "Epoch 182/800\n",
      "10/10 [==============================] - 0s 664us/step - loss: 0.0206 - accuracy: 0.1845\n",
      "Epoch 183/800\n",
      "10/10 [==============================] - 0s 623us/step - loss: 0.0201 - accuracy: 0.1845\n",
      "Epoch 184/800\n",
      "10/10 [==============================] - 0s 640us/step - loss: 0.0176 - accuracy: 0.0396\n",
      "Epoch 185/800\n",
      "10/10 [==============================] - 0s 655us/step - loss: 0.0148 - accuracy: 0.1390  \n",
      "Epoch 186/800\n",
      "10/10 [==============================] - 0s 620us/step - loss: 0.0115 - accuracy: 0.0526\n",
      "Epoch 187/800\n",
      "10/10 [==============================] - 0s 666us/step - loss: 0.0144 - accuracy: 0.1087\n",
      "Epoch 188/800\n",
      "10/10 [==============================] - 0s 608us/step - loss: 0.0129 - accuracy: 0.0860\n",
      "Epoch 189/800\n",
      "10/10 [==============================] - 0s 630us/step - loss: 0.0151 - accuracy: 0.0182\n",
      "Epoch 190/800\n",
      "10/10 [==============================] - 0s 658us/step - loss: 0.0120 - accuracy: 0.0678\n",
      "Epoch 191/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 0.0221 - accuracy: 0.1390\n",
      "Epoch 192/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 0.0111 - accuracy: 0.1087  \n",
      "Epoch 193/800\n",
      "10/10 [==============================] - 0s 632us/step - loss: 0.0114 - accuracy: 0.0396\n",
      "Epoch 194/800\n",
      "10/10 [==============================] - 0s 625us/step - loss: 0.0099 - accuracy: 0.0182\n",
      "Epoch 195/800\n",
      "10/10 [==============================] - 0s 633us/step - loss: 0.0152 - accuracy: 0.1087\n",
      "Epoch 196/800\n",
      "10/10 [==============================] - 0s 617us/step - loss: 0.0127 - accuracy: 0.0526\n",
      "Epoch 197/800\n",
      "10/10 [==============================] - 0s 632us/step - loss: 0.0080 - accuracy: 0.0678  \n",
      "Epoch 198/800\n",
      "10/10 [==============================] - 0s 601us/step - loss: 0.0225 - accuracy: 0.1845\n",
      "Epoch 199/800\n",
      "10/10 [==============================] - 0s 654us/step - loss: 0.0196 - accuracy: 0.2754\n",
      "Epoch 200/800\n",
      "10/10 [==============================] - 0s 642us/step - loss: 0.0099 - accuracy: 0.0182\n",
      "Epoch 201/800\n",
      "10/10 [==============================] - 0s 607us/step - loss: 0.0107 - accuracy: 0.0396\n",
      "Epoch 202/800\n",
      "10/10 [==============================] - 0s 641us/step - loss: 0.0135 - accuracy: 0.1845  \n",
      "Epoch 203/800\n",
      "10/10 [==============================] - 0s 618us/step - loss: 0.0084 - accuracy: 0.0678\n",
      "Epoch 204/800\n",
      "10/10 [==============================] - 0s 629us/step - loss: 0.0162 - accuracy: 0.0678\n",
      "Epoch 205/800\n",
      "10/10 [==============================] - 0s 651us/step - loss: 0.0076 - accuracy: 0.0396  \n",
      "Epoch 206/800\n",
      "10/10 [==============================] - 0s 683us/step - loss: 0.0181 - accuracy: 0.2754\n",
      "Epoch 207/800\n",
      "10/10 [==============================] - 0s 681us/step - loss: 0.0149 - accuracy: 0.0860\n",
      "Epoch 208/800\n",
      "10/10 [==============================] - 0s 622us/step - loss: 0.0121 - accuracy: 0.1087\n",
      "Epoch 209/800\n",
      "10/10 [==============================] - 0s 616us/step - loss: 0.0184 - accuracy: 0.2754\n",
      "Epoch 210/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 0.0135 - accuracy: 0.1845\n",
      "Epoch 211/800\n",
      "10/10 [==============================] - 0s 611us/step - loss: 0.0145 - accuracy: 0.1845\n",
      "Epoch 212/800\n",
      "10/10 [==============================] - 0s 626us/step - loss: 0.0170 - accuracy: 0.2754\n",
      "Epoch 213/800\n",
      "10/10 [==============================] - 0s 649us/step - loss: 0.0097 - accuracy: 0.0526\n",
      "Epoch 214/800\n",
      "10/10 [==============================] - 0s 617us/step - loss: 0.0184 - accuracy: 0.2754\n",
      "Epoch 215/800\n",
      "10/10 [==============================] - 0s 640us/step - loss: 0.0126 - accuracy: 0.0526\n",
      "Epoch 216/800\n",
      "10/10 [==============================] - 0s 620us/step - loss: 0.0091 - accuracy: 0.0396  \n",
      "Epoch 217/800\n",
      "10/10 [==============================] - 0s 655us/step - loss: 0.0126 - accuracy: 0.1087\n",
      "Epoch 218/800\n",
      "10/10 [==============================] - 0s 617us/step - loss: 0.0081 - accuracy: 0.0396  \n",
      "Epoch 219/800\n",
      "10/10 [==============================] - 0s 615us/step - loss: 0.0100 - accuracy: 0.1087  \n",
      "Epoch 220/800\n",
      "10/10 [==============================] - 0s 683us/step - loss: 0.0112 - accuracy: 0.1390\n",
      "Epoch 221/800\n",
      "10/10 [==============================] - 0s 621us/step - loss: 0.0109 - accuracy: 0.0678  \n",
      "Epoch 222/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 0.0112 - accuracy: 0.0860\n",
      "Epoch 223/800\n",
      "10/10 [==============================] - 0s 645us/step - loss: 0.0076 - accuracy: 0.0678\n",
      "Epoch 224/800\n",
      "10/10 [==============================] - 0s 600us/step - loss: 0.0094 - accuracy: 0.1390\n",
      "Epoch 225/800\n",
      "10/10 [==============================] - 0s 653us/step - loss: 0.0160 - accuracy: 0.2754\n",
      "Epoch 226/800\n",
      "10/10 [==============================] - 0s 639us/step - loss: 0.0093 - accuracy: 0.0526\n",
      "Epoch 227/800\n",
      "10/10 [==============================] - 0s 649us/step - loss: 0.0115 - accuracy: 0.0678\n",
      "Epoch 228/800\n",
      "10/10 [==============================] - 0s 642us/step - loss: 0.0061 - accuracy: 0.0283\n",
      "Epoch 229/800\n",
      "10/10 [==============================] - 0s 622us/step - loss: 0.0100 - accuracy: 0.1087\n",
      "Epoch 230/800\n",
      "10/10 [==============================] - 0s 655us/step - loss: 0.0083 - accuracy: 0.0526\n",
      "Epoch 231/800\n",
      "10/10 [==============================] - 0s 627us/step - loss: 0.0086 - accuracy: 0.0283\n",
      "Epoch 232/800\n",
      "10/10 [==============================] - 0s 639us/step - loss: 0.0106 - accuracy: 0.1845  \n",
      "Epoch 233/800\n",
      "10/10 [==============================] - 0s 637us/step - loss: 0.0067 - accuracy: 0.0283  \n",
      "Epoch 234/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 611us/step - loss: 0.0063 - accuracy: 0.0182  \n",
      "Epoch 235/800\n",
      "10/10 [==============================] - 0s 633us/step - loss: 0.0081 - accuracy: 0.0396\n",
      "Epoch 236/800\n",
      "10/10 [==============================] - 0s 603us/step - loss: 0.0081 - accuracy: 0.0283\n",
      "Epoch 237/800\n",
      "10/10 [==============================] - 0s 687us/step - loss: 0.0113 - accuracy: 0.0860\n",
      "Epoch 238/800\n",
      "10/10 [==============================] - 0s 613us/step - loss: 0.0056 - accuracy: 0.0678\n",
      "Epoch 239/800\n",
      "10/10 [==============================] - 0s 610us/step - loss: 0.0088 - accuracy: 0.0283\n",
      "Epoch 240/800\n",
      "10/10 [==============================] - 0s 637us/step - loss: 0.0072 - accuracy: 0.0283  \n",
      "Epoch 241/800\n",
      "10/10 [==============================] - 0s 603us/step - loss: 0.0076 - accuracy: 0.0678\n",
      "Epoch 242/800\n",
      "10/10 [==============================] - 0s 711us/step - loss: 0.0108 - accuracy: 0.1845\n",
      "Epoch 243/800\n",
      "10/10 [==============================] - 0s 661us/step - loss: 0.0138 - accuracy: 0.2754\n",
      "Epoch 244/800\n",
      "10/10 [==============================] - 0s 602us/step - loss: 0.0077 - accuracy: 0.0678  \n",
      "Epoch 245/800\n",
      "10/10 [==============================] - 0s 666us/step - loss: 0.0074 - accuracy: 0.1390  \n",
      "Epoch 246/800\n",
      "10/10 [==============================] - 0s 614us/step - loss: 0.0128 - accuracy: 0.2754\n",
      "Epoch 247/800\n",
      "10/10 [==============================] - 0s 646us/step - loss: 0.0094 - accuracy: 0.0860\n",
      "Epoch 248/800\n",
      "10/10 [==============================] - 0s 647us/step - loss: 0.0069 - accuracy: 0.0526\n",
      "Epoch 249/800\n",
      "10/10 [==============================] - 0s 633us/step - loss: 0.0098 - accuracy: 0.1087\n",
      "Epoch 250/800\n",
      "10/10 [==============================] - 0s 655us/step - loss: 0.0084 - accuracy: 0.1390\n",
      "Epoch 251/800\n",
      "10/10 [==============================] - 0s 595us/step - loss: 0.0079 - accuracy: 0.0678\n",
      "Epoch 252/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 0.0070 - accuracy: 0.1087\n",
      "Epoch 253/800\n",
      "10/10 [==============================] - 0s 637us/step - loss: 0.0091 - accuracy: 0.1087\n",
      "Epoch 254/800\n",
      "10/10 [==============================] - 0s 622us/step - loss: 0.0080 - accuracy: 0.1845  \n",
      "Epoch 255/800\n",
      "10/10 [==============================] - 0s 664us/step - loss: 0.0109 - accuracy: 0.2754\n",
      "Epoch 256/800\n",
      "10/10 [==============================] - 0s 591us/step - loss: 0.0061 - accuracy: 0.1087  \n",
      "Epoch 257/800\n",
      "10/10 [==============================] - 0s 619us/step - loss: 0.0088 - accuracy: 0.1390\n",
      "Epoch 258/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 0.0057 - accuracy: 0.0678  \n",
      "Epoch 259/800\n",
      "10/10 [==============================] - 0s 622us/step - loss: 0.0078 - accuracy: 0.1087\n",
      "Epoch 260/800\n",
      "10/10 [==============================] - 0s 660us/step - loss: 0.0060 - accuracy: 0.0283\n",
      "Epoch 261/800\n",
      "10/10 [==============================] - 0s 612us/step - loss: 0.0090 - accuracy: 0.0678\n",
      "Epoch 262/800\n",
      "10/10 [==============================] - 0s 634us/step - loss: 0.0051 - accuracy: 0.0283\n",
      "Epoch 263/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 0.0061 - accuracy: 0.1087  \n",
      "Epoch 264/800\n",
      "10/10 [==============================] - 0s 672us/step - loss: 0.0049 - accuracy: 0.0182\n",
      "Epoch 265/800\n",
      "10/10 [==============================] - 0s 661us/step - loss: 0.0072 - accuracy: 0.1845  \n",
      "Epoch 266/800\n",
      "10/10 [==============================] - 0s 627us/step - loss: 0.0074 - accuracy: 0.1087\n",
      "Epoch 267/800\n",
      "10/10 [==============================] - 0s 605us/step - loss: 0.0069 - accuracy: 0.1390  \n",
      "Epoch 268/800\n",
      "10/10 [==============================] - 0s 677us/step - loss: 0.0075 - accuracy: 0.0860\n",
      "Epoch 269/800\n",
      "10/10 [==============================] - 0s 659us/step - loss: 0.0043 - accuracy: 0.0860  \n",
      "Epoch 270/800\n",
      "10/10 [==============================] - 0s 666us/step - loss: 0.0061 - accuracy: 0.0396\n",
      "Epoch 271/800\n",
      "10/10 [==============================] - 0s 598us/step - loss: 0.0070 - accuracy: 0.0678\n",
      "Epoch 272/800\n",
      "10/10 [==============================] - 0s 603us/step - loss: 0.0057 - accuracy: 0.0396\n",
      "Epoch 273/800\n",
      "10/10 [==============================] - 0s 644us/step - loss: 0.0065 - accuracy: 0.0526\n",
      "Epoch 274/800\n",
      "10/10 [==============================] - 0s 612us/step - loss: 0.0106 - accuracy: 0.2754\n",
      "Epoch 275/800\n",
      "10/10 [==============================] - 0s 665us/step - loss: 0.0053 - accuracy: 0.0860  \n",
      "Epoch 276/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 0.0050 - accuracy: 0.0182\n",
      "Epoch 277/800\n",
      "10/10 [==============================] - 0s 622us/step - loss: 0.0053 - accuracy: 0.0678\n",
      "Epoch 278/800\n",
      "10/10 [==============================] - 0s 630us/step - loss: 0.0049 - accuracy: 0.0526\n",
      "Epoch 279/800\n",
      "10/10 [==============================] - 0s 614us/step - loss: 0.0065 - accuracy: 0.1087\n",
      "Epoch 280/800\n",
      "10/10 [==============================] - 0s 657us/step - loss: 0.0077 - accuracy: 0.1845\n",
      "Epoch 281/800\n",
      "10/10 [==============================] - 0s 585us/step - loss: 0.0032 - accuracy: 0.0283  \n",
      "Epoch 282/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 0.0056 - accuracy: 0.0396\n",
      "Epoch 283/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 0.0072 - accuracy: 0.1087\n",
      "Epoch 284/800\n",
      "10/10 [==============================] - 0s 625us/step - loss: 0.0062 - accuracy: 0.1087\n",
      "Epoch 285/800\n",
      "10/10 [==============================] - 0s 651us/step - loss: 0.0077 - accuracy: 0.1390\n",
      "Epoch 286/800\n",
      "10/10 [==============================] - 0s 604us/step - loss: 0.0085 - accuracy: 0.1845\n",
      "Epoch 287/800\n",
      "10/10 [==============================] - 0s 641us/step - loss: 0.0042 - accuracy: 0.0283  \n",
      "Epoch 288/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 0.0088 - accuracy: 0.2754\n",
      "Epoch 289/800\n",
      "10/10 [==============================] - 0s 668us/step - loss: 0.0045 - accuracy: 0.0860\n",
      "Epoch 290/800\n",
      "10/10 [==============================] - 0s 630us/step - loss: 0.0066 - accuracy: 0.1390\n",
      "Epoch 291/800\n",
      "10/10 [==============================] - 0s 607us/step - loss: 0.0048 - accuracy: 0.0526  \n",
      "Epoch 292/800\n",
      "10/10 [==============================] - 0s 612us/step - loss: 0.0024 - accuracy: 0.0283  \n",
      "Epoch 293/800\n",
      "10/10 [==============================] - 0s 665us/step - loss: 0.0040 - accuracy: 0.0860  \n",
      "Epoch 294/800\n",
      "10/10 [==============================] - 0s 616us/step - loss: 0.0071 - accuracy: 0.2754\n",
      "Epoch 295/800\n",
      "10/10 [==============================] - 0s 708us/step - loss: 0.0048 - accuracy: 0.0526\n",
      "Epoch 296/800\n",
      "10/10 [==============================] - 0s 666us/step - loss: 0.0056 - accuracy: 0.0396\n",
      "Epoch 297/800\n",
      "10/10 [==============================] - 0s 626us/step - loss: 0.0047 - accuracy: 0.0860\n",
      "Epoch 298/800\n",
      "10/10 [==============================] - 0s 640us/step - loss: 0.0033 - accuracy: 0.0396  \n",
      "Epoch 299/800\n",
      "10/10 [==============================] - 0s 621us/step - loss: 0.0045 - accuracy: 0.0182\n",
      "Epoch 300/800\n",
      "10/10 [==============================] - 0s 633us/step - loss: 0.0057 - accuracy: 0.0396\n",
      "Epoch 301/800\n",
      "10/10 [==============================] - 0s 611us/step - loss: 0.0035 - accuracy: 0.0860  \n",
      "Epoch 302/800\n",
      "10/10 [==============================] - 0s 627us/step - loss: 0.0031 - accuracy: 0.0860  \n",
      "Epoch 303/800\n",
      "10/10 [==============================] - 0s 667us/step - loss: 0.0029 - accuracy: 0.0182\n",
      "Epoch 304/800\n",
      "10/10 [==============================] - 0s 626us/step - loss: 0.0038 - accuracy: 0.0182\n",
      "Epoch 305/800\n",
      "10/10 [==============================] - 0s 615us/step - loss: 0.0037 - accuracy: 0.0526\n",
      "Epoch 306/800\n",
      "10/10 [==============================] - 0s 650us/step - loss: 0.0030 - accuracy: 0.0283\n",
      "Epoch 307/800\n",
      "10/10 [==============================] - 0s 607us/step - loss: 0.0046 - accuracy: 0.0283\n",
      "Epoch 308/800\n",
      "10/10 [==============================] - 0s 657us/step - loss: 0.0046 - accuracy: 0.0396\n",
      "Epoch 309/800\n",
      "10/10 [==============================] - 0s 616us/step - loss: 0.0039 - accuracy: 0.1845  \n",
      "Epoch 310/800\n",
      "10/10 [==============================] - 0s 608us/step - loss: 0.0037 - accuracy: 0.1390  \n",
      "Epoch 311/800\n",
      "10/10 [==============================] - 0s 636us/step - loss: 0.0033 - accuracy: 0.0678\n",
      "Epoch 312/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 0.0029 - accuracy: 0.0860  \n",
      "Epoch 313/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 658us/step - loss: 0.0040 - accuracy: 0.1845  \n",
      "Epoch 314/800\n",
      "10/10 [==============================] - 0s 624us/step - loss: 0.0047 - accuracy: 0.1845\n",
      "Epoch 315/800\n",
      "10/10 [==============================] - 0s 605us/step - loss: 0.0035 - accuracy: 0.0678  \n",
      "Epoch 316/800\n",
      "10/10 [==============================] - 0s 644us/step - loss: 0.0037 - accuracy: 0.1845\n",
      "Epoch 317/800\n",
      "10/10 [==============================] - 0s 614us/step - loss: 0.0020 - accuracy: 0.0283  \n",
      "Epoch 318/800\n",
      "10/10 [==============================] - 0s 651us/step - loss: 0.0050 - accuracy: 0.2754\n",
      "Epoch 319/800\n",
      "10/10 [==============================] - 0s 617us/step - loss: 0.0028 - accuracy: 0.0283\n",
      "Epoch 320/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 0.0048 - accuracy: 0.1390\n",
      "Epoch 321/800\n",
      "10/10 [==============================] - 0s 634us/step - loss: 0.0030 - accuracy: 0.0396\n",
      "Epoch 322/800\n",
      "10/10 [==============================] - 0s 623us/step - loss: 0.0023 - accuracy: 0.0182\n",
      "Epoch 323/800\n",
      "10/10 [==============================] - 0s 659us/step - loss: 0.0032 - accuracy: 0.0860\n",
      "Epoch 324/800\n",
      "10/10 [==============================] - 0s 604us/step - loss: 0.0029 - accuracy: 0.0283\n",
      "Epoch 325/800\n",
      "10/10 [==============================] - 0s 656us/step - loss: 0.0029 - accuracy: 0.0283\n",
      "Epoch 326/800\n",
      "10/10 [==============================] - 0s 644us/step - loss: 0.0028 - accuracy: 0.0526\n",
      "Epoch 327/800\n",
      "10/10 [==============================] - 0s 609us/step - loss: 0.0036 - accuracy: 0.1845  \n",
      "Epoch 328/800\n",
      "10/10 [==============================] - 0s 646us/step - loss: 0.0026 - accuracy: 0.0526  \n",
      "Epoch 329/800\n",
      "10/10 [==============================] - 0s 594us/step - loss: 0.0032 - accuracy: 0.1087\n",
      "Epoch 330/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 0.0031 - accuracy: 0.0182\n",
      "Epoch 331/800\n",
      "10/10 [==============================] - 0s 660us/step - loss: 0.0037 - accuracy: 0.1087\n",
      "Epoch 332/800\n",
      "10/10 [==============================] - 0s 624us/step - loss: 0.0016 - accuracy: 0.0182\n",
      "Epoch 333/800\n",
      "10/10 [==============================] - 0s 712us/step - loss: 0.0020 - accuracy: 0.0678  \n",
      "Epoch 334/800\n",
      "10/10 [==============================] - 0s 586us/step - loss: 0.0020 - accuracy: 0.0396  \n",
      "Epoch 335/800\n",
      "10/10 [==============================] - 0s 619us/step - loss: 0.0030 - accuracy: 0.0283\n",
      "Epoch 336/800\n",
      "10/10 [==============================] - 0s 612us/step - loss: 0.0019 - accuracy: 0.0526  \n",
      "Epoch 337/800\n",
      "10/10 [==============================] - 0s 614us/step - loss: 0.0026 - accuracy: 0.1087  \n",
      "Epoch 338/800\n",
      "10/10 [==============================] - 0s 661us/step - loss: 0.0030 - accuracy: 0.0860\n",
      "Epoch 339/800\n",
      "10/10 [==============================] - 0s 610us/step - loss: 0.0024 - accuracy: 0.0678  \n",
      "Epoch 340/800\n",
      "10/10 [==============================] - 0s 630us/step - loss: 0.0020 - accuracy: 0.0526  \n",
      "Epoch 341/800\n",
      "10/10 [==============================] - 0s 622us/step - loss: 0.0025 - accuracy: 0.1390  \n",
      "Epoch 342/800\n",
      "10/10 [==============================] - 0s 611us/step - loss: 0.0027 - accuracy: 0.0396\n",
      "Epoch 343/800\n",
      "10/10 [==============================] - 0s 652us/step - loss: 0.0022 - accuracy: 0.0678  \n",
      "Epoch 344/800\n",
      "10/10 [==============================] - 0s 643us/step - loss: 0.0021 - accuracy: 0.0283\n",
      "Epoch 345/800\n",
      "10/10 [==============================] - 0s 621us/step - loss: 0.0037 - accuracy: 0.2754\n",
      "Epoch 346/800\n",
      "10/10 [==============================] - 0s 611us/step - loss: 0.0027 - accuracy: 0.0396\n",
      "Epoch 347/800\n",
      "10/10 [==============================] - 0s 668us/step - loss: 0.0021 - accuracy: 0.0526\n",
      "Epoch 348/800\n",
      "10/10 [==============================] - 0s 645us/step - loss: 0.0028 - accuracy: 0.1845  \n",
      "Epoch 349/800\n",
      "10/10 [==============================] - 0s 607us/step - loss: 0.0021 - accuracy: 0.0860  \n",
      "Epoch 350/800\n",
      "10/10 [==============================] - 0s 596us/step - loss: 0.0027 - accuracy: 0.1845  \n",
      "Epoch 351/800\n",
      "10/10 [==============================] - 0s 665us/step - loss: 0.0014 - accuracy: 0.0283  \n",
      "Epoch 352/800\n",
      "10/10 [==============================] - 0s 610us/step - loss: 0.0015 - accuracy: 0.0526  \n",
      "Epoch 353/800\n",
      "10/10 [==============================] - 0s 664us/step - loss: 0.0019 - accuracy: 0.0182\n",
      "Epoch 354/800\n",
      "10/10 [==============================] - 0s 657us/step - loss: 0.0025 - accuracy: 0.1845  \n",
      "Epoch 355/800\n",
      "10/10 [==============================] - 0s 648us/step - loss: 0.0018 - accuracy: 0.0283\n",
      "Epoch 356/800\n",
      "10/10 [==============================] - 0s 636us/step - loss: 0.0015 - accuracy: 0.0182\n",
      "Epoch 357/800\n",
      "10/10 [==============================] - 0s 635us/step - loss: 0.0015 - accuracy: 0.0526  \n",
      "Epoch 358/800\n",
      "10/10 [==============================] - 0s 673us/step - loss: 0.0020 - accuracy: 0.0678\n",
      "Epoch 359/800\n",
      "10/10 [==============================] - 0s 643us/step - loss: 0.0018 - accuracy: 0.0860\n",
      "Epoch 360/800\n",
      "10/10 [==============================] - 0s 607us/step - loss: 0.0013 - accuracy: 0.0182\n",
      "Epoch 361/800\n",
      "10/10 [==============================] - 0s 655us/step - loss: 0.0015 - accuracy: 0.1087  \n",
      "Epoch 362/800\n",
      "10/10 [==============================] - 0s 614us/step - loss: 0.0012 - accuracy: 0.0678  \n",
      "Epoch 363/800\n",
      "10/10 [==============================] - 0s 649us/step - loss: 0.0017 - accuracy: 0.0283\n",
      "Epoch 364/800\n",
      "10/10 [==============================] - 0s 624us/step - loss: 0.0014 - accuracy: 0.0526  \n",
      "Epoch 365/800\n",
      "10/10 [==============================] - 0s 660us/step - loss: 0.0013 - accuracy: 0.0526  \n",
      "Epoch 366/800\n",
      "10/10 [==============================] - 0s 644us/step - loss: 0.0012 - accuracy: 0.0678  \n",
      "Epoch 367/800\n",
      "10/10 [==============================] - 0s 602us/step - loss: 0.0020 - accuracy: 0.2754\n",
      "Epoch 368/800\n",
      "10/10 [==============================] - 0s 623us/step - loss: 0.0011 - accuracy: 0.0182  \n",
      "Epoch 369/800\n",
      "10/10 [==============================] - 0s 652us/step - loss: 0.0019 - accuracy: 0.0860\n",
      "Epoch 370/800\n",
      "10/10 [==============================] - 0s 637us/step - loss: 8.8771e-04 - accuracy: 0.0182\n",
      "Epoch 371/800\n",
      "10/10 [==============================] - 0s 646us/step - loss: 0.0021 - accuracy: 0.2754\n",
      "Epoch 372/800\n",
      "10/10 [==============================] - 0s 635us/step - loss: 0.0012 - accuracy: 0.0860  \n",
      "Epoch 373/800\n",
      "10/10 [==============================] - 0s 651us/step - loss: 0.0020 - accuracy: 0.1845\n",
      "Epoch 374/800\n",
      "10/10 [==============================] - 0s 670us/step - loss: 0.0019 - accuracy: 0.2754\n",
      "Epoch 375/800\n",
      "10/10 [==============================] - 0s 603us/step - loss: 0.0011 - accuracy: 0.0396\n",
      "Epoch 376/800\n",
      "10/10 [==============================] - 0s 662us/step - loss: 0.0022 - accuracy: 0.2754\n",
      "Epoch 377/800\n",
      "10/10 [==============================] - 0s 634us/step - loss: 8.7081e-04 - accuracy: 0.0182\n",
      "Epoch 378/800\n",
      "10/10 [==============================] - 0s 632us/step - loss: 8.9101e-04 - accuracy: 0.0283\n",
      "Epoch 379/800\n",
      "10/10 [==============================] - 0s 646us/step - loss: 0.0014 - accuracy: 0.0182\n",
      "Epoch 380/800\n",
      "10/10 [==============================] - 0s 639us/step - loss: 0.0013 - accuracy: 0.0678  \n",
      "Epoch 381/800\n",
      "10/10 [==============================] - 0s 653us/step - loss: 0.0013 - accuracy: 0.1845  \n",
      "Epoch 382/800\n",
      "10/10 [==============================] - 0s 610us/step - loss: 0.0014 - accuracy: 0.0396\n",
      "Epoch 383/800\n",
      "10/10 [==============================] - 0s 600us/step - loss: 0.0018 - accuracy: 0.1845\n",
      "Epoch 384/800\n",
      "10/10 [==============================] - 0s 667us/step - loss: 0.0017 - accuracy: 0.2754\n",
      "Epoch 385/800\n",
      "10/10 [==============================] - 0s 639us/step - loss: 0.0011 - accuracy: 0.0678\n",
      "Epoch 386/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 0.0013 - accuracy: 0.0526\n",
      "Epoch 387/800\n",
      "10/10 [==============================] - 0s 673us/step - loss: 9.4263e-04 - accuracy: 0.0860\n",
      "Epoch 388/800\n",
      "10/10 [==============================] - 0s 664us/step - loss: 8.1954e-04 - accuracy: 0.0678\n",
      "Epoch 389/800\n",
      "10/10 [==============================] - 0s 649us/step - loss: 9.6017e-04 - accuracy: 0.0860\n",
      "Epoch 390/800\n",
      "10/10 [==============================] - 0s 620us/step - loss: 5.6585e-04 - accuracy: 0.0283\n",
      "Epoch 391/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 632us/step - loss: 8.3500e-04 - accuracy: 0.1087\n",
      "Epoch 392/800\n",
      "10/10 [==============================] - 0s 667us/step - loss: 0.0011 - accuracy: 0.0678\n",
      "Epoch 393/800\n",
      "10/10 [==============================] - 0s 612us/step - loss: 5.9753e-04 - accuracy: 0.0526\n",
      "Epoch 394/800\n",
      "10/10 [==============================] - 0s 661us/step - loss: 7.6603e-04 - accuracy: 0.0678\n",
      "Epoch 395/800\n",
      "10/10 [==============================] - 0s 599us/step - loss: 6.1913e-04 - accuracy: 0.0526\n",
      "Epoch 396/800\n",
      "10/10 [==============================] - 0s 654us/step - loss: 5.3690e-04 - accuracy: 0.0526\n",
      "Epoch 397/800\n",
      "10/10 [==============================] - 0s 634us/step - loss: 8.0986e-04 - accuracy: 0.1390\n",
      "Epoch 398/800\n",
      "10/10 [==============================] - 0s 645us/step - loss: 7.1237e-04 - accuracy: 0.0182\n",
      "Epoch 399/800\n",
      "10/10 [==============================] - 0s 656us/step - loss: 7.5849e-04 - accuracy: 0.0526\n",
      "Epoch 400/800\n",
      "10/10 [==============================] - 0s 595us/step - loss: 6.9057e-04 - accuracy: 0.1087\n",
      "Epoch 401/800\n",
      "10/10 [==============================] - 0s 637us/step - loss: 0.0012 - accuracy: 0.2754\n",
      "Epoch 402/800\n",
      "10/10 [==============================] - 0s 615us/step - loss: 6.6613e-04 - accuracy: 0.0678\n",
      "Epoch 403/800\n",
      "10/10 [==============================] - 0s 624us/step - loss: 9.7657e-04 - accuracy: 0.2754\n",
      "Epoch 404/800\n",
      "10/10 [==============================] - 0s 664us/step - loss: 6.7014e-04 - accuracy: 0.0860\n",
      "Epoch 405/800\n",
      "10/10 [==============================] - 0s 609us/step - loss: 8.0416e-04 - accuracy: 0.0396\n",
      "Epoch 406/800\n",
      "10/10 [==============================] - 0s 667us/step - loss: 3.8446e-04 - accuracy: 0.0396\n",
      "Epoch 407/800\n",
      "10/10 [==============================] - 0s 615us/step - loss: 4.9236e-04 - accuracy: 0.0860\n",
      "Epoch 408/800\n",
      "10/10 [==============================] - 0s 658us/step - loss: 3.5672e-04 - accuracy: 0.0182\n",
      "Epoch 409/800\n",
      "10/10 [==============================] - 0s 665us/step - loss: 8.1153e-04 - accuracy: 0.1390\n",
      "Epoch 410/800\n",
      "10/10 [==============================] - 0s 605us/step - loss: 5.5377e-04 - accuracy: 0.0526\n",
      "Epoch 411/800\n",
      "10/10 [==============================] - 0s 628us/step - loss: 6.0069e-04 - accuracy: 0.0396\n",
      "Epoch 412/800\n",
      "10/10 [==============================] - 0s 670us/step - loss: 6.0354e-04 - accuracy: 0.1390\n",
      "Epoch 413/800\n",
      "10/10 [==============================] - 0s 599us/step - loss: 5.6188e-04 - accuracy: 0.0396\n",
      "Epoch 414/800\n",
      "10/10 [==============================] - 0s 664us/step - loss: 5.7276e-04 - accuracy: 0.1087\n",
      "Epoch 415/800\n",
      "10/10 [==============================] - 0s 599us/step - loss: 4.1890e-04 - accuracy: 0.0396\n",
      "Epoch 416/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 5.7733e-04 - accuracy: 0.0396\n",
      "Epoch 417/800\n",
      "10/10 [==============================] - 0s 634us/step - loss: 4.5891e-04 - accuracy: 0.0678\n",
      "Epoch 418/800\n",
      "10/10 [==============================] - 0s 615us/step - loss: 5.2324e-04 - accuracy: 0.0860\n",
      "Epoch 419/800\n",
      "10/10 [==============================] - 0s 645us/step - loss: 6.6389e-04 - accuracy: 0.2754\n",
      "Epoch 420/800\n",
      "10/10 [==============================] - 0s 621us/step - loss: 6.2089e-04 - accuracy: 0.1087\n",
      "Epoch 421/800\n",
      "10/10 [==============================] - 0s 630us/step - loss: 4.0300e-04 - accuracy: 0.1390\n",
      "Epoch 422/800\n",
      "10/10 [==============================] - 0s 657us/step - loss: 4.7833e-04 - accuracy: 0.0283\n",
      "Epoch 423/800\n",
      "10/10 [==============================] - 0s 634us/step - loss: 2.8368e-04 - accuracy: 0.0283\n",
      "Epoch 424/800\n",
      "10/10 [==============================] - 0s 659us/step - loss: 4.1044e-04 - accuracy: 0.0283\n",
      "Epoch 425/800\n",
      "10/10 [==============================] - 0s 616us/step - loss: 4.0165e-04 - accuracy: 0.0678\n",
      "Epoch 426/800\n",
      "10/10 [==============================] - 0s 611us/step - loss: 4.3193e-04 - accuracy: 0.0182\n",
      "Epoch 427/800\n",
      "10/10 [==============================] - 0s 641us/step - loss: 4.3787e-04 - accuracy: 0.1845\n",
      "Epoch 428/800\n",
      "10/10 [==============================] - 0s 612us/step - loss: 3.3104e-04 - accuracy: 0.0526\n",
      "Epoch 429/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 3.6396e-04 - accuracy: 0.1087\n",
      "Epoch 430/800\n",
      "10/10 [==============================] - 0s 609us/step - loss: 3.2592e-04 - accuracy: 0.0860\n",
      "Epoch 431/800\n",
      "10/10 [==============================] - 0s 634us/step - loss: 3.6877e-04 - accuracy: 0.1845\n",
      "Epoch 432/800\n",
      "10/10 [==============================] - 0s 645us/step - loss: 5.4915e-04 - accuracy: 0.2754\n",
      "Epoch 433/800\n",
      "10/10 [==============================] - 0s 613us/step - loss: 3.6905e-04 - accuracy: 0.0396\n",
      "Epoch 434/800\n",
      "10/10 [==============================] - 0s 637us/step - loss: 4.9658e-04 - accuracy: 0.2754\n",
      "Epoch 435/800\n",
      "10/10 [==============================] - 0s 625us/step - loss: 3.9278e-04 - accuracy: 0.1390\n",
      "Epoch 436/800\n",
      "10/10 [==============================] - 0s 627us/step - loss: 3.9576e-04 - accuracy: 0.0526\n",
      "Epoch 437/800\n",
      "10/10 [==============================] - 0s 670us/step - loss: 2.1883e-04 - accuracy: 0.0182\n",
      "Epoch 438/800\n",
      "10/10 [==============================] - 0s 611us/step - loss: 4.1085e-04 - accuracy: 0.2754\n",
      "Epoch 439/800\n",
      "10/10 [==============================] - 0s 653us/step - loss: 2.4450e-04 - accuracy: 0.1390\n",
      "Epoch 440/800\n",
      "10/10 [==============================] - 0s 646us/step - loss: 4.9321e-04 - accuracy: 0.2754\n",
      "Epoch 441/800\n",
      "10/10 [==============================] - 0s 616us/step - loss: 3.1376e-04 - accuracy: 0.1087\n",
      "Epoch 442/800\n",
      "10/10 [==============================] - 0s 680us/step - loss: 2.6213e-04 - accuracy: 0.1390\n",
      "Epoch 443/800\n",
      "10/10 [==============================] - 0s 616us/step - loss: 3.8897e-04 - accuracy: 0.1845\n",
      "Epoch 444/800\n",
      "10/10 [==============================] - 0s 629us/step - loss: 1.7661e-04 - accuracy: 0.0678\n",
      "Epoch 445/800\n",
      "10/10 [==============================] - 0s 646us/step - loss: 2.0708e-04 - accuracy: 0.0678\n",
      "Epoch 446/800\n",
      "10/10 [==============================] - 0s 610us/step - loss: 2.7717e-04 - accuracy: 0.1390\n",
      "Epoch 447/800\n",
      "10/10 [==============================] - 0s 655us/step - loss: 3.4500e-04 - accuracy: 0.1390\n",
      "Epoch 448/800\n",
      "10/10 [==============================] - 0s 625us/step - loss: 2.3622e-04 - accuracy: 0.1087\n",
      "Epoch 449/800\n",
      "10/10 [==============================] - 0s 674us/step - loss: 2.0657e-04 - accuracy: 0.0860\n",
      "Epoch 450/800\n",
      "10/10 [==============================] - 0s 645us/step - loss: 1.2745e-04 - accuracy: 0.0182\n",
      "Epoch 451/800\n",
      "10/10 [==============================] - 0s 609us/step - loss: 2.9522e-04 - accuracy: 0.1845\n",
      "Epoch 452/800\n",
      "10/10 [==============================] - 0s 635us/step - loss: 1.2663e-04 - accuracy: 0.0283\n",
      "Epoch 453/800\n",
      "10/10 [==============================] - 0s 637us/step - loss: 1.9520e-04 - accuracy: 0.1087\n",
      "Epoch 454/800\n",
      "10/10 [==============================] - 0s 613us/step - loss: 1.6844e-04 - accuracy: 0.0678\n",
      "Epoch 455/800\n",
      "10/10 [==============================] - 0s 636us/step - loss: 1.8263e-04 - accuracy: 0.1087\n",
      "Epoch 456/800\n",
      "10/10 [==============================] - 0s 619us/step - loss: 1.9063e-04 - accuracy: 0.0396\n",
      "Epoch 457/800\n",
      "10/10 [==============================] - 0s 639us/step - loss: 1.3043e-04 - accuracy: 0.0860\n",
      "Epoch 458/800\n",
      "10/10 [==============================] - 0s 604us/step - loss: 1.4361e-04 - accuracy: 0.0283\n",
      "Epoch 459/800\n",
      "10/10 [==============================] - 0s 647us/step - loss: 8.8491e-05 - accuracy: 0.0182\n",
      "Epoch 460/800\n",
      "10/10 [==============================] - 0s 620us/step - loss: 1.8663e-04 - accuracy: 0.0396\n",
      "Epoch 461/800\n",
      "10/10 [==============================] - 0s 622us/step - loss: 1.0286e-04 - accuracy: 0.0678\n",
      "Epoch 462/800\n",
      "10/10 [==============================] - 0s 663us/step - loss: 1.2717e-04 - accuracy: 0.1087\n",
      "Epoch 463/800\n",
      "10/10 [==============================] - 0s 629us/step - loss: 1.0632e-04 - accuracy: 0.0678\n",
      "Epoch 464/800\n",
      "10/10 [==============================] - 0s 667us/step - loss: 1.2416e-04 - accuracy: 0.0860\n",
      "Epoch 465/800\n",
      "10/10 [==============================] - 0s 688us/step - loss: 9.6777e-05 - accuracy: 0.0526\n",
      "Epoch 466/800\n",
      "10/10 [==============================] - 0s 595us/step - loss: 1.3128e-04 - accuracy: 0.0283\n",
      "Epoch 467/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 618us/step - loss: 1.5119e-04 - accuracy: 0.0860\n",
      "Epoch 468/800\n",
      "10/10 [==============================] - 0s 620us/step - loss: 1.1429e-04 - accuracy: 0.0526\n",
      "Epoch 469/800\n",
      "10/10 [==============================] - 0s 646us/step - loss: 1.1646e-04 - accuracy: 0.0182\n",
      "Epoch 470/800\n",
      "10/10 [==============================] - 0s 679us/step - loss: 1.4661e-04 - accuracy: 0.0396\n",
      "Epoch 471/800\n",
      "10/10 [==============================] - 0s 592us/step - loss: 6.9538e-05 - accuracy: 0.0283\n",
      "Epoch 472/800\n",
      "10/10 [==============================] - 0s 650us/step - loss: 9.6164e-05 - accuracy: 0.0860\n",
      "Epoch 473/800\n",
      "10/10 [==============================] - 0s 598us/step - loss: 1.0011e-04 - accuracy: 0.0678\n",
      "Epoch 474/800\n",
      "10/10 [==============================] - 0s 668us/step - loss: 8.7308e-05 - accuracy: 0.0526\n",
      "Epoch 475/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 9.0251e-05 - accuracy: 0.1087\n",
      "Epoch 476/800\n",
      "10/10 [==============================] - 0s 611us/step - loss: 1.3250e-04 - accuracy: 0.1087\n",
      "Epoch 477/800\n",
      "10/10 [==============================] - 0s 640us/step - loss: 9.6007e-05 - accuracy: 0.1390\n",
      "Epoch 478/800\n",
      "10/10 [==============================] - 0s 595us/step - loss: 1.2269e-04 - accuracy: 0.2754\n",
      "Epoch 479/800\n",
      "10/10 [==============================] - 0s 650us/step - loss: 6.8980e-05 - accuracy: 0.0283\n",
      "Epoch 480/800\n",
      "10/10 [==============================] - 0s 619us/step - loss: 9.7895e-05 - accuracy: 0.1845\n",
      "Epoch 481/800\n",
      "10/10 [==============================] - 0s 621us/step - loss: 8.9458e-05 - accuracy: 0.1845\n",
      "Epoch 482/800\n",
      "10/10 [==============================] - 0s 623us/step - loss: 6.1375e-05 - accuracy: 0.0678\n",
      "Epoch 483/800\n",
      "10/10 [==============================] - 0s 597us/step - loss: 7.9597e-05 - accuracy: 0.0860\n",
      "Epoch 484/800\n",
      "10/10 [==============================] - 0s 626us/step - loss: 1.1538e-04 - accuracy: 0.1845\n",
      "Epoch 485/800\n",
      "10/10 [==============================] - 0s 658us/step - loss: 6.7071e-05 - accuracy: 0.1845\n",
      "Epoch 486/800\n",
      "10/10 [==============================] - 0s 626us/step - loss: 8.0960e-05 - accuracy: 0.0526\n",
      "Epoch 487/800\n",
      "10/10 [==============================] - 0s 642us/step - loss: 9.5437e-05 - accuracy: 0.1845\n",
      "Epoch 488/800\n",
      "10/10 [==============================] - 0s 604us/step - loss: 4.6583e-05 - accuracy: 0.0396\n",
      "Epoch 489/800\n",
      "10/10 [==============================] - 0s 668us/step - loss: 8.0666e-05 - accuracy: 0.2754\n",
      "Epoch 490/800\n",
      "10/10 [==============================] - 0s 597us/step - loss: 3.6138e-05 - accuracy: 0.0396\n",
      "Epoch 491/800\n",
      "10/10 [==============================] - 0s 610us/step - loss: 4.5432e-05 - accuracy: 0.0283\n",
      "Epoch 492/800\n",
      "10/10 [==============================] - 0s 618us/step - loss: 7.4884e-05 - accuracy: 0.2754\n",
      "Epoch 493/800\n",
      "10/10 [==============================] - 0s 615us/step - loss: 7.7727e-05 - accuracy: 0.2754\n",
      "Epoch 494/800\n",
      "10/10 [==============================] - 0s 652us/step - loss: 6.9095e-05 - accuracy: 0.1087\n",
      "Epoch 495/800\n",
      "10/10 [==============================] - 0s 617us/step - loss: 5.1711e-05 - accuracy: 0.1845\n",
      "Epoch 496/800\n",
      "10/10 [==============================] - 0s 649us/step - loss: 4.2510e-05 - accuracy: 0.0182\n",
      "Epoch 497/800\n",
      "10/10 [==============================] - 0s 646us/step - loss: 6.8102e-05 - accuracy: 0.2754\n",
      "Epoch 498/800\n",
      "10/10 [==============================] - 0s 611us/step - loss: 5.5715e-05 - accuracy: 0.0283\n",
      "Epoch 499/800\n",
      "10/10 [==============================] - 0s 633us/step - loss: 5.4754e-05 - accuracy: 0.0860\n",
      "Epoch 500/800\n",
      "10/10 [==============================] - 0s 599us/step - loss: 2.5645e-05 - accuracy: 0.0678\n",
      "Epoch 501/800\n",
      "10/10 [==============================] - 0s 619us/step - loss: 3.0031e-05 - accuracy: 0.0678\n",
      "Epoch 502/800\n",
      "10/10 [==============================] - 0s 659us/step - loss: 5.8276e-05 - accuracy: 0.2754\n",
      "Epoch 503/800\n",
      "10/10 [==============================] - 0s 632us/step - loss: 2.5721e-05 - accuracy: 0.0526\n",
      "Epoch 504/800\n",
      "10/10 [==============================] - 0s 651us/step - loss: 2.5222e-05 - accuracy: 0.0678\n",
      "Epoch 505/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 3.3070e-05 - accuracy: 0.0182\n",
      "Epoch 506/800\n",
      "10/10 [==============================] - 0s 648us/step - loss: 2.8988e-05 - accuracy: 0.0526\n",
      "Epoch 507/800\n",
      "10/10 [==============================] - 0s 627us/step - loss: 2.7856e-05 - accuracy: 0.1390\n",
      "Epoch 508/800\n",
      "10/10 [==============================] - 0s 617us/step - loss: 3.8948e-05 - accuracy: 0.0860\n",
      "Epoch 509/800\n",
      "10/10 [==============================] - 0s 626us/step - loss: 3.0614e-05 - accuracy: 0.0678\n",
      "Epoch 510/800\n",
      "10/10 [==============================] - 0s 602us/step - loss: 2.2072e-05 - accuracy: 0.0526\n",
      "Epoch 511/800\n",
      "10/10 [==============================] - 0s 635us/step - loss: 2.2109e-05 - accuracy: 0.0396\n",
      "Epoch 512/800\n",
      "10/10 [==============================] - 0s 650us/step - loss: 3.8742e-05 - accuracy: 0.1390\n",
      "Epoch 513/800\n",
      "10/10 [==============================] - 0s 625us/step - loss: 1.8201e-05 - accuracy: 0.0526\n",
      "Epoch 514/800\n",
      "10/10 [==============================] - 0s 677us/step - loss: 1.6710e-05 - accuracy: 0.0678\n",
      "Epoch 515/800\n",
      "10/10 [==============================] - 0s 681us/step - loss: 1.5566e-05 - accuracy: 0.0182\n",
      "Epoch 516/800\n",
      "10/10 [==============================] - 0s 635us/step - loss: 3.6155e-05 - accuracy: 0.2754\n",
      "Epoch 517/800\n",
      "10/10 [==============================] - 0s 673us/step - loss: 1.9385e-05 - accuracy: 0.0283\n",
      "Epoch 518/800\n",
      "10/10 [==============================] - 0s 629us/step - loss: 1.9800e-05 - accuracy: 0.0678\n",
      "Epoch 519/800\n",
      "10/10 [==============================] - 0s 612us/step - loss: 1.0948e-05 - accuracy: 0.0396\n",
      "Epoch 520/800\n",
      "10/10 [==============================] - 0s 633us/step - loss: 2.3082e-05 - accuracy: 0.1087\n",
      "Epoch 521/800\n",
      "10/10 [==============================] - 0s 630us/step - loss: 2.0798e-05 - accuracy: 0.0860\n",
      "Epoch 522/800\n",
      "10/10 [==============================] - 0s 689us/step - loss: 2.3720e-05 - accuracy: 0.2754\n",
      "Epoch 523/800\n",
      "10/10 [==============================] - 0s 627us/step - loss: 1.6170e-05 - accuracy: 0.1390\n",
      "Epoch 524/800\n",
      "10/10 [==============================] - 0s 621us/step - loss: 2.0314e-05 - accuracy: 0.2754\n",
      "Epoch 525/800\n",
      "10/10 [==============================] - 0s 658us/step - loss: 1.4326e-05 - accuracy: 0.1845\n",
      "Epoch 526/800\n",
      "10/10 [==============================] - 0s 627us/step - loss: 2.3452e-05 - accuracy: 0.2754\n",
      "Epoch 527/800\n",
      "10/10 [==============================] - 0s 623us/step - loss: 9.3668e-06 - accuracy: 0.0678\n",
      "Epoch 528/800\n",
      "10/10 [==============================] - 0s 611us/step - loss: 1.5051e-05 - accuracy: 0.1390\n",
      "Epoch 529/800\n",
      "10/10 [==============================] - 0s 617us/step - loss: 1.3891e-05 - accuracy: 0.0678\n",
      "Epoch 530/800\n",
      "10/10 [==============================] - 0s 671us/step - loss: 1.1131e-05 - accuracy: 0.0526\n",
      "Epoch 531/800\n",
      "10/10 [==============================] - 0s 612us/step - loss: 1.0231e-05 - accuracy: 0.0678\n",
      "Epoch 532/800\n",
      "10/10 [==============================] - 0s 635us/step - loss: 8.5531e-06 - accuracy: 0.0283\n",
      "Epoch 533/800\n",
      "10/10 [==============================] - 0s 611us/step - loss: 1.1494e-05 - accuracy: 0.1845\n",
      "Epoch 534/800\n",
      "10/10 [==============================] - 0s 628us/step - loss: 9.9945e-06 - accuracy: 0.0860\n",
      "Epoch 535/800\n",
      "10/10 [==============================] - 0s 648us/step - loss: 1.3159e-05 - accuracy: 0.2754\n",
      "Epoch 536/800\n",
      "10/10 [==============================] - 0s 602us/step - loss: 9.8410e-06 - accuracy: 0.0860\n",
      "Epoch 537/800\n",
      "10/10 [==============================] - 0s 651us/step - loss: 1.4334e-05 - accuracy: 0.2754\n",
      "Epoch 538/800\n",
      "10/10 [==============================] - 0s 628us/step - loss: 1.1605e-05 - accuracy: 0.2754\n",
      "Epoch 539/800\n",
      "10/10 [==============================] - 0s 634us/step - loss: 5.5851e-06 - accuracy: 0.0526\n",
      "Epoch 540/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 5.0943e-06 - accuracy: 0.0396\n",
      "Epoch 541/800\n",
      "10/10 [==============================] - 0s 644us/step - loss: 7.0861e-06 - accuracy: 0.0526\n",
      "Epoch 542/800\n",
      "10/10 [==============================] - 0s 686us/step - loss: 6.1187e-06 - accuracy: 0.0182\n",
      "Epoch 543/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 647us/step - loss: 6.0701e-06 - accuracy: 0.0860\n",
      "Epoch 544/800\n",
      "10/10 [==============================] - 0s 640us/step - loss: 9.1380e-06 - accuracy: 0.2754\n",
      "Epoch 545/800\n",
      "10/10 [==============================] - 0s 646us/step - loss: 4.6722e-06 - accuracy: 0.0283\n",
      "Epoch 546/800\n",
      "10/10 [==============================] - 0s 617us/step - loss: 3.7008e-06 - accuracy: 0.0396\n",
      "Epoch 547/800\n",
      "10/10 [==============================] - 0s 697us/step - loss: 6.1633e-06 - accuracy: 0.1845\n",
      "Epoch 548/800\n",
      "10/10 [==============================] - 0s 608us/step - loss: 3.7250e-06 - accuracy: 0.0283\n",
      "Epoch 549/800\n",
      "10/10 [==============================] - 0s 662us/step - loss: 3.5271e-06 - accuracy: 0.0526\n",
      "Epoch 550/800\n",
      "10/10 [==============================] - 0s 636us/step - loss: 6.4666e-06 - accuracy: 0.2754\n",
      "Epoch 551/800\n",
      "10/10 [==============================] - 0s 621us/step - loss: 2.5983e-06 - accuracy: 0.0396\n",
      "Epoch 552/800\n",
      "10/10 [==============================] - 0s 668us/step - loss: 5.0329e-06 - accuracy: 0.0678\n",
      "Epoch 553/800\n",
      "10/10 [==============================] - 0s 592us/step - loss: 4.8199e-06 - accuracy: 0.0396\n",
      "Epoch 554/800\n",
      "10/10 [==============================] - 0s 648us/step - loss: 2.5592e-06 - accuracy: 0.0678\n",
      "Epoch 555/800\n",
      "10/10 [==============================] - 0s 645us/step - loss: 5.5038e-06 - accuracy: 0.2754\n",
      "Epoch 556/800\n",
      "10/10 [==============================] - 0s 627us/step - loss: 2.9510e-06 - accuracy: 0.0526\n",
      "Epoch 557/800\n",
      "10/10 [==============================] - 0s 681us/step - loss: 3.7188e-06 - accuracy: 0.0396\n",
      "Epoch 558/800\n",
      "10/10 [==============================] - 0s 595us/step - loss: 3.3309e-06 - accuracy: 0.0678\n",
      "Epoch 559/800\n",
      "10/10 [==============================] - 0s 610us/step - loss: 1.9240e-06 - accuracy: 0.0526\n",
      "Epoch 560/800\n",
      "10/10 [==============================] - 0s 625us/step - loss: 2.5213e-06 - accuracy: 0.1087\n",
      "Epoch 561/800\n",
      "10/10 [==============================] - 0s 597us/step - loss: 2.8359e-06 - accuracy: 0.0283\n",
      "Epoch 562/800\n",
      "10/10 [==============================] - 0s 639us/step - loss: 2.0257e-06 - accuracy: 0.1087\n",
      "Epoch 563/800\n",
      "10/10 [==============================] - 0s 581us/step - loss: 2.2487e-06 - accuracy: 0.0526\n",
      "Epoch 564/800\n",
      "10/10 [==============================] - 0s 692us/step - loss: 2.9499e-06 - accuracy: 0.1845\n",
      "Epoch 565/800\n",
      "10/10 [==============================] - 0s 625us/step - loss: 1.9489e-06 - accuracy: 0.1087\n",
      "Epoch 566/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 2.2558e-06 - accuracy: 0.0860\n",
      "Epoch 567/800\n",
      "10/10 [==============================] - 0s 713us/step - loss: 2.8536e-06 - accuracy: 0.1845\n",
      "Epoch 568/800\n",
      "10/10 [==============================] - 0s 606us/step - loss: 1.8204e-06 - accuracy: 0.0526\n",
      "Epoch 569/800\n",
      "10/10 [==============================] - 0s 623us/step - loss: 3.0934e-06 - accuracy: 0.1845\n",
      "Epoch 570/800\n",
      "10/10 [==============================] - 0s 691us/step - loss: 2.2030e-06 - accuracy: 0.0678\n",
      "Epoch 571/800\n",
      "10/10 [==============================] - 0s 621us/step - loss: 2.5332e-06 - accuracy: 0.2754\n",
      "Epoch 572/800\n",
      "10/10 [==============================] - 0s 630us/step - loss: 1.0580e-06 - accuracy: 0.0396\n",
      "Epoch 573/800\n",
      "10/10 [==============================] - 0s 605us/step - loss: 1.0946e-06 - accuracy: 0.0396\n",
      "Epoch 574/800\n",
      "10/10 [==============================] - 0s 624us/step - loss: 1.8117e-06 - accuracy: 0.1845\n",
      "Epoch 575/800\n",
      "10/10 [==============================] - 0s 612us/step - loss: 1.1565e-06 - accuracy: 0.0860\n",
      "Epoch 576/800\n",
      "10/10 [==============================] - 0s 603us/step - loss: 8.7918e-07 - accuracy: 0.0678\n",
      "Epoch 577/800\n",
      "10/10 [==============================] - 0s 687us/step - loss: 1.0751e-06 - accuracy: 0.0396\n",
      "Epoch 578/800\n",
      "10/10 [==============================] - 0s 601us/step - loss: 1.2026e-06 - accuracy: 0.0526\n",
      "Epoch 579/800\n",
      "10/10 [==============================] - 0s 636us/step - loss: 1.1975e-06 - accuracy: 0.1087\n",
      "Epoch 580/800\n",
      "10/10 [==============================] - 0s 614us/step - loss: 1.0174e-06 - accuracy: 0.1845\n",
      "Epoch 581/800\n",
      "10/10 [==============================] - 0s 619us/step - loss: 4.4724e-07 - accuracy: 0.0396\n",
      "Epoch 582/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 6.8460e-07 - accuracy: 0.1087\n",
      "Epoch 583/800\n",
      "10/10 [==============================] - 0s 583us/step - loss: 5.5486e-07 - accuracy: 0.0678\n",
      "Epoch 584/800\n",
      "10/10 [==============================] - 0s 652us/step - loss: 7.1863e-07 - accuracy: 0.0283\n",
      "Epoch 585/800\n",
      "10/10 [==============================] - 0s 604us/step - loss: 6.7996e-07 - accuracy: 0.0182\n",
      "Epoch 586/800\n",
      "10/10 [==============================] - 0s 635us/step - loss: 8.4837e-07 - accuracy: 0.1845\n",
      "Epoch 587/800\n",
      "10/10 [==============================] - 0s 643us/step - loss: 8.2357e-07 - accuracy: 0.0860\n",
      "Epoch 588/800\n",
      "10/10 [==============================] - 0s 604us/step - loss: 7.8807e-07 - accuracy: 0.0526\n",
      "Epoch 589/800\n",
      "10/10 [==============================] - 0s 630us/step - loss: 3.8360e-07 - accuracy: 0.0182\n",
      "Epoch 590/800\n",
      "10/10 [==============================] - 0s 632us/step - loss: 7.0628e-07 - accuracy: 0.0526\n",
      "Epoch 591/800\n",
      "10/10 [==============================] - 0s 632us/step - loss: 2.8959e-07 - accuracy: 0.0396\n",
      "Epoch 592/800\n",
      "10/10 [==============================] - 0s 618us/step - loss: 3.5950e-07 - accuracy: 0.0396\n",
      "Epoch 593/800\n",
      "10/10 [==============================] - 0s 611us/step - loss: 3.6328e-07 - accuracy: 0.0526\n",
      "Epoch 594/800\n",
      "10/10 [==============================] - 0s 619us/step - loss: 3.4852e-07 - accuracy: 0.0526\n",
      "Epoch 595/800\n",
      "10/10 [==============================] - 0s 627us/step - loss: 4.0789e-07 - accuracy: 0.0182\n",
      "Epoch 596/800\n",
      "10/10 [==============================] - 0s 612us/step - loss: 3.8005e-07 - accuracy: 0.0860\n",
      "Epoch 597/800\n",
      "10/10 [==============================] - 0s 647us/step - loss: 4.6696e-07 - accuracy: 0.2754\n",
      "Epoch 598/800\n",
      "10/10 [==============================] - 0s 621us/step - loss: 3.0179e-07 - accuracy: 0.0396\n",
      "Epoch 599/800\n",
      "10/10 [==============================] - 0s 623us/step - loss: 2.6686e-07 - accuracy: 0.1087\n",
      "Epoch 600/800\n",
      "10/10 [==============================] - 0s 606us/step - loss: 2.0626e-07 - accuracy: 0.0678\n",
      "Epoch 601/800\n",
      "10/10 [==============================] - 0s 586us/step - loss: 3.1674e-07 - accuracy: 0.0678\n",
      "Epoch 602/800\n",
      "10/10 [==============================] - 0s 627us/step - loss: 4.1821e-07 - accuracy: 0.2754\n",
      "Epoch 603/800\n",
      "10/10 [==============================] - 0s 592us/step - loss: 2.3342e-07 - accuracy: 0.0526\n",
      "Epoch 604/800\n",
      "10/10 [==============================] - 0s 624us/step - loss: 1.4874e-07 - accuracy: 0.0182\n",
      "Epoch 605/800\n",
      "10/10 [==============================] - 0s 595us/step - loss: 2.2578e-07 - accuracy: 0.1087\n",
      "Epoch 606/800\n",
      "10/10 [==============================] - 0s 613us/step - loss: 1.2711e-07 - accuracy: 0.0396\n",
      "Epoch 607/800\n",
      "10/10 [==============================] - 0s 635us/step - loss: 1.7923e-07 - accuracy: 0.0283\n",
      "Epoch 608/800\n",
      "10/10 [==============================] - 0s 604us/step - loss: 1.4327e-07 - accuracy: 0.1087\n",
      "Epoch 609/800\n",
      "10/10 [==============================] - 0s 639us/step - loss: 1.2542e-07 - accuracy: 0.0182\n",
      "Epoch 610/800\n",
      "10/10 [==============================] - 0s 623us/step - loss: 1.5814e-07 - accuracy: 0.0283\n",
      "Epoch 611/800\n",
      "10/10 [==============================] - 0s 634us/step - loss: 1.5989e-07 - accuracy: 0.0396\n",
      "Epoch 612/800\n",
      "10/10 [==============================] - 0s 606us/step - loss: 1.2306e-07 - accuracy: 0.0396\n",
      "Epoch 613/800\n",
      "10/10 [==============================] - 0s 596us/step - loss: 8.8233e-08 - accuracy: 0.0396\n",
      "Epoch 614/800\n",
      "10/10 [==============================] - 0s 630us/step - loss: 1.5889e-07 - accuracy: 0.1390\n",
      "Epoch 615/800\n",
      "10/10 [==============================] - 0s 601us/step - loss: 1.2707e-07 - accuracy: 0.1845\n",
      "Epoch 616/800\n",
      "10/10 [==============================] - 0s 653us/step - loss: 1.3287e-07 - accuracy: 0.0860\n",
      "Epoch 617/800\n",
      "10/10 [==============================] - 0s 627us/step - loss: 8.1828e-08 - accuracy: 0.0182\n",
      "Epoch 618/800\n",
      "10/10 [==============================] - 0s 592us/step - loss: 1.1068e-07 - accuracy: 0.1390\n",
      "Epoch 619/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 643us/step - loss: 6.1911e-08 - accuracy: 0.0526\n",
      "Epoch 620/800\n",
      "10/10 [==============================] - 0s 582us/step - loss: 8.0067e-08 - accuracy: 0.0860\n",
      "Epoch 621/800\n",
      "10/10 [==============================] - 0s 647us/step - loss: 7.8433e-08 - accuracy: 0.0860\n",
      "Epoch 622/800\n",
      "10/10 [==============================] - 0s 607us/step - loss: 7.4911e-08 - accuracy: 0.1845\n",
      "Epoch 623/800\n",
      "10/10 [==============================] - 0s 658us/step - loss: 6.6656e-08 - accuracy: 0.0678\n",
      "Epoch 624/800\n",
      "10/10 [==============================] - 0s 597us/step - loss: 8.2506e-08 - accuracy: 0.2754\n",
      "Epoch 625/800\n",
      "10/10 [==============================] - 0s 653us/step - loss: 6.4093e-08 - accuracy: 0.0860\n",
      "Epoch 626/800\n",
      "10/10 [==============================] - 0s 646us/step - loss: 6.3534e-08 - accuracy: 0.2754\n",
      "Epoch 627/800\n",
      "10/10 [==============================] - 0s 607us/step - loss: 3.9134e-08 - accuracy: 0.0678\n",
      "Epoch 628/800\n",
      "10/10 [==============================] - 0s 671us/step - loss: 6.0030e-08 - accuracy: 0.1087\n",
      "Epoch 629/800\n",
      "10/10 [==============================] - 0s 584us/step - loss: 5.2641e-08 - accuracy: 0.2754\n",
      "Epoch 630/800\n",
      "10/10 [==============================] - 0s 618us/step - loss: 3.5907e-08 - accuracy: 0.0860\n",
      "Epoch 631/800\n",
      "10/10 [==============================] - 0s 640us/step - loss: 3.2485e-08 - accuracy: 0.0860\n",
      "Epoch 632/800\n",
      "10/10 [==============================] - 0s 608us/step - loss: 3.2610e-08 - accuracy: 0.1087\n",
      "Epoch 633/800\n",
      "10/10 [==============================] - 0s 619us/step - loss: 3.4388e-08 - accuracy: 0.1390\n",
      "Epoch 634/800\n",
      "10/10 [==============================] - 0s 596us/step - loss: 2.0033e-08 - accuracy: 0.0526\n",
      "Epoch 635/800\n",
      "10/10 [==============================] - 0s 649us/step - loss: 2.0752e-08 - accuracy: 0.1087\n",
      "Epoch 636/800\n",
      "10/10 [==============================] - 0s 578us/step - loss: 2.5765e-08 - accuracy: 0.1390\n",
      "Epoch 637/800\n",
      "10/10 [==============================] - 0s 595us/step - loss: 2.9129e-08 - accuracy: 0.2754\n",
      "Epoch 638/800\n",
      "10/10 [==============================] - 0s 617us/step - loss: 1.7325e-08 - accuracy: 0.0283\n",
      "Epoch 639/800\n",
      "10/10 [==============================] - 0s 617us/step - loss: 2.4206e-08 - accuracy: 0.2754\n",
      "Epoch 640/800\n",
      "10/10 [==============================] - 0s 625us/step - loss: 1.8113e-08 - accuracy: 0.0678\n",
      "Epoch 641/800\n",
      "10/10 [==============================] - 0s 596us/step - loss: 1.8632e-08 - accuracy: 0.1390\n",
      "Epoch 642/800\n",
      "10/10 [==============================] - 0s 618us/step - loss: 8.2579e-09 - accuracy: 0.0396\n",
      "Epoch 643/800\n",
      "10/10 [==============================] - 0s 628us/step - loss: 1.9872e-08 - accuracy: 0.1845\n",
      "Epoch 644/800\n",
      "10/10 [==============================] - 0s 630us/step - loss: 1.1432e-08 - accuracy: 0.0182\n",
      "Epoch 645/800\n",
      "10/10 [==============================] - 0s 641us/step - loss: 9.7312e-09 - accuracy: 0.0182\n",
      "Epoch 646/800\n",
      "10/10 [==============================] - 0s 595us/step - loss: 7.6471e-09 - accuracy: 0.0526\n",
      "Epoch 647/800\n",
      "10/10 [==============================] - 0s 633us/step - loss: 9.3471e-09 - accuracy: 0.0182\n",
      "Epoch 648/800\n",
      "10/10 [==============================] - 0s 644us/step - loss: 5.6320e-09 - accuracy: 0.0182\n",
      "Epoch 649/800\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.3656e-09 - accuracy: 0.0182\n",
      "Epoch 650/800\n",
      "10/10 [==============================] - 0s 672us/step - loss: 9.0552e-09 - accuracy: 0.1845\n",
      "Epoch 651/800\n",
      "10/10 [==============================] - 0s 714us/step - loss: 8.1468e-09 - accuracy: 0.0860\n",
      "Epoch 652/800\n",
      "10/10 [==============================] - 0s 636us/step - loss: 7.1889e-09 - accuracy: 0.0678\n",
      "Epoch 653/800\n",
      "10/10 [==============================] - 0s 627us/step - loss: 5.2927e-09 - accuracy: 0.1390\n",
      "Epoch 654/800\n",
      "10/10 [==============================] - 0s 647us/step - loss: 7.4627e-09 - accuracy: 0.1390\n",
      "Epoch 655/800\n",
      "10/10 [==============================] - 0s 616us/step - loss: 3.1308e-09 - accuracy: 0.0182\n",
      "Epoch 656/800\n",
      "10/10 [==============================] - 0s 651us/step - loss: 5.6984e-09 - accuracy: 0.0283\n",
      "Epoch 657/800\n",
      "10/10 [==============================] - 0s 612us/step - loss: 3.7640e-09 - accuracy: 0.0182\n",
      "Epoch 658/800\n",
      "10/10 [==============================] - 0s 619us/step - loss: 3.2488e-09 - accuracy: 0.0396\n",
      "Epoch 659/800\n",
      "10/10 [==============================] - 0s 652us/step - loss: 2.8760e-09 - accuracy: 0.0182\n",
      "Epoch 660/800\n",
      "10/10 [==============================] - 0s 611us/step - loss: 2.7409e-09 - accuracy: 0.0182\n",
      "Epoch 661/800\n",
      "10/10 [==============================] - 0s 637us/step - loss: 2.6957e-09 - accuracy: 0.0182\n",
      "Epoch 662/800\n",
      "10/10 [==============================] - 0s 614us/step - loss: 2.6073e-09 - accuracy: 0.0678\n",
      "Epoch 663/800\n",
      "10/10 [==============================] - 0s 635us/step - loss: 2.2438e-09 - accuracy: 0.1087\n",
      "Epoch 664/800\n",
      "10/10 [==============================] - 0s 644us/step - loss: 1.6607e-09 - accuracy: 0.0678\n",
      "Epoch 665/800\n",
      "10/10 [==============================] - 0s 622us/step - loss: 2.0722e-09 - accuracy: 0.0526\n",
      "Epoch 666/800\n",
      "10/10 [==============================] - 0s 648us/step - loss: 1.9904e-09 - accuracy: 0.1845\n",
      "Epoch 667/800\n",
      "10/10 [==============================] - 0s 626us/step - loss: 1.4208e-09 - accuracy: 0.0283\n",
      "Epoch 668/800\n",
      "10/10 [==============================] - 0s 621us/step - loss: 1.3049e-09 - accuracy: 0.1087\n",
      "Epoch 669/800\n",
      "10/10 [==============================] - 0s 648us/step - loss: 1.8290e-09 - accuracy: 0.1390\n",
      "Epoch 670/800\n",
      "10/10 [==============================] - 0s 637us/step - loss: 1.3601e-09 - accuracy: 0.0396\n",
      "Epoch 671/800\n",
      "10/10 [==============================] - 0s 649us/step - loss: 8.5929e-10 - accuracy: 0.0182\n",
      "Epoch 672/800\n",
      "10/10 [==============================] - 0s 628us/step - loss: 1.5170e-09 - accuracy: 0.1845\n",
      "Epoch 673/800\n",
      "10/10 [==============================] - 0s 606us/step - loss: 8.5561e-10 - accuracy: 0.0283\n",
      "Epoch 674/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 8.9601e-10 - accuracy: 0.0396\n",
      "Epoch 675/800\n",
      "10/10 [==============================] - 0s 630us/step - loss: 1.1506e-09 - accuracy: 0.1087\n",
      "Epoch 676/800\n",
      "10/10 [==============================] - 0s 677us/step - loss: 8.2934e-10 - accuracy: 0.1845\n",
      "Epoch 677/800\n",
      "10/10 [==============================] - 0s 629us/step - loss: 4.5901e-10 - accuracy: 0.0678\n",
      "Epoch 678/800\n",
      "10/10 [==============================] - 0s 632us/step - loss: 3.6016e-10 - accuracy: 0.0182\n",
      "Epoch 679/800\n",
      "10/10 [==============================] - 0s 628us/step - loss: 9.8942e-10 - accuracy: 0.2754\n",
      "Epoch 680/800\n",
      "10/10 [==============================] - 0s 616us/step - loss: 6.0700e-10 - accuracy: 0.1087\n",
      "Epoch 681/800\n",
      "10/10 [==============================] - 0s 664us/step - loss: 6.7012e-10 - accuracy: 0.1845\n",
      "Epoch 682/800\n",
      "10/10 [==============================] - 0s 600us/step - loss: 3.1109e-10 - accuracy: 0.0396\n",
      "Epoch 683/800\n",
      "10/10 [==============================] - 0s 633us/step - loss: 4.1143e-10 - accuracy: 0.0182\n",
      "Epoch 684/800\n",
      "10/10 [==============================] - 0s 657us/step - loss: 2.4886e-10 - accuracy: 0.0182\n",
      "Epoch 685/800\n",
      "10/10 [==============================] - 0s 609us/step - loss: 3.3681e-10 - accuracy: 0.0860\n",
      "Epoch 686/800\n",
      "10/10 [==============================] - 0s 641us/step - loss: 2.5605e-10 - accuracy: 0.0860\n",
      "Epoch 687/800\n",
      "10/10 [==============================] - 0s 607us/step - loss: 1.9046e-10 - accuracy: 0.0526\n",
      "Epoch 688/800\n",
      "10/10 [==============================] - 0s 603us/step - loss: 1.9452e-10 - accuracy: 0.0678\n",
      "Epoch 689/800\n",
      "10/10 [==============================] - 0s 671us/step - loss: 3.6154e-10 - accuracy: 0.2754\n",
      "Epoch 690/800\n",
      "10/10 [==============================] - 0s 643us/step - loss: 2.5126e-10 - accuracy: 0.0678\n",
      "Epoch 691/800\n",
      "10/10 [==============================] - 0s 651us/step - loss: 1.3080e-10 - accuracy: 0.0860\n",
      "Epoch 692/800\n",
      "10/10 [==============================] - 0s 622us/step - loss: 1.2859e-10 - accuracy: 0.0283\n",
      "Epoch 693/800\n",
      "10/10 [==============================] - 0s 598us/step - loss: 1.2295e-10 - accuracy: 0.0860\n",
      "Epoch 694/800\n",
      "10/10 [==============================] - 0s 632us/step - loss: 1.2615e-10 - accuracy: 0.0396\n",
      "Epoch 695/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 584us/step - loss: 1.9678e-10 - accuracy: 0.2754\n",
      "Epoch 696/800\n",
      "10/10 [==============================] - 0s 689us/step - loss: 1.5043e-10 - accuracy: 0.2754\n",
      "Epoch 697/800\n",
      "10/10 [==============================] - 0s 645us/step - loss: 1.3680e-10 - accuracy: 0.0860\n",
      "Epoch 698/800\n",
      "10/10 [==============================] - 0s 629us/step - loss: 7.5837e-11 - accuracy: 0.0526\n",
      "Epoch 699/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 5.8005e-11 - accuracy: 0.1087\n",
      "Epoch 700/800\n",
      "10/10 [==============================] - 0s 590us/step - loss: 1.1931e-10 - accuracy: 0.2754\n",
      "Epoch 701/800\n",
      "10/10 [==============================] - 0s 671us/step - loss: 5.8111e-11 - accuracy: 0.0283\n",
      "Epoch 702/800\n",
      "10/10 [==============================] - 0s 588us/step - loss: 4.7617e-11 - accuracy: 0.0526\n",
      "Epoch 703/800\n",
      "10/10 [==============================] - 0s 624us/step - loss: 6.3115e-11 - accuracy: 0.1845\n",
      "Epoch 704/800\n",
      "10/10 [==============================] - 0s 630us/step - loss: 4.4703e-11 - accuracy: 0.0396\n",
      "Epoch 705/800\n",
      "10/10 [==============================] - 0s 604us/step - loss: 6.0546e-11 - accuracy: 0.2754\n",
      "Epoch 706/800\n",
      "10/10 [==============================] - 0s 662us/step - loss: 3.0629e-11 - accuracy: 0.1390\n",
      "Epoch 707/800\n",
      "10/10 [==============================] - 0s 608us/step - loss: 4.0583e-11 - accuracy: 0.0396\n",
      "Epoch 708/800\n",
      "10/10 [==============================] - 0s 629us/step - loss: 4.6508e-11 - accuracy: 0.2754\n",
      "Epoch 709/800\n",
      "10/10 [==============================] - 0s 630us/step - loss: 2.1825e-11 - accuracy: 0.0678\n",
      "Epoch 710/800\n",
      "10/10 [==============================] - 0s 591us/step - loss: 3.5148e-11 - accuracy: 0.2754\n",
      "Epoch 711/800\n",
      "10/10 [==============================] - 0s 646us/step - loss: 2.4624e-11 - accuracy: 0.1087\n",
      "Epoch 712/800\n",
      "10/10 [==============================] - 0s 634us/step - loss: 1.1745e-11 - accuracy: 0.0860\n",
      "Epoch 713/800\n",
      "10/10 [==============================] - 0s 633us/step - loss: 1.8855e-11 - accuracy: 0.1087\n",
      "Epoch 714/800\n",
      "10/10 [==============================] - 0s 590us/step - loss: 1.7119e-11 - accuracy: 0.0396\n",
      "Epoch 715/800\n",
      "10/10 [==============================] - 0s 638us/step - loss: 1.3124e-11 - accuracy: 0.0678\n",
      "Epoch 716/800\n",
      "10/10 [==============================] - 0s 645us/step - loss: 1.4394e-11 - accuracy: 0.0678\n",
      "Epoch 717/800\n",
      "10/10 [==============================] - 0s 604us/step - loss: 8.8181e-12 - accuracy: 0.0396\n",
      "Epoch 718/800\n",
      "10/10 [==============================] - 0s 625us/step - loss: 8.2757e-12 - accuracy: 0.0283\n",
      "Epoch 719/800\n",
      "10/10 [==============================] - 0s 599us/step - loss: 8.3272e-12 - accuracy: 0.0396\n",
      "Epoch 720/800\n",
      "10/10 [==============================] - 0s 612us/step - loss: 1.0731e-11 - accuracy: 0.1390\n",
      "Epoch 721/800\n",
      "10/10 [==============================] - 0s 628us/step - loss: 9.9558e-12 - accuracy: 0.1390\n",
      "Epoch 722/800\n",
      "10/10 [==============================] - 0s 626us/step - loss: 7.8089e-12 - accuracy: 0.1087\n",
      "Epoch 723/800\n",
      "10/10 [==============================] - 0s 660us/step - loss: 7.4906e-12 - accuracy: 0.1390\n",
      "Epoch 724/800\n",
      "10/10 [==============================] - 0s 608us/step - loss: 7.4617e-12 - accuracy: 0.1845\n",
      "Epoch 725/800\n",
      "10/10 [==============================] - 0s 627us/step - loss: 8.7515e-12 - accuracy: 0.2754\n",
      "Epoch 726/800\n",
      "10/10 [==============================] - 0s 624us/step - loss: 6.0046e-12 - accuracy: 0.0860\n",
      "Epoch 727/800\n",
      "10/10 [==============================] - 0s 606us/step - loss: 6.1449e-12 - accuracy: 0.1845\n",
      "Epoch 728/800\n",
      "10/10 [==============================] - 0s 631us/step - loss: 3.1341e-12 - accuracy: 0.0678\n",
      "Epoch 729/800\n",
      "10/10 [==============================] - 0s 601us/step - loss: 5.5335e-12 - accuracy: 0.1845\n",
      "Epoch 730/800\n",
      "10/10 [==============================] - 0s 625us/step - loss: 3.1023e-12 - accuracy: 0.0678\n",
      "Epoch 731/800\n",
      "10/10 [==============================] - 0s 595us/step - loss: 4.2123e-12 - accuracy: 0.1390\n",
      "Epoch 732/800\n",
      "10/10 [==============================] - 0s 616us/step - loss: 6.8460e-12 - accuracy: 0.2754\n",
      "Epoch 733/800\n",
      "10/10 [==============================] - 0s 634us/step - loss: 6.7319e-12 - accuracy: 0.0860\n",
      "Epoch 734/800\n",
      "10/10 [==============================] - 0s 620us/step - loss: 5.4967e-12 - accuracy: 0.2754\n",
      "Epoch 735/800\n",
      "10/10 [==============================] - 0s 632us/step - loss: 6.3594e-12 - accuracy: 0.2754\n",
      "Epoch 736/800\n",
      "10/10 [==============================] - 0s 616us/step - loss: 4.8721e-12 - accuracy: 0.2754\n",
      "Epoch 737/800\n",
      "10/10 [==============================] - 0s 620us/step - loss: 1.8411e-12 - accuracy: 0.0396\n",
      "Epoch 738/800\n",
      "10/10 [==============================] - 0s 642us/step - loss: 2.0099e-12 - accuracy: 0.0396\n",
      "Epoch 739/800\n",
      "10/10 [==============================] - 0s 617us/step - loss: 3.0434e-12 - accuracy: 0.1087\n",
      "Epoch 740/800\n",
      "10/10 [==============================] - 0s 657us/step - loss: 3.1102e-12 - accuracy: 0.0283\n",
      "Epoch 741/800\n",
      "10/10 [==============================] - 0s 617us/step - loss: 2.5288e-12 - accuracy: 0.0678\n",
      "Epoch 742/800\n",
      "10/10 [==============================] - 0s 624us/step - loss: 3.7938e-12 - accuracy: 0.1390\n",
      "Epoch 743/800\n",
      "10/10 [==============================] - 0s 652us/step - loss: 2.3626e-12 - accuracy: 0.0283\n",
      "Epoch 744/800\n",
      "10/10 [==============================] - 0s 617us/step - loss: 1.6425e-12 - accuracy: 0.0283\n",
      "Epoch 745/800\n",
      "10/10 [==============================] - 0s 639us/step - loss: 1.8413e-12 - accuracy: 0.0526\n",
      "Epoch 746/800\n",
      "10/10 [==============================] - 0s 608us/step - loss: 3.9357e-12 - accuracy: 0.2754\n",
      "Epoch 747/800\n",
      "10/10 [==============================] - 0s 625us/step - loss: 3.3113e-12 - accuracy: 0.1845\n",
      "Epoch 748/800\n",
      "10/10 [==============================] - 0s 624us/step - loss: 2.5273e-12 - accuracy: 0.0182\n",
      "Epoch 749/800\n",
      "10/10 [==============================] - 0s 616us/step - loss: 1.5310e-12 - accuracy: 0.0283\n",
      "Epoch 750/800\n",
      "10/10 [==============================] - 0s 635us/step - loss: 1.7313e-12 - accuracy: 0.1845\n",
      "Epoch 751/800\n",
      "10/10 [==============================] - 0s 613us/step - loss: 1.9333e-12 - accuracy: 0.1390\n",
      "Epoch 752/800\n",
      "10/10 [==============================] - 0s 625us/step - loss: 1.5873e-12 - accuracy: 0.1845\n",
      "Epoch 753/800\n",
      "10/10 [==============================] - 0s 615us/step - loss: 8.9119e-13 - accuracy: 0.0860\n",
      "Epoch 754/800\n",
      "10/10 [==============================] - 0s 594us/step - loss: 1.1049e-12 - accuracy: 0.0283\n",
      "Epoch 755/800\n",
      "10/10 [==============================] - 0s 632us/step - loss: 9.1519e-13 - accuracy: 0.0396\n",
      "Epoch 756/800\n",
      "10/10 [==============================] - 0s 613us/step - loss: 8.5576e-13 - accuracy: 0.0182\n",
      "Epoch 757/800\n",
      "10/10 [==============================] - 0s 637us/step - loss: 8.3157e-13 - accuracy: 0.0283\n",
      "Epoch 758/800\n",
      "10/10 [==============================] - 0s 607us/step - loss: 7.5522e-13 - accuracy: 0.0283\n",
      "Epoch 759/800\n",
      "10/10 [==============================] - 0s 600us/step - loss: 8.2637e-13 - accuracy: 0.0860\n",
      "Epoch 760/800\n",
      "10/10 [==============================] - 0s 673us/step - loss: 1.3863e-12 - accuracy: 0.1087\n",
      "Epoch 761/800\n",
      "10/10 [==============================] - 0s 606us/step - loss: 8.6298e-13 - accuracy: 0.0678\n",
      "Epoch 762/800\n",
      "10/10 [==============================] - 0s 652us/step - loss: 1.5490e-12 - accuracy: 0.0283\n",
      "Epoch 763/800\n",
      "10/10 [==============================] - 0s 620us/step - loss: 1.2333e-12 - accuracy: 0.1390\n",
      "Epoch 764/800\n",
      "10/10 [==============================] - 0s 622us/step - loss: 1.6622e-12 - accuracy: 0.0283\n",
      "Epoch 765/800\n",
      "10/10 [==============================] - 0s 645us/step - loss: 9.9061e-13 - accuracy: 0.1087\n",
      "Epoch 766/800\n",
      "10/10 [==============================] - 0s 613us/step - loss: 1.1675e-12 - accuracy: 0.1845\n",
      "Epoch 767/800\n",
      "10/10 [==============================] - 0s 621us/step - loss: 1.3107e-12 - accuracy: 0.1390\n",
      "Epoch 768/800\n",
      "10/10 [==============================] - 0s 613us/step - loss: 1.0574e-12 - accuracy: 0.1845\n",
      "Epoch 769/800\n",
      "10/10 [==============================] - 0s 667us/step - loss: 1.0039e-12 - accuracy: 0.1390\n",
      "Epoch 770/800\n",
      "10/10 [==============================] - 0s 637us/step - loss: 1.0650e-12 - accuracy: 0.0396\n",
      "Epoch 771/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 604us/step - loss: 6.0135e-13 - accuracy: 0.0283\n",
      "Epoch 772/800\n",
      "10/10 [==============================] - 0s 643us/step - loss: 8.3144e-13 - accuracy: 0.0396\n",
      "Epoch 773/800\n",
      "10/10 [==============================] - 0s 607us/step - loss: 1.8125e-12 - accuracy: 0.1845\n",
      "Epoch 774/800\n",
      "10/10 [==============================] - 0s 660us/step - loss: 6.8312e-13 - accuracy: 0.0182\n",
      "Epoch 775/800\n",
      "10/10 [==============================] - 0s 604us/step - loss: 1.3744e-12 - accuracy: 0.0283\n",
      "Epoch 776/800\n",
      "10/10 [==============================] - 0s 618us/step - loss: 1.2618e-12 - accuracy: 0.1390\n",
      "Epoch 777/800\n",
      "10/10 [==============================] - 0s 645us/step - loss: 9.1153e-13 - accuracy: 0.0678\n",
      "Epoch 778/800\n",
      "10/10 [==============================] - 0s 601us/step - loss: 6.5805e-13 - accuracy: 0.0526\n",
      "Epoch 779/800\n",
      "10/10 [==============================] - 0s 640us/step - loss: 1.3858e-12 - accuracy: 0.0678\n",
      "Epoch 780/800\n",
      "10/10 [==============================] - 0s 594us/step - loss: 6.4313e-13 - accuracy: 0.0182\n",
      "Epoch 781/800\n",
      "10/10 [==============================] - 0s 642us/step - loss: 1.1553e-12 - accuracy: 0.0678\n",
      "Epoch 782/800\n",
      "10/10 [==============================] - 0s 641us/step - loss: 7.7916e-13 - accuracy: 0.0860\n",
      "Epoch 783/800\n",
      "10/10 [==============================] - 0s 615us/step - loss: 6.7610e-13 - accuracy: 0.0526\n",
      "Epoch 784/800\n",
      "10/10 [==============================] - 0s 652us/step - loss: 9.8862e-13 - accuracy: 0.0182\n",
      "Epoch 785/800\n",
      "10/10 [==============================] - 0s 593us/step - loss: 1.2053e-12 - accuracy: 0.1390\n",
      "Epoch 786/800\n",
      "10/10 [==============================] - 0s 637us/step - loss: 9.1694e-13 - accuracy: 0.0396\n",
      "Epoch 787/800\n",
      "10/10 [==============================] - 0s 634us/step - loss: 1.0587e-12 - accuracy: 0.0860\n",
      "Epoch 788/800\n",
      "10/10 [==============================] - 0s 628us/step - loss: 1.0621e-12 - accuracy: 0.0860\n",
      "Epoch 789/800\n",
      "10/10 [==============================] - 0s 645us/step - loss: 7.0377e-13 - accuracy: 0.0526\n",
      "Epoch 790/800\n",
      "10/10 [==============================] - 0s 599us/step - loss: 9.2540e-13 - accuracy: 0.0526\n",
      "Epoch 791/800\n",
      "10/10 [==============================] - 0s 661us/step - loss: 7.5347e-13 - accuracy: 0.0396\n",
      "Epoch 792/800\n",
      "10/10 [==============================] - 0s 597us/step - loss: 1.1575e-12 - accuracy: 0.0678\n",
      "Epoch 793/800\n",
      "10/10 [==============================] - 0s 633us/step - loss: 1.2535e-12 - accuracy: 0.2754\n",
      "Epoch 794/800\n",
      "10/10 [==============================] - 0s 617us/step - loss: 9.4493e-13 - accuracy: 0.0283\n",
      "Epoch 795/800\n",
      "10/10 [==============================] - 0s 623us/step - loss: 9.5631e-13 - accuracy: 0.0860\n",
      "Epoch 796/800\n",
      "10/10 [==============================] - 0s 647us/step - loss: 8.8620e-13 - accuracy: 0.0526\n",
      "Epoch 797/800\n",
      "10/10 [==============================] - 0s 579us/step - loss: 1.6709e-12 - accuracy: 0.0860\n",
      "Epoch 798/800\n",
      "10/10 [==============================] - 0s 615us/step - loss: 9.3879e-13 - accuracy: 0.0182\n",
      "Epoch 799/800\n",
      "10/10 [==============================] - 0s 636us/step - loss: 5.4575e-13 - accuracy: 0.0396\n",
      "Epoch 800/800\n",
      "10/10 [==============================] - 0s 603us/step - loss: 6.9282e-13 - accuracy: 0.1390\n",
      "10/10 [==============================] - 0s 545us/step - loss: 6.5512e-13 - accuracy: 0.1000\n",
      "loss : 6.551203806867689e-13\n",
      "acc : 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "# numpy 불러오기\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 생성\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "y = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# keras 불러오기\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()  # 모델을 순차적으로 구성하겠다고 선언\n",
    "model.add(Dense(1, input_dim=1, activation='relu'))  # 순차적 구성 모델에 Dense 레이어를 추가하겠다는 의미\n",
    "\n",
    "model.summary()\n",
    "# 모델 컴파일\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(x, y, epochs=800, batch_size=1)\n",
    "\n",
    "# 모델 평가 \n",
    "loss, acc = model.evaluate(x, y, batch_size=1)\n",
    "\n",
    "print('loss :', loss)\n",
    "print('acc :', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evalute는 최종 결과에 대한 평가  \n",
    "evalute의 반환은 loss, acc가 반환되고, loss 는 작을 수록 학습이 잘 진행되고 있다는 뜻이고, acc 는 1에 가까울 수록 정확하다는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc, loss 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "x_len = np.arange(len(loss))\n",
    "plt.plot(x_len, loss)\n",
    "\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "x_len = np.arange(len(loss))\n",
    "plt.plot(x_len, accuracy)\n",
    "\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['acc'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc는 낮게 나왔지만, 예측은 잘하는 모습.. 뭐가 문제일까 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000013],\n",
       "       [2.000001 ],\n",
       "       [3.0000007],\n",
       "       [4.0000005],\n",
       "       [5.       ],\n",
       "       [5.9999995],\n",
       "       [6.9999995],\n",
       "       [7.999999 ],\n",
       "       [8.999999 ],\n",
       "       [9.999999 ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 101~110까지 예측 모델 구하기\n",
    "데이터를 훈련시킬 데이터와 테스트할 데이터를 분리함.  \n",
    "훈련에 사용할 데이터는 1~10 데이터를 사용함. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 불러오기\n",
    "import numpy as np\n",
    "\n",
    "# train 데이터 생성\n",
    "x_train = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "y_train = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# test 데이터 생성\n",
    "x_test = np.array([101, 102, 103, 104, 105, 106, 107, 108, 109, 110])\n",
    "y_test = np.array([101, 102, 103, 104, 105, 106, 107, 108, 109, 110])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두번째 모델은 layer가 추가 되었음. Dense()안에 있는 숫자를 노드를 의미함.  \n",
    "따라서 입력으로 부터 5개의 노드를 거치는 레이어를 추가한 것임.  \n",
    "다시 5개의 노드는 3개를 노드를 가지는 레이어를 거치고,  \n",
    "마지막에 1개의 노드를 가지는 레이어를 거쳐 출력값이 나오게 됨.  \n",
    "\n",
    "모델을 한눈에 보려면 model.summary() 메서드를 사용하면 됨.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 10        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=1, activation='relu'))\n",
    "model.add(Dense(3))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param 는 parameter의 약자임. 파라미터는 각 노드간의 가중치와 노드마다의 편향으로 이루어져 있음  \n",
    "그러므로 첫번째 레이어에는 1->5 이므로 5개의 가중치와 5개의 편향이 더해지게 되어 10개의 파라미터,    \n",
    "두번째 레이어는 5->3 15개의 가중치와 3개의 편향이 더해져 18개의 파라미터,  \n",
    "마지막 레이어는 3->1 3개의 가중치와 1개의 편향이 더해져 4개의 파라미터가 생성되게 됨.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fit` 에서 `validation_data`가 추가되었음.  이는 훈련데이터와 검증데이터를 나눠서 학습과 평가를 하기 위해서임  \n",
    "`validation_data` 에는 원래 훈련데이터와는 다른 평가용 데이터를 입력하면 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 11.6867 - val_loss: 2047.9916\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.3977 - val_loss: 1614.8258\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.1346 - val_loss: 1145.9943\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.6706 - val_loss: 817.9100\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8136 - val_loss: 557.9669\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8806 - val_loss: 357.0435\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0583 - val_loss: 225.0847\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6029 - val_loss: 145.0349\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1503 - val_loss: 99.9754\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1051 - val_loss: 67.2558\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0919 - val_loss: 46.8724\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0302 - val_loss: 37.1187\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0351 - val_loss: 29.5391\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0262 - val_loss: 25.9891\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0207 - val_loss: 24.1538\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0304 - val_loss: 23.4901\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0242 - val_loss: 22.3818\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 21.6032\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 21.2388\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0226 - val_loss: 21.2333\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0194 - val_loss: 21.0657\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 20.5936\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 20.2271\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0201 - val_loss: 19.8650\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0222 - val_loss: 19.2696\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0326 - val_loss: 20.0130\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 18.2782\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 17.8493\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0222 - val_loss: 17.4676\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 16.8056\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 16.7694\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 16.0757\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0242 - val_loss: 15.2009\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 15.3112\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 15.1617\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 14.5103\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 13.7852\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 13.7385\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 12.8788\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 12.6764\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 12.6940\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 12.4530\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 11.0588\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 10.5672\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 10.7868\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 10.1437\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 10.2057\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 9.3788\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 9.0925\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 9.3170\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 9.1248\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 8.4220\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 7.9512\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 7.9611\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 7.4318\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 6.9467\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 7.1370\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 6.4578\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 6.2121\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 5.7646\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 5.9383\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 5.6900\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 5.7570\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 4.9942\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 5.1043\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 5.0157\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 4.3522\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 4.1559\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 4.1444\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 3.9898\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 4.1979\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 3.7597\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 3.4165\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 3.1049\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 3.0291\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 3.0419\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 2.7119\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 2.7137\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 2.8549\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 2.4482\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 2.2764\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 2.3158\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 2.0756\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 1.9757\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 2.1356\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 1.8358\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 1.6664\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 1.5350\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 1.6086\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 1.5536\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 1.4248\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 1.2068\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 1.2047\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 1.0886\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.9775e-04 - val_loss: 1.0708\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 1.1284\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.1445e-04 - val_loss: 0.9163\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.9447\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.9185\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.9970e-04 - val_loss: 0.7638\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.1880e-04 - val_loss: 0.7685\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.4861e-04 - val_loss: 0.7124\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.3420e-04 - val_loss: 0.6327\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.4533e-04 - val_loss: 0.6890\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.6680e-04 - val_loss: 0.6232\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.4583e-04 - val_loss: 0.5676\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.7133e-04 - val_loss: 0.4813\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.7508e-04 - val_loss: 0.4759\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5173e-04 - val_loss: 0.4647\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.3912e-04 - val_loss: 0.4507\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.0934e-04 - val_loss: 0.4127\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.5414e-04 - val_loss: 0.3547\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.6114e-04 - val_loss: 0.3352\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9391e-04 - val_loss: 0.3361\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.6613e-04 - val_loss: 0.3379\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8585e-04 - val_loss: 0.2783\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.2288e-04 - val_loss: 0.2440\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.5280e-04 - val_loss: 0.2392\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8290e-04 - val_loss: 0.2680\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.5171e-04 - val_loss: 0.2072\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2766e-04 - val_loss: 0.2070\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8755e-04 - val_loss: 0.1864\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.7189e-04 - val_loss: 0.1971\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6725e-04 - val_loss: 0.1653\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9888e-04 - val_loss: 0.1501\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.4532e-05 - val_loss: 0.1292\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0949e-04 - val_loss: 0.1345\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.3751e-05 - val_loss: 0.1218\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1549e-04 - val_loss: 0.1169\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4039e-04 - val_loss: 0.0938\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1849e-04 - val_loss: 0.0940\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.1029e-05 - val_loss: 0.0887\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2068e-04 - val_loss: 0.0924\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.8228e-05 - val_loss: 0.0743\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.2735e-05 - val_loss: 0.0650\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.9100e-05 - val_loss: 0.0677\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6033e-05 - val_loss: 0.0586\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.5800e-05 - val_loss: 0.0581\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.3055e-05 - val_loss: 0.0534\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5867e-05 - val_loss: 0.0522\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.7349e-05 - val_loss: 0.0410\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9820e-05 - val_loss: 0.0339\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.9041e-05 - val_loss: 0.0380\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.4058e-05 - val_loss: 0.0361\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9714e-05 - val_loss: 0.0299\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9176e-05 - val_loss: 0.0261\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9084e-05 - val_loss: 0.0276\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9572e-05 - val_loss: 0.0264\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.4761e-05 - val_loss: 0.0223\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.2151e-05 - val_loss: 0.0202\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1395e-05 - val_loss: 0.0157\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6645e-05 - val_loss: 0.0180\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1200e-05 - val_loss: 0.0159\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.4411e-06 - val_loss: 0.0147\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2710e-05 - val_loss: 0.0119\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5293e-05 - val_loss: 0.0122\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2501e-05 - val_loss: 0.0103\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0905e-05 - val_loss: 0.0098\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.0540e-06 - val_loss: 0.0096\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.2994e-06 - val_loss: 0.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.5670e-06 - val_loss: 0.0070\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.2258e-06 - val_loss: 0.0069\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.8581e-06 - val_loss: 0.0068\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.7051e-06 - val_loss: 0.0057\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.3404e-06 - val_loss: 0.0047\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.7385e-06 - val_loss: 0.0044\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.8105e-06 - val_loss: 0.0041\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.4332e-06 - val_loss: 0.0037\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.7401e-06 - val_loss: 0.0035\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.6145e-06 - val_loss: 0.0031\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.6585e-06 - val_loss: 0.0025\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.5132e-06 - val_loss: 0.0025\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.1438e-06 - val_loss: 0.0022\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8977e-06 - val_loss: 0.0022\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3337e-06 - val_loss: 0.0016\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1615e-06 - val_loss: 0.0015\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7586e-06 - val_loss: 0.0015\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2238e-06 - val_loss: 0.0015\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6687e-06 - val_loss: 0.0013\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.4236e-07 - val_loss: 9.3301e-04\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.4317e-07 - val_loss: 9.1107e-04\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0252e-06 - val_loss: 0.0010\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0451e-06 - val_loss: 7.4827e-04\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.3277e-07 - val_loss: 6.6127e-04\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.0074e-07 - val_loss: 7.0381e-04\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.3044e-07 - val_loss: 5.6260e-04\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.9319e-07 - val_loss: 4.5238e-04\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.8265e-07 - val_loss: 4.1465e-04\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.7981e-07 - val_loss: 3.8580e-04\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.0588e-07 - val_loss: 3.4406e-04\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3720e-07 - val_loss: 3.5074e-04\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.2856e-07 - val_loss: 3.2055e-04\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2193e-07 - val_loss: 2.1471e-04\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3890e-07 - val_loss: 2.0009e-04\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0426e-07 - val_loss: 2.1159e-04\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0571e-07 - val_loss: 1.8548e-04\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4524e-07 - val_loss: 1.7676e-04\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3878e-07 - val_loss: 1.3483e-04\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.5010e-07 - val_loss: 1.2650e-04\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1427e-07 - val_loss: 1.0020e-04\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.2147e-08 - val_loss: 8.5551e-05\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4111e-08 - val_loss: 8.4915e-05\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.2610e-08 - val_loss: 8.4382e-05\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.6533e-08 - val_loss: 5.9652e-05\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.7737e-08 - val_loss: 5.8607e-05\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.5515e-08 - val_loss: 5.4395e-05\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5551e-08 - val_loss: 4.9686e-05\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.2511e-08 - val_loss: 3.4247e-05\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.8937e-08 - val_loss: 3.4847e-05\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.0135e-08 - val_loss: 3.4371e-05\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9457e-08 - val_loss: 2.7455e-05\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.5177e-08 - val_loss: 2.4221e-05\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8759e-08 - val_loss: 1.4091e-05\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.4412e-08 - val_loss: 1.8354e-05\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5994e-08 - val_loss: 1.8894e-05\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1846e-08 - val_loss: 1.5632e-05\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5628e-08 - val_loss: 9.3590e-06\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6810e-08 - val_loss: 1.0802e-05\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1183e-08 - val_loss: 1.1505e-05\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1538e-08 - val_loss: 6.8976e-06\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.8669e-09 - val_loss: 6.6478e-06\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2843e-08 - val_loss: 6.5150e-06\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.2793e-09 - val_loss: 4.0945e-06\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9232e-09 - val_loss: 5.0148e-06\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.2200e-09 - val_loss: 4.6099e-06\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.2592e-09 - val_loss: 2.8816e-06\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9161e-09 - val_loss: 2.9152e-06\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.4184e-09 - val_loss: 2.8814e-06\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.8322e-09 - val_loss: 2.5081e-06\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2852e-09 - val_loss: 2.3394e-06\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7111e-09 - val_loss: 1.7557e-06\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2827e-09 - val_loss: 1.3108e-06\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8175e-09 - val_loss: 1.2935e-06\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2737e-09 - val_loss: 1.2710e-06\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1209e-09 - val_loss: 1.0901e-06\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3002e-09 - val_loss: 1.0335e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.9635e-10 - val_loss: 7.7980e-07\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.8170e-10 - val_loss: 5.9535e-07\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.9695e-10 - val_loss: 6.0235e-07\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.7032e-10 - val_loss: 5.7674e-07\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.7220e-10 - val_loss: 4.9518e-07\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8661e-10 - val_loss: 2.8553e-07\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.1692e-10 - val_loss: 3.1042e-07\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9477e-10 - val_loss: 2.9696e-07\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.1336e-10 - val_loss: 3.0202e-07\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7318e-10 - val_loss: 2.0416e-07\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4345e-10 - val_loss: 1.9124e-07\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2653e-10 - val_loss: 1.8469e-07\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3184e-10 - val_loss: 1.6180e-07\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6146e-10 - val_loss: 1.4505e-07\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0220e-10 - val_loss: 1.3038e-07\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3296e-10 - val_loss: 1.1030e-07\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5321e-10 - val_loss: 9.4157e-08\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.6470e-11 - val_loss: 8.3307e-08\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.7547e-11 - val_loss: 8.0618e-08\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.2024e-11 - val_loss: 6.6223e-08\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.1573e-11 - val_loss: 5.5274e-08\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.6754e-11 - val_loss: 5.0361e-08\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.4182e-11 - val_loss: 4.7660e-08\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.1619e-11 - val_loss: 4.2171e-08\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.2819e-11 - val_loss: 3.6746e-08\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0541e-11 - val_loss: 3.1089e-08\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.1036e-11 - val_loss: 3.3563e-08\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1565e-11 - val_loss: 3.0291e-08\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0911e-11 - val_loss: 2.4011e-08\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.6718e-11 - val_loss: 2.3091e-08\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2964e-11 - val_loss: 2.0606e-08\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3669e-11 - val_loss: 1.7887e-08\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2128e-11 - val_loss: 1.7480e-08\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1184e-11 - val_loss: 1.6869e-08\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5206e-11 - val_loss: 1.5128e-08\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.9659e-12 - val_loss: 1.3312e-08\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2961e-11 - val_loss: 1.1636e-08\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0689e-11 - val_loss: 9.1211e-09\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.8220e-12 - val_loss: 8.8417e-09\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.4335e-12 - val_loss: 8.6962e-09\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.6820e-12 - val_loss: 8.4168e-09\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1342e-11 - val_loss: 6.0652e-09\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.3105e-12 - val_loss: 5.9430e-09\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.5203e-12 - val_loss: 5.8324e-09\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.4860e-12 - val_loss: 5.3900e-09\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.5345e-12 - val_loss: 5.1688e-09\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.0999e-12 - val_loss: 4.7497e-09\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0479e-12 - val_loss: 4.5402e-09\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.1330e-12 - val_loss: 4.2317e-09\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.9298e-12 - val_loss: 3.5507e-09\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3171e-12 - val_loss: 3.3877e-09\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.3100e-12 - val_loss: 3.2247e-09\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1831e-12 - val_loss: 3.0617e-09\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.5414e-12 - val_loss: 2.8114e-09\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1187e-12 - val_loss: 2.7241e-09\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9578e-12 - val_loss: 2.5611e-09\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.2225e-12 - val_loss: 2.1711e-09\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3590e-12 - val_loss: 2.1711e-09\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5954e-12 - val_loss: 2.1071e-09\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.6203e-12 - val_loss: 2.1071e-09\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5404e-12 - val_loss: 2.8231e-09\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1317e-12 - val_loss: 2.4855e-09\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.4035e-12 - val_loss: 2.3341e-09\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2620e-12 - val_loss: 2.1711e-09\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3960e-12 - val_loss: 2.0547e-09\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3448e-12 - val_loss: 1.9907e-09\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2022e-12 - val_loss: 1.9267e-09\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1488e-12 - val_loss: 1.7870e-09\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5945e-12 - val_loss: 1.7870e-09\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1637e-12 - val_loss: 1.6589e-09\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2945e-12 - val_loss: 1.6589e-09\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2953e-12 - val_loss: 1.4785e-09\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.7673e-13 - val_loss: 1.3621e-09\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 8.5275e-13 - val_loss: 1.3621e-09\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0437e-12 - val_loss: 1.2573e-09\n",
      "Epoch 312/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 5.7963e-13 - val_loss: 1.2573e-09\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.1317e-13 - val_loss: 1.2573e-09\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.6134e-13 - val_loss: 1.2573e-09\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.8714e-13 - val_loss: 1.2573e-09\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.5490e-13 - val_loss: 1.1933e-09\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6551e-13 - val_loss: 1.1409e-09\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9866e-13 - val_loss: 1.1409e-09\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.6026e-13 - val_loss: 1.0885e-09\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.2690e-13 - val_loss: 9.9535e-10\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.2692e-13 - val_loss: 9.9535e-10\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9968e-13 - val_loss: 9.9535e-10\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.1542e-13 - val_loss: 9.4296e-10\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.7030e-13 - val_loss: 9.4296e-10\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8345e-13 - val_loss: 9.4296e-10\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.6535e-13 - val_loss: 9.4296e-10\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.3455e-13 - val_loss: 8.7311e-10\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.9549e-13 - val_loss: 8.7311e-10\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.7169e-13 - val_loss: 8.7311e-10\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.3689e-13 - val_loss: 8.0327e-10\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.4457e-13 - val_loss: 8.0327e-10\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8092e-13 - val_loss: 7.6252e-10\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.0943e-13 - val_loss: 7.6252e-10\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.1932e-13 - val_loss: 7.6252e-10\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.2814e-13 - val_loss: 7.2177e-10\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.7763e-13 - val_loss: 6.6939e-10\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.7111e-13 - val_loss: 6.6939e-10\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.5024e-13 - val_loss: 6.2864e-10\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4036e-13 - val_loss: 5.8790e-10\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8998e-13 - val_loss: 5.8790e-10\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.8728e-13 - val_loss: 5.5879e-10\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.1764e-13 - val_loss: 5.5879e-10\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.5807e-13 - val_loss: 5.5879e-10\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.6016e-13 - val_loss: 5.1805e-10\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.8925e-13 - val_loss: 5.1805e-10\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.3877e-13 - val_loss: 4.4820e-10\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.7377e-13 - val_loss: 4.4820e-10\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.5656e-13 - val_loss: 4.4820e-10\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.1151e-13 - val_loss: 4.1910e-10\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.7560e-13 - val_loss: 4.1910e-10\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.6822e-13 - val_loss: 3.8999e-10\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.9004e-13 - val_loss: 3.8999e-10\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.7233e-13 - val_loss: 3.8999e-10\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.5273e-13 - val_loss: 3.4925e-10\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.0382e-13 - val_loss: 3.4925e-10\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1962e-12 - val_loss: 2.7358e-10\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.6792e-13 - val_loss: 2.5611e-10\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.8024e-13 - val_loss: 2.5611e-10\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.8949e-13 - val_loss: 2.2701e-10\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.8253e-13 - val_loss: 2.2701e-10\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.1974e-13 - val_loss: 2.0373e-10\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.8562e-13 - val_loss: 2.0373e-10\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.1586e-13 - val_loss: 2.5611e-10\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0673e-12 - val_loss: 2.0373e-10\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.4479e-13 - val_loss: 2.2701e-10\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9135e-13 - val_loss: 2.2701e-10\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.5896e-13 - val_loss: 2.2701e-10\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.3599e-13 - val_loss: 2.5611e-10\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.2901e-13 - val_loss: 2.2701e-10\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.1553e-13 - val_loss: 2.2701e-10\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.0936e-13 - val_loss: 2.0955e-10\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.8866e-13 - val_loss: 2.2701e-10\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2951e-13 - val_loss: 2.0955e-10\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.2967e-13 - val_loss: 2.0955e-10\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.7190e-13 - val_loss: 2.0955e-10\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6146e-13 - val_loss: 2.0955e-10\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.3946e-13 - val_loss: 2.0955e-10\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.5746e-13 - val_loss: 2.0955e-10\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5235e-13 - val_loss: 1.8626e-10\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.2347e-13 - val_loss: 2.0955e-10\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9799e-13 - val_loss: 1.5716e-10\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.6827e-13 - val_loss: 1.5716e-10\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.0551e-13 - val_loss: 1.5134e-10\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0256e-13 - val_loss: 1.5134e-10\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.8789e-13 - val_loss: 1.2806e-10\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.7117e-13 - val_loss: 1.2806e-10\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 5.0580e-13 - val_loss: 1.2806e-10\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9042e-13 - val_loss: 1.2224e-10\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.5808e-13 - val_loss: 1.0477e-10\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8526e-13 - val_loss: 9.8953e-11\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2967e-13 - val_loss: 9.8953e-11\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.2992e-14 - val_loss: 9.8953e-11\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8009e-13 - val_loss: 9.8953e-11\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4401e-13 - val_loss: 7.5670e-11\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.8935e-14 - val_loss: 7.5670e-11\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1767e-13 - val_loss: 7.5670e-11\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.7158e-14 - val_loss: 7.5670e-11\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.0425e-14 - val_loss: 7.5670e-11\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.7721e-13 - val_loss: 7.5670e-11\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2094e-13 - val_loss: 7.5670e-11\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2381e-13 - val_loss: 7.5670e-11\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8850e-13 - val_loss: 7.5670e-11\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1464e-13 - val_loss: 7.5670e-11\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1532e-13 - val_loss: 7.5670e-11\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2306e-13 - val_loss: 7.5670e-11\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.0955e-13 - val_loss: 7.5670e-11\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.2137e-14 - val_loss: 7.5670e-11\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1840e-13 - val_loss: 7.5670e-11\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9771e-13 - val_loss: 7.5670e-11\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.0320e-14 - val_loss: 7.5670e-11\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.5618e-14 - val_loss: 7.5670e-11\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2112e-13 - val_loss: 7.5670e-11\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8616e-13 - val_loss: 7.5670e-11\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9765e-13 - val_loss: 7.5670e-11\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.6767e-13 - val_loss: 7.5670e-11\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1646e-13 - val_loss: 7.5670e-11\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.4105e-14 - val_loss: 7.5670e-11\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.5856e-14 - val_loss: 7.5670e-11\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9119e-13 - val_loss: 7.5670e-11\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.7572e-14 - val_loss: 7.5670e-11\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2833e-13 - val_loss: 7.5670e-11\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.3603e-14 - val_loss: 5.8208e-11\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6839e-13 - val_loss: 5.8208e-11\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.4346e-14 - val_loss: 5.8208e-11\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0827e-13 - val_loss: 5.8208e-11\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3426e-13 - val_loss: 5.8208e-11\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.2125e-14 - val_loss: 5.8208e-11\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2387e-13 - val_loss: 5.8208e-11\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6809e-13 - val_loss: 6.4028e-11\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4614e-13 - val_loss: 6.4028e-11\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2161e-13 - val_loss: 6.4028e-11\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.2596e-14 - val_loss: 6.4028e-11\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8706e-13 - val_loss: 6.4028e-11\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.4230e-13 - val_loss: 6.4028e-11\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9779e-13 - val_loss: 6.4028e-11\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3933e-13 - val_loss: 4.0745e-11\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3664e-13 - val_loss: 4.0745e-11\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.6829e-13 - val_loss: 1.7462e-11\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1619e-13 - val_loss: 1.7462e-11\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9752e-13 - val_loss: 2.3283e-11\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9822e-13 - val_loss: 2.3283e-11\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4790e-14 - val_loss: 2.3283e-11\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8504e-14 - val_loss: 2.3283e-11\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3121e-13 - val_loss: 2.3283e-11\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1122e-13 - val_loss: 2.3283e-11\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.2585e-13 - val_loss: 2.3283e-11\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2398e-13 - val_loss: 2.3283e-11\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.2844e-13 - val_loss: 2.3283e-11\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5830e-13 - val_loss: 2.3283e-11\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9626e-13 - val_loss: 1.7462e-11\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.2499e-13 - val_loss: 1.7462e-11\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3607e-13 - val_loss: 1.7462e-11\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9902e-13 - val_loss: 1.7462e-11\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0583e-13 - val_loss: 2.3283e-11\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9209e-13 - val_loss: 2.3283e-11\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4044e-13 - val_loss: 2.3283e-11\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0318e-13 - val_loss: 2.3283e-11\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.0228e-13 - val_loss: 2.3283e-11\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.5375e-14 - val_loss: 2.3283e-11\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0380e-13 - val_loss: 2.3283e-11\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.9284e-14 - val_loss: 2.3283e-11\n",
      "Epoch 462/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3056e-13 - val_loss: 2.3283e-11\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0127e-13 - val_loss: 2.3283e-11\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.7394e-14 - val_loss: 2.3283e-11\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5265e-13 - val_loss: 2.3283e-11\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.6037e-14 - val_loss: 2.3283e-11\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.6883e-14 - val_loss: 2.3283e-11\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.6696e-14 - val_loss: 4.6566e-11\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.3568e-14 - val_loss: 4.6566e-11\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7043e-13 - val_loss: 4.6566e-11\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2960e-13 - val_loss: 4.6566e-11\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0969e-13 - val_loss: 4.6566e-11\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7747e-13 - val_loss: 4.6566e-11\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2236e-13 - val_loss: 4.6566e-11\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.6631e-13 - val_loss: 4.6566e-11\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0580e-13 - val_loss: 4.6566e-11\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1149e-13 - val_loss: 5.8208e-11\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.7706e-14 - val_loss: 5.8208e-11\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0447e-13 - val_loss: 5.8208e-11\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4038e-13 - val_loss: 5.8208e-11\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9571e-13 - val_loss: 5.8208e-11\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6357e-13 - val_loss: 5.8208e-11\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.4421e-14 - val_loss: 5.8208e-11\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.1445e-14 - val_loss: 5.8208e-11\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2295e-13 - val_loss: 4.0745e-11\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0674e-13 - val_loss: 4.0745e-11\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.2024e-14 - val_loss: 5.8208e-11\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0921e-13 - val_loss: 5.8208e-11\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4668e-13 - val_loss: 5.8208e-11\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.1239e-14 - val_loss: 5.8208e-11\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.5159e-14 - val_loss: 5.8208e-11\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.8300e-14 - val_loss: 5.8208e-11\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9406e-13 - val_loss: 5.8208e-11\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.0885e-14 - val_loss: 5.8208e-11\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.9973e-14 - val_loss: 5.8208e-11\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5292e-13 - val_loss: 4.0745e-11\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.2623e-14 - val_loss: 5.8208e-11\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8354e-13 - val_loss: 5.8208e-11\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.3316e-14 - val_loss: 5.8208e-11\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9866e-13 - val_loss: 5.8208e-11\n",
      "10/10 [==============================] - 0s 518us/step - loss: 5.8208e-11\n",
      "loss :  5.820766091346741e-11\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=1, activation='relu'))\n",
    "model.add(Dense(3))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.fit(x_train, y_train, epochs=500, batch_size=1, validation_data=(x_test, y_test))\n",
    "loss = model.evaluate(x_test, y_test, batch_size=1)\n",
    "\n",
    "print('loss : ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과물 : \n",
      " [[101.     ]\n",
      " [102.00001]\n",
      " [103.00001]\n",
      " [104.     ]\n",
      " [105.00001]\n",
      " [106.     ]\n",
      " [107.     ]\n",
      " [108.00001]\n",
      " [109.00001]\n",
      " [110.00001]]\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(x_test)\n",
    "print('결과물 : \\n', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 케라스 기본구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 데이터 준비\n",
    "2. 모델 구성\n",
    "3. 컴파일, 훈련\n",
    "4. 평가 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
