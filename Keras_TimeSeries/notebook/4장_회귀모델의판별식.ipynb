{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회귀모델의 판별식\n",
    "RMSE(평균 제곱근 오차) 는 회귀 분석을 평가할때 가장 많이 쓰는 지표 중 하나,  \n",
    "대부분의 파이썬, 딥러닝, 머신러닝은 API 나 프레임워크, 함수가 거의 만들어져 있으나 RMSE 는 없는 듯.   \n",
    "그래서 사이킷런에서 제공하는 MSE 기능에 에 np.sqrt 해서 만들게 됨.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 5)                 10        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 1s 48ms/step - loss: 19.7818 - mse: 19.7818 - val_loss: 7984.8242 - val_mse: 7984.8242\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.5361 - mse: 36.5361 - val_loss: 7726.3877 - val_mse: 7726.3877\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 23.2986 - mse: 23.2986 - val_loss: 7482.5415 - val_mse: 7482.5415\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 27.2811 - mse: 27.2811 - val_loss: 7238.2266 - val_mse: 7238.2266\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 19.8942 - mse: 19.8942 - val_loss: 6997.8877 - val_mse: 6997.8877\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 29.8892 - mse: 29.8892 - val_loss: 6728.5234 - val_mse: 6728.5234\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 19.3075 - mse: 19.3075 - val_loss: 6483.2607 - val_mse: 6483.2607\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 23.1755 - mse: 23.1755 - val_loss: 6210.4990 - val_mse: 6210.4990\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 28.6996 - mse: 28.6996 - val_loss: 5921.9785 - val_mse: 5921.9785\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 12.3702 - mse: 12.3702 - val_loss: 5680.7480 - val_mse: 5680.7480\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 15.0782 - mse: 15.0782 - val_loss: 5416.5166 - val_mse: 5416.5166\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 13.2585 - mse: 13.2585 - val_loss: 5143.3076 - val_mse: 5143.3076\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 12.8575 - mse: 12.8575 - val_loss: 4866.4727 - val_mse: 4866.4727\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 11.9816 - mse: 11.9816 - val_loss: 4601.7529 - val_mse: 4601.7529\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 15.9988 - mse: 15.9988 - val_loss: 4321.3516 - val_mse: 4321.3516\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 10.2237 - mse: 10.2237 - val_loss: 4088.0747 - val_mse: 4088.0747\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 11.6147 - mse: 11.6147 - val_loss: 3822.1218 - val_mse: 3822.1218\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 11.0768 - mse: 11.0768 - val_loss: 3564.9849 - val_mse: 3564.9849\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.5689 - mse: 9.5689 - val_loss: 3332.6465 - val_mse: 3332.6465\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.6325 - mse: 7.6325 - val_loss: 3096.3579 - val_mse: 3096.3579\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 11.0563 - mse: 11.0563 - val_loss: 2862.2712 - val_mse: 2862.2712\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.1147 - mse: 6.1147 - val_loss: 2650.7271 - val_mse: 2650.7271\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6617 - mse: 5.6617 - val_loss: 2452.5815 - val_mse: 2452.5815\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.7318 - mse: 4.7318 - val_loss: 2267.4041 - val_mse: 2267.4041\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.7113 - mse: 5.7113 - val_loss: 2062.1597 - val_mse: 2062.1597\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.0605 - mse: 5.0605 - val_loss: 1884.7434 - val_mse: 1884.7434\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9763 - mse: 2.9763 - val_loss: 1732.2549 - val_mse: 1732.2549\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1841 - mse: 2.1841 - val_loss: 1597.9153 - val_mse: 1597.9153\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2958 - mse: 1.2958 - val_loss: 1468.3038 - val_mse: 1468.3038\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9816 - mse: 1.9816 - val_loss: 1330.6179 - val_mse: 1330.6179\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.6043 - mse: 2.6043 - val_loss: 1198.3564 - val_mse: 1198.3564\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0996 - mse: 2.0996 - val_loss: 1084.0464 - val_mse: 1084.0464\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9511 - mse: 0.9511 - val_loss: 996.0221 - val_mse: 996.0221\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9442 - mse: 0.9442 - val_loss: 908.9337 - val_mse: 908.9337\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6610 - mse: 0.6610 - val_loss: 836.9372 - val_mse: 836.9372\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8920 - mse: 0.8920 - val_loss: 757.8891 - val_mse: 757.8891\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3459 - mse: 1.3459 - val_loss: 686.7357 - val_mse: 686.7357\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8306 - mse: 0.8306 - val_loss: 632.4100 - val_mse: 632.4100\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6541 - mse: 0.6541 - val_loss: 586.6298 - val_mse: 586.6298\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6177 - mse: 0.6177 - val_loss: 540.5873 - val_mse: 540.5873\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4246 - mse: 0.4246 - val_loss: 506.5447 - val_mse: 506.5447\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4815 - mse: 0.4815 - val_loss: 473.8434 - val_mse: 473.8434\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4623 - mse: 0.4623 - val_loss: 440.0631 - val_mse: 440.0631\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3793 - mse: 0.3793 - val_loss: 413.5765 - val_mse: 413.5765\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4684 - mse: 0.4684 - val_loss: 388.9535 - val_mse: 388.9535\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2793 - mse: 0.2793 - val_loss: 371.8554 - val_mse: 371.8554\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2589 - mse: 0.2589 - val_loss: 357.3060 - val_mse: 357.3060\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1824 - mse: 0.1824 - val_loss: 341.6755 - val_mse: 341.6755\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2914 - mse: 0.2914 - val_loss: 329.9004 - val_mse: 329.9004\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2694 - mse: 0.2694 - val_loss: 316.1553 - val_mse: 316.1553\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2679 - mse: 0.2679 - val_loss: 303.3337 - val_mse: 303.3337\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1886 - mse: 0.1886 - val_loss: 291.8113 - val_mse: 291.8113\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1959 - mse: 0.1959 - val_loss: 283.5838 - val_mse: 283.5838\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1897 - mse: 0.1897 - val_loss: 278.0504 - val_mse: 278.0504\n",
      "Epoch 55/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3667 - mse: 0.3667 - val_loss: 275.0637 - val_mse: 275.0637\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2695 - mse: 0.2695 - val_loss: 271.0793 - val_mse: 271.0793\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3537 - mse: 0.3537 - val_loss: 263.0970 - val_mse: 263.0970\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2149 - mse: 0.2149 - val_loss: 257.8508 - val_mse: 257.8508\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3052 - mse: 0.3052 - val_loss: 253.2460 - val_mse: 253.2460\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1711 - mse: 0.1711 - val_loss: 250.3998 - val_mse: 250.3998\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1514 - mse: 0.1514 - val_loss: 247.8725 - val_mse: 247.8725\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2791 - mse: 0.2791 - val_loss: 243.4762 - val_mse: 243.4762\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2093 - mse: 0.2093 - val_loss: 238.1471 - val_mse: 238.1471\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1409 - mse: 0.1409 - val_loss: 236.9245 - val_mse: 236.9245\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3349 - mse: 0.3349 - val_loss: 236.8488 - val_mse: 236.8488\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3494 - mse: 0.3494 - val_loss: 233.6114 - val_mse: 233.6114\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1942 - mse: 0.1942 - val_loss: 230.9324 - val_mse: 230.9324\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2302 - mse: 0.2302 - val_loss: 229.5435 - val_mse: 229.5435\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2168 - mse: 0.2168 - val_loss: 222.7800 - val_mse: 222.7800\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2828 - mse: 0.2828 - val_loss: 222.5481 - val_mse: 222.5481\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2380 - mse: 0.2380 - val_loss: 220.3308 - val_mse: 220.3308\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1943 - mse: 0.1943 - val_loss: 216.3273 - val_mse: 216.3273\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1886 - mse: 0.1886 - val_loss: 211.9628 - val_mse: 211.9628\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2717 - mse: 0.2717 - val_loss: 210.0262 - val_mse: 210.0262\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1278 - mse: 0.1278 - val_loss: 206.4659 - val_mse: 206.4659\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1530 - mse: 0.1530 - val_loss: 206.1591 - val_mse: 206.1591\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1789 - mse: 0.1789 - val_loss: 208.1502 - val_mse: 208.1502\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2071 - mse: 0.2071 - val_loss: 205.6549 - val_mse: 205.6549\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1313 - mse: 0.1313 - val_loss: 201.3836 - val_mse: 201.3836\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2782 - mse: 0.2782 - val_loss: 199.2085 - val_mse: 199.2085\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1643 - mse: 0.1643 - val_loss: 199.1901 - val_mse: 199.1901\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1589 - mse: 0.1589 - val_loss: 198.0880 - val_mse: 198.0880\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1656 - mse: 0.1656 - val_loss: 196.9013 - val_mse: 196.9013\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1638 - mse: 0.1638 - val_loss: 190.6632 - val_mse: 190.6632\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1999 - mse: 0.1999 - val_loss: 189.0139 - val_mse: 189.0139\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2234 - mse: 0.2234 - val_loss: 188.3510 - val_mse: 188.3510\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2677 - mse: 0.2677 - val_loss: 188.4459 - val_mse: 188.4459\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1326 - mse: 0.1326 - val_loss: 183.1594 - val_mse: 183.1594\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1102 - mse: 0.1102 - val_loss: 179.5269 - val_mse: 179.5269\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2324 - mse: 0.2324 - val_loss: 177.3369 - val_mse: 177.3369\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1798 - mse: 0.1798 - val_loss: 176.0126 - val_mse: 176.0126\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1110 - mse: 0.1110 - val_loss: 175.4239 - val_mse: 175.4239\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1921 - mse: 0.1921 - val_loss: 173.3482 - val_mse: 173.3482\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1250 - mse: 0.1250 - val_loss: 170.2605 - val_mse: 170.2605\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1343 - mse: 0.1343 - val_loss: 166.9947 - val_mse: 166.9947\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1577 - mse: 0.1577 - val_loss: 168.4715 - val_mse: 168.4715\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2041 - mse: 0.2041 - val_loss: 166.3255 - val_mse: 166.3255\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1394 - mse: 0.1394 - val_loss: 166.2982 - val_mse: 166.2982\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1727 - mse: 0.1727 - val_loss: 163.3167 - val_mse: 163.3167\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1609 - mse: 0.1609 - val_loss: 159.8134 - val_mse: 159.8134\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2336 - mse: 0.2336 - val_loss: 158.8745 - val_mse: 158.8745\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1056 - mse: 0.1056 - val_loss: 153.9881 - val_mse: 153.9881\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0880 - mse: 0.0880 - val_loss: 150.2661 - val_mse: 150.2661\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1720 - mse: 0.1720 - val_loss: 151.5998 - val_mse: 151.5998\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1442 - mse: 0.1442 - val_loss: 148.6429 - val_mse: 148.6429\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1024 - mse: 0.1024 - val_loss: 145.3296 - val_mse: 145.3296\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2395 - mse: 0.2395 - val_loss: 146.1459 - val_mse: 146.1459\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1139 - mse: 0.1139 - val_loss: 144.5031 - val_mse: 144.5031\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1781 - mse: 0.1781 - val_loss: 144.3585 - val_mse: 144.3585\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1519 - mse: 0.1519 - val_loss: 143.3393 - val_mse: 143.3393\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0758 - mse: 0.0758 - val_loss: 139.6446 - val_mse: 139.6446\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1778 - mse: 0.1778 - val_loss: 137.3812 - val_mse: 137.3812\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1448 - mse: 0.1448 - val_loss: 132.8234 - val_mse: 132.8234\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1116 - mse: 0.1116 - val_loss: 134.4327 - val_mse: 134.4327\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1188 - mse: 0.1188 - val_loss: 129.9881 - val_mse: 129.9881\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1435 - mse: 0.1435 - val_loss: 129.6342 - val_mse: 129.6342\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 129.8570 - val_mse: 129.8570\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1377 - mse: 0.1377 - val_loss: 127.1218 - val_mse: 127.1218\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1934 - mse: 0.1934 - val_loss: 123.5099 - val_mse: 123.5099\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1024 - mse: 0.1024 - val_loss: 120.2528 - val_mse: 120.2528\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0995 - mse: 0.0995 - val_loss: 118.6051 - val_mse: 118.6051\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0991 - mse: 0.0991 - val_loss: 117.3429 - val_mse: 117.3429\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0871 - mse: 0.0871 - val_loss: 118.9818 - val_mse: 118.9818\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1363 - mse: 0.1363 - val_loss: 114.0109 - val_mse: 114.0109\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0672 - mse: 0.0672 - val_loss: 111.1911 - val_mse: 111.1911\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0955 - mse: 0.0955 - val_loss: 111.8573 - val_mse: 111.8573\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1660 - mse: 0.1660 - val_loss: 110.0601 - val_mse: 110.0601\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1144 - mse: 0.1144 - val_loss: 108.2091 - val_mse: 108.2091\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0846 - mse: 0.0846 - val_loss: 107.1881 - val_mse: 107.1881\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1374 - mse: 0.1374 - val_loss: 104.2301 - val_mse: 104.2301\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0677 - mse: 0.0677 - val_loss: 103.2832 - val_mse: 103.2832\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0642 - mse: 0.0642 - val_loss: 102.4982 - val_mse: 102.4982\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1108 - mse: 0.1108 - val_loss: 101.9002 - val_mse: 101.9002\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0856 - mse: 0.0856 - val_loss: 101.1301 - val_mse: 101.1301\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0916 - mse: 0.0916 - val_loss: 99.7727 - val_mse: 99.7727\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0683 - mse: 0.0683 - val_loss: 97.0495 - val_mse: 97.0495\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1398 - mse: 0.1398 - val_loss: 95.7913 - val_mse: 95.7913\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0839 - mse: 0.0839 - val_loss: 91.0549 - val_mse: 91.0549\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0838 - mse: 0.0838 - val_loss: 90.1408 - val_mse: 90.1408\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1003 - mse: 0.1003 - val_loss: 91.0970 - val_mse: 91.0970\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0883 - mse: 0.0883 - val_loss: 87.9520 - val_mse: 87.9520\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 86.0946 - val_mse: 86.0946\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1030 - mse: 0.1030 - val_loss: 84.7189 - val_mse: 84.7189\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0764 - mse: 0.0764 - val_loss: 83.9733 - val_mse: 83.9733\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0971 - mse: 0.0971 - val_loss: 82.6768 - val_mse: 82.6768\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0994 - mse: 0.0994 - val_loss: 81.7997 - val_mse: 81.7997\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0941 - mse: 0.0941 - val_loss: 81.5411 - val_mse: 81.5411\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0845 - mse: 0.0845 - val_loss: 81.2224 - val_mse: 81.2224\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 77.7150 - val_mse: 77.7150\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0739 - mse: 0.0739 - val_loss: 75.5680 - val_mse: 75.5680\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0910 - mse: 0.0910 - val_loss: 72.1249 - val_mse: 72.1249\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1027 - mse: 0.1027 - val_loss: 73.1018 - val_mse: 73.1018\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0843 - mse: 0.0843 - val_loss: 70.6113 - val_mse: 70.6113\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0513 - mse: 0.0513 - val_loss: 69.4864 - val_mse: 69.4864\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1108 - mse: 0.1108 - val_loss: 68.9339 - val_mse: 68.9339\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1050 - mse: 0.1050 - val_loss: 68.9719 - val_mse: 68.9719\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0971 - mse: 0.0971 - val_loss: 68.1679 - val_mse: 68.1679\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 66.6763 - val_mse: 66.6763\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0621 - mse: 0.0621 - val_loss: 63.5245 - val_mse: 63.5245\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0747 - mse: 0.0747 - val_loss: 62.4759 - val_mse: 62.4759\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0820 - mse: 0.0820 - val_loss: 61.7820 - val_mse: 61.7820\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0674 - mse: 0.0674 - val_loss: 60.8666 - val_mse: 60.8666\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0639 - mse: 0.0639 - val_loss: 60.3368 - val_mse: 60.3368\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0444 - mse: 0.0444 - val_loss: 58.7790 - val_mse: 58.7790\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0818 - mse: 0.0818 - val_loss: 56.1547 - val_mse: 56.1547\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 54.9217 - val_mse: 54.9217\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 53.3691 - val_mse: 53.3691\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0590 - mse: 0.0590 - val_loss: 53.6732 - val_mse: 53.6732\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 54.2302 - val_mse: 54.2302\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 51.8002 - val_mse: 51.8002\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 50.6848 - val_mse: 50.6848\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 49.9748 - val_mse: 49.9748\n",
      "Epoch 173/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 48.9455 - val_mse: 48.9455\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 48.3412 - val_mse: 48.3412\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0662 - mse: 0.0662 - val_loss: 49.2215 - val_mse: 49.2215\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 47.0406 - val_mse: 47.0406\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 44.6559 - val_mse: 44.6559\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 43.0337 - val_mse: 43.0337\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0498 - mse: 0.0498 - val_loss: 42.6922 - val_mse: 42.6922\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0604 - mse: 0.0604 - val_loss: 42.1874 - val_mse: 42.1874\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 40.5136 - val_mse: 40.5136\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 41.4226 - val_mse: 41.4226\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0576 - mse: 0.0576 - val_loss: 39.6299 - val_mse: 39.6299\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 39.3391 - val_mse: 39.3391\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0570 - mse: 0.0570 - val_loss: 37.6940 - val_mse: 37.6940\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 36.7818 - val_mse: 36.7818\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 35.8932 - val_mse: 35.8932\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 34.6641 - val_mse: 34.6641\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 34.5629 - val_mse: 34.5629\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 33.3460 - val_mse: 33.3460\n",
      "Epoch 191/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 32.7640 - val_mse: 32.7640\n",
      "Epoch 192/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0375 - mse: 0.0375 - val_loss: 32.5099 - val_mse: 32.5099\n",
      "Epoch 193/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 31.6163 - val_mse: 31.6163\n",
      "Epoch 194/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 31.5964 - val_mse: 31.5964\n",
      "Epoch 195/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 29.1812 - val_mse: 29.1812\n",
      "Epoch 196/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 29.2082 - val_mse: 29.2082\n",
      "Epoch 197/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 28.5796 - val_mse: 28.5796\n",
      "Epoch 198/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0414 - mse: 0.0414 - val_loss: 28.0719 - val_mse: 28.0719\n",
      "Epoch 199/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 27.9288 - val_mse: 27.9288\n",
      "Epoch 200/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 27.3878 - val_mse: 27.3878\n",
      "Epoch 201/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 26.6870 - val_mse: 26.6870\n",
      "Epoch 202/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 24.6321 - val_mse: 24.6321\n",
      "Epoch 203/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 24.4201 - val_mse: 24.4201\n",
      "Epoch 204/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 23.6115 - val_mse: 23.6115\n",
      "Epoch 205/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 23.6859 - val_mse: 23.6859\n",
      "Epoch 206/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 23.9789 - val_mse: 23.9789\n",
      "Epoch 207/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 22.1112 - val_mse: 22.1112\n",
      "Epoch 208/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 21.2895 - val_mse: 21.2895\n",
      "Epoch 209/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 20.8969 - val_mse: 20.8969\n",
      "Epoch 210/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 20.5477 - val_mse: 20.5477\n",
      "Epoch 211/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 20.9089 - val_mse: 20.9089\n",
      "Epoch 212/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 20.4721 - val_mse: 20.4721\n",
      "Epoch 213/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 19.1291 - val_mse: 19.1291\n",
      "Epoch 214/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 18.5343 - val_mse: 18.5343\n",
      "Epoch 215/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 17.5666 - val_mse: 17.5666\n",
      "Epoch 216/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 17.5701 - val_mse: 17.5701\n",
      "Epoch 217/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 17.3626 - val_mse: 17.3626\n",
      "Epoch 218/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 17.1443 - val_mse: 17.1443\n",
      "Epoch 219/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 16.4163 - val_mse: 16.4163\n",
      "Epoch 220/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 15.6628 - val_mse: 15.6628\n",
      "Epoch 221/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 15.7604 - val_mse: 15.7604\n",
      "Epoch 222/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 14.9631 - val_mse: 14.9631\n",
      "Epoch 223/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 14.6761 - val_mse: 14.6761\n",
      "Epoch 224/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 13.8012 - val_mse: 13.8012\n",
      "Epoch 225/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 13.8956 - val_mse: 13.8956\n",
      "Epoch 226/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 13.4532 - val_mse: 13.4532\n",
      "Epoch 227/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 13.2101 - val_mse: 13.2101\n",
      "Epoch 228/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 12.8544 - val_mse: 12.8544\n",
      "Epoch 229/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 12.1016 - val_mse: 12.1016\n",
      "Epoch 230/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 12.0269 - val_mse: 12.0269\n",
      "Epoch 231/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 11.6851 - val_mse: 11.6851\n",
      "Epoch 232/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 11.2235 - val_mse: 11.2235\n",
      "Epoch 233/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 10.8074 - val_mse: 10.8074\n",
      "Epoch 234/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 10.2583 - val_mse: 10.2583\n",
      "Epoch 235/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 9.8753 - val_mse: 9.8753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 9.7587 - val_mse: 9.7587\n",
      "Epoch 237/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 9.4905 - val_mse: 9.4905\n",
      "Epoch 238/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 9.5458 - val_mse: 9.5458\n",
      "Epoch 239/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 9.1596 - val_mse: 9.1596\n",
      "Epoch 240/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 8.8505 - val_mse: 8.8505\n",
      "Epoch 241/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 8.4880 - val_mse: 8.4880\n",
      "Epoch 242/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 8.2567 - val_mse: 8.2567\n",
      "Epoch 243/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 8.1002 - val_mse: 8.1002\n",
      "Epoch 244/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 7.8008 - val_mse: 7.8008\n",
      "Epoch 245/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 7.5964 - val_mse: 7.5964\n",
      "Epoch 246/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 7.3822 - val_mse: 7.3822\n",
      "Epoch 247/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 7.0631 - val_mse: 7.0631\n",
      "Epoch 248/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 6.4491 - val_mse: 6.4491\n",
      "Epoch 249/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 6.7667 - val_mse: 6.7667\n",
      "Epoch 250/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 6.4207 - val_mse: 6.4207\n",
      "Epoch 251/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 6.2722 - val_mse: 6.2722\n",
      "Epoch 252/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 5.9101 - val_mse: 5.9101\n",
      "Epoch 253/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 5.7410 - val_mse: 5.7410\n",
      "Epoch 254/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 5.3961 - val_mse: 5.3961\n",
      "Epoch 255/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 5.6043 - val_mse: 5.6043\n",
      "Epoch 256/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 5.3263 - val_mse: 5.3263\n",
      "Epoch 257/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 5.0300 - val_mse: 5.0300\n",
      "Epoch 258/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 4.8809 - val_mse: 4.8809\n",
      "Epoch 259/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 4.5945 - val_mse: 4.5945\n",
      "Epoch 260/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 4.5437 - val_mse: 4.5437\n",
      "Epoch 261/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 4.2576 - val_mse: 4.2576\n",
      "Epoch 262/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 4.1260 - val_mse: 4.1260\n",
      "Epoch 263/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 4.0860 - val_mse: 4.0860\n",
      "Epoch 264/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 4.0613 - val_mse: 4.0613\n",
      "Epoch 265/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 3.9592 - val_mse: 3.9592\n",
      "Epoch 266/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 3.5961 - val_mse: 3.5961\n",
      "Epoch 267/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 3.4736 - val_mse: 3.4736\n",
      "Epoch 268/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 3.3569 - val_mse: 3.3569\n",
      "Epoch 269/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 3.2450 - val_mse: 3.2450\n",
      "Epoch 270/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 3.1934 - val_mse: 3.1934\n",
      "Epoch 271/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 3.0908 - val_mse: 3.0908\n",
      "Epoch 272/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 2.9579 - val_mse: 2.9579\n",
      "Epoch 273/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 2.8872 - val_mse: 2.8872\n",
      "Epoch 274/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 2.7322 - val_mse: 2.7322\n",
      "Epoch 275/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 2.6501 - val_mse: 2.6501\n",
      "Epoch 276/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 2.3733 - val_mse: 2.3733\n",
      "Epoch 277/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 2.3263 - val_mse: 2.3263\n",
      "Epoch 278/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 2.3189 - val_mse: 2.3189\n",
      "Epoch 279/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 2.2630 - val_mse: 2.2630\n",
      "Epoch 280/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 2.1417 - val_mse: 2.1417\n",
      "Epoch 281/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 2.0484 - val_mse: 2.0484\n",
      "Epoch 282/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 1.9756 - val_mse: 1.9756\n",
      "Epoch 283/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.8423 - val_mse: 1.8423\n",
      "Epoch 284/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.8771 - val_mse: 1.8771\n",
      "Epoch 285/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 1.9062 - val_mse: 1.9062\n",
      "Epoch 286/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.7026 - val_mse: 1.7026\n",
      "Epoch 287/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.5755 - val_mse: 1.5755\n",
      "Epoch 288/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 1.5260 - val_mse: 1.5260\n",
      "Epoch 289/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.4358 - val_mse: 1.4358\n",
      "Epoch 290/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.4369 - val_mse: 1.4369\n",
      "Epoch 291/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.4065 - val_mse: 1.4065\n",
      "Epoch 292/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.3723 - val_mse: 1.3723\n",
      "Epoch 293/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 1.2314 - val_mse: 1.2314\n",
      "Epoch 294/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.3363e-04 - mse: 9.3363e-04 - val_loss: 1.1663 - val_mse: 1.1663\n",
      "Epoch 295/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 1.1896 - val_mse: 1.1896\n",
      "Epoch 296/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.2970e-04 - mse: 9.2970e-04 - val_loss: 1.1997 - val_mse: 1.1997\n",
      "Epoch 297/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 1.0514 - val_mse: 1.0514\n",
      "Epoch 298/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.3506e-04 - mse: 9.3506e-04 - val_loss: 1.0024 - val_mse: 1.0024\n",
      "Epoch 299/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.9818e-04 - mse: 7.9818e-04 - val_loss: 0.9293 - val_mse: 0.9293\n",
      "Epoch 300/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.9476 - val_mse: 0.9476\n",
      "10/10 [==============================] - 0s 586us/step - loss: 0.9476 - mse: 0.9476\n",
      "loss :  0.9475603103637695\n",
      "결과물 : \n",
      " [[100.07132 ]\n",
      " [101.06147 ]\n",
      " [102.05161 ]\n",
      " [103.04176 ]\n",
      " [104.03192 ]\n",
      " [105.022064]\n",
      " [106.0122  ]\n",
      " [107.00235 ]\n",
      " [107.9925  ]\n",
      " [108.98265 ]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np \n",
    "\n",
    "x_train = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "y_train = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "x_test = np.array([101, 102, 103, 104, 105, 106, 107, 108, 109, 110])\n",
    "y_test = np.array([101, 102, 103, 104, 105, 106, 107, 108, 109, 110])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=1, activation='relu'))\n",
    "model.add(Dense(3))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=300, batch_size=1, validation_data=(x_test, y_test))\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test, batch_size=1)\n",
    "\n",
    "print('loss : ', loss)\n",
    "y_predict = model.predict(x_test)\n",
    "print('결과물 : \\n', y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원래 데이터에서 평균을 뺀값을 제곱하여 모두 더한 뒤 전체 개수로 나눈 값에 루트를 씌운 값   \n",
    "여기서는 실제 데이터와 예측한 값을 뺀 값을 제곱하여 더한뒤 평균에 루트를 씌운 값  \n",
    "회귀 분석 모델을 만들때 RMSE 는 낮을 수록 정밀도가 높다고 판단함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  0.9734262751584412\n"
     ]
    }
   ],
   "source": [
    "# RMSE 구하기 \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def RMSE(y_test, y_predict):\n",
    "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "\n",
    "print('RMSE : ', RMSE(y_test ,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이어서 RMSE와 함께 회귀 분석에서 가장 많이 쓰이는 지표인 R2를 구해봄  \n",
    "R2는 R2, R2 score, R 제곱, 설명력, 결정계수 등으로 불리는데 보통 `R2`, `결정계수` 로 많이 불림  \n",
    "회귀 분석에서는 가장 많이 사용하는 지표이고, RMSE와 반대로 높을 수록 좋은 지표이며 최댓값은 1  \n",
    "\n",
    "R2 score 는 사이킷 런에서 제공함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  0.8851443984037773\n"
     ]
    }
   ],
   "source": [
    "# R1 구하기 \n",
    "from sklearn.metrics import r2_score\n",
    "r2_y_predict = r2_score(y_test, y_predict)\n",
    "print(\"R2 : \", r2_y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀모델 추가 코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation 추가\n",
    "앞선 코드에서는 모델을 학습시킬때, 검증데이터를 test 로 하였음.  \n",
    "훈련세트에 검증 데이터가 들어가고, 검증 데이터로 다시 테스트 한다는 것은 평가에 검증데이터가 반영된다는 문제가 있음  \n",
    "그래서 일반적으로는 Train데이터의 일부분을 검증데이터로 사용하고, Test 데이터는 건들이지 않음 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 43.4273 - mse: 43.4273 - val_loss: 10307.2354 - val_mse: 10307.2354\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 28.8485 - mse: 28.8485 - val_loss: 9608.0840 - val_mse: 9608.0840\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 26.7694 - mse: 26.7694 - val_loss: 8892.8115 - val_mse: 8892.8115\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 24.4490 - mse: 24.4490 - val_loss: 8174.1357 - val_mse: 8174.1357\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 29.3007 - mse: 29.3007 - val_loss: 7438.3447 - val_mse: 7438.3447\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 21.8957 - mse: 21.8957 - val_loss: 6724.5674 - val_mse: 6724.5674\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 17.3657 - mse: 17.3657 - val_loss: 6004.2085 - val_mse: 6004.2085\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 19.9398 - mse: 19.9398 - val_loss: 5262.4624 - val_mse: 5262.4624\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 11.7626 - mse: 11.7626 - val_loss: 4569.2178 - val_mse: 4569.2178\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.9687 - mse: 6.9687 - val_loss: 3900.1333 - val_mse: 3900.1333\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 16.2364 - mse: 16.2364 - val_loss: 3169.4690 - val_mse: 3169.4690\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 10.6072 - mse: 10.6072 - val_loss: 2591.3132 - val_mse: 2591.3132\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.4008 - mse: 4.4008 - val_loss: 2112.3745 - val_mse: 2112.3745\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.1011 - mse: 6.1011 - val_loss: 1649.9548 - val_mse: 1649.9548\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9040 - mse: 2.9040 - val_loss: 1289.9891 - val_mse: 1289.9891\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3793 - mse: 1.3793 - val_loss: 1003.9177 - val_mse: 1003.9177\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4764 - mse: 1.4764 - val_loss: 770.0804 - val_mse: 770.0804\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7849 - mse: 0.7849 - val_loss: 604.6232 - val_mse: 604.6232\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4854 - mse: 0.4854 - val_loss: 484.1557 - val_mse: 484.1557\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2750 - mse: 0.2750 - val_loss: 407.4250 - val_mse: 407.4250\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4239 - mse: 0.4239 - val_loss: 327.8729 - val_mse: 327.8729\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2995 - mse: 0.2995 - val_loss: 288.8287 - val_mse: 288.8287\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2026 - mse: 0.2026 - val_loss: 266.4980 - val_mse: 266.4980\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2601 - mse: 0.2601 - val_loss: 246.7240 - val_mse: 246.7240\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2217 - mse: 0.2217 - val_loss: 236.3611 - val_mse: 236.3611\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2259 - mse: 0.2259 - val_loss: 223.5499 - val_mse: 223.5499\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2046 - mse: 0.2046 - val_loss: 217.0726 - val_mse: 217.0726\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2386 - mse: 0.2386 - val_loss: 217.2395 - val_mse: 217.2395\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2415 - mse: 0.2415 - val_loss: 214.1658 - val_mse: 214.1658\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3093 - mse: 0.3093 - val_loss: 214.9191 - val_mse: 214.9191\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2445 - mse: 0.2445 - val_loss: 211.4442 - val_mse: 211.4442\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1859 - mse: 0.1859 - val_loss: 205.1110 - val_mse: 205.1110\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2684 - mse: 0.2684 - val_loss: 198.5743 - val_mse: 198.5743\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2196 - mse: 0.2196 - val_loss: 200.5247 - val_mse: 200.5247\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1575 - mse: 0.1575 - val_loss: 196.3441 - val_mse: 196.3441\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3278 - mse: 0.3278 - val_loss: 196.9353 - val_mse: 196.9353\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1323 - mse: 0.1323 - val_loss: 188.1808 - val_mse: 188.1808\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1677 - mse: 0.1677 - val_loss: 181.4216 - val_mse: 181.4216\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1800 - mse: 0.1800 - val_loss: 181.8322 - val_mse: 181.8322\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1570 - mse: 0.1570 - val_loss: 176.4589 - val_mse: 176.4589\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2093 - mse: 0.2093 - val_loss: 174.5305 - val_mse: 174.5305\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2559 - mse: 0.2559 - val_loss: 174.4371 - val_mse: 174.4371\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1531 - mse: 0.1531 - val_loss: 166.3078 - val_mse: 166.3078\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1507 - mse: 0.1507 - val_loss: 162.0074 - val_mse: 162.0074\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1096 - mse: 0.1096 - val_loss: 166.5475 - val_mse: 166.5475\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1886 - mse: 0.1886 - val_loss: 158.3253 - val_mse: 158.3253\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1946 - mse: 0.1946 - val_loss: 155.3732 - val_mse: 155.3732\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2153 - mse: 0.2153 - val_loss: 151.8376 - val_mse: 151.8376\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2012 - mse: 0.2012 - val_loss: 146.8822 - val_mse: 146.8822\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1618 - mse: 0.1618 - val_loss: 150.3951 - val_mse: 150.3951\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1175 - mse: 0.1175 - val_loss: 140.3979 - val_mse: 140.3979\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2014 - mse: 0.2014 - val_loss: 138.6060 - val_mse: 138.6060\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1386 - mse: 0.1386 - val_loss: 134.0987 - val_mse: 134.0987\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2215 - mse: 0.2215 - val_loss: 132.7481 - val_mse: 132.7481\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1254 - mse: 0.1254 - val_loss: 125.0149 - val_mse: 125.0149\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1871 - mse: 0.1871 - val_loss: 124.0866 - val_mse: 124.0866\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1928 - mse: 0.1928 - val_loss: 126.3237 - val_mse: 126.3237\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1465 - mse: 0.1465 - val_loss: 122.5984 - val_mse: 122.5984\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0646 - mse: 0.0646 - val_loss: 118.2500 - val_mse: 118.2500\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1098 - mse: 0.1098 - val_loss: 111.8633 - val_mse: 111.8633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1176 - mse: 0.1176 - val_loss: 113.5715 - val_mse: 113.5715\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0963 - mse: 0.0963 - val_loss: 109.7788 - val_mse: 109.7788\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1102 - mse: 0.1102 - val_loss: 108.9879 - val_mse: 108.9879\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1185 - mse: 0.1185 - val_loss: 109.4442 - val_mse: 109.4442\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0905 - mse: 0.0905 - val_loss: 103.2494 - val_mse: 103.2494\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1202 - mse: 0.1202 - val_loss: 96.1043 - val_mse: 96.1043\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1109 - mse: 0.1109 - val_loss: 97.2203 - val_mse: 97.2203\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0747 - mse: 0.0747 - val_loss: 94.5895 - val_mse: 94.5895\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0745 - mse: 0.0745 - val_loss: 91.5690 - val_mse: 91.5690\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0576 - mse: 0.0576 - val_loss: 86.0518 - val_mse: 86.0518\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0677 - mse: 0.0677 - val_loss: 87.5186 - val_mse: 87.5186\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0755 - mse: 0.0755 - val_loss: 81.8223 - val_mse: 81.8223\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1001 - mse: 0.1001 - val_loss: 81.7327 - val_mse: 81.7327\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0676 - mse: 0.0676 - val_loss: 83.5900 - val_mse: 83.5900\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0704 - mse: 0.0704 - val_loss: 77.9356 - val_mse: 77.9356\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0877 - mse: 0.0877 - val_loss: 77.1540 - val_mse: 77.1540\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0888 - mse: 0.0888 - val_loss: 75.0529 - val_mse: 75.0529\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0474 - mse: 0.0474 - val_loss: 69.3439 - val_mse: 69.3439\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0573 - mse: 0.0573 - val_loss: 66.8076 - val_mse: 66.8076\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0864 - mse: 0.0864 - val_loss: 66.2132 - val_mse: 66.2132\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0635 - mse: 0.0635 - val_loss: 62.5175 - val_mse: 62.5175\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0561 - mse: 0.0561 - val_loss: 62.0800 - val_mse: 62.0800\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0548 - mse: 0.0548 - val_loss: 60.8397 - val_mse: 60.8397\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0642 - mse: 0.0642 - val_loss: 58.5616 - val_mse: 58.5616\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0894 - mse: 0.0894 - val_loss: 58.2240 - val_mse: 58.2240\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 55.8849 - val_mse: 55.8849\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0960 - mse: 0.0960 - val_loss: 55.0978 - val_mse: 55.0978\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0523 - mse: 0.0523 - val_loss: 50.9323 - val_mse: 50.9323\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 49.6676 - val_mse: 49.6676\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 48.7495 - val_mse: 48.7495\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0730 - mse: 0.0730 - val_loss: 45.7556 - val_mse: 45.7556\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0457 - mse: 0.0457 - val_loss: 45.6271 - val_mse: 45.6271\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0615 - mse: 0.0615 - val_loss: 47.8770 - val_mse: 47.8770\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 40.8485 - val_mse: 40.8485\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 39.8900 - val_mse: 39.8900\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 39.0777 - val_mse: 39.0777\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 37.9093 - val_mse: 37.9093\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 38.2573 - val_mse: 38.2573\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 34.3383 - val_mse: 34.3383\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 32.4413 - val_mse: 32.4413\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 32.8406 - val_mse: 32.8406\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 31.8723 - val_mse: 31.8723\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 31.0814 - val_mse: 31.0814\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 31.2817 - val_mse: 31.2817\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 27.6522 - val_mse: 27.6522\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 26.3263 - val_mse: 26.3263\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 25.7600 - val_mse: 25.7600\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 24.8532 - val_mse: 24.8532\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 24.0135 - val_mse: 24.0135\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 24.9667 - val_mse: 24.9667\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 21.9595 - val_mse: 21.9595\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 19.8963 - val_mse: 19.8963\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 20.1204 - val_mse: 20.1204\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 21.2251 - val_mse: 21.2251\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 19.2212 - val_mse: 19.2212\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 18.3508 - val_mse: 18.3508\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 16.1207 - val_mse: 16.1207\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 16.4926 - val_mse: 16.4926\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 15.2450 - val_mse: 15.2450\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 16.6382 - val_mse: 16.6382\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 15.8190 - val_mse: 15.8190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 13.2626 - val_mse: 13.2626\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 11.9045 - val_mse: 11.9045\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 13.5143 - val_mse: 13.5143\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 11.5991 - val_mse: 11.5991\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 11.7932 - val_mse: 11.7932\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 10.6873 - val_mse: 10.6873\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 10.8121 - val_mse: 10.8121\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 10.6277 - val_mse: 10.6277\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 9.1048 - val_mse: 9.1048\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 9.4522 - val_mse: 9.4522\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 9.1332 - val_mse: 9.1332\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 7.9708 - val_mse: 7.9708\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 8.4070 - val_mse: 8.4070\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 7.2769 - val_mse: 7.2769\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 6.6960 - val_mse: 6.6960\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 6.4253 - val_mse: 6.4253\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 6.5785 - val_mse: 6.5785\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 6.4741 - val_mse: 6.4741\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 6.4939 - val_mse: 6.4939\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 5.2187 - val_mse: 5.2187\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 5.0358 - val_mse: 5.0358\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 5.1727 - val_mse: 5.1727\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 4.6324 - val_mse: 4.6324\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 4.4748 - val_mse: 4.4748\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 4.6656 - val_mse: 4.6656\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 4.1807 - val_mse: 4.1807\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 3.8132 - val_mse: 3.8132\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 3.7849 - val_mse: 3.7849\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 3.3175 - val_mse: 3.3175\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 3.1976 - val_mse: 3.1976\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 3.1564 - val_mse: 3.1564\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 2.7350 - val_mse: 2.7350\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 2.9871 - val_mse: 2.9871\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 2.6389 - val_mse: 2.6389\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 2.4071 - val_mse: 2.4071\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 2.1055 - val_mse: 2.1055\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 2.3165 - val_mse: 2.3165\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.3049 - val_mse: 2.3049\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.9646 - val_mse: 1.9646\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 1.9514 - val_mse: 1.9514\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.6353 - val_mse: 1.6353\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 1.4759 - val_mse: 1.4759\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.5060 - val_mse: 1.5060\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.4765 - val_mse: 1.4765\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 1.4750 - val_mse: 1.4750\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 1.3047 - val_mse: 1.3047\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 1.0413 - val_mse: 1.0413\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.1686e-04 - mse: 9.1686e-04 - val_loss: 1.0474 - val_mse: 1.0474\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.1624 - val_mse: 1.1624\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.5437e-04 - mse: 7.5437e-04 - val_loss: 1.0252 - val_mse: 1.0252\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.0251e-04 - mse: 9.0251e-04 - val_loss: 0.9139 - val_mse: 0.9139\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.8992 - val_mse: 0.8992\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.8425e-04 - mse: 8.8425e-04 - val_loss: 0.8278 - val_mse: 0.8278\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.2065e-04 - mse: 9.2065e-04 - val_loss: 0.7981 - val_mse: 0.7981\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.0448e-04 - mse: 9.0448e-04 - val_loss: 0.6641 - val_mse: 0.6641\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.1616e-04 - mse: 7.1616e-04 - val_loss: 0.6680 - val_mse: 0.6680\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.5059e-04 - mse: 8.5059e-04 - val_loss: 0.6462 - val_mse: 0.6462\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.6748e-04 - mse: 4.6748e-04 - val_loss: 0.5527 - val_mse: 0.5527\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.9578e-04 - mse: 4.9578e-04 - val_loss: 0.5417 - val_mse: 0.5417\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9679e-04 - mse: 3.9679e-04 - val_loss: 0.5087 - val_mse: 0.5087\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.0093e-04 - mse: 4.0093e-04 - val_loss: 0.5386 - val_mse: 0.5386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.2659e-04 - mse: 6.2659e-04 - val_loss: 0.4198 - val_mse: 0.4198\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9216e-04 - mse: 3.9216e-04 - val_loss: 0.3857 - val_mse: 0.3857\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.0415e-04 - mse: 6.0415e-04 - val_loss: 0.3700 - val_mse: 0.3700\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9344e-04 - mse: 3.9344e-04 - val_loss: 0.3763 - val_mse: 0.3763\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.8822e-04 - mse: 3.8822e-04 - val_loss: 0.3505 - val_mse: 0.3505\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.7635e-04 - mse: 4.7635e-04 - val_loss: 0.3396 - val_mse: 0.3396\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.3070e-04 - mse: 3.3070e-04 - val_loss: 0.2791 - val_mse: 0.2791\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8628e-04 - mse: 2.8628e-04 - val_loss: 0.2733 - val_mse: 0.2733\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.6713e-04 - mse: 2.6713e-04 - val_loss: 0.2168 - val_mse: 0.2168\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.7114e-04 - mse: 3.7114e-04 - val_loss: 0.2314 - val_mse: 0.2314\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.4482e-04 - mse: 2.4482e-04 - val_loss: 0.2156 - val_mse: 0.2156\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1260e-04 - mse: 2.1260e-04 - val_loss: 0.2107 - val_mse: 0.2107\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6508e-04 - mse: 1.6508e-04 - val_loss: 0.1997 - val_mse: 0.1997\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2540e-04 - mse: 2.2540e-04 - val_loss: 0.1648 - val_mse: 0.1648\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3987e-04 - mse: 2.3987e-04 - val_loss: 0.1698 - val_mse: 0.1698\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3723e-04 - mse: 1.3723e-04 - val_loss: 0.1588 - val_mse: 0.1588\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.4932e-05 - mse: 8.4932e-05 - val_loss: 0.1256 - val_mse: 0.1256\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2560e-04 - mse: 1.2560e-04 - val_loss: 0.1240 - val_mse: 0.1240\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6315e-04 - mse: 1.6315e-04 - val_loss: 0.1156 - val_mse: 0.1156\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.1570e-05 - mse: 7.1570e-05 - val_loss: 0.1135 - val_mse: 0.1135\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2732e-04 - mse: 1.2732e-04 - val_loss: 0.0969 - val_mse: 0.0969\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2735e-04 - mse: 1.2735e-04 - val_loss: 0.1047 - val_mse: 0.1047\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0077e-04 - mse: 1.0077e-04 - val_loss: 0.0831 - val_mse: 0.0831\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0425e-04 - mse: 1.0425e-04 - val_loss: 0.0692 - val_mse: 0.0692\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3519e-04 - mse: 1.3519e-04 - val_loss: 0.0740 - val_mse: 0.0740\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.1765e-05 - mse: 9.1765e-05 - val_loss: 0.0727 - val_mse: 0.0727\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.1719e-05 - mse: 7.1719e-05 - val_loss: 0.0593 - val_mse: 0.0593\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.7975e-05 - mse: 6.7975e-05 - val_loss: 0.0650 - val_mse: 0.0650\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.8541e-05 - mse: 8.8541e-05 - val_loss: 0.0469 - val_mse: 0.0469\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.5140e-05 - mse: 6.5140e-05 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.3272e-05 - mse: 7.3272e-05 - val_loss: 0.0418 - val_mse: 0.0418\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.8682e-05 - mse: 3.8682e-05 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.5857e-05 - mse: 3.5857e-05 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.6777e-05 - mse: 3.6777e-05 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.4339e-05 - mse: 2.4339e-05 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.0150e-05 - mse: 4.0150e-05 - val_loss: 0.0321 - val_mse: 0.0321\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8544e-05 - mse: 1.8544e-05 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.4887e-05 - mse: 4.4887e-05 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0973e-05 - mse: 2.0973e-05 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.1343e-05 - mse: 3.1343e-05 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.7565e-05 - mse: 3.7565e-05 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2037e-05 - mse: 2.2037e-05 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1724e-05 - mse: 1.1724e-05 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.4475e-06 - mse: 9.4475e-06 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.5005e-05 - mse: 2.5005e-05 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.4798e-06 - mse: 7.4798e-06 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.9792e-06 - mse: 8.9792e-06 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0682e-05 - mse: 1.0682e-05 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3778e-05 - mse: 1.3778e-05 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3397e-05 - mse: 1.3397e-05 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.6270e-06 - mse: 9.6270e-06 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0115e-05 - mse: 1.0115e-05 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.7860e-06 - mse: 4.7860e-06 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.1308e-06 - mse: 9.1308e-06 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.5357e-06 - mse: 4.5357e-06 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.9724e-06 - mse: 4.9724e-06 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.5440e-06 - mse: 3.5440e-06 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.9033e-06 - mse: 4.9033e-06 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.4369e-06 - mse: 4.4369e-06 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.0458e-06 - mse: 4.0458e-06 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.1799e-06 - mse: 3.1799e-06 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.6773e-06 - mse: 4.6773e-06 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.3205e-06 - mse: 3.3205e-06 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3734e-06 - mse: 2.3734e-06 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3771e-06 - mse: 1.3771e-06 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.1290e-06 - mse: 3.1290e-06 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9798e-06 - mse: 2.9798e-06 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3074e-06 - mse: 2.3074e-06 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1014e-06 - mse: 1.1014e-06 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3632e-06 - mse: 1.3632e-06 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0582e-06 - mse: 1.0582e-06 - val_loss: 8.8899e-04 - val_mse: 8.8899e-04\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.2185e-07 - mse: 7.2185e-07 - val_loss: 8.0628e-04 - val_mse: 8.0628e-04\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0543e-06 - mse: 1.0543e-06 - val_loss: 9.2056e-04 - val_mse: 9.2056e-04\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.8189e-07 - mse: 7.8189e-07 - val_loss: 7.2589e-04 - val_mse: 7.2589e-04\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.8178e-07 - mse: 9.8178e-07 - val_loss: 6.4266e-04 - val_mse: 6.4266e-04\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1416e-06 - mse: 1.1416e-06 - val_loss: 5.8343e-04 - val_mse: 5.8343e-04\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.2898e-07 - mse: 4.2898e-07 - val_loss: 4.8163e-04 - val_mse: 4.8163e-04\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.0406e-07 - mse: 6.0406e-07 - val_loss: 4.4872e-04 - val_mse: 4.4872e-04\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.0483e-07 - mse: 7.0483e-07 - val_loss: 3.8856e-04 - val_mse: 3.8856e-04\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.9838e-07 - mse: 6.9838e-07 - val_loss: 4.0910e-04 - val_mse: 4.0910e-04\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.5741e-07 - mse: 4.5741e-07 - val_loss: 3.2103e-04 - val_mse: 3.2103e-04\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.9079e-07 - mse: 4.9079e-07 - val_loss: 2.4458e-04 - val_mse: 2.4458e-04\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.4254e-07 - mse: 2.4254e-07 - val_loss: 2.7194e-04 - val_mse: 2.7194e-04\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1787e-07 - mse: 2.1787e-07 - val_loss: 2.6832e-04 - val_mse: 2.6832e-04\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8351e-07 - mse: 1.8351e-07 - val_loss: 2.3032e-04 - val_mse: 2.3032e-04\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9513e-07 - mse: 1.9513e-07 - val_loss: 1.8438e-04 - val_mse: 1.8438e-04\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.4432e-07 - mse: 2.4432e-07 - val_loss: 1.7805e-04 - val_mse: 1.7805e-04\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0912e-07 - mse: 2.0912e-07 - val_loss: 1.4983e-04 - val_mse: 1.4983e-04\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9876e-07 - mse: 1.9876e-07 - val_loss: 1.3324e-04 - val_mse: 1.3324e-04\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0578e-07 - mse: 2.0578e-07 - val_loss: 1.1650e-04 - val_mse: 1.1650e-04\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8462e-07 - mse: 1.8462e-07 - val_loss: 1.0765e-04 - val_mse: 1.0765e-04\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3333e-07 - mse: 1.3333e-07 - val_loss: 9.0475e-05 - val_mse: 9.0475e-05\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.0942e-08 - mse: 8.0942e-08 - val_loss: 7.8178e-05 - val_mse: 7.8178e-05\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1237e-07 - mse: 1.1237e-07 - val_loss: 7.9044e-05 - val_mse: 7.9044e-05\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.8138e-08 - mse: 8.8138e-08 - val_loss: 5.3344e-05 - val_mse: 5.3344e-05\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.1426e-08 - mse: 5.1426e-08 - val_loss: 6.2077e-05 - val_mse: 6.2077e-05\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.3433e-08 - mse: 4.3433e-08 - val_loss: 5.2566e-05 - val_mse: 5.2566e-05\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.3791e-08 - mse: 3.3791e-08 - val_loss: 4.5931e-05 - val_mse: 4.5931e-05\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.8120e-08 - mse: 5.8120e-08 - val_loss: 3.5585e-05 - val_mse: 3.5585e-05\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.7642e-08 - mse: 4.7642e-08 - val_loss: 3.8861e-05 - val_mse: 3.8861e-05\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3538e-08 - mse: 2.3538e-08 - val_loss: 2.6307e-05 - val_mse: 2.6307e-05\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2270e-08 - mse: 2.2270e-08 - val_loss: 2.6700e-05 - val_mse: 2.6700e-05\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.6708e-08 - mse: 2.6708e-08 - val_loss: 3.1830e-05 - val_mse: 3.1830e-05\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.4472e-08 - mse: 3.4472e-08 - val_loss: 1.6851e-05 - val_mse: 1.6851e-05\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.7648e-08 - mse: 3.7648e-08 - val_loss: 1.8218e-05 - val_mse: 1.8218e-05\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8587e-08 - mse: 1.8587e-08 - val_loss: 1.4520e-05 - val_mse: 1.4520e-05\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1879e-08 - mse: 1.1879e-08 - val_loss: 1.3854e-05 - val_mse: 1.3854e-05\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6429e-08 - mse: 1.6429e-08 - val_loss: 1.3236e-05 - val_mse: 1.3236e-05\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.9864e-09 - mse: 8.9864e-09 - val_loss: 1.2021e-05 - val_mse: 1.2021e-05\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5451e-08 - mse: 1.5451e-08 - val_loss: 8.7733e-06 - val_mse: 8.7733e-06\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.8627e-09 - mse: 7.8627e-09 - val_loss: 8.1612e-06 - val_mse: 8.1612e-06\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2336e-08 - mse: 1.2336e-08 - val_loss: 6.8653e-06 - val_mse: 6.8653e-06\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.4380e-09 - mse: 6.4380e-09 - val_loss: 6.7939e-06 - val_mse: 6.7939e-06\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.9023e-09 - mse: 6.9023e-09 - val_loss: 4.6628e-06 - val_mse: 4.6628e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.5485e-09 - mse: 5.5485e-09 - val_loss: 5.6165e-06 - val_mse: 5.6165e-06\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.6318e-09 - mse: 3.6318e-09 - val_loss: 3.1880e-06 - val_mse: 3.1880e-06\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9079e-09 - mse: 3.9079e-09 - val_loss: 3.8511e-06 - val_mse: 3.8511e-06\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.8937e-09 - mse: 4.8937e-09 - val_loss: 3.4776e-06 - val_mse: 3.4776e-06\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8805e-09 - mse: 2.8805e-09 - val_loss: 2.0056e-06 - val_mse: 2.0056e-06\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.5117e-09 - mse: 3.5117e-09 - val_loss: 2.3241e-06 - val_mse: 2.3241e-06\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3619e-09 - mse: 2.3619e-09 - val_loss: 2.2918e-06 - val_mse: 2.2918e-06\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8102e-09 - mse: 1.8102e-09 - val_loss: 1.6943e-06 - val_mse: 1.6943e-06\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1220e-09 - mse: 1.1220e-09 - val_loss: 1.3418e-06 - val_mse: 1.3418e-06\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2020e-09 - mse: 1.2020e-09 - val_loss: 1.5317e-06 - val_mse: 1.5317e-06\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1335e-09 - mse: 2.1335e-09 - val_loss: 1.1543e-06 - val_mse: 1.1543e-06\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0928e-09 - mse: 1.0928e-09 - val_loss: 7.0197e-07 - val_mse: 7.0197e-07\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1521e-09 - mse: 1.1521e-09 - val_loss: 7.7803e-07 - val_mse: 7.7803e-07\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.8891e-10 - mse: 6.8891e-10 - val_loss: 7.9446e-07 - val_mse: 7.9446e-07\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.6899e-10 - mse: 8.6899e-10 - val_loss: 7.3299e-07 - val_mse: 7.3299e-07\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.7577e-10 - mse: 7.7577e-10 - val_loss: 4.2456e-07 - val_mse: 4.2456e-07\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.1314e-10 - mse: 4.1314e-10 - val_loss: 4.6949e-07 - val_mse: 4.6949e-07\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.4896e-10 - mse: 4.4896e-10 - val_loss: 4.6535e-07 - val_mse: 4.6535e-07\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.3843e-10 - mse: 4.3843e-10 - val_loss: 4.2657e-07 - val_mse: 4.2657e-07\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8908e-10 - mse: 2.8908e-10 - val_loss: 2.3847e-07 - val_mse: 2.3847e-07\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4908e-10 - mse: 5.4908e-10 - val_loss: 2.4145e-07 - val_mse: 2.4145e-07\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9257e-10 - mse: 1.9257e-10 - val_loss: 2.3253e-07 - val_mse: 2.3253e-07\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.5859e-10 - mse: 2.5859e-10 - val_loss: 2.1809e-07 - val_mse: 2.1809e-07\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.7962e-10 - mse: 2.7962e-10 - val_loss: 1.8259e-07 - val_mse: 1.8259e-07\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9619e-10 - mse: 1.9619e-10 - val_loss: 1.7236e-07 - val_mse: 1.7236e-07\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4048e-10 - mse: 1.4048e-10 - val_loss: 1.4444e-07 - val_mse: 1.4444e-07\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.2104e-11 - mse: 9.2104e-11 - val_loss: 1.3870e-07 - val_mse: 1.3870e-07\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8043e-10 - mse: 1.8043e-10 - val_loss: 1.1382e-07 - val_mse: 1.1382e-07\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2275e-10 - mse: 1.2275e-10 - val_loss: 9.1316e-08 - val_mse: 9.1316e-08\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.7675e-11 - mse: 6.7675e-11 - val_loss: 7.7160e-08 - val_mse: 7.7160e-08\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.8585e-11 - mse: 7.8585e-11 - val_loss: 7.1304e-08 - val_mse: 7.1304e-08\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.7052e-11 - mse: 5.7052e-11 - val_loss: 7.0501e-08 - val_mse: 7.0501e-08\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.3833e-11 - mse: 3.3833e-11 - val_loss: 5.3830e-08 - val_mse: 5.3830e-08\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.3689e-11 - mse: 7.3689e-11 - val_loss: 5.3120e-08 - val_mse: 5.3120e-08\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.5141e-11 - mse: 4.5141e-11 - val_loss: 4.1840e-08 - val_mse: 4.1840e-08\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.4640e-11 - mse: 4.4640e-11 - val_loss: 4.1223e-08 - val_mse: 4.1223e-08\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.4420e-11 - mse: 3.4420e-11 - val_loss: 3.9989e-08 - val_mse: 3.9989e-08\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.5447e-11 - mse: 4.5447e-11 - val_loss: 4.0606e-08 - val_mse: 4.0606e-08\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.4199e-11 - mse: 4.4199e-11 - val_loss: 3.0815e-08 - val_mse: 3.0815e-08\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.0724e-11 - mse: 3.0724e-11 - val_loss: 2.8196e-08 - val_mse: 2.8196e-08\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.7355e-11 - mse: 2.7355e-11 - val_loss: 2.5693e-08 - val_mse: 2.5693e-08\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3899e-11 - mse: 2.3899e-11 - val_loss: 1.9791e-08 - val_mse: 1.9791e-08\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6231e-11 - mse: 1.6231e-11 - val_loss: 1.9791e-08 - val_mse: 1.9791e-08\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9522e-11 - mse: 2.9522e-11 - val_loss: 1.7253e-08 - val_mse: 1.7253e-08\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7638e-11 - mse: 1.7638e-11 - val_loss: 1.4971e-08 - val_mse: 1.4971e-08\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1120e-11 - mse: 2.1120e-11 - val_loss: 1.4971e-08 - val_mse: 1.4971e-08\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.0447e-12 - mse: 9.0447e-12 - val_loss: 1.4226e-08 - val_mse: 1.4226e-08\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2948e-11 - mse: 1.2948e-11 - val_loss: 1.3865e-08 - val_mse: 1.3865e-08\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4152e-11 - mse: 1.4152e-11 - val_loss: 1.2806e-08 - val_mse: 1.2806e-08\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.8790e-12 - mse: 8.8790e-12 - val_loss: 1.2491e-08 - val_mse: 1.2491e-08\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0561e-11 - mse: 1.0561e-11 - val_loss: 1.0850e-08 - val_mse: 1.0850e-08\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.5658e-12 - mse: 8.5658e-12 - val_loss: 9.9069e-09 - val_mse: 9.9069e-09\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.4154e-12 - mse: 6.4154e-12 - val_loss: 7.8697e-09 - val_mse: 7.8697e-09\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.6437e-12 - mse: 7.6437e-12 - val_loss: 7.6252e-09 - val_mse: 7.6252e-09\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.4010e-12 - mse: 7.4010e-12 - val_loss: 6.7987e-09 - val_mse: 6.7987e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.1375e-12 - mse: 8.1375e-12 - val_loss: 5.8440e-09 - val_mse: 5.8440e-09\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.8851e-12 - mse: 6.8851e-12 - val_loss: 5.8440e-09 - val_mse: 5.8440e-09\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5430e-12 - mse: 5.5430e-12 - val_loss: 5.6229e-09 - val_mse: 5.6229e-09\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.7499e-12 - mse: 5.7499e-12 - val_loss: 5.4017e-09 - val_mse: 5.4017e-09\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9037e-12 - mse: 3.9037e-12 - val_loss: 5.4017e-09 - val_mse: 5.4017e-09\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.1379e-12 - mse: 4.1379e-12 - val_loss: 5.4017e-09 - val_mse: 5.4017e-09\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.5431e-12 - mse: 3.5431e-12 - val_loss: 4.9360e-09 - val_mse: 4.9360e-09\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.1464e-12 - mse: 3.1464e-12 - val_loss: 4.3656e-09 - val_mse: 4.3656e-09\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.2608e-12 - mse: 4.2608e-12 - val_loss: 4.3656e-09 - val_mse: 4.3656e-09\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9808e-12 - mse: 3.9808e-12 - val_loss: 4.3656e-09 - val_mse: 4.3656e-09\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.4844e-12 - mse: 3.4844e-12 - val_loss: 3.9465e-09 - val_mse: 3.9465e-09\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.0034e-12 - mse: 4.0034e-12 - val_loss: 3.7486e-09 - val_mse: 3.7486e-09\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5810e-12 - mse: 1.5810e-12 - val_loss: 3.7486e-09 - val_mse: 3.7486e-09\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.7598e-12 - mse: 2.7598e-12 - val_loss: 3.5740e-09 - val_mse: 3.5740e-09\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1459e-12 - mse: 2.1459e-12 - val_loss: 3.2480e-09 - val_mse: 3.2480e-09\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9214e-12 - mse: 1.9214e-12 - val_loss: 3.0734e-09 - val_mse: 3.0734e-09\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9888e-12 - mse: 1.9888e-12 - val_loss: 3.0734e-09 - val_mse: 3.0734e-09\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0216e-12 - mse: 2.0216e-12 - val_loss: 3.0734e-09 - val_mse: 3.0734e-09\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5342e-12 - mse: 1.5342e-12 - val_loss: 3.0734e-09 - val_mse: 3.0734e-09\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2799e-12 - mse: 2.2799e-12 - val_loss: 3.0734e-09 - val_mse: 3.0734e-09\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0861e-12 - mse: 2.0861e-12 - val_loss: 3.0734e-09 - val_mse: 3.0734e-09\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1894e-12 - mse: 1.1894e-12 - val_loss: 3.0734e-09 - val_mse: 3.0734e-09\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7405e-12 - mse: 1.7405e-12 - val_loss: 2.8755e-09 - val_mse: 2.8755e-09\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6673e-12 - mse: 1.6673e-12 - val_loss: 2.8755e-09 - val_mse: 2.8755e-09\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4280e-12 - mse: 1.4280e-12 - val_loss: 2.7241e-09 - val_mse: 2.7241e-09\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7269e-12 - mse: 1.7269e-12 - val_loss: 2.5728e-09 - val_mse: 2.5728e-09\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1402e-12 - mse: 2.1402e-12 - val_loss: 2.1420e-09 - val_mse: 2.1420e-09\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.6979e-12 - mse: 2.6979e-12 - val_loss: 2.1420e-09 - val_mse: 2.1420e-09\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0532e-12 - mse: 2.0532e-12 - val_loss: 2.1420e-09 - val_mse: 2.1420e-09\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9023e-12 - mse: 1.9023e-12 - val_loss: 1.8394e-09 - val_mse: 1.8394e-09\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.7524e-13 - mse: 7.7524e-13 - val_loss: 1.8394e-09 - val_mse: 1.8394e-09\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1795e-12 - mse: 1.1795e-12 - val_loss: 1.8394e-09 - val_mse: 1.8394e-09\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1563e-12 - mse: 1.1563e-12 - val_loss: 1.8394e-09 - val_mse: 1.8394e-09\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.4245e-13 - mse: 8.4245e-13 - val_loss: 1.8394e-09 - val_mse: 1.8394e-09\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.6321e-13 - mse: 9.6321e-13 - val_loss: 1.8394e-09 - val_mse: 1.8394e-09\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.2110e-13 - mse: 9.2110e-13 - val_loss: 1.8394e-09 - val_mse: 1.8394e-09\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1862e-12 - mse: 1.1862e-12 - val_loss: 1.8394e-09 - val_mse: 1.8394e-09\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1476e-12 - mse: 1.1476e-12 - val_loss: 1.8394e-09 - val_mse: 1.8394e-09\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1098e-12 - mse: 1.1098e-12 - val_loss: 1.8394e-09 - val_mse: 1.8394e-09\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5824e-12 - mse: 1.5824e-12 - val_loss: 1.8394e-09 - val_mse: 1.8394e-09\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.2235e-13 - mse: 7.2235e-13 - val_loss: 1.8394e-09 - val_mse: 1.8394e-09\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1021e-12 - mse: 1.1021e-12 - val_loss: 1.8394e-09 - val_mse: 1.8394e-09\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6301e-12 - mse: 1.6301e-12 - val_loss: 1.7113e-09 - val_mse: 1.7113e-09\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2139e-12 - mse: 1.2139e-12 - val_loss: 1.7113e-09 - val_mse: 1.7113e-09\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.7833e-13 - mse: 6.7833e-13 - val_loss: 1.7113e-09 - val_mse: 1.7113e-09\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0280e-12 - mse: 1.0280e-12 - val_loss: 1.7113e-09 - val_mse: 1.7113e-09\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.1697e-13 - mse: 9.1697e-13 - val_loss: 1.7113e-09 - val_mse: 1.7113e-09\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.7445e-13 - mse: 9.7445e-13 - val_loss: 1.7113e-09 - val_mse: 1.7113e-09\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.6397e-13 - mse: 9.6397e-13 - val_loss: 1.7113e-09 - val_mse: 1.7113e-09\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.0480e-13 - mse: 6.0480e-13 - val_loss: 1.7113e-09 - val_mse: 1.7113e-09\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1828e-12 - mse: 1.1828e-12 - val_loss: 1.6065e-09 - val_mse: 1.6065e-09\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0805e-12 - mse: 1.0805e-12 - val_loss: 1.2689e-09 - val_mse: 1.2689e-09\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.6991e-13 - mse: 8.6991e-13 - val_loss: 1.2689e-09 - val_mse: 1.2689e-09\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.8675e-13 - mse: 7.8675e-13 - val_loss: 1.2689e-09 - val_mse: 1.2689e-09\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0078e-12 - mse: 1.0078e-12 - val_loss: 1.2689e-09 - val_mse: 1.2689e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.2979e-13 - mse: 8.2979e-13 - val_loss: 1.2689e-09 - val_mse: 1.2689e-09\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.6209e-13 - mse: 9.6209e-13 - val_loss: 1.2689e-09 - val_mse: 1.2689e-09\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2897e-12 - mse: 1.2897e-12 - val_loss: 1.2689e-09 - val_mse: 1.2689e-09\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.3921e-13 - mse: 6.3921e-13 - val_loss: 1.2689e-09 - val_mse: 1.2689e-09\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.8011e-13 - mse: 7.8011e-13 - val_loss: 1.2689e-09 - val_mse: 1.2689e-09\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1223e-12 - mse: 1.1223e-12 - val_loss: 1.2689e-09 - val_mse: 1.2689e-09\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.3011e-13 - mse: 8.3011e-13 - val_loss: 1.2689e-09 - val_mse: 1.2689e-09\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.4547e-13 - mse: 9.4547e-13 - val_loss: 1.2689e-09 - val_mse: 1.2689e-09\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0128e-12 - mse: 1.0128e-12 - val_loss: 1.2689e-09 - val_mse: 1.2689e-09\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.8599e-13 - mse: 6.8599e-13 - val_loss: 1.2689e-09 - val_mse: 1.2689e-09\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1031e-12 - mse: 1.1031e-12 - val_loss: 1.0361e-09 - val_mse: 1.0361e-09\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.3914e-13 - mse: 9.3914e-13 - val_loss: 8.7311e-10 - val_mse: 8.7311e-10\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0528e-12 - mse: 1.0528e-12 - val_loss: 8.7311e-10 - val_mse: 8.7311e-10\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4739e-13 - mse: 5.4739e-13 - val_loss: 8.7311e-10 - val_mse: 8.7311e-10\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.6629e-13 - mse: 7.6629e-13 - val_loss: 8.7311e-10 - val_mse: 8.7311e-10\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2947e-12 - mse: 1.2947e-12 - val_loss: 7.6834e-10 - val_mse: 7.6834e-10\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.2416e-13 - mse: 6.2416e-13 - val_loss: 7.6834e-10 - val_mse: 7.6834e-10\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.8667e-13 - mse: 5.8667e-13 - val_loss: 7.6834e-10 - val_mse: 7.6834e-10\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.6659e-13 - mse: 6.6659e-13 - val_loss: 7.6834e-10 - val_mse: 7.6834e-10\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.4562e-13 - mse: 7.4562e-13 - val_loss: 7.6834e-10 - val_mse: 7.6834e-10\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.6946e-13 - mse: 3.6946e-13 - val_loss: 7.6834e-10 - val_mse: 7.6834e-10\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.0733e-13 - mse: 3.0733e-13 - val_loss: 7.6834e-10 - val_mse: 7.6834e-10\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.0955e-13 - mse: 5.0955e-13 - val_loss: 7.6834e-10 - val_mse: 7.6834e-10\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.6045e-13 - mse: 3.6045e-13 - val_loss: 7.6834e-10 - val_mse: 7.6834e-10\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.3309e-13 - mse: 5.3309e-13 - val_loss: 7.6834e-10 - val_mse: 7.6834e-10\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.2619e-13 - mse: 4.2619e-13 - val_loss: 7.6834e-10 - val_mse: 7.6834e-10\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.8820e-13 - mse: 4.8820e-13 - val_loss: 7.6834e-10 - val_mse: 7.6834e-10\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.3027e-13 - mse: 4.3027e-13 - val_loss: 7.6834e-10 - val_mse: 7.6834e-10\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.5380e-13 - mse: 4.5380e-13 - val_loss: 7.6834e-10 - val_mse: 7.6834e-10\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3151e-12 - mse: 1.3151e-12 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4248e-13 - mse: 5.4248e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.2006e-13 - mse: 6.2006e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0952e-13 - mse: 2.0952e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.1792e-13 - mse: 7.1792e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2475e-12 - mse: 1.2475e-12 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8770e-13 - mse: 2.8770e-13 - val_loss: 6.8685e-10 - val_mse: 6.8685e-10\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.1005e-13 - mse: 6.1005e-13 - val_loss: 6.0536e-10 - val_mse: 6.0536e-10\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.6232e-13 - mse: 6.6232e-13 - val_loss: 6.0536e-10 - val_mse: 6.0536e-10\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0180e-12 - mse: 1.0180e-12 - val_loss: 5.4715e-10 - val_mse: 5.4715e-10\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8752e-13 - mse: 2.8752e-13 - val_loss: 5.4715e-10 - val_mse: 5.4715e-10\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.7919e-13 - mse: 5.7919e-13 - val_loss: 5.4715e-10 - val_mse: 5.4715e-10\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2190e-12 - mse: 1.2190e-12 - val_loss: 5.4715e-10 - val_mse: 5.4715e-10\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.8893e-13 - mse: 9.8893e-13 - val_loss: 5.4715e-10 - val_mse: 5.4715e-10\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.5294e-13 - mse: 9.5294e-13 - val_loss: 4.8894e-10 - val_mse: 4.8894e-10\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.7062e-13 - mse: 6.7062e-13 - val_loss: 4.8894e-10 - val_mse: 4.8894e-10\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.2982e-13 - mse: 4.2982e-13 - val_loss: 4.8894e-10 - val_mse: 4.8894e-10\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4819e-13 - mse: 5.4819e-13 - val_loss: 4.8894e-10 - val_mse: 4.8894e-10\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1965e-12 - mse: 1.1965e-12 - val_loss: 4.8894e-10 - val_mse: 4.8894e-10\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.6561e-13 - mse: 6.6561e-13 - val_loss: 4.8894e-10 - val_mse: 4.8894e-10\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.7765e-13 - mse: 2.7765e-13 - val_loss: 4.8894e-10 - val_mse: 4.8894e-10\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.5323e-13 - mse: 7.5323e-13 - val_loss: 4.8894e-10 - val_mse: 4.8894e-10\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.6698e-13 - mse: 2.6698e-13 - val_loss: 4.8894e-10 - val_mse: 4.8894e-10\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.1987e-13 - mse: 6.1987e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.5605e-13 - mse: 7.5605e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.0038e-13 - mse: 4.0038e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6104e-13 - mse: 5.6104e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.3607e-13 - mse: 9.3607e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.2700e-13 - mse: 4.2700e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.3304e-13 - mse: 3.3304e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.0926e-13 - mse: 5.0926e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2075e-13 - mse: 2.2075e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2057e-13 - mse: 2.2057e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8143e-13 - mse: 2.8143e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9401e-13 - mse: 2.9401e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2117e-13 - mse: 2.2117e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.0874e-13 - mse: 3.0874e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3606e-13 - mse: 2.3606e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2395e-13 - mse: 2.2395e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.3571e-13 - mse: 3.3571e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5002e-13 - mse: 1.5002e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1181e-13 - mse: 2.1181e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.0530e-13 - mse: 3.0530e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.4029e-13 - mse: 2.4029e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8.9903e-14 - mse: 8.9903e-14 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.8768e-13 - mse: 4.8768e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.6840e-13 - mse: 2.6840e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.4999e-13 - mse: 3.4999e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3251e-13 - mse: 2.3251e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.4613e-13 - mse: 3.4613e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3284e-13 - mse: 2.3284e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1762e-13 - mse: 2.1762e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.0787e-13 - mse: 4.0787e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.2494e-13 - mse: 3.2494e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9004e-13 - mse: 1.9004e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.2177e-13 - mse: 3.2177e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0643e-13 - mse: 2.0643e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.0016e-13 - mse: 4.0016e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9707e-13 - mse: 1.9707e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.2012e-13 - mse: 3.2012e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6161e-13 - mse: 1.6161e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2996e-13 - mse: 2.2996e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.1926e-13 - mse: 4.1926e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.3477e-13 - mse: 3.3477e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 3.4688e-13 - mse: 3.4688e-13 - val_loss: 4.3074e-10 - val_mse: 4.3074e-10\n",
      "10/10 [==============================] - 0s 575us/step - loss: 6.0936e-12 - mse: 6.0936e-12\n",
      "mse :  [6.093614328406272e-12, 6.093614328406272e-12]\n",
      "[[11.      ]\n",
      " [11.999999]\n",
      " [12.999999]\n",
      " [14.      ]\n",
      " [14.999998]\n",
      " [15.999999]\n",
      " [16.999998]\n",
      " [17.999994]\n",
      " [18.999998]\n",
      " [19.999996]]\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 준비 \n",
    "import numpy as np \n",
    "\n",
    "x_train = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "y_train = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "x_val = np.array([101, 102, 103, 104, 105])\n",
    "y_val = np.array([101, 102, 103, 104, 105])\n",
    "\n",
    "x_test = np.array([11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
    "y_test = np.array([11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
    "\n",
    "# 2. 모델 구성\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(3))\n",
    "model.add(Dense(4))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 훈련\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=500, batch_size=1, validation_data=(x_val, y_val))\n",
    "\n",
    "# 4. 평가예측\n",
    "mse = model.evaluate(x_test, y_test, batch_size=1)\n",
    "print('mse : ', mse)\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mse는 6.093614328406272e-12 로 매우 낮은 수치, predict도 거의 정확하게 나왔음.  \n",
    "RMSE와 R2 지표를 추가하여 회귀모델을 예측정확도를 평가해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  2.468524762257535e-06\n",
      "R2_score :  0.9999999999992614\n"
     ]
    }
   ],
   "source": [
    "# RMSE \n",
    "from sklearn.metrics import mean_squared_error\n",
    "def RMSE(y_test, y_predict):\n",
    "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "print('RMSE : ', RMSE(y_test, y_predict))\n",
    "\n",
    "# R2\n",
    "from sklearn.metrics import r2_score\n",
    "print('R2_score : ', r2_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE 는 실제 데이터와 예측한 값의 **차이**의 제곱에 평균을 루트한 값이므로 값이 작을수록 좋은 예측을 한것이고,  \n",
    "R2_score는 예측값의 분산 / 실제값의 분산으로 나온 값으로 값이 1에 가까울 수록 높은 예측정확도를 보이는 것으로 판단할 수 있음  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분리\n",
    "데이터를 일일이 쓰지 않고, 많은 데이터를 분리하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 준비\n",
    "import numpy as np\n",
    "x = np.array(range(1, 101))\n",
    "y = np.array(range(1, 101))\n",
    "\n",
    "# 6:2:2 의 비율로 train:valid:test 로 나누어 봄\n",
    "x_train = x[:60]\n",
    "y_train = y[:60]\n",
    "\n",
    "x_val = x[60:80]\n",
    "y_val = y[60:80]\n",
    "\n",
    "x_test = x[80:]\n",
    "y_test = y[80:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구성, 훈련, 평가예측, 평가지표는 동일함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 5)                 10        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1291.9540 - mse: 1291.9540 - val_loss: 4264.3989 - val_mse: 4264.3989\n",
      "Epoch 2/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 881.7377 - mse: 881.7377 - val_loss: 2736.6511 - val_mse: 2736.6511\n",
      "Epoch 3/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 449.4891 - mse: 449.4891 - val_loss: 1377.6157 - val_mse: 1377.6157\n",
      "Epoch 4/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 215.7838 - mse: 215.7838 - val_loss: 441.5402 - val_mse: 441.5402\n",
      "Epoch 5/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 49.9637 - mse: 49.9637 - val_loss: 88.5462 - val_mse: 88.5462\n",
      "Epoch 6/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.8812 - mse: 6.8812 - val_loss: 12.5714 - val_mse: 12.5714\n",
      "Epoch 7/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2460 - mse: 1.2460 - val_loss: 2.9253 - val_mse: 2.9253\n",
      "Epoch 8/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.7952 - mse: 0.7952 - val_loss: 2.0548 - val_mse: 2.0548\n",
      "Epoch 9/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6960 - mse: 0.6960 - val_loss: 2.0215 - val_mse: 2.0215\n",
      "Epoch 10/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.7919 - mse: 0.7919 - val_loss: 1.9061 - val_mse: 1.9061\n",
      "Epoch 11/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6607 - mse: 0.6607 - val_loss: 1.8258 - val_mse: 1.8258\n",
      "Epoch 12/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.7459 - mse: 0.7459 - val_loss: 1.7760 - val_mse: 1.7760\n",
      "Epoch 13/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5739 - mse: 0.5739 - val_loss: 1.6054 - val_mse: 1.6054\n",
      "Epoch 14/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6101 - mse: 0.6101 - val_loss: 1.6628 - val_mse: 1.6628\n",
      "Epoch 15/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.7193 - mse: 0.7193 - val_loss: 1.4372 - val_mse: 1.4372\n",
      "Epoch 16/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5134 - mse: 0.5134 - val_loss: 1.5806 - val_mse: 1.5806\n",
      "Epoch 17/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5221 - mse: 0.5221 - val_loss: 1.2736 - val_mse: 1.2736\n",
      "Epoch 18/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6383 - mse: 0.6383 - val_loss: 1.4070 - val_mse: 1.4070\n",
      "Epoch 19/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6011 - mse: 0.6011 - val_loss: 1.2041 - val_mse: 1.2041\n",
      "Epoch 20/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6964 - mse: 0.6964 - val_loss: 1.2970 - val_mse: 1.2970\n",
      "Epoch 21/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5707 - mse: 0.5707 - val_loss: 1.1284 - val_mse: 1.1284\n",
      "Epoch 22/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4524 - mse: 0.4524 - val_loss: 1.1031 - val_mse: 1.1031\n",
      "Epoch 23/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4588 - mse: 0.4588 - val_loss: 0.9970 - val_mse: 0.9970\n",
      "Epoch 24/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5663 - mse: 0.5663 - val_loss: 0.9033 - val_mse: 0.9033\n",
      "Epoch 25/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5505 - mse: 0.5505 - val_loss: 1.1483 - val_mse: 1.1483\n",
      "Epoch 26/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4553 - mse: 0.4553 - val_loss: 0.7878 - val_mse: 0.7878\n",
      "Epoch 27/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4253 - mse: 0.4253 - val_loss: 1.1078 - val_mse: 1.1078\n",
      "Epoch 28/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3748 - mse: 0.3748 - val_loss: 0.7864 - val_mse: 0.7864\n",
      "Epoch 29/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4306 - mse: 0.4306 - val_loss: 0.8118 - val_mse: 0.8118\n",
      "Epoch 30/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3133 - mse: 0.3133 - val_loss: 1.0347 - val_mse: 1.0347\n",
      "Epoch 31/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2879 - mse: 0.2879 - val_loss: 0.4924 - val_mse: 0.4924\n",
      "Epoch 32/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2398 - mse: 0.2398 - val_loss: 0.9529 - val_mse: 0.9529\n",
      "Epoch 33/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2748 - mse: 0.2748 - val_loss: 0.7092 - val_mse: 0.7092\n",
      "Epoch 34/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3035 - mse: 0.3035 - val_loss: 0.3119 - val_mse: 0.3119\n",
      "Epoch 35/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2352 - mse: 0.2352 - val_loss: 0.5213 - val_mse: 0.5213\n",
      "Epoch 36/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2823 - mse: 0.2823 - val_loss: 0.3646 - val_mse: 0.3646\n",
      "Epoch 37/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2181 - mse: 0.2181 - val_loss: 0.5241 - val_mse: 0.5241\n",
      "Epoch 38/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1817 - mse: 0.1817 - val_loss: 0.4191 - val_mse: 0.4191\n",
      "Epoch 39/1000\n",
      "60/60 [==============================] - 0s 977us/step - loss: 0.1588 - mse: 0.1588 - val_loss: 0.1839 - val_mse: 0.1839\n",
      "Epoch 40/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2025 - mse: 0.2025 - val_loss: 0.4992 - val_mse: 0.4992\n",
      "Epoch 41/1000\n",
      "60/60 [==============================] - 0s 979us/step - loss: 0.1830 - mse: 0.1830 - val_loss: 0.2741 - val_mse: 0.2741\n",
      "Epoch 42/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1341 - mse: 0.1341 - val_loss: 0.3139 - val_mse: 0.3139\n",
      "Epoch 43/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0992 - mse: 0.0992 - val_loss: 0.7126 - val_mse: 0.7126\n",
      "Epoch 44/1000\n",
      "60/60 [==============================] - 0s 975us/step - loss: 0.1419 - mse: 0.1419 - val_loss: 0.2474 - val_mse: 0.2474\n",
      "Epoch 45/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1398 - mse: 0.1398 - val_loss: 0.1904 - val_mse: 0.1904\n",
      "Epoch 46/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0798 - mse: 0.0798 - val_loss: 0.3168 - val_mse: 0.3168\n",
      "Epoch 47/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1028 - mse: 0.1028 - val_loss: 0.2681 - val_mse: 0.2681\n",
      "Epoch 48/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 0.0800 - mse: 0.0800 - val_loss: 0.2108 - val_mse: 0.2108\n",
      "Epoch 49/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 0.0785 - mse: 0.0785 - val_loss: 0.1766 - val_mse: 0.1766\n",
      "Epoch 50/1000\n",
      "60/60 [==============================] - 0s 892us/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.2406 - val_mse: 0.2406\n",
      "Epoch 51/1000\n",
      "60/60 [==============================] - 0s 989us/step - loss: 0.0719 - mse: 0.0719 - val_loss: 0.0709 - val_mse: 0.0709\n",
      "Epoch 52/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0547 - mse: 0.0547 - val_loss: 0.1395 - val_mse: 0.1395\n",
      "Epoch 53/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.1665 - val_mse: 0.1665\n",
      "Epoch 54/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 0.0516 - mse: 0.0516 - val_loss: 0.1862 - val_mse: 0.1862\n",
      "Epoch 55/1000\n",
      "60/60 [==============================] - 0s 918us/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0928 - val_mse: 0.0928\n",
      "Epoch 56/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0701 - val_mse: 0.0701\n",
      "Epoch 57/1000\n",
      "60/60 [==============================] - 0s 908us/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0435 - val_mse: 0.0435\n",
      "Epoch 58/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0723 - val_mse: 0.0723\n",
      "Epoch 59/1000\n",
      "60/60 [==============================] - 0s 954us/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0696 - val_mse: 0.0696\n",
      "Epoch 60/1000\n",
      "60/60 [==============================] - 0s 962us/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0562 - val_mse: 0.0562\n",
      "Epoch 61/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 62/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 63/1000\n",
      "60/60 [==============================] - 0s 922us/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 64/1000\n",
      "60/60 [==============================] - 0s 922us/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 65/1000\n",
      "60/60 [==============================] - 0s 978us/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 66/1000\n",
      "60/60 [==============================] - 0s 952us/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 67/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 68/1000\n",
      "60/60 [==============================] - 0s 898us/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 69/1000\n",
      "60/60 [==============================] - 0s 987us/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 70/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 71/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 72/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 73/1000\n",
      "60/60 [==============================] - 0s 995us/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 74/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 75/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 76/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 77/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.5835e-04 - mse: 7.5835e-04 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 78/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.3354e-04 - mse: 5.3354e-04 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 79/1000\n",
      "60/60 [==============================] - 0s 932us/step - loss: 4.3351e-04 - mse: 4.3351e-04 - val_loss: 1.4058e-04 - val_mse: 1.4058e-04\n",
      "Epoch 80/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2747e-04 - mse: 3.2747e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 81/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1486e-04 - mse: 2.1486e-04 - val_loss: 9.0436e-04 - val_mse: 9.0436e-04\n",
      "Epoch 82/1000\n",
      "60/60 [==============================] - 0s 925us/step - loss: 1.9487e-04 - mse: 1.9487e-04 - val_loss: 2.9343e-04 - val_mse: 2.9343e-04\n",
      "Epoch 83/1000\n",
      "60/60 [==============================] - 0s 910us/step - loss: 1.1727e-04 - mse: 1.1727e-04 - val_loss: 9.5258e-05 - val_mse: 9.5258e-05\n",
      "Epoch 84/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 9.1279e-05 - mse: 9.1279e-05 - val_loss: 2.0405e-04 - val_mse: 2.0405e-04\n",
      "Epoch 85/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 6.8133e-05 - mse: 6.8133e-05 - val_loss: 7.6002e-05 - val_mse: 7.6002e-05\n",
      "Epoch 86/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3622e-05 - mse: 4.3622e-05 - val_loss: 1.3824e-04 - val_mse: 1.3824e-04\n",
      "Epoch 87/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 3.8438e-05 - mse: 3.8438e-05 - val_loss: 6.1706e-05 - val_mse: 6.1706e-05\n",
      "Epoch 88/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 2.3833e-05 - mse: 2.3833e-05 - val_loss: 1.1423e-04 - val_mse: 1.1423e-04\n",
      "Epoch 89/1000\n",
      "60/60 [==============================] - 0s 932us/step - loss: 1.4166e-05 - mse: 1.4166e-05 - val_loss: 3.0680e-05 - val_mse: 3.0680e-05\n",
      "Epoch 90/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 1.3152e-05 - mse: 1.3152e-05 - val_loss: 1.4015e-05 - val_mse: 1.4015e-05\n",
      "Epoch 91/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 9.2240e-06 - mse: 9.2240e-06 - val_loss: 1.2807e-05 - val_mse: 1.2807e-05\n",
      "Epoch 92/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4029e-06 - mse: 5.4029e-06 - val_loss: 1.2392e-05 - val_mse: 1.2392e-05\n",
      "Epoch 93/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5345e-06 - mse: 3.5345e-06 - val_loss: 5.7978e-06 - val_mse: 5.7978e-06\n",
      "Epoch 94/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9244e-06 - mse: 1.9244e-06 - val_loss: 3.6013e-06 - val_mse: 3.6013e-06\n",
      "Epoch 95/1000\n",
      "60/60 [==============================] - 0s 985us/step - loss: 1.2360e-06 - mse: 1.2360e-06 - val_loss: 2.5682e-06 - val_mse: 2.5682e-06\n",
      "Epoch 96/1000\n",
      "60/60 [==============================] - 0s 932us/step - loss: 9.3393e-07 - mse: 9.3393e-07 - val_loss: 1.3412e-06 - val_mse: 1.3412e-06\n",
      "Epoch 97/1000\n",
      "60/60 [==============================] - 0s 984us/step - loss: 5.0068e-07 - mse: 5.0068e-07 - val_loss: 2.9162e-07 - val_mse: 2.9162e-07\n",
      "Epoch 98/1000\n",
      "60/60 [==============================] - 0s 999us/step - loss: 4.0789e-07 - mse: 4.0789e-07 - val_loss: 3.9043e-07 - val_mse: 3.9043e-07\n",
      "Epoch 99/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 1.7250e-07 - mse: 1.7250e-07 - val_loss: 1.0521e-07 - val_mse: 1.0521e-07\n",
      "Epoch 100/1000\n",
      "60/60 [==============================] - 0s 981us/step - loss: 1.5382e-07 - mse: 1.5382e-07 - val_loss: 3.6788e-07 - val_mse: 3.6788e-07\n",
      "Epoch 101/1000\n",
      "60/60 [==============================] - 0s 970us/step - loss: 7.6485e-08 - mse: 7.6485e-08 - val_loss: 2.5696e-07 - val_mse: 2.5696e-07\n",
      "Epoch 102/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 5.0542e-08 - mse: 5.0542e-08 - val_loss: 1.8343e-07 - val_mse: 1.8343e-07\n",
      "Epoch 103/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6557e-08 - mse: 2.6557e-08 - val_loss: 3.6504e-08 - val_mse: 3.6504e-08\n",
      "Epoch 104/1000\n",
      "60/60 [==============================] - 0s 996us/step - loss: 1.5507e-08 - mse: 1.5507e-08 - val_loss: 3.3240e-08 - val_mse: 3.3240e-08\n",
      "Epoch 105/1000\n",
      "60/60 [==============================] - 0s 924us/step - loss: 8.5334e-09 - mse: 8.5334e-09 - val_loss: 2.5184e-08 - val_mse: 2.5184e-08\n",
      "Epoch 106/1000\n",
      "60/60 [==============================] - 0s 922us/step - loss: 3.4646e-09 - mse: 3.4646e-09 - val_loss: 2.5502e-09 - val_mse: 2.5502e-09\n",
      "Epoch 107/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 1.9943e-09 - mse: 1.9943e-09 - val_loss: 1.4203e-09 - val_mse: 1.4203e-09\n",
      "Epoch 108/1000\n",
      "60/60 [==============================] - 0s 959us/step - loss: 8.7037e-10 - mse: 8.7037e-10 - val_loss: 2.1464e-10 - val_mse: 2.1464e-10\n",
      "Epoch 109/1000\n",
      "60/60 [==============================] - 0s 918us/step - loss: 5.7210e-10 - mse: 5.7210e-10 - val_loss: 7.1886e-10 - val_mse: 7.1886e-10\n",
      "Epoch 110/1000\n",
      "60/60 [==============================] - 0s 932us/step - loss: 2.4445e-10 - mse: 2.4445e-10 - val_loss: 7.3414e-10 - val_mse: 7.3414e-10\n",
      "Epoch 111/1000\n",
      "60/60 [==============================] - 0s 901us/step - loss: 1.2791e-10 - mse: 1.2791e-10 - val_loss: 6.9995e-10 - val_mse: 6.9995e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "60/60 [==============================] - 0s 980us/step - loss: 8.5712e-11 - mse: 8.5712e-11 - val_loss: 1.6225e-10 - val_mse: 1.6225e-10\n",
      "Epoch 113/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 3.2359e-11 - mse: 3.2359e-11 - val_loss: 1.4625e-10 - val_mse: 1.4625e-10\n",
      "Epoch 114/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 3.1347e-11 - mse: 3.1347e-11 - val_loss: 8.2218e-11 - val_mse: 8.2218e-11\n",
      "Epoch 115/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 1.7684e-11 - mse: 1.7684e-11 - val_loss: 1.7462e-11 - val_mse: 1.7462e-11\n",
      "Epoch 116/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 1.5564e-11 - mse: 1.5564e-11 - val_loss: 1.4552e-11 - val_mse: 1.4552e-11\n",
      "Epoch 117/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 1.3584e-11 - mse: 1.3584e-11 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
      "Epoch 118/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 1.8383e-11 - mse: 1.8383e-11 - val_loss: 3.4925e-11 - val_mse: 3.4925e-11\n",
      "Epoch 119/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 1.2160e-11 - mse: 1.2160e-11 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
      "Epoch 120/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 5.8383e-12 - mse: 5.8383e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 121/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 5.8063e-12 - mse: 5.8063e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 122/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5220e-11 - mse: 1.5220e-11 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 123/1000\n",
      "60/60 [==============================] - 0s 972us/step - loss: 5.6232e-12 - mse: 5.6232e-12 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 124/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 5.7244e-12 - mse: 5.7244e-12 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
      "Epoch 125/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.8421e-12 - mse: 8.8421e-12 - val_loss: 3.5652e-11 - val_mse: 3.5652e-11\n",
      "Epoch 126/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.4059e-12 - mse: 7.4059e-12 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 127/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2081e-12 - mse: 4.2081e-12 - val_loss: 5.0204e-11 - val_mse: 5.0204e-11\n",
      "Epoch 128/1000\n",
      "60/60 [==============================] - 0s 986us/step - loss: 6.1101e-12 - mse: 6.1101e-12 - val_loss: 5.2387e-11 - val_mse: 5.2387e-11\n",
      "Epoch 129/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.8529e-12 - mse: 5.8529e-12 - val_loss: 3.7835e-11 - val_mse: 3.7835e-11\n",
      "Epoch 130/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.9170e-12 - mse: 4.9170e-12 - val_loss: 4.9477e-11 - val_mse: 4.9477e-11\n",
      "Epoch 131/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4776e-12 - mse: 5.4776e-12 - val_loss: 3.5652e-11 - val_mse: 3.5652e-11\n",
      "Epoch 132/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.6753e-12 - mse: 5.6753e-12 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
      "Epoch 133/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6334e-12 - mse: 6.6334e-12 - val_loss: 3.5652e-11 - val_mse: 3.5652e-11\n",
      "Epoch 134/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3999e-12 - mse: 6.3999e-12 - val_loss: 4.4383e-11 - val_mse: 4.4383e-11\n",
      "Epoch 135/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8571e-12 - mse: 7.8571e-12 - val_loss: 3.5652e-11 - val_mse: 3.5652e-11\n",
      "Epoch 136/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.8989e-12 - mse: 5.8989e-12 - val_loss: 4.1473e-11 - val_mse: 4.1473e-11\n",
      "Epoch 137/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2306e-11 - mse: 1.2306e-11 - val_loss: 8.5856e-11 - val_mse: 8.5856e-11\n",
      "Epoch 138/1000\n",
      "60/60 [==============================] - 0s 985us/step - loss: 6.3232e-12 - mse: 6.3232e-12 - val_loss: 2.5466e-11 - val_mse: 2.5466e-11\n",
      "Epoch 139/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.0285e-12 - mse: 8.0285e-12 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
      "Epoch 140/1000\n",
      "60/60 [==============================] - 0s 979us/step - loss: 7.6585e-12 - mse: 7.6585e-12 - val_loss: 8.7311e-12 - val_mse: 8.7311e-12\n",
      "Epoch 141/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4938e-12 - mse: 5.4938e-12 - val_loss: 1.1642e-11 - val_mse: 1.1642e-11\n",
      "Epoch 142/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3369e-12 - mse: 2.3369e-12 - val_loss: 1.4552e-11 - val_mse: 1.4552e-11\n",
      "Epoch 143/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 6.3484e-12 - mse: 6.3484e-12 - val_loss: 8.7311e-12 - val_mse: 8.7311e-12\n",
      "Epoch 144/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.9733e-12 - mse: 7.9733e-12 - val_loss: 1.7462e-11 - val_mse: 1.7462e-11\n",
      "Epoch 145/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 5.7819e-12 - mse: 5.7819e-12 - val_loss: 7.9308e-11 - val_mse: 7.9308e-11\n",
      "Epoch 146/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 5.5595e-12 - mse: 5.5595e-12 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
      "Epoch 147/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 6.1888e-12 - mse: 6.1888e-12 - val_loss: 5.5297e-11 - val_mse: 5.5297e-11\n",
      "Epoch 148/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 3.7059e-12 - mse: 3.7059e-12 - val_loss: 7.0577e-11 - val_mse: 7.0577e-11\n",
      "Epoch 149/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3118e-12 - mse: 7.3118e-12 - val_loss: 5.9663e-10 - val_mse: 5.9663e-10\n",
      "Epoch 150/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.4255e-11 - mse: 7.4255e-11 - val_loss: 5.8135e-10 - val_mse: 5.8135e-10\n",
      "Epoch 151/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9148e-11 - mse: 2.9148e-11 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
      "Epoch 152/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 8.3854e-12 - mse: 8.3854e-12 - val_loss: 1.3242e-10 - val_mse: 1.3242e-10\n",
      "Epoch 153/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 3.6248e-12 - mse: 3.6248e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
      "Epoch 154/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.6290e-12 - mse: 4.6290e-12 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
      "Epoch 155/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3837e-12 - mse: 6.3837e-12 - val_loss: 1.3388e-10 - val_mse: 1.3388e-10\n",
      "Epoch 156/1000\n",
      "60/60 [==============================] - 0s 918us/step - loss: 9.8106e-12 - mse: 9.8106e-12 - val_loss: 6.4756e-11 - val_mse: 6.4756e-11\n",
      "Epoch 157/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.4064e-12 - mse: 6.4064e-12 - val_loss: 4.1473e-11 - val_mse: 4.1473e-11\n",
      "Epoch 158/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9419e-11 - mse: 1.9419e-11 - val_loss: 2.6193e-11 - val_mse: 2.6193e-11\n",
      "Epoch 159/1000\n",
      "60/60 [==============================] - 0s 978us/step - loss: 9.5199e-12 - mse: 9.5199e-12 - val_loss: 5.8935e-11 - val_mse: 5.8935e-11\n",
      "Epoch 160/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 4.6094e-12 - mse: 4.6094e-12 - val_loss: 8.7311e-12 - val_mse: 8.7311e-12\n",
      "Epoch 161/1000\n",
      "60/60 [==============================] - 0s 967us/step - loss: 8.6162e-12 - mse: 8.6162e-12 - val_loss: 8.8039e-11 - val_mse: 8.8039e-11\n",
      "Epoch 162/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 3.4029e-11 - mse: 3.4029e-11 - val_loss: 3.1578e-10 - val_mse: 3.1578e-10\n",
      "Epoch 163/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9705e-10 - mse: 6.9705e-10 - val_loss: 1.7280e-08 - val_mse: 1.7280e-08\n",
      "Epoch 164/1000\n",
      "60/60 [==============================] - 0s 944us/step - loss: 2.3866e-08 - mse: 2.3866e-08 - val_loss: 4.2572e-08 - val_mse: 4.2572e-08\n",
      "Epoch 165/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 1.9464e-07 - mse: 1.9464e-07 - val_loss: 1.0092e-09 - val_mse: 1.0092e-09\n",
      "Epoch 166/1000\n",
      "60/60 [==============================] - 0s 983us/step - loss: 1.9030e-08 - mse: 1.9030e-08 - val_loss: 2.5357e-09 - val_mse: 2.5357e-09\n",
      "Epoch 167/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 1.9257e-10 - mse: 1.9257e-10 - val_loss: 3.8563e-11 - val_mse: 3.8563e-11\n",
      "Epoch 168/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7950e-12 - mse: 6.7950e-12 - val_loss: 3.4925e-11 - val_mse: 3.4925e-11\n",
      "Epoch 169/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7594e-10 - mse: 1.7594e-10 - val_loss: 8.3339e-09 - val_mse: 8.3339e-09\n",
      "Epoch 170/1000\n",
      "60/60 [==============================] - 0s 995us/step - loss: 2.2889e-09 - mse: 2.2889e-09 - val_loss: 6.7390e-09 - val_mse: 6.7390e-09\n",
      "Epoch 171/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.8678e-10 - mse: 9.8678e-10 - val_loss: 5.6272e-09 - val_mse: 5.6272e-09\n",
      "Epoch 172/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0050e-09 - mse: 3.0050e-09 - val_loss: 1.3831e-08 - val_mse: 1.3831e-08\n",
      "Epoch 173/1000\n",
      "60/60 [==============================] - 0s 981us/step - loss: 9.8588e-08 - mse: 9.8588e-08 - val_loss: 1.8923e-07 - val_mse: 1.8923e-07\n",
      "Epoch 174/1000\n",
      "60/60 [==============================] - 0s 963us/step - loss: 1.5759e-06 - mse: 1.5759e-06 - val_loss: 6.4156e-05 - val_mse: 6.4156e-05\n",
      "Epoch 175/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 2.4378e-06 - mse: 2.4378e-06 - val_loss: 3.3574e-07 - val_mse: 3.3574e-07\n",
      "Epoch 176/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 1.7266e-06 - mse: 1.7266e-06 - val_loss: 3.9567e-06 - val_mse: 3.9567e-06\n",
      "Epoch 177/1000\n",
      "60/60 [==============================] - 0s 964us/step - loss: 7.8540e-05 - mse: 7.8540e-05 - val_loss: 1.0131e-04 - val_mse: 1.0131e-04\n",
      "Epoch 178/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 2.2994e-05 - mse: 2.2994e-05 - val_loss: 4.7612e-05 - val_mse: 4.7612e-05\n",
      "Epoch 179/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3942e-04 - mse: 1.3942e-04 - val_loss: 0.0418 - val_mse: 0.0418\n",
      "Epoch 180/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0892 - mse: 0.0892 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 181/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 0.0035 - mse: 0.0035 - val_loss: 1.0693e-04 - val_mse: 1.0693e-04\n",
      "Epoch 182/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.0310e-05 - mse: 9.0310e-05 - val_loss: 2.5554e-04 - val_mse: 2.5554e-04\n",
      "Epoch 183/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.6136e-05 - mse: 4.6136e-05 - val_loss: 9.0528e-05 - val_mse: 9.0528e-05\n",
      "Epoch 184/1000\n",
      "60/60 [==============================] - 0s 979us/step - loss: 1.1856e-05 - mse: 1.1856e-05 - val_loss: 6.2424e-05 - val_mse: 6.2424e-05\n",
      "Epoch 185/1000\n",
      "60/60 [==============================] - 0s 985us/step - loss: 2.7357e-05 - mse: 2.7357e-05 - val_loss: 8.4104e-08 - val_mse: 8.4104e-08\n",
      "Epoch 186/1000\n",
      "60/60 [==============================] - 0s 963us/step - loss: 4.5255e-06 - mse: 4.5255e-06 - val_loss: 7.9276e-07 - val_mse: 7.9276e-07\n",
      "Epoch 187/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7975e-07 - mse: 3.7975e-07 - val_loss: 1.5359e-07 - val_mse: 1.5359e-07\n",
      "Epoch 188/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 4.7749e-07 - mse: 4.7749e-07 - val_loss: 1.9679e-06 - val_mse: 1.9679e-06\n",
      "Epoch 189/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1196e-06 - mse: 3.1196e-06 - val_loss: 5.8674e-05 - val_mse: 5.8674e-05\n",
      "Epoch 190/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6118e-05 - mse: 2.6118e-05 - val_loss: 4.2590e-06 - val_mse: 4.2590e-06\n",
      "Epoch 191/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5701e-07 - mse: 2.5701e-07 - val_loss: 1.6823e-05 - val_mse: 1.6823e-05\n",
      "Epoch 192/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0941e-06 - mse: 2.0941e-06 - val_loss: 1.2765e-06 - val_mse: 1.2765e-06\n",
      "Epoch 193/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1197e-07 - mse: 4.1197e-07 - val_loss: 2.0020e-07 - val_mse: 2.0020e-07\n",
      "Epoch 194/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8361e-08 - mse: 3.8361e-08 - val_loss: 7.6451e-06 - val_mse: 7.6451e-06\n",
      "Epoch 195/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.2883e-07 - mse: 8.2883e-07 - val_loss: 3.8390e-06 - val_mse: 3.8390e-06\n",
      "Epoch 196/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1293e-07 - mse: 1.1293e-07 - val_loss: 7.4724e-10 - val_mse: 7.4724e-10\n",
      "Epoch 197/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4988e-09 - mse: 4.4988e-09 - val_loss: 1.9612e-08 - val_mse: 1.9612e-08\n",
      "Epoch 198/1000\n",
      "60/60 [==============================] - 0s 968us/step - loss: 6.2186e-09 - mse: 6.2186e-09 - val_loss: 1.3599e-08 - val_mse: 1.3599e-08\n",
      "Epoch 199/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2189e-09 - mse: 4.2189e-09 - val_loss: 6.9301e-08 - val_mse: 6.9301e-08\n",
      "Epoch 200/1000\n",
      "60/60 [==============================] - 0s 975us/step - loss: 1.0449e-07 - mse: 1.0449e-07 - val_loss: 1.1076e-07 - val_mse: 1.1076e-07\n",
      "Epoch 201/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8292e-07 - mse: 4.8292e-07 - val_loss: 1.1702e-05 - val_mse: 1.1702e-05\n",
      "Epoch 202/1000\n",
      "60/60 [==============================] - 0s 979us/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.1037 - val_mse: 0.1037\n",
      "Epoch 203/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0503 - val_mse: 0.0503\n",
      "Epoch 204/1000\n",
      "60/60 [==============================] - 0s 920us/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 205/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 206/1000\n",
      "60/60 [==============================] - 0s 896us/step - loss: 0.0028 - mse: 0.0028 - val_loss: 7.4532e-04 - val_mse: 7.4532e-04\n",
      "Epoch 207/1000\n",
      "60/60 [==============================] - 0s 999us/step - loss: 1.1078e-04 - mse: 1.1078e-04 - val_loss: 2.0272e-04 - val_mse: 2.0272e-04\n",
      "Epoch 208/1000\n",
      "60/60 [==============================] - 0s 977us/step - loss: 2.8413e-05 - mse: 2.8413e-05 - val_loss: 3.9934e-05 - val_mse: 3.9934e-05\n",
      "Epoch 209/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 3.1568e-06 - mse: 3.1568e-06 - val_loss: 6.7157e-10 - val_mse: 6.7157e-10\n",
      "Epoch 210/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2771e-08 - mse: 3.2771e-08 - val_loss: 1.6468e-08 - val_mse: 1.6468e-08\n",
      "Epoch 211/1000\n",
      "60/60 [==============================] - 0s 970us/step - loss: 1.5843e-08 - mse: 1.5843e-08 - val_loss: 2.4262e-08 - val_mse: 2.4262e-08\n",
      "Epoch 212/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7341e-08 - mse: 2.7341e-08 - val_loss: 7.5015e-09 - val_mse: 7.5015e-09\n",
      "Epoch 213/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 6.9723e-08 - mse: 6.9723e-08 - val_loss: 6.9922e-10 - val_mse: 6.9922e-10\n",
      "Epoch 214/1000\n",
      "60/60 [==============================] - 0s 913us/step - loss: 3.5430e-09 - mse: 3.5430e-09 - val_loss: 6.9354e-09 - val_mse: 6.9354e-09\n",
      "Epoch 215/1000\n",
      "60/60 [==============================] - 0s 926us/step - loss: 2.8460e-08 - mse: 2.8460e-08 - val_loss: 2.3017e-08 - val_mse: 2.3017e-08\n",
      "Epoch 216/1000\n",
      "60/60 [==============================] - 0s 963us/step - loss: 2.5579e-08 - mse: 2.5579e-08 - val_loss: 1.1815e-08 - val_mse: 1.1815e-08\n",
      "Epoch 217/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1899e-08 - mse: 2.1899e-08 - val_loss: 1.2908e-09 - val_mse: 1.2908e-09\n",
      "Epoch 218/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 5.7999e-08 - mse: 5.7999e-08 - val_loss: 4.6757e-08 - val_mse: 4.6757e-08\n",
      "Epoch 219/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 9.6212e-08 - mse: 9.6212e-08 - val_loss: 3.8344e-10 - val_mse: 3.8344e-10\n",
      "Epoch 220/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 3.3537e-09 - mse: 3.3537e-09 - val_loss: 1.1220e-09 - val_mse: 1.1220e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 1.5731e-08 - mse: 1.5731e-08 - val_loss: 3.5737e-08 - val_mse: 3.5737e-08\n",
      "Epoch 222/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6439e-08 - mse: 1.6439e-08 - val_loss: 1.1436e-08 - val_mse: 1.1436e-08\n",
      "Epoch 223/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3110e-08 - mse: 4.3110e-08 - val_loss: 4.1178e-07 - val_mse: 4.1178e-07\n",
      "Epoch 224/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 8.6397e-07 - mse: 8.6397e-07 - val_loss: 1.1672e-04 - val_mse: 1.1672e-04\n",
      "Epoch 225/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.1221 - val_mse: 0.1221\n",
      "Epoch 226/1000\n",
      "60/60 [==============================] - 0s 995us/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.8078 - val_mse: 0.8078\n",
      "Epoch 227/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 0.0554 - mse: 0.0554 - val_loss: 5.3163e-04 - val_mse: 5.3163e-04\n",
      "Epoch 228/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 5.6044e-05 - val_mse: 5.6044e-05\n",
      "Epoch 229/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3747e-05 - mse: 8.3747e-05 - val_loss: 2.6347e-05 - val_mse: 2.6347e-05\n",
      "Epoch 230/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6790e-05 - mse: 1.6790e-05 - val_loss: 3.2492e-05 - val_mse: 3.2492e-05\n",
      "Epoch 231/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 1.4803e-06 - mse: 1.4803e-06 - val_loss: 2.1982e-06 - val_mse: 2.1982e-06\n",
      "Epoch 232/1000\n",
      "60/60 [==============================] - 0s 923us/step - loss: 2.9626e-07 - mse: 2.9626e-07 - val_loss: 2.6629e-08 - val_mse: 2.6629e-08\n",
      "Epoch 233/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 1.4877e-07 - mse: 1.4877e-07 - val_loss: 4.2382e-09 - val_mse: 4.2382e-09\n",
      "Epoch 234/1000\n",
      "60/60 [==============================] - 0s 961us/step - loss: 1.7629e-07 - mse: 1.7629e-07 - val_loss: 5.6898e-10 - val_mse: 5.6898e-10\n",
      "Epoch 235/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 2.7011e-07 - mse: 2.7011e-07 - val_loss: 7.1239e-09 - val_mse: 7.1239e-09\n",
      "Epoch 236/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 2.5168e-07 - mse: 2.5168e-07 - val_loss: 5.1534e-08 - val_mse: 5.1534e-08\n",
      "Epoch 237/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.4418e-07 - mse: 6.4418e-07 - val_loss: 7.1910e-06 - val_mse: 7.1910e-06\n",
      "Epoch 238/1000\n",
      "60/60 [==============================] - 0s 971us/step - loss: 6.7445e-07 - mse: 6.7445e-07 - val_loss: 4.2914e-09 - val_mse: 4.2914e-09\n",
      "Epoch 239/1000\n",
      "60/60 [==============================] - 0s 932us/step - loss: 1.6618e-07 - mse: 1.6618e-07 - val_loss: 4.0942e-07 - val_mse: 4.0942e-07\n",
      "Epoch 240/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 3.8385e-07 - mse: 3.8385e-07 - val_loss: 1.7695e-07 - val_mse: 1.7695e-07\n",
      "Epoch 241/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 1.0907e-07 - mse: 1.0907e-07 - val_loss: 4.3554e-09 - val_mse: 4.3554e-09\n",
      "Epoch 242/1000\n",
      "60/60 [==============================] - 0s 989us/step - loss: 9.5105e-08 - mse: 9.5105e-08 - val_loss: 7.2036e-06 - val_mse: 7.2036e-06\n",
      "Epoch 243/1000\n",
      "60/60 [==============================] - 0s 919us/step - loss: 6.1783e-07 - mse: 6.1783e-07 - val_loss: 1.7809e-08 - val_mse: 1.7809e-08\n",
      "Epoch 244/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 2.0746e-07 - mse: 2.0746e-07 - val_loss: 3.0918e-08 - val_mse: 3.0918e-08\n",
      "Epoch 245/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 1.5364e-07 - mse: 1.5364e-07 - val_loss: 7.9308e-10 - val_mse: 7.9308e-10\n",
      "Epoch 246/1000\n",
      "60/60 [==============================] - 0s 989us/step - loss: 7.2264e-08 - mse: 7.2264e-08 - val_loss: 1.4348e-07 - val_mse: 1.4348e-07\n",
      "Epoch 247/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.6536e-07 - mse: 4.6536e-07 - val_loss: 1.2308e-05 - val_mse: 1.2308e-05\n",
      "Epoch 248/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7777e-05 - mse: 3.7777e-05 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 249/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 250/1000\n",
      "60/60 [==============================] - 0s 924us/step - loss: 7.2829e-04 - mse: 7.2829e-04 - val_loss: 1.0556e-05 - val_mse: 1.0556e-05\n",
      "Epoch 251/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 0.0010 - mse: 0.0010 - val_loss: 7.4025e-04 - val_mse: 7.4025e-04\n",
      "Epoch 252/1000\n",
      "60/60 [==============================] - 0s 968us/step - loss: 4.2529e-04 - mse: 4.2529e-04 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 253/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 254/1000\n",
      "60/60 [==============================] - 0s 987us/step - loss: 8.5961e-05 - mse: 8.5961e-05 - val_loss: 4.1004e-04 - val_mse: 4.1004e-04\n",
      "Epoch 255/1000\n",
      "60/60 [==============================] - 0s 921us/step - loss: 3.8934e-04 - mse: 3.8934e-04 - val_loss: 0.0685 - val_mse: 0.0685\n",
      "Epoch 256/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 9.9507e-04 - val_mse: 9.9507e-04\n",
      "Epoch 257/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 2.5855e-04 - mse: 2.5855e-04 - val_loss: 6.5650e-05 - val_mse: 6.5650e-05\n",
      "Epoch 258/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 2.2654e-04 - mse: 2.2654e-04 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 259/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 0.0660 - mse: 0.0660 - val_loss: 0.5165 - val_mse: 0.5165\n",
      "Epoch 260/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 0.0558 - mse: 0.0558 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 261/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.7975e-06 - val_mse: 1.7975e-06\n",
      "Epoch 262/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.9819e-05 - mse: 4.9819e-05 - val_loss: 1.4907e-06 - val_mse: 1.4907e-06\n",
      "Epoch 263/1000\n",
      "60/60 [==============================] - 0s 983us/step - loss: 5.7251e-06 - mse: 5.7251e-06 - val_loss: 1.9157e-05 - val_mse: 1.9157e-05\n",
      "Epoch 264/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9758e-06 - mse: 1.9758e-06 - val_loss: 1.5505e-07 - val_mse: 1.5505e-07\n",
      "Epoch 265/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3908e-07 - mse: 7.3908e-07 - val_loss: 2.5632e-07 - val_mse: 2.5632e-07\n",
      "Epoch 266/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 3.6409e-07 - mse: 3.6409e-07 - val_loss: 2.8385e-08 - val_mse: 2.8385e-08\n",
      "Epoch 267/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5233e-07 - mse: 1.5233e-07 - val_loss: 4.3117e-07 - val_mse: 4.3117e-07\n",
      "Epoch 268/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 9.8128e-07 - mse: 9.8128e-07 - val_loss: 4.3562e-07 - val_mse: 4.3562e-07\n",
      "Epoch 269/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0222e-07 - mse: 1.0222e-07 - val_loss: 4.0891e-10 - val_mse: 4.0891e-10\n",
      "Epoch 270/1000\n",
      "60/60 [==============================] - 0s 993us/step - loss: 2.1141e-07 - mse: 2.1141e-07 - val_loss: 1.1142e-06 - val_mse: 1.1142e-06\n",
      "Epoch 271/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6819e-07 - mse: 1.6819e-07 - val_loss: 5.8975e-07 - val_mse: 5.8975e-07\n",
      "Epoch 272/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.7216e-07 - mse: 8.7216e-07 - val_loss: 2.5166e-06 - val_mse: 2.5166e-06\n",
      "Epoch 273/1000\n",
      "60/60 [==============================] - 0s 924us/step - loss: 8.2117e-07 - mse: 8.2117e-07 - val_loss: 1.1452e-06 - val_mse: 1.1452e-06\n",
      "Epoch 274/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 5.4883e-07 - mse: 5.4883e-07 - val_loss: 4.5746e-07 - val_mse: 4.5746e-07\n",
      "Epoch 275/1000\n",
      "60/60 [==============================] - 0s 902us/step - loss: 1.6603e-07 - mse: 1.6603e-07 - val_loss: 1.5265e-07 - val_mse: 1.5265e-07\n",
      "Epoch 276/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0758e-07 - mse: 4.0758e-07 - val_loss: 7.2569e-07 - val_mse: 7.2569e-07\n",
      "Epoch 277/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4582e-06 - mse: 1.4582e-06 - val_loss: 1.1112e-05 - val_mse: 1.1112e-05\n",
      "Epoch 278/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6352e-06 - mse: 1.6352e-06 - val_loss: 5.2823e-10 - val_mse: 5.2823e-10\n",
      "Epoch 279/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1304e-07 - mse: 7.1304e-07 - val_loss: 7.5235e-08 - val_mse: 7.5235e-08\n",
      "Epoch 280/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 6.0512e-07 - mse: 6.0512e-07 - val_loss: 3.3859e-06 - val_mse: 3.3859e-06\n",
      "Epoch 281/1000\n",
      "60/60 [==============================] - 0s 990us/step - loss: 1.8000e-06 - mse: 1.8000e-06 - val_loss: 2.6058e-08 - val_mse: 2.6058e-08\n",
      "Epoch 282/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 3.4499e-07 - mse: 3.4499e-07 - val_loss: 5.3213e-07 - val_mse: 5.3213e-07\n",
      "Epoch 283/1000\n",
      "60/60 [==============================] - 0s 970us/step - loss: 4.5967e-07 - mse: 4.5967e-07 - val_loss: 4.0668e-07 - val_mse: 4.0668e-07\n",
      "Epoch 284/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 3.4001e-07 - mse: 3.4001e-07 - val_loss: 7.6334e-08 - val_mse: 7.6334e-08\n",
      "Epoch 285/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 2.3061e-06 - mse: 2.3061e-06 - val_loss: 3.2148e-04 - val_mse: 3.2148e-04\n",
      "Epoch 286/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 287/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 1.2735e-05 - val_mse: 1.2735e-05\n",
      "Epoch 288/1000\n",
      "60/60 [==============================] - 0s 944us/step - loss: 6.6738e-05 - mse: 6.6738e-05 - val_loss: 9.6418e-05 - val_mse: 9.6418e-05\n",
      "Epoch 289/1000\n",
      "60/60 [==============================] - 0s 919us/step - loss: 8.7663e-06 - mse: 8.7663e-06 - val_loss: 3.5988e-07 - val_mse: 3.5988e-07\n",
      "Epoch 290/1000\n",
      "60/60 [==============================] - 0s 987us/step - loss: 2.2474e-07 - mse: 2.2474e-07 - val_loss: 2.3318e-08 - val_mse: 2.3318e-08\n",
      "Epoch 291/1000\n",
      "60/60 [==============================] - 0s 977us/step - loss: 8.5526e-07 - mse: 8.5526e-07 - val_loss: 2.0832e-06 - val_mse: 2.0832e-06\n",
      "Epoch 292/1000\n",
      "60/60 [==============================] - 0s 983us/step - loss: 4.7981e-07 - mse: 4.7981e-07 - val_loss: 3.2501e-06 - val_mse: 3.2501e-06\n",
      "Epoch 293/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 9.4937e-07 - mse: 9.4937e-07 - val_loss: 7.6236e-07 - val_mse: 7.6236e-07\n",
      "Epoch 294/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9448e-07 - mse: 5.9448e-07 - val_loss: 5.1155e-07 - val_mse: 5.1155e-07\n",
      "Epoch 295/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0489e-06 - mse: 1.0489e-06 - val_loss: 4.4635e-07 - val_mse: 4.4635e-07\n",
      "Epoch 296/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4830e-07 - mse: 5.4830e-07 - val_loss: 1.3833e-06 - val_mse: 1.3833e-06\n",
      "Epoch 297/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 6.0956e-07 - mse: 6.0956e-07 - val_loss: 5.0779e-09 - val_mse: 5.0779e-09\n",
      "Epoch 298/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 3.4252e-07 - mse: 3.4252e-07 - val_loss: 5.1981e-06 - val_mse: 5.1981e-06\n",
      "Epoch 299/1000\n",
      "60/60 [==============================] - 0s 944us/step - loss: 7.5895e-06 - mse: 7.5895e-06 - val_loss: 7.5166e-07 - val_mse: 7.5166e-07\n",
      "Epoch 300/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 5.0651e-07 - mse: 5.0651e-07 - val_loss: 2.2893e-05 - val_mse: 2.2893e-05\n",
      "Epoch 301/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 2.4412e-06 - mse: 2.4412e-06 - val_loss: 1.9648e-05 - val_mse: 1.9648e-05\n",
      "Epoch 302/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 2.2982e-05 - mse: 2.2982e-05 - val_loss: 7.9040e-05 - val_mse: 7.9040e-05\n",
      "Epoch 303/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 1.0671e-05 - mse: 1.0671e-05 - val_loss: 6.0644e-05 - val_mse: 6.0644e-05\n",
      "Epoch 304/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9718e-05 - mse: 5.9718e-05 - val_loss: 2.6596e-05 - val_mse: 2.6596e-05\n",
      "Epoch 305/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 3.0934e-05 - mse: 3.0934e-05 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 306/1000\n",
      "60/60 [==============================] - 0s 899us/step - loss: 5.1679e-04 - mse: 5.1679e-04 - val_loss: 5.5758e-04 - val_mse: 5.5758e-04\n",
      "Epoch 307/1000\n",
      "60/60 [==============================] - 0s 970us/step - loss: 0.0019 - mse: 0.0019 - val_loss: 8.5586e-06 - val_mse: 8.5586e-06\n",
      "Epoch 308/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.5918e-06 - mse: 9.5918e-06 - val_loss: 2.0577e-05 - val_mse: 2.0577e-05\n",
      "Epoch 309/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 4.9256e-05 - mse: 4.9256e-05 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 310/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.1338 - val_mse: 0.1338\n",
      "Epoch 311/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 0.1737 - mse: 0.1737 - val_loss: 0.1254 - val_mse: 0.1254\n",
      "Epoch 312/1000\n",
      "60/60 [==============================] - 0s 963us/step - loss: 0.0091 - mse: 0.0091 - val_loss: 1.3226e-04 - val_mse: 1.3226e-04\n",
      "Epoch 313/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0572e-05 - mse: 1.0572e-05 - val_loss: 3.7078e-08 - val_mse: 3.7078e-08\n",
      "Epoch 314/1000\n",
      "60/60 [==============================] - 0s 981us/step - loss: 2.7852e-07 - mse: 2.7852e-07 - val_loss: 8.9628e-08 - val_mse: 8.9628e-08\n",
      "Epoch 315/1000\n",
      "60/60 [==============================] - 0s 988us/step - loss: 2.0943e-07 - mse: 2.0943e-07 - val_loss: 2.8600e-08 - val_mse: 2.8600e-08\n",
      "Epoch 316/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8423e-06 - mse: 1.8423e-06 - val_loss: 4.1480e-07 - val_mse: 4.1480e-07\n",
      "Epoch 317/1000\n",
      "60/60 [==============================] - 0s 976us/step - loss: 2.3295e-06 - mse: 2.3295e-06 - val_loss: 6.0307e-08 - val_mse: 6.0307e-08\n",
      "Epoch 318/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5053e-06 - mse: 1.5053e-06 - val_loss: 1.9846e-08 - val_mse: 1.9846e-08\n",
      "Epoch 319/1000\n",
      "60/60 [==============================] - 0s 961us/step - loss: 1.3846e-06 - mse: 1.3846e-06 - val_loss: 4.9307e-08 - val_mse: 4.9307e-08\n",
      "Epoch 320/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.4979e-07 - mse: 7.4979e-07 - val_loss: 6.7763e-07 - val_mse: 6.7763e-07\n",
      "Epoch 321/1000\n",
      "60/60 [==============================] - 0s 984us/step - loss: 1.7542e-07 - mse: 1.7542e-07 - val_loss: 1.8045e-07 - val_mse: 1.8045e-07\n",
      "Epoch 322/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 2.5947e-06 - mse: 2.5947e-06 - val_loss: 1.6117e-06 - val_mse: 1.6117e-06\n",
      "Epoch 323/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 1.1547e-06 - mse: 1.1547e-06 - val_loss: 9.8757e-09 - val_mse: 9.8757e-09\n",
      "Epoch 324/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.7293e-07 - mse: 9.7293e-07 - val_loss: 3.2401e-07 - val_mse: 3.2401e-07\n",
      "Epoch 325/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.7282e-07 - mse: 4.7282e-07 - val_loss: 5.1657e-07 - val_mse: 5.1657e-07\n",
      "Epoch 326/1000\n",
      "60/60 [==============================] - 0s 945us/step - loss: 8.8804e-07 - mse: 8.8804e-07 - val_loss: 1.9043e-08 - val_mse: 1.9043e-08\n",
      "Epoch 327/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 7.4882e-08 - mse: 7.4882e-08 - val_loss: 1.4579e-07 - val_mse: 1.4579e-07\n",
      "Epoch 328/1000\n",
      "60/60 [==============================] - 0s 965us/step - loss: 1.2864e-06 - mse: 1.2864e-06 - val_loss: 9.5117e-06 - val_mse: 9.5117e-06\n",
      "Epoch 329/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0359e-05 - mse: 1.0359e-05 - val_loss: 5.4404e-06 - val_mse: 5.4404e-06\n",
      "Epoch 330/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 1.2688e-06 - mse: 1.2688e-06 - val_loss: 7.6790e-09 - val_mse: 7.6790e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 7.8051e-07 - mse: 7.8051e-07 - val_loss: 5.0978e-08 - val_mse: 5.0978e-08\n",
      "Epoch 332/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 6.5579e-07 - mse: 6.5579e-07 - val_loss: 4.0360e-05 - val_mse: 4.0360e-05\n",
      "Epoch 333/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 1.3513e-05 - mse: 1.3513e-05 - val_loss: 1.1007e-04 - val_mse: 1.1007e-04\n",
      "Epoch 334/1000\n",
      "60/60 [==============================] - 0s 964us/step - loss: 1.6306e-04 - mse: 1.6306e-04 - val_loss: 8.3167e-04 - val_mse: 8.3167e-04\n",
      "Epoch 335/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 1.7906e-04 - mse: 1.7906e-04 - val_loss: 3.4542e-07 - val_mse: 3.4542e-07\n",
      "Epoch 336/1000\n",
      "60/60 [==============================] - 0s 963us/step - loss: 3.0832e-05 - mse: 3.0832e-05 - val_loss: 8.6373e-07 - val_mse: 8.6373e-07\n",
      "Epoch 337/1000\n",
      "60/60 [==============================] - 0s 995us/step - loss: 4.7433e-07 - mse: 4.7433e-07 - val_loss: 9.3084e-07 - val_mse: 9.3084e-07\n",
      "Epoch 338/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.2478e-07 - mse: 6.2478e-07 - val_loss: 3.1535e-07 - val_mse: 3.1535e-07\n",
      "Epoch 339/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9734e-06 - mse: 5.9734e-06 - val_loss: 2.4146e-07 - val_mse: 2.4146e-07\n",
      "Epoch 340/1000\n",
      "60/60 [==============================] - 0s 998us/step - loss: 5.5288e-06 - mse: 5.5288e-06 - val_loss: 1.5090e-05 - val_mse: 1.5090e-05\n",
      "Epoch 341/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 6.1605e-05 - mse: 6.1605e-05 - val_loss: 8.9915e-05 - val_mse: 8.9915e-05\n",
      "Epoch 342/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 7.3208e-05 - mse: 7.3208e-05 - val_loss: 2.0596e-04 - val_mse: 2.0596e-04\n",
      "Epoch 343/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 5.3022e-05 - mse: 5.3022e-05 - val_loss: 8.5483e-04 - val_mse: 8.5483e-04\n",
      "Epoch 344/1000\n",
      "60/60 [==============================] - 0s 957us/step - loss: 4.5809e-04 - mse: 4.5809e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 345/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 0.0033 - mse: 0.0033 - val_loss: 1.4240e-06 - val_mse: 1.4240e-06\n",
      "Epoch 346/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.7517 - val_mse: 0.7517\n",
      "Epoch 347/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 0.1505 - mse: 0.1505 - val_loss: 0.4434 - val_mse: 0.4434\n",
      "Epoch 348/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0653 - mse: 0.0653 - val_loss: 0.0486 - val_mse: 0.0486\n",
      "Epoch 349/1000\n",
      "60/60 [==============================] - 0s 974us/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0970 - val_mse: 0.0970\n",
      "Epoch 350/1000\n",
      "60/60 [==============================] - 0s 965us/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 351/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 352/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2891e-05 - mse: 4.2891e-05 - val_loss: 4.2777e-05 - val_mse: 4.2777e-05\n",
      "Epoch 353/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5041e-06 - mse: 5.5041e-06 - val_loss: 3.7344e-07 - val_mse: 3.7344e-07\n",
      "Epoch 354/1000\n",
      "60/60 [==============================] - 0s 925us/step - loss: 2.3049e-06 - mse: 2.3049e-06 - val_loss: 6.8485e-07 - val_mse: 6.8485e-07\n",
      "Epoch 355/1000\n",
      "60/60 [==============================] - 0s 924us/step - loss: 1.0074e-06 - mse: 1.0074e-06 - val_loss: 3.4379e-09 - val_mse: 3.4379e-09\n",
      "Epoch 356/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 6.7815e-07 - mse: 6.7815e-07 - val_loss: 3.6145e-06 - val_mse: 3.6145e-06\n",
      "Epoch 357/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3453e-06 - mse: 1.3453e-06 - val_loss: 5.2092e-07 - val_mse: 5.2092e-07\n",
      "Epoch 358/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 4.1081e-06 - mse: 4.1081e-06 - val_loss: 3.1847e-07 - val_mse: 3.1847e-07\n",
      "Epoch 359/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.9465e-07 - mse: 9.9465e-07 - val_loss: 3.3435e-06 - val_mse: 3.3435e-06\n",
      "Epoch 360/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5799e-06 - mse: 1.5799e-06 - val_loss: 3.9489e-06 - val_mse: 3.9489e-06\n",
      "Epoch 361/1000\n",
      "60/60 [==============================] - 0s 924us/step - loss: 2.8610e-06 - mse: 2.8610e-06 - val_loss: 2.0086e-08 - val_mse: 2.0086e-08\n",
      "Epoch 362/1000\n",
      "60/60 [==============================] - 0s 920us/step - loss: 1.2906e-06 - mse: 1.2906e-06 - val_loss: 9.3754e-07 - val_mse: 9.3754e-07\n",
      "Epoch 363/1000\n",
      "60/60 [==============================] - 0s 909us/step - loss: 1.0944e-06 - mse: 1.0944e-06 - val_loss: 6.1074e-08 - val_mse: 6.1074e-08\n",
      "Epoch 364/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 9.5081e-07 - mse: 9.5081e-07 - val_loss: 3.8425e-06 - val_mse: 3.8425e-06\n",
      "Epoch 365/1000\n",
      "60/60 [==============================] - 0s 957us/step - loss: 1.5616e-06 - mse: 1.5616e-06 - val_loss: 2.4723e-07 - val_mse: 2.4723e-07\n",
      "Epoch 366/1000\n",
      "60/60 [==============================] - 0s 963us/step - loss: 2.7032e-06 - mse: 2.7032e-06 - val_loss: 9.8947e-06 - val_mse: 9.8947e-06\n",
      "Epoch 367/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 4.2126e-06 - mse: 4.2126e-06 - val_loss: 6.1156e-06 - val_mse: 6.1156e-06\n",
      "Epoch 368/1000\n",
      "60/60 [==============================] - 0s 962us/step - loss: 3.0479e-06 - mse: 3.0479e-06 - val_loss: 2.3635e-06 - val_mse: 2.3635e-06\n",
      "Epoch 369/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 2.4417e-06 - mse: 2.4417e-06 - val_loss: 2.3701e-06 - val_mse: 2.3701e-06\n",
      "Epoch 370/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 3.6409e-06 - mse: 3.6409e-06 - val_loss: 1.2975e-07 - val_mse: 1.2975e-07\n",
      "Epoch 371/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5188e-06 - mse: 2.5188e-06 - val_loss: 3.3478e-06 - val_mse: 3.3478e-06\n",
      "Epoch 372/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 1.5247e-06 - mse: 1.5247e-06 - val_loss: 1.4459e-07 - val_mse: 1.4459e-07\n",
      "Epoch 373/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 4.1878e-07 - mse: 4.1878e-07 - val_loss: 2.4520e-09 - val_mse: 2.4520e-09\n",
      "Epoch 374/1000\n",
      "60/60 [==============================] - 0s 921us/step - loss: 2.1739e-06 - mse: 2.1739e-06 - val_loss: 2.5625e-06 - val_mse: 2.5625e-06\n",
      "Epoch 375/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 7.7070e-07 - mse: 7.7070e-07 - val_loss: 1.9599e-06 - val_mse: 1.9599e-06\n",
      "Epoch 376/1000\n",
      "60/60 [==============================] - 0s 965us/step - loss: 1.2613e-06 - mse: 1.2613e-06 - val_loss: 2.7199e-07 - val_mse: 2.7199e-07\n",
      "Epoch 377/1000\n",
      "60/60 [==============================] - 0s 924us/step - loss: 8.9995e-07 - mse: 8.9995e-07 - val_loss: 2.8965e-06 - val_mse: 2.8965e-06\n",
      "Epoch 378/1000\n",
      "60/60 [==============================] - 0s 992us/step - loss: 8.9914e-07 - mse: 8.9914e-07 - val_loss: 1.3795e-07 - val_mse: 1.3795e-07\n",
      "Epoch 379/1000\n",
      "60/60 [==============================] - 0s 963us/step - loss: 1.6942e-06 - mse: 1.6942e-06 - val_loss: 6.7544e-06 - val_mse: 6.7544e-06\n",
      "Epoch 380/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 1.8474e-05 - mse: 1.8474e-05 - val_loss: 4.3087e-05 - val_mse: 4.3087e-05\n",
      "Epoch 381/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 3.4072e-05 - mse: 3.4072e-05 - val_loss: 8.1906e-05 - val_mse: 8.1906e-05\n",
      "Epoch 382/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 1.8887e-04 - mse: 1.8887e-04 - val_loss: 1.1986e-04 - val_mse: 1.1986e-04\n",
      "Epoch 383/1000\n",
      "60/60 [==============================] - 0s 923us/step - loss: 2.4117e-05 - mse: 2.4117e-05 - val_loss: 1.3098e-05 - val_mse: 1.3098e-05\n",
      "Epoch 384/1000\n",
      "60/60 [==============================] - 0s 908us/step - loss: 1.0549e-05 - mse: 1.0549e-05 - val_loss: 9.4449e-08 - val_mse: 9.4449e-08\n",
      "Epoch 385/1000\n",
      "60/60 [==============================] - 0s 963us/step - loss: 2.5676e-07 - mse: 2.5676e-07 - val_loss: 6.4910e-08 - val_mse: 6.4910e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 2.2115e-06 - mse: 2.2115e-06 - val_loss: 4.2423e-07 - val_mse: 4.2423e-07\n",
      "Epoch 387/1000\n",
      "60/60 [==============================] - 0s 975us/step - loss: 1.0518e-04 - mse: 1.0518e-04 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 388/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.3167 - val_mse: 0.3167\n",
      "Epoch 389/1000\n",
      "60/60 [==============================] - 0s 918us/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 390/1000\n",
      "60/60 [==============================] - 0s 959us/step - loss: 2.9147e-04 - mse: 2.9147e-04 - val_loss: 6.0112e-05 - val_mse: 6.0112e-05\n",
      "Epoch 391/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 0.0016 - mse: 0.0016 - val_loss: 2.5409e-04 - val_mse: 2.5409e-04\n",
      "Epoch 392/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 3.7381e-04 - mse: 3.7381e-04 - val_loss: 5.8203e-05 - val_mse: 5.8203e-05\n",
      "Epoch 393/1000\n",
      "60/60 [==============================] - 0s 932us/step - loss: 2.4989e-04 - mse: 2.4989e-04 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 394/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 395/1000\n",
      "60/60 [==============================] - 0s 926us/step - loss: 0.0015 - mse: 0.0015 - val_loss: 3.7743e-05 - val_mse: 3.7743e-05\n",
      "Epoch 396/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 7.9929e-06 - mse: 7.9929e-06 - val_loss: 1.0537e-05 - val_mse: 1.0537e-05\n",
      "Epoch 397/1000\n",
      "60/60 [==============================] - 0s 967us/step - loss: 5.0308e-06 - mse: 5.0308e-06 - val_loss: 5.8977e-08 - val_mse: 5.8977e-08\n",
      "Epoch 398/1000\n",
      "60/60 [==============================] - 0s 918us/step - loss: 4.6906e-06 - mse: 4.6906e-06 - val_loss: 1.6995e-07 - val_mse: 1.6995e-07\n",
      "Epoch 399/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 1.7995e-06 - mse: 1.7995e-06 - val_loss: 2.8412e-07 - val_mse: 2.8412e-07\n",
      "Epoch 400/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.3037e-06 - mse: 5.3037e-06 - val_loss: 1.2211e-06 - val_mse: 1.2211e-06\n",
      "Epoch 401/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3769e-06 - mse: 2.3769e-06 - val_loss: 5.8823e-07 - val_mse: 5.8823e-07\n",
      "Epoch 402/1000\n",
      "60/60 [==============================] - 0s 969us/step - loss: 1.5801e-06 - mse: 1.5801e-06 - val_loss: 4.8592e-07 - val_mse: 4.8592e-07\n",
      "Epoch 403/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3960e-06 - mse: 2.3960e-06 - val_loss: 1.3718e-08 - val_mse: 1.3718e-08\n",
      "Epoch 404/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5935e-06 - mse: 4.5935e-06 - val_loss: 2.3155e-06 - val_mse: 2.3155e-06\n",
      "Epoch 405/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3067e-05 - mse: 1.3067e-05 - val_loss: 1.5946e-07 - val_mse: 1.5946e-07\n",
      "Epoch 406/1000\n",
      "60/60 [==============================] - 0s 964us/step - loss: 4.7563e-06 - mse: 4.7563e-06 - val_loss: 1.3999e-04 - val_mse: 1.3999e-04\n",
      "Epoch 407/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2000e-05 - mse: 2.2000e-05 - val_loss: 2.4249e-04 - val_mse: 2.4249e-04\n",
      "Epoch 408/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 3.9172e-04 - mse: 3.9172e-04 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 409/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 410/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 4.5649e-04 - mse: 4.5649e-04 - val_loss: 8.3765e-06 - val_mse: 8.3765e-06\n",
      "Epoch 411/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4147e-05 - mse: 1.4147e-05 - val_loss: 1.6260e-04 - val_mse: 1.6260e-04\n",
      "Epoch 412/1000\n",
      "60/60 [==============================] - 0s 924us/step - loss: 2.6840e-04 - mse: 2.6840e-04 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 413/1000\n",
      "60/60 [==============================] - 0s 986us/step - loss: 2.3120e-04 - mse: 2.3120e-04 - val_loss: 4.2185e-04 - val_mse: 4.2185e-04\n",
      "Epoch 414/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8679e-04 - mse: 1.8679e-04 - val_loss: 1.8021e-04 - val_mse: 1.8021e-04\n",
      "Epoch 415/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 2.1286e-04 - mse: 2.1286e-04 - val_loss: 4.6400e-07 - val_mse: 4.6400e-07\n",
      "Epoch 416/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6843e-04 - mse: 3.6843e-04 - val_loss: 4.2700e-04 - val_mse: 4.2700e-04\n",
      "Epoch 417/1000\n",
      "60/60 [==============================] - 0s 961us/step - loss: 0.0173 - mse: 0.0173 - val_loss: 1.1911e-06 - val_mse: 1.1911e-06\n",
      "Epoch 418/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 2.4207e-04 - mse: 2.4207e-04 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 419/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.2925e-04 - mse: 5.2925e-04 - val_loss: 3.3041e-04 - val_mse: 3.3041e-04\n",
      "Epoch 420/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5172e-04 - mse: 2.5172e-04 - val_loss: 2.1397e-05 - val_mse: 2.1397e-05\n",
      "Epoch 421/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 4.1009e-05 - mse: 4.1009e-05 - val_loss: 2.0843e-07 - val_mse: 2.0843e-07\n",
      "Epoch 422/1000\n",
      "60/60 [==============================] - 0s 916us/step - loss: 2.3284e-06 - mse: 2.3284e-06 - val_loss: 4.2791e-05 - val_mse: 4.2791e-05\n",
      "Epoch 423/1000\n",
      "60/60 [==============================] - 0s 932us/step - loss: 7.6513e-06 - mse: 7.6513e-06 - val_loss: 3.2957e-05 - val_mse: 3.2957e-05\n",
      "Epoch 424/1000\n",
      "60/60 [==============================] - 0s 957us/step - loss: 7.3868e-06 - mse: 7.3868e-06 - val_loss: 5.0815e-08 - val_mse: 5.0815e-08\n",
      "Epoch 425/1000\n",
      "60/60 [==============================] - 0s 920us/step - loss: 3.0497e-06 - mse: 3.0497e-06 - val_loss: 3.6118e-05 - val_mse: 3.6118e-05\n",
      "Epoch 426/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 3.4829e-05 - mse: 3.4829e-05 - val_loss: 4.0731e-05 - val_mse: 4.0731e-05\n",
      "Epoch 427/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 5.7169e-06 - mse: 5.7169e-06 - val_loss: 8.0695e-05 - val_mse: 8.0695e-05\n",
      "Epoch 428/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0777e-04 - mse: 2.0777e-04 - val_loss: 1.6321e-04 - val_mse: 1.6321e-04\n",
      "Epoch 429/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 1.0856e-04 - mse: 1.0856e-04 - val_loss: 5.4961e-04 - val_mse: 5.4961e-04\n",
      "Epoch 430/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 2.3389e-04 - mse: 2.3389e-04 - val_loss: 6.8239e-04 - val_mse: 6.8239e-04\n",
      "Epoch 431/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.2730 - val_mse: 0.2730\n",
      "Epoch 432/1000\n",
      "60/60 [==============================] - 0s 984us/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 433/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 5.3559e-04 - val_mse: 5.3559e-04\n",
      "Epoch 434/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 9.5554e-05 - mse: 9.5554e-05 - val_loss: 5.2488e-06 - val_mse: 5.2488e-06\n",
      "Epoch 435/1000\n",
      "60/60 [==============================] - 0s 965us/step - loss: 2.8230e-06 - mse: 2.8230e-06 - val_loss: 2.2366e-06 - val_mse: 2.2366e-06\n",
      "Epoch 436/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 1.2582e-06 - mse: 1.2582e-06 - val_loss: 6.8769e-07 - val_mse: 6.8769e-07\n",
      "Epoch 437/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 3.4922e-06 - mse: 3.4922e-06 - val_loss: 3.1750e-06 - val_mse: 3.1750e-06\n",
      "Epoch 438/1000\n",
      "60/60 [==============================] - 0s 970us/step - loss: 2.0176e-06 - mse: 2.0176e-06 - val_loss: 8.1196e-07 - val_mse: 8.1196e-07\n",
      "Epoch 439/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8204e-06 - mse: 1.8204e-06 - val_loss: 5.6731e-06 - val_mse: 5.6731e-06\n",
      "Epoch 440/1000\n",
      "60/60 [==============================] - 0s 964us/step - loss: 5.3274e-06 - mse: 5.3274e-06 - val_loss: 7.8527e-08 - val_mse: 7.8527e-08\n",
      "Epoch 441/1000\n",
      "60/60 [==============================] - 0s 908us/step - loss: 3.1543e-06 - mse: 3.1543e-06 - val_loss: 6.3993e-08 - val_mse: 6.3993e-08\n",
      "Epoch 442/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 1.7235e-06 - mse: 1.7235e-06 - val_loss: 2.3176e-06 - val_mse: 2.3176e-06\n",
      "Epoch 443/1000\n",
      "60/60 [==============================] - 0s 899us/step - loss: 3.9996e-06 - mse: 3.9996e-06 - val_loss: 6.7381e-06 - val_mse: 6.7381e-06\n",
      "Epoch 444/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 4.0233e-06 - mse: 4.0233e-06 - val_loss: 1.6817e-06 - val_mse: 1.6817e-06\n",
      "Epoch 445/1000\n",
      "60/60 [==============================] - 0s 969us/step - loss: 3.3104e-06 - mse: 3.3104e-06 - val_loss: 1.8861e-05 - val_mse: 1.8861e-05\n",
      "Epoch 446/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7040e-06 - mse: 6.7040e-06 - val_loss: 2.9287e-07 - val_mse: 2.9287e-07\n",
      "Epoch 447/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3442e-06 - mse: 2.3442e-06 - val_loss: 1.4160e-05 - val_mse: 1.4160e-05\n",
      "Epoch 448/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 7.6577e-05 - mse: 7.6577e-05 - val_loss: 1.4997e-05 - val_mse: 1.4997e-05\n",
      "Epoch 449/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.1762e-06 - mse: 6.1762e-06 - val_loss: 5.1121e-05 - val_mse: 5.1121e-05\n",
      "Epoch 450/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0099e-04 - mse: 1.0099e-04 - val_loss: 6.6321e-05 - val_mse: 6.6321e-05\n",
      "Epoch 451/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1705e-04 - mse: 2.1705e-04 - val_loss: 1.6649e-06 - val_mse: 1.6649e-06\n",
      "Epoch 452/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 6.1050e-05 - mse: 6.1050e-05 - val_loss: 3.4465e-04 - val_mse: 3.4465e-04\n",
      "Epoch 453/1000\n",
      "60/60 [==============================] - 0s 952us/step - loss: 2.6213e-05 - mse: 2.6213e-05 - val_loss: 2.8226e-05 - val_mse: 2.8226e-05\n",
      "Epoch 454/1000\n",
      "60/60 [==============================] - 0s 944us/step - loss: 2.0129e-05 - mse: 2.0129e-05 - val_loss: 7.2331e-04 - val_mse: 7.2331e-04\n",
      "Epoch 455/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 8.3524e-05 - mse: 8.3524e-05 - val_loss: 1.3873e-04 - val_mse: 1.3873e-04\n",
      "Epoch 456/1000\n",
      "60/60 [==============================] - 0s 996us/step - loss: 4.9506e-05 - mse: 4.9506e-05 - val_loss: 7.6017e-04 - val_mse: 7.6017e-04\n",
      "Epoch 457/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 0.0012 - mse: 0.0012 - val_loss: 8.8474e-04 - val_mse: 8.8474e-04\n",
      "Epoch 458/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 0.1584 - mse: 0.1584 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 459/1000\n",
      "60/60 [==============================] - 0s 893us/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 460/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 461/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3202e-04 - mse: 6.3202e-04 - val_loss: 6.6323e-04 - val_mse: 6.6323e-04\n",
      "Epoch 462/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.7885e-05 - mse: 7.7885e-05 - val_loss: 2.5342e-05 - val_mse: 2.5342e-05\n",
      "Epoch 463/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 2.5616e-06 - mse: 2.5616e-06 - val_loss: 1.3255e-06 - val_mse: 1.3255e-06\n",
      "Epoch 464/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3961e-06 - mse: 2.3961e-06 - val_loss: 1.5374e-06 - val_mse: 1.5374e-06\n",
      "Epoch 465/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.3833e-06 - mse: 5.3833e-06 - val_loss: 3.2863e-06 - val_mse: 3.2863e-06\n",
      "Epoch 466/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 1.9633e-06 - mse: 1.9633e-06 - val_loss: 4.0597e-06 - val_mse: 4.0597e-06\n",
      "Epoch 467/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0627e-06 - mse: 3.0627e-06 - val_loss: 1.1525e-07 - val_mse: 1.1525e-07\n",
      "Epoch 468/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 1.0511e-06 - mse: 1.0511e-06 - val_loss: 1.1581e-07 - val_mse: 1.1581e-07\n",
      "Epoch 469/1000\n",
      "60/60 [==============================] - 0s 960us/step - loss: 1.4258e-06 - mse: 1.4258e-06 - val_loss: 5.0293e-06 - val_mse: 5.0293e-06\n",
      "Epoch 470/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8681e-06 - mse: 2.8681e-06 - val_loss: 2.4165e-06 - val_mse: 2.4165e-06\n",
      "Epoch 471/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5306e-06 - mse: 1.5306e-06 - val_loss: 4.8865e-07 - val_mse: 4.8865e-07\n",
      "Epoch 472/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0046e-06 - mse: 2.0046e-06 - val_loss: 3.0703e-05 - val_mse: 3.0703e-05\n",
      "Epoch 473/1000\n",
      "60/60 [==============================] - 0s 998us/step - loss: 2.9434e-06 - mse: 2.9434e-06 - val_loss: 8.1747e-07 - val_mse: 8.1747e-07\n",
      "Epoch 474/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2793e-06 - mse: 1.2793e-06 - val_loss: 6.2113e-06 - val_mse: 6.2113e-06\n",
      "Epoch 475/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 8.0544e-06 - mse: 8.0544e-06 - val_loss: 4.3445e-05 - val_mse: 4.3445e-05\n",
      "Epoch 476/1000\n",
      "60/60 [==============================] - 0s 964us/step - loss: 1.7988e-05 - mse: 1.7988e-05 - val_loss: 1.0192e-07 - val_mse: 1.0192e-07\n",
      "Epoch 477/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4878e-05 - mse: 2.4878e-05 - val_loss: 1.9557e-04 - val_mse: 1.9557e-04\n",
      "Epoch 478/1000\n",
      "60/60 [==============================] - 0s 913us/step - loss: 6.2685e-05 - mse: 6.2685e-05 - val_loss: 1.0157e-05 - val_mse: 1.0157e-05\n",
      "Epoch 479/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 6.7533e-06 - mse: 6.7533e-06 - val_loss: 7.1963e-08 - val_mse: 7.1963e-08\n",
      "Epoch 480/1000\n",
      "60/60 [==============================] - 0s 898us/step - loss: 1.1756e-06 - mse: 1.1756e-06 - val_loss: 4.9956e-06 - val_mse: 4.9956e-06\n",
      "Epoch 481/1000\n",
      "60/60 [==============================] - 0s 957us/step - loss: 1.3975e-05 - mse: 1.3975e-05 - val_loss: 5.0867e-06 - val_mse: 5.0867e-06\n",
      "Epoch 482/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1922e-06 - mse: 2.1922e-06 - val_loss: 1.2725e-05 - val_mse: 1.2725e-05\n",
      "Epoch 483/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 2.6398e-06 - mse: 2.6398e-06 - val_loss: 4.6214e-07 - val_mse: 4.6214e-07\n",
      "Epoch 484/1000\n",
      "60/60 [==============================] - 0s 926us/step - loss: 4.8332e-06 - mse: 4.8332e-06 - val_loss: 1.6575e-04 - val_mse: 1.6575e-04\n",
      "Epoch 485/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8187e-05 - mse: 3.8187e-05 - val_loss: 7.6588e-08 - val_mse: 7.6588e-08\n",
      "Epoch 486/1000\n",
      "60/60 [==============================] - 0s 982us/step - loss: 1.3952e-05 - mse: 1.3952e-05 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 487/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 2.7828e-04 - mse: 2.7828e-04 - val_loss: 6.1539e-05 - val_mse: 6.1539e-05\n",
      "Epoch 488/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3265e-05 - mse: 1.3265e-05 - val_loss: 3.6659e-05 - val_mse: 3.6659e-05\n",
      "Epoch 489/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1080e-05 - mse: 1.1080e-05 - val_loss: 4.8738e-04 - val_mse: 4.8738e-04\n",
      "Epoch 490/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 6.1382e-05 - mse: 6.1382e-05 - val_loss: 6.1668e-08 - val_mse: 6.1668e-08\n",
      "Epoch 491/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 4.2951e-06 - mse: 4.2951e-06 - val_loss: 1.1776e-05 - val_mse: 1.1776e-05\n",
      "Epoch 492/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 3.5673e-06 - mse: 3.5673e-06 - val_loss: 3.9344e-04 - val_mse: 3.9344e-04\n",
      "Epoch 493/1000\n",
      "60/60 [==============================] - 0s 969us/step - loss: 2.9693e-05 - mse: 2.9693e-05 - val_loss: 5.5153e-04 - val_mse: 5.5153e-04\n",
      "Epoch 494/1000\n",
      "60/60 [==============================] - 0s 926us/step - loss: 4.5718e-05 - mse: 4.5718e-05 - val_loss: 1.2963e-06 - val_mse: 1.2963e-06\n",
      "Epoch 495/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.1977e-06 - mse: 6.1977e-06 - val_loss: 1.6882e-04 - val_mse: 1.6882e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9956e-05 - mse: 2.9956e-05 - val_loss: 3.9118e-05 - val_mse: 3.9118e-05\n",
      "Epoch 497/1000\n",
      "60/60 [==============================] - 0s 998us/step - loss: 2.0110e-04 - mse: 2.0110e-04 - val_loss: 6.1235e-05 - val_mse: 6.1235e-05\n",
      "Epoch 498/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 2.2781e-05 - mse: 2.2781e-05 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 499/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.6004 - val_mse: 0.6004\n",
      "Epoch 500/1000\n",
      "60/60 [==============================] - 0s 999us/step - loss: 0.0728 - mse: 0.0728 - val_loss: 0.0664 - val_mse: 0.0664\n",
      "Epoch 501/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 502/1000\n",
      "60/60 [==============================] - 0s 971us/step - loss: 0.0014 - mse: 0.0014 - val_loss: 2.7433e-05 - val_mse: 2.7433e-05\n",
      "Epoch 503/1000\n",
      "60/60 [==============================] - 0s 984us/step - loss: 4.0761e-05 - mse: 4.0761e-05 - val_loss: 2.5189e-04 - val_mse: 2.5189e-04\n",
      "Epoch 504/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 1.4604e-05 - mse: 1.4604e-05 - val_loss: 2.1439e-06 - val_mse: 2.1439e-06\n",
      "Epoch 505/1000\n",
      "60/60 [==============================] - 0s 970us/step - loss: 1.1773e-06 - mse: 1.1773e-06 - val_loss: 1.2433e-05 - val_mse: 1.2433e-05\n",
      "Epoch 506/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 6.6340e-06 - mse: 6.6340e-06 - val_loss: 6.2644e-08 - val_mse: 6.2644e-08\n",
      "Epoch 507/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 2.7119e-06 - mse: 2.7119e-06 - val_loss: 3.1311e-07 - val_mse: 3.1311e-07\n",
      "Epoch 508/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 1.0928e-06 - mse: 1.0928e-06 - val_loss: 8.1461e-06 - val_mse: 8.1461e-06\n",
      "Epoch 509/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 2.7123e-06 - mse: 2.7123e-06 - val_loss: 2.6636e-07 - val_mse: 2.6636e-07\n",
      "Epoch 510/1000\n",
      "60/60 [==============================] - 0s 922us/step - loss: 9.7002e-07 - mse: 9.7002e-07 - val_loss: 4.0451e-06 - val_mse: 4.0451e-06\n",
      "Epoch 511/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 2.1862e-06 - mse: 2.1862e-06 - val_loss: 3.5574e-05 - val_mse: 3.5574e-05\n",
      "Epoch 512/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 7.1469e-06 - mse: 7.1469e-06 - val_loss: 2.2499e-07 - val_mse: 2.2499e-07\n",
      "Epoch 513/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9547e-06 - mse: 2.9547e-06 - val_loss: 2.7065e-05 - val_mse: 2.7065e-05\n",
      "Epoch 514/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5399e-06 - mse: 1.5399e-06 - val_loss: 1.1361e-05 - val_mse: 1.1361e-05\n",
      "Epoch 515/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6493e-06 - mse: 1.6493e-06 - val_loss: 1.9893e-07 - val_mse: 1.9893e-07\n",
      "Epoch 516/1000\n",
      "60/60 [==============================] - 0s 992us/step - loss: 5.8704e-07 - mse: 5.8704e-07 - val_loss: 2.6995e-06 - val_mse: 2.6995e-06\n",
      "Epoch 517/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4134e-06 - mse: 1.4134e-06 - val_loss: 6.3613e-06 - val_mse: 6.3613e-06\n",
      "Epoch 518/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3612e-06 - mse: 2.3612e-06 - val_loss: 6.4646e-06 - val_mse: 6.4646e-06\n",
      "Epoch 519/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 1.4018e-04 - mse: 1.4018e-04 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 520/1000\n",
      "60/60 [==============================] - 0s 988us/step - loss: 3.6537e-04 - mse: 3.6537e-04 - val_loss: 9.9293e-05 - val_mse: 9.9293e-05\n",
      "Epoch 521/1000\n",
      "60/60 [==============================] - 0s 984us/step - loss: 1.8318e-05 - mse: 1.8318e-05 - val_loss: 3.4705e-04 - val_mse: 3.4705e-04\n",
      "Epoch 522/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.5479e-05 - mse: 9.5479e-05 - val_loss: 7.9760e-04 - val_mse: 7.9760e-04\n",
      "Epoch 523/1000\n",
      "60/60 [==============================] - 0s 987us/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 524/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 525/1000\n",
      "60/60 [==============================] - 0s 954us/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 526/1000\n",
      "60/60 [==============================] - 0s 921us/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 527/1000\n",
      "60/60 [==============================] - 0s 954us/step - loss: 0.0014 - mse: 0.0014 - val_loss: 5.9678e-04 - val_mse: 5.9678e-04\n",
      "Epoch 528/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4512e-05 - mse: 2.4512e-05 - val_loss: 6.9428e-06 - val_mse: 6.9428e-06\n",
      "Epoch 529/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 1.0887e-06 - mse: 1.0887e-06 - val_loss: 2.8658e-06 - val_mse: 2.8658e-06\n",
      "Epoch 530/1000\n",
      "60/60 [==============================] - 0s 989us/step - loss: 1.5203e-06 - mse: 1.5203e-06 - val_loss: 6.9233e-07 - val_mse: 6.9233e-07\n",
      "Epoch 531/1000\n",
      "60/60 [==============================] - 0s 994us/step - loss: 1.6902e-06 - mse: 1.6902e-06 - val_loss: 9.5555e-06 - val_mse: 9.5555e-06\n",
      "Epoch 532/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 2.7360e-06 - mse: 2.7360e-06 - val_loss: 3.0090e-07 - val_mse: 3.0090e-07\n",
      "Epoch 533/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 4.2385e-06 - mse: 4.2385e-06 - val_loss: 6.0702e-04 - val_mse: 6.0702e-04\n",
      "Epoch 534/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1407e-04 - mse: 1.1407e-04 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 535/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 3.4390e-05 - val_mse: 3.4390e-05\n",
      "Epoch 536/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 1.8985e-04 - mse: 1.8985e-04 - val_loss: 2.2245e-07 - val_mse: 2.2245e-07\n",
      "Epoch 537/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 7.4877e-05 - mse: 7.4877e-05 - val_loss: 3.4117e-04 - val_mse: 3.4117e-04\n",
      "Epoch 538/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 4.4457e-05 - mse: 4.4457e-05 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 539/1000\n",
      "60/60 [==============================] - 0s 963us/step - loss: 0.0106 - mse: 0.0106 - val_loss: 1.9953e-04 - val_mse: 1.9953e-04\n",
      "Epoch 540/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 3.3145e-04 - mse: 3.3145e-04 - val_loss: 2.9228e-05 - val_mse: 2.9228e-05\n",
      "Epoch 541/1000\n",
      "60/60 [==============================] - 0s 925us/step - loss: 1.4587e-05 - mse: 1.4587e-05 - val_loss: 4.8267e-06 - val_mse: 4.8267e-06\n",
      "Epoch 542/1000\n",
      "60/60 [==============================] - 0s 907us/step - loss: 3.5411e-06 - mse: 3.5411e-06 - val_loss: 3.4157e-06 - val_mse: 3.4157e-06\n",
      "Epoch 543/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9939e-06 - mse: 1.9939e-06 - val_loss: 3.2595e-06 - val_mse: 3.2595e-06\n",
      "Epoch 544/1000\n",
      "60/60 [==============================] - 0s 994us/step - loss: 1.2115e-05 - mse: 1.2115e-05 - val_loss: 3.2730e-05 - val_mse: 3.2730e-05\n",
      "Epoch 545/1000\n",
      "60/60 [==============================] - 0s 985us/step - loss: 4.0849e-06 - mse: 4.0849e-06 - val_loss: 1.2392e-04 - val_mse: 1.2392e-04\n",
      "Epoch 546/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.6747e-05 - mse: 7.6747e-05 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 547/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8291e-04 - mse: 3.8291e-04 - val_loss: 1.7413e-04 - val_mse: 1.7413e-04\n",
      "Epoch 548/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 6.3105e-04 - mse: 6.3105e-04 - val_loss: 0.0608 - val_mse: 0.0608\n",
      "Epoch 549/1000\n",
      "60/60 [==============================] - 0s 912us/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.1252 - val_mse: 0.1252\n",
      "Epoch 550/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 0.0314 - mse: 0.0314 - val_loss: 7.8996e-05 - val_mse: 7.8996e-05\n",
      "Epoch 551/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 3.5713e-05 - mse: 3.5713e-05 - val_loss: 4.2911e-05 - val_mse: 4.2911e-05\n",
      "Epoch 552/1000\n",
      "60/60 [==============================] - 0s 945us/step - loss: 1.8486e-04 - mse: 1.8486e-04 - val_loss: 3.2521e-05 - val_mse: 3.2521e-05\n",
      "Epoch 553/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 1.8384e-05 - mse: 1.8384e-05 - val_loss: 4.7651e-05 - val_mse: 4.7651e-05\n",
      "Epoch 554/1000\n",
      "60/60 [==============================] - 0s 978us/step - loss: 1.3098e-05 - mse: 1.3098e-05 - val_loss: 9.5516e-06 - val_mse: 9.5516e-06\n",
      "Epoch 555/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3204e-06 - mse: 1.3204e-06 - val_loss: 2.0452e-07 - val_mse: 2.0452e-07\n",
      "Epoch 556/1000\n",
      "60/60 [==============================] - 0s 977us/step - loss: 3.9015e-07 - mse: 3.9015e-07 - val_loss: 1.7861e-07 - val_mse: 1.7861e-07\n",
      "Epoch 557/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 1.4459e-07 - mse: 1.4459e-07 - val_loss: 1.8397e-08 - val_mse: 1.8397e-08\n",
      "Epoch 558/1000\n",
      "60/60 [==============================] - 0s 925us/step - loss: 1.5719e-09 - mse: 1.5719e-09 - val_loss: 2.6776e-10 - val_mse: 2.6776e-10\n",
      "Epoch 559/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 3.4596e-11 - mse: 3.4596e-11 - val_loss: 4.1473e-11 - val_mse: 4.1473e-11\n",
      "Epoch 560/1000\n",
      "60/60 [==============================] - 0s 952us/step - loss: 7.1509e-12 - mse: 7.1509e-12 - val_loss: 8.9494e-11 - val_mse: 8.9494e-11\n",
      "Epoch 561/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8107e-10 - mse: 2.8107e-10 - val_loss: 1.1205e-10 - val_mse: 1.1205e-10\n",
      "Epoch 562/1000\n",
      "60/60 [==============================] - 0s 984us/step - loss: 8.1158e-10 - mse: 8.1158e-10 - val_loss: 6.1627e-10 - val_mse: 6.1627e-10\n",
      "Epoch 563/1000\n",
      "60/60 [==============================] - 0s 899us/step - loss: 2.3190e-08 - mse: 2.3190e-08 - val_loss: 5.8625e-08 - val_mse: 5.8625e-08\n",
      "Epoch 564/1000\n",
      "60/60 [==============================] - 0s 993us/step - loss: 4.7669e-07 - mse: 4.7669e-07 - val_loss: 1.9679e-07 - val_mse: 1.9679e-07\n",
      "Epoch 565/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 2.0373e-08 - mse: 2.0373e-08 - val_loss: 2.5159e-08 - val_mse: 2.5159e-08\n",
      "Epoch 566/1000\n",
      "60/60 [==============================] - 0s 963us/step - loss: 3.8945e-09 - mse: 3.8945e-09 - val_loss: 2.3016e-07 - val_mse: 2.3016e-07\n",
      "Epoch 567/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1357e-07 - mse: 1.1357e-07 - val_loss: 1.1476e-08 - val_mse: 1.1476e-08\n",
      "Epoch 568/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8161e-09 - mse: 2.8161e-09 - val_loss: 1.8343e-09 - val_mse: 1.8343e-09\n",
      "Epoch 569/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 3.4088e-08 - mse: 3.4088e-08 - val_loss: 1.5881e-06 - val_mse: 1.5881e-06\n",
      "Epoch 570/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 5.1840e-06 - mse: 5.1840e-06 - val_loss: 2.9605e-05 - val_mse: 2.9605e-05\n",
      "Epoch 571/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 6.7453e-05 - mse: 6.7453e-05 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 572/1000\n",
      "60/60 [==============================] - 0s 954us/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0373 - val_mse: 0.0373\n",
      "Epoch 573/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.2745 - val_mse: 0.2745\n",
      "Epoch 574/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 3.2316e-05 - val_mse: 3.2316e-05\n",
      "Epoch 575/1000\n",
      "60/60 [==============================] - 0s 926us/step - loss: 2.6909e-04 - mse: 2.6909e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 576/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 2.0760e-04 - mse: 2.0760e-04 - val_loss: 6.5536e-05 - val_mse: 6.5536e-05\n",
      "Epoch 577/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 7.2449e-06 - mse: 7.2449e-06 - val_loss: 1.2906e-06 - val_mse: 1.2906e-06\n",
      "Epoch 578/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 7.1171e-07 - mse: 7.1171e-07 - val_loss: 2.4664e-06 - val_mse: 2.4664e-06\n",
      "Epoch 579/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0742e-07 - mse: 1.0742e-07 - val_loss: 1.4668e-07 - val_mse: 1.4668e-07\n",
      "Epoch 580/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 7.1952e-08 - mse: 7.1952e-08 - val_loss: 2.1049e-09 - val_mse: 2.1049e-09\n",
      "Epoch 581/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 3.7297e-10 - mse: 3.7297e-10 - val_loss: 1.5862e-10 - val_mse: 1.5862e-10\n",
      "Epoch 582/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 1.7843e-11 - mse: 1.7843e-11 - val_loss: 7.2032e-10 - val_mse: 7.2032e-10\n",
      "Epoch 583/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 3.8797e-10 - mse: 3.8797e-10 - val_loss: 4.9477e-11 - val_mse: 4.9477e-11\n",
      "Epoch 584/1000\n",
      "60/60 [==============================] - 0s 959us/step - loss: 2.6442e-11 - mse: 2.6442e-11 - val_loss: 5.6752e-11 - val_mse: 5.6752e-11\n",
      "Epoch 585/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0563e-11 - mse: 1.0563e-11 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
      "Epoch 586/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8874e-12 - mse: 2.8874e-12 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
      "Epoch 587/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5264e-12 - mse: 2.5264e-12 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
      "Epoch 588/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 6.6739e-12 - mse: 6.6739e-12 - val_loss: 3.9290e-11 - val_mse: 3.9290e-11\n",
      "Epoch 589/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 5.4351e-12 - mse: 5.4351e-12 - val_loss: 7.9308e-11 - val_mse: 7.9308e-11\n",
      "Epoch 590/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1369e-11 - mse: 1.1369e-11 - val_loss: 4.0745e-11 - val_mse: 4.0745e-11\n",
      "Epoch 591/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0905e-11 - mse: 1.0905e-11 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
      "Epoch 592/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4712e-12 - mse: 3.4712e-12 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
      "Epoch 593/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8576e-11 - mse: 1.8576e-11 - val_loss: 3.7107e-11 - val_mse: 3.7107e-11\n",
      "Epoch 594/1000\n",
      "60/60 [==============================] - 0s 925us/step - loss: 6.4623e-11 - mse: 6.4623e-11 - val_loss: 3.9072e-10 - val_mse: 3.9072e-10\n",
      "Epoch 595/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 1.1114e-10 - mse: 1.1114e-10 - val_loss: 4.7294e-11 - val_mse: 4.7294e-11\n",
      "Epoch 596/1000\n",
      "60/60 [==============================] - 0s 972us/step - loss: 7.7694e-10 - mse: 7.7694e-10 - val_loss: 2.2366e-09 - val_mse: 2.2366e-09\n",
      "Epoch 597/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.6085e-10 - mse: 8.6085e-10 - val_loss: 5.3624e-10 - val_mse: 5.3624e-10\n",
      "Epoch 598/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3924e-09 - mse: 2.3924e-09 - val_loss: 7.8811e-07 - val_mse: 7.8811e-07\n",
      "Epoch 599/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 9.2080e-08 - mse: 9.2080e-08 - val_loss: 2.2337e-08 - val_mse: 2.2337e-08\n",
      "Epoch 600/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 3.9387e-08 - mse: 3.9387e-08 - val_loss: 5.6227e-07 - val_mse: 5.6227e-07\n",
      "Epoch 601/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7654e-07 - mse: 1.7654e-07 - val_loss: 1.1720e-06 - val_mse: 1.1720e-06\n",
      "Epoch 602/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2571e-08 - mse: 7.2571e-08 - val_loss: 8.8687e-08 - val_mse: 8.8687e-08\n",
      "Epoch 603/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 3.7719e-07 - mse: 3.7719e-07 - val_loss: 5.1810e-07 - val_mse: 5.1810e-07\n",
      "Epoch 604/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1369e-07 - mse: 4.1369e-07 - val_loss: 3.2596e-10 - val_mse: 3.2596e-10\n",
      "Epoch 605/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 935us/step - loss: 2.9194e-05 - mse: 2.9194e-05 - val_loss: 1.7279e-04 - val_mse: 1.7279e-04\n",
      "Epoch 606/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 607/1000\n",
      "60/60 [==============================] - 0s 894us/step - loss: 0.1349 - mse: 0.1349 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 608/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 609/1000\n",
      "60/60 [==============================] - 0s 915us/step - loss: 2.7113e-04 - mse: 2.7113e-04 - val_loss: 2.3755e-04 - val_mse: 2.3755e-04\n",
      "Epoch 610/1000\n",
      "60/60 [==============================] - 0s 973us/step - loss: 4.4875e-05 - mse: 4.4875e-05 - val_loss: 1.3847e-07 - val_mse: 1.3847e-07\n",
      "Epoch 611/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 2.1138e-07 - mse: 2.1138e-07 - val_loss: 1.3904e-08 - val_mse: 1.3904e-08\n",
      "Epoch 612/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 1.3408e-08 - mse: 1.3408e-08 - val_loss: 4.7075e-10 - val_mse: 4.7075e-10\n",
      "Epoch 613/1000\n",
      "60/60 [==============================] - 0s 903us/step - loss: 9.5158e-10 - mse: 9.5158e-10 - val_loss: 2.1319e-10 - val_mse: 2.1319e-10\n",
      "Epoch 614/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0282e-10 - mse: 5.0282e-10 - val_loss: 1.6007e-11 - val_mse: 1.6007e-11\n",
      "Epoch 615/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1378e-12 - mse: 5.1378e-12 - val_loss: 1.8917e-11 - val_mse: 1.8917e-11\n",
      "Epoch 616/1000\n",
      "60/60 [==============================] - 0s 945us/step - loss: 5.7568e-12 - mse: 5.7568e-12 - val_loss: 2.0373e-11 - val_mse: 2.0373e-11\n",
      "Epoch 617/1000\n",
      "60/60 [==============================] - 0s 985us/step - loss: 7.7271e-12 - mse: 7.7271e-12 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 618/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9429e-12 - mse: 6.9429e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 619/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.5258e-12 - mse: 9.5258e-12 - val_loss: 4.8021e-11 - val_mse: 4.8021e-11\n",
      "Epoch 620/1000\n",
      "60/60 [==============================] - 0s 986us/step - loss: 6.0673e-12 - mse: 6.0673e-12 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
      "Epoch 621/1000\n",
      "60/60 [==============================] - 0s 932us/step - loss: 3.1974e-12 - mse: 3.1974e-12 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
      "Epoch 622/1000\n",
      "60/60 [==============================] - 0s 926us/step - loss: 6.0845e-12 - mse: 6.0845e-12 - val_loss: 1.3097e-11 - val_mse: 1.3097e-11\n",
      "Epoch 623/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9661e-12 - mse: 2.9661e-12 - val_loss: 1.8917e-11 - val_mse: 1.8917e-11\n",
      "Epoch 624/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1479e-12 - mse: 3.1479e-12 - val_loss: 7.2760e-12 - val_mse: 7.2760e-12\n",
      "Epoch 625/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 4.3154e-12 - mse: 4.3154e-12 - val_loss: 1.3824e-11 - val_mse: 1.3824e-11\n",
      "Epoch 626/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8621e-12 - mse: 4.8621e-12 - val_loss: 3.7835e-11 - val_mse: 3.7835e-11\n",
      "Epoch 627/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.6193e-12 - mse: 5.6193e-12 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 628/1000\n",
      "60/60 [==============================] - 0s 945us/step - loss: 4.2857e-12 - mse: 4.2857e-12 - val_loss: 8.3674e-11 - val_mse: 8.3674e-11\n",
      "Epoch 629/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 1.1343e-11 - mse: 1.1343e-11 - val_loss: 1.3097e-11 - val_mse: 1.3097e-11\n",
      "Epoch 630/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 1.0807e-10 - mse: 1.0807e-10 - val_loss: 6.2573e-11 - val_mse: 6.2573e-11\n",
      "Epoch 631/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1634e-10 - mse: 2.1634e-10 - val_loss: 5.8222e-09 - val_mse: 5.8222e-09\n",
      "Epoch 632/1000\n",
      "60/60 [==============================] - 0s 926us/step - loss: 7.5674e-10 - mse: 7.5674e-10 - val_loss: 1.2515e-10 - val_mse: 1.2515e-10\n",
      "Epoch 633/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 1.4170e-11 - mse: 1.4170e-11 - val_loss: 5.0932e-11 - val_mse: 5.0932e-11\n",
      "Epoch 634/1000\n",
      "60/60 [==============================] - 0s 982us/step - loss: 9.7346e-12 - mse: 9.7346e-12 - val_loss: 3.8563e-11 - val_mse: 3.8563e-11\n",
      "Epoch 635/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 1.1720e-11 - mse: 1.1720e-11 - val_loss: 1.4552e-12 - val_mse: 1.4552e-12\n",
      "Epoch 636/1000\n",
      "60/60 [==============================] - 0s 910us/step - loss: 9.1624e-11 - mse: 9.1624e-11 - val_loss: 3.6889e-10 - val_mse: 3.6889e-10\n",
      "Epoch 637/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 2.7625e-10 - mse: 2.7625e-10 - val_loss: 1.0186e-11 - val_mse: 1.0186e-11\n",
      "Epoch 638/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 1.7359e-09 - mse: 1.7359e-09 - val_loss: 4.6090e-08 - val_mse: 4.6090e-08\n",
      "Epoch 639/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 4.8785e-09 - mse: 4.8785e-09 - val_loss: 1.7171e-10 - val_mse: 1.7171e-10\n",
      "Epoch 640/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.7263e-12 - mse: 9.7263e-12 - val_loss: 7.4870e-10 - val_mse: 7.4870e-10\n",
      "Epoch 641/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.3085e-10 - mse: 5.3085e-10 - val_loss: 3.1454e-09 - val_mse: 3.1454e-09\n",
      "Epoch 642/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 8.2207e-10 - mse: 8.2207e-10 - val_loss: 1.3195e-08 - val_mse: 1.3195e-08\n",
      "Epoch 643/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.4856e-10 - mse: 7.4856e-10 - val_loss: 1.6444e-10 - val_mse: 1.6444e-10\n",
      "Epoch 644/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7798e-11 - mse: 1.7798e-11 - val_loss: 9.7498e-11 - val_mse: 9.7498e-11\n",
      "Epoch 645/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 1.9450e-10 - mse: 1.9450e-10 - val_loss: 6.3301e-11 - val_mse: 6.3301e-11\n",
      "Epoch 646/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 3.7801e-11 - mse: 3.7801e-11 - val_loss: 5.4497e-10 - val_mse: 5.4497e-10\n",
      "Epoch 647/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 7.2513e-11 - mse: 7.2513e-11 - val_loss: 1.6084e-08 - val_mse: 1.6084e-08\n",
      "Epoch 648/1000\n",
      "60/60 [==============================] - 0s 977us/step - loss: 3.2898e-09 - mse: 3.2898e-09 - val_loss: 2.2007e-07 - val_mse: 2.2007e-07\n",
      "Epoch 649/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 2.2197e-07 - mse: 2.2197e-07 - val_loss: 3.2399e-05 - val_mse: 3.2399e-05\n",
      "Epoch 650/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 2.1898e-04 - mse: 2.1898e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 651/1000\n",
      "60/60 [==============================] - 0s 965us/step - loss: 7.3693e-04 - mse: 7.3693e-04 - val_loss: 3.1059e-04 - val_mse: 3.1059e-04\n",
      "Epoch 652/1000\n",
      "60/60 [==============================] - 0s 907us/step - loss: 6.6314e-05 - mse: 6.6314e-05 - val_loss: 2.7347e-05 - val_mse: 2.7347e-05\n",
      "Epoch 653/1000\n",
      "60/60 [==============================] - 0s 916us/step - loss: 2.5995e-04 - mse: 2.5995e-04 - val_loss: 6.4473e-04 - val_mse: 6.4473e-04\n",
      "Epoch 654/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 6.2879e-04 - val_mse: 6.2879e-04\n",
      "Epoch 655/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0739 - mse: 0.0739 - val_loss: 0.0519 - val_mse: 0.0519\n",
      "Epoch 656/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 0.0275 - mse: 0.0275 - val_loss: 3.4851e-05 - val_mse: 3.4851e-05\n",
      "Epoch 657/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 3.9825e-04 - mse: 3.9825e-04 - val_loss: 6.1359e-05 - val_mse: 6.1359e-05\n",
      "Epoch 658/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 3.2995e-06 - mse: 3.2995e-06 - val_loss: 3.7835e-11 - val_mse: 3.7835e-11\n",
      "Epoch 659/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 2.5074e-07 - mse: 2.5074e-07 - val_loss: 5.2037e-07 - val_mse: 5.2037e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9636e-08 - mse: 6.9636e-08 - val_loss: 4.4092e-10 - val_mse: 4.4092e-10\n",
      "Epoch 661/1000\n",
      "60/60 [==============================] - 0s 964us/step - loss: 1.6250e-10 - mse: 1.6250e-10 - val_loss: 8.0036e-12 - val_mse: 8.0036e-12\n",
      "Epoch 662/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.6774e-12 - mse: 9.6774e-12 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
      "Epoch 663/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 1.2163e-11 - mse: 1.2163e-11 - val_loss: 7.1304e-11 - val_mse: 7.1304e-11\n",
      "Epoch 664/1000\n",
      "60/60 [==============================] - 0s 911us/step - loss: 8.1072e-12 - mse: 8.1072e-12 - val_loss: 3.7835e-11 - val_mse: 3.7835e-11\n",
      "Epoch 665/1000\n",
      "60/60 [==============================] - 0s 916us/step - loss: 4.0076e-12 - mse: 4.0076e-12 - val_loss: 3.7107e-11 - val_mse: 3.7107e-11\n",
      "Epoch 666/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 7.4046e-12 - mse: 7.4046e-12 - val_loss: 7.4942e-11 - val_mse: 7.4942e-11\n",
      "Epoch 667/1000\n",
      "60/60 [==============================] - 0s 972us/step - loss: 7.0903e-12 - mse: 7.0903e-12 - val_loss: 1.7099e-10 - val_mse: 1.7099e-10\n",
      "Epoch 668/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 2.0703e-11 - mse: 2.0703e-11 - val_loss: 3.4925e-11 - val_mse: 3.4925e-11\n",
      "Epoch 669/1000\n",
      "60/60 [==============================] - 0s 989us/step - loss: 8.6620e-12 - mse: 8.6620e-12 - val_loss: 6.5484e-11 - val_mse: 6.5484e-11\n",
      "Epoch 670/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1830e-12 - mse: 5.1830e-12 - val_loss: 1.0259e-10 - val_mse: 1.0259e-10\n",
      "Epoch 671/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0315e-11 - mse: 1.0315e-11 - val_loss: 3.2742e-10 - val_mse: 3.2742e-10\n",
      "Epoch 672/1000\n",
      "60/60 [==============================] - 0s 979us/step - loss: 3.5003e-11 - mse: 3.5003e-11 - val_loss: 2.6121e-10 - val_mse: 2.6121e-10\n",
      "Epoch 673/1000\n",
      "60/60 [==============================] - 0s 932us/step - loss: 3.6916e-10 - mse: 3.6916e-10 - val_loss: 1.9936e-10 - val_mse: 1.9936e-10\n",
      "Epoch 674/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.9420e-10 - mse: 7.9420e-10 - val_loss: 2.5422e-09 - val_mse: 2.5422e-09\n",
      "Epoch 675/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2142e-09 - mse: 2.2142e-09 - val_loss: 1.4242e-08 - val_mse: 1.4242e-08\n",
      "Epoch 676/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 1.8478e-09 - mse: 1.8478e-09 - val_loss: 1.1137e-08 - val_mse: 1.1137e-08\n",
      "Epoch 677/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5475e-09 - mse: 1.5475e-09 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
      "Epoch 678/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6588e-11 - mse: 3.6588e-11 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
      "Epoch 679/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0381e-11 - mse: 1.0381e-11 - val_loss: 4.0018e-11 - val_mse: 4.0018e-11\n",
      "Epoch 680/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0544e-11 - mse: 1.0544e-11 - val_loss: 8.6584e-11 - val_mse: 8.6584e-11\n",
      "Epoch 681/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7385e-11 - mse: 2.7385e-11 - val_loss: 6.1846e-11 - val_mse: 6.1846e-11\n",
      "Epoch 682/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6398e-10 - mse: 3.6398e-10 - val_loss: 1.0055e-09 - val_mse: 1.0055e-09\n",
      "Epoch 683/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2480e-09 - mse: 3.2480e-09 - val_loss: 7.4422e-07 - val_mse: 7.4422e-07\n",
      "Epoch 684/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.8679e-07 - mse: 9.8679e-07 - val_loss: 1.2214e-05 - val_mse: 1.2214e-05\n",
      "Epoch 685/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9728e-05 - mse: 1.9728e-05 - val_loss: 1.0526e-05 - val_mse: 1.0526e-05\n",
      "Epoch 686/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.8490e-06 - mse: 8.8490e-06 - val_loss: 1.3122e-06 - val_mse: 1.3122e-06\n",
      "Epoch 687/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4637e-07 - mse: 2.4637e-07 - val_loss: 1.3184e-07 - val_mse: 1.3184e-07\n",
      "Epoch 688/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2856e-08 - mse: 7.2856e-08 - val_loss: 4.7692e-06 - val_mse: 4.7692e-06\n",
      "Epoch 689/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1325e-07 - mse: 3.1325e-07 - val_loss: 1.2675e-08 - val_mse: 1.2675e-08\n",
      "Epoch 690/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.1746e-07 - mse: 6.1746e-07 - val_loss: 7.5251e-06 - val_mse: 7.5251e-06\n",
      "Epoch 691/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2989e-06 - mse: 2.2989e-06 - val_loss: 1.2363e-07 - val_mse: 1.2363e-07\n",
      "Epoch 692/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 3.5505e-09 - mse: 3.5505e-09 - val_loss: 4.2167e-08 - val_mse: 4.2167e-08\n",
      "Epoch 693/1000\n",
      "60/60 [==============================] - 0s 977us/step - loss: 8.6613e-09 - mse: 8.6613e-09 - val_loss: 2.3923e-08 - val_mse: 2.3923e-08\n",
      "Epoch 694/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.9266e-09 - mse: 4.9266e-09 - val_loss: 5.7356e-08 - val_mse: 5.7356e-08\n",
      "Epoch 695/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.7642e-07 - mse: 5.7642e-07 - val_loss: 5.2061e-05 - val_mse: 5.2061e-05\n",
      "Epoch 696/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3486e-06 - mse: 4.3486e-06 - val_loss: 1.5028e-04 - val_mse: 1.5028e-04\n",
      "Epoch 697/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 2.9512e-04 - mse: 2.9512e-04 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 698/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 4.2269e-04 - val_mse: 4.2269e-04\n",
      "Epoch 699/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0777 - val_mse: 0.0777\n",
      "Epoch 700/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1406 - mse: 0.1406 - val_loss: 1.0751e-04 - val_mse: 1.0751e-04\n",
      "Epoch 701/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4867e-04 - mse: 1.4867e-04 - val_loss: 1.3642e-04 - val_mse: 1.3642e-04\n",
      "Epoch 702/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4124e-05 - mse: 3.4124e-05 - val_loss: 9.8241e-08 - val_mse: 9.8241e-08\n",
      "Epoch 703/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9185e-07 - mse: 1.9185e-07 - val_loss: 1.1798e-06 - val_mse: 1.1798e-06\n",
      "Epoch 704/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7392e-07 - mse: 2.7392e-07 - val_loss: 1.9789e-07 - val_mse: 1.9789e-07\n",
      "Epoch 705/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5516e-08 - mse: 3.5516e-08 - val_loss: 1.7189e-08 - val_mse: 1.7189e-08\n",
      "Epoch 706/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2850e-08 - mse: 2.2850e-08 - val_loss: 5.6098e-10 - val_mse: 5.6098e-10\n",
      "Epoch 707/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5022e-10 - mse: 1.5022e-10 - val_loss: 1.0485e-09 - val_mse: 1.0485e-09\n",
      "Epoch 708/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8216e-11 - mse: 7.8216e-11 - val_loss: 7.2032e-11 - val_mse: 7.2032e-11\n",
      "Epoch 709/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.0064e-12 - mse: 7.0064e-12 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
      "Epoch 710/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0853e-11 - mse: 1.0853e-11 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 711/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0692e-12 - mse: 5.0692e-12 - val_loss: 1.8917e-11 - val_mse: 1.8917e-11\n",
      "Epoch 712/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9853e-12 - mse: 6.9853e-12 - val_loss: 5.3114e-11 - val_mse: 5.3114e-11\n",
      "Epoch 713/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4540e-11 - mse: 1.4540e-11 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
      "Epoch 714/1000\n",
      "60/60 [==============================] - 0s 896us/step - loss: 5.2614e-12 - mse: 5.2614e-12 - val_loss: 4.0018e-11 - val_mse: 4.0018e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 715/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 6.5981e-12 - mse: 6.5981e-12 - val_loss: 1.1642e-11 - val_mse: 1.1642e-11\n",
      "Epoch 716/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1462e-11 - mse: 2.1462e-11 - val_loss: 4.9949e-09 - val_mse: 4.9949e-09\n",
      "Epoch 717/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.0713e-10 - mse: 7.0713e-10 - val_loss: 4.8531e-10 - val_mse: 4.8531e-10\n",
      "Epoch 718/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4011e-11 - mse: 2.4011e-11 - val_loss: 2.0373e-11 - val_mse: 2.0373e-11\n",
      "Epoch 719/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.6770e-12 - mse: 9.6770e-12 - val_loss: 4.4383e-11 - val_mse: 4.4383e-11\n",
      "Epoch 720/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3574e-11 - mse: 2.3574e-11 - val_loss: 1.3097e-11 - val_mse: 1.3097e-11\n",
      "Epoch 721/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6954e-12 - mse: 6.6954e-12 - val_loss: 1.6007e-11 - val_mse: 1.6007e-11\n",
      "Epoch 722/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.8563e-12 - mse: 8.8563e-12 - val_loss: 1.0405e-10 - val_mse: 1.0405e-10\n",
      "Epoch 723/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.4777e-12 - mse: 8.4777e-12 - val_loss: 4.2201e-11 - val_mse: 4.2201e-11\n",
      "Epoch 724/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9165e-12 - mse: 8.9165e-12 - val_loss: 2.2555e-11 - val_mse: 2.2555e-11\n",
      "Epoch 725/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.6193e-12 - mse: 7.6193e-12 - val_loss: 1.9645e-11 - val_mse: 1.9645e-11\n",
      "Epoch 726/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8568e-11 - mse: 3.8568e-11 - val_loss: 8.9494e-11 - val_mse: 8.9494e-11\n",
      "Epoch 727/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5571e-11 - mse: 2.5571e-11 - val_loss: 6.5484e-11 - val_mse: 6.5484e-11\n",
      "Epoch 728/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6105e-11 - mse: 2.6105e-11 - val_loss: 7.9090e-10 - val_mse: 7.9090e-10\n",
      "Epoch 729/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 5.1559e-10 - mse: 5.1559e-10 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
      "Epoch 730/1000\n",
      "60/60 [==============================] - 0s 980us/step - loss: 7.8661e-10 - mse: 7.8661e-10 - val_loss: 4.7105e-09 - val_mse: 4.7105e-09\n",
      "Epoch 731/1000\n",
      "60/60 [==============================] - 0s 983us/step - loss: 2.3258e-09 - mse: 2.3258e-09 - val_loss: 5.2161e-09 - val_mse: 5.2161e-09\n",
      "Epoch 732/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 3.5363e-09 - mse: 3.5363e-09 - val_loss: 2.8092e-07 - val_mse: 2.8092e-07\n",
      "Epoch 733/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 2.7747e-08 - mse: 2.7747e-08 - val_loss: 3.3877e-09 - val_mse: 3.3877e-09\n",
      "Epoch 734/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3429e-08 - mse: 2.3429e-08 - val_loss: 3.7567e-08 - val_mse: 3.7567e-08\n",
      "Epoch 735/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 7.4481e-09 - mse: 7.4481e-09 - val_loss: 8.7588e-09 - val_mse: 8.7588e-09\n",
      "Epoch 736/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 1.2417e-08 - mse: 1.2417e-08 - val_loss: 1.4348e-09 - val_mse: 1.4348e-09\n",
      "Epoch 737/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0423e-09 - mse: 3.0423e-09 - val_loss: 2.6241e-07 - val_mse: 2.6241e-07\n",
      "Epoch 738/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.2014e-08 - mse: 5.2014e-08 - val_loss: 1.9591e-06 - val_mse: 1.9591e-06\n",
      "Epoch 739/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3299e-06 - mse: 1.3299e-06 - val_loss: 5.4242e-09 - val_mse: 5.4242e-09\n",
      "Epoch 740/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9095e-08 - mse: 1.9095e-08 - val_loss: 5.5508e-08 - val_mse: 5.5508e-08\n",
      "Epoch 741/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7244e-08 - mse: 3.7244e-08 - val_loss: 7.8043e-07 - val_mse: 7.8043e-07\n",
      "Epoch 742/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.7320e-06 - mse: 8.7320e-06 - val_loss: 6.5478e-04 - val_mse: 6.5478e-04\n",
      "Epoch 743/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.5950e-05 - mse: 8.5950e-05 - val_loss: 7.2785e-04 - val_mse: 7.2785e-04\n",
      "Epoch 744/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1934e-04 - mse: 2.1934e-04 - val_loss: 5.2925e-04 - val_mse: 5.2925e-04\n",
      "Epoch 745/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3082e-04 - mse: 2.3082e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 746/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.0991e-04 - mse: 8.0991e-04 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 747/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 748/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 9.8920e-05 - val_mse: 9.8920e-05\n",
      "Epoch 749/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9631e-05 - mse: 1.9631e-05 - val_loss: 5.8257e-05 - val_mse: 5.8257e-05\n",
      "Epoch 750/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7739e-05 - mse: 2.7739e-05 - val_loss: 5.7362e-06 - val_mse: 5.7362e-06\n",
      "Epoch 751/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 8.3843e-06 - mse: 8.3843e-06 - val_loss: 7.0803e-08 - val_mse: 7.0803e-08\n",
      "Epoch 752/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4288e-07 - mse: 4.4288e-07 - val_loss: 4.1495e-09 - val_mse: 4.1495e-09\n",
      "Epoch 753/1000\n",
      "60/60 [==============================] - 0s 975us/step - loss: 1.4870e-07 - mse: 1.4870e-07 - val_loss: 3.6624e-06 - val_mse: 3.6624e-06\n",
      "Epoch 754/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.1342e-07 - mse: 6.1342e-07 - val_loss: 4.5337e-05 - val_mse: 4.5337e-05\n",
      "Epoch 755/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5595e-05 - mse: 2.5595e-05 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 756/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.9175 - val_mse: 0.9175\n",
      "Epoch 757/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5065 - mse: 0.5065 - val_loss: 0.3407 - val_mse: 0.3407\n",
      "Epoch 758/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0483 - mse: 0.0483 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 759/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 760/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3969e-04 - mse: 1.3969e-04 - val_loss: 7.1380e-05 - val_mse: 7.1380e-05\n",
      "Epoch 761/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1053e-06 - mse: 3.1053e-06 - val_loss: 1.1921e-07 - val_mse: 1.1921e-07\n",
      "Epoch 762/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0975e-07 - mse: 1.0975e-07 - val_loss: 7.4807e-08 - val_mse: 7.4807e-08\n",
      "Epoch 763/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5962e-08 - mse: 2.5962e-08 - val_loss: 5.8066e-08 - val_mse: 5.8066e-08\n",
      "Epoch 764/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1011e-08 - mse: 1.1011e-08 - val_loss: 8.4568e-09 - val_mse: 8.4568e-09\n",
      "Epoch 765/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0479e-09 - mse: 1.0479e-09 - val_loss: 8.3601e-10 - val_mse: 8.3601e-10\n",
      "Epoch 766/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7025e-11 - mse: 6.7025e-11 - val_loss: 4.2201e-11 - val_mse: 4.2201e-11\n",
      "Epoch 767/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.8762e-12 - mse: 6.8762e-12 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
      "Epoch 768/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 5.6531e-12 - mse: 5.6531e-12 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
      "Epoch 769/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4909e-12 - mse: 5.4909e-12 - val_loss: 3.8563e-11 - val_mse: 3.8563e-11\n",
      "Epoch 770/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.2895e-12 - mse: 6.2895e-12 - val_loss: 1.0332e-10 - val_mse: 1.0332e-10\n",
      "Epoch 771/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.8209e-12 - mse: 9.8209e-12 - val_loss: 4.0745e-11 - val_mse: 4.0745e-11\n",
      "Epoch 772/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8024e-12 - mse: 3.8024e-12 - val_loss: 3.7835e-11 - val_mse: 3.7835e-11\n",
      "Epoch 773/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3830e-12 - mse: 3.3830e-12 - val_loss: 4.9477e-11 - val_mse: 4.9477e-11\n",
      "Epoch 774/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1424e-12 - mse: 3.1424e-12 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
      "Epoch 775/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9155e-12 - mse: 5.9155e-12 - val_loss: 4.0745e-11 - val_mse: 4.0745e-11\n",
      "Epoch 776/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3575e-12 - mse: 6.3575e-12 - val_loss: 3.9290e-11 - val_mse: 3.9290e-11\n",
      "Epoch 777/1000\n",
      "60/60 [==============================] - 0s 993us/step - loss: 4.4648e-12 - mse: 4.4648e-12 - val_loss: 4.2201e-11 - val_mse: 4.2201e-11\n",
      "Epoch 778/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2656e-12 - mse: 4.2656e-12 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
      "Epoch 779/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8301e-12 - mse: 3.8301e-12 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
      "Epoch 780/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7319e-12 - mse: 2.7319e-12 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
      "Epoch 781/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 2.7891e-12 - mse: 2.7891e-12 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
      "Epoch 782/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3289e-12 - mse: 3.3289e-12 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
      "Epoch 783/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3501e-12 - mse: 3.3501e-12 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
      "Epoch 784/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8660e-12 - mse: 2.8660e-12 - val_loss: 1.8917e-11 - val_mse: 1.8917e-11\n",
      "Epoch 785/1000\n",
      "60/60 [==============================] - 0s 944us/step - loss: 2.5684e-12 - mse: 2.5684e-12 - val_loss: 1.8917e-11 - val_mse: 1.8917e-11\n",
      "Epoch 786/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.6023e-12 - mse: 4.6023e-12 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
      "Epoch 787/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8677e-12 - mse: 7.8677e-12 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
      "Epoch 788/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3655e-12 - mse: 3.3655e-12 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
      "Epoch 789/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2771e-12 - mse: 2.2771e-12 - val_loss: 1.8917e-11 - val_mse: 1.8917e-11\n",
      "Epoch 790/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1262e-12 - mse: 4.1262e-12 - val_loss: 1.6007e-11 - val_mse: 1.6007e-11\n",
      "Epoch 791/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4486e-12 - mse: 4.4486e-12 - val_loss: 2.3283e-11 - val_mse: 2.3283e-11\n",
      "Epoch 792/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5133e-12 - mse: 2.5133e-12 - val_loss: 4.8021e-11 - val_mse: 4.8021e-11\n",
      "Epoch 793/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1295e-12 - mse: 4.1295e-12 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 794/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.2728e-12 - mse: 9.2728e-12 - val_loss: 4.0745e-11 - val_mse: 4.0745e-11\n",
      "Epoch 795/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.2623e-12 - mse: 8.2623e-12 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 796/1000\n",
      "60/60 [==============================] - 0s 991us/step - loss: 3.5680e-12 - mse: 3.5680e-12 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
      "Epoch 797/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 4.1352e-12 - mse: 4.1352e-12 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
      "Epoch 798/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7696e-12 - mse: 2.7696e-12 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
      "Epoch 799/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.7564e-12 - mse: 5.7564e-12 - val_loss: 1.1933e-10 - val_mse: 1.1933e-10\n",
      "Epoch 800/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3442e-11 - mse: 1.3442e-11 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
      "Epoch 801/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 3.9872e-12 - mse: 3.9872e-12 - val_loss: 3.4925e-11 - val_mse: 3.4925e-11\n",
      "Epoch 802/1000\n",
      "60/60 [==============================] - 0s 975us/step - loss: 3.0298e-12 - mse: 3.0298e-12 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 803/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4956e-12 - mse: 1.4956e-12 - val_loss: 1.8190e-11 - val_mse: 1.8190e-11\n",
      "Epoch 804/1000\n",
      "60/60 [==============================] - 0s 996us/step - loss: 7.7826e-11 - mse: 7.7826e-11 - val_loss: 4.9477e-11 - val_mse: 4.9477e-11\n",
      "Epoch 805/1000\n",
      "60/60 [==============================] - 0s 979us/step - loss: 2.1074e-10 - mse: 2.1074e-10 - val_loss: 4.9477e-11 - val_mse: 4.9477e-11\n",
      "Epoch 806/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 6.1140e-12 - mse: 6.1140e-12 - val_loss: 5.3114e-11 - val_mse: 5.3114e-11\n",
      "Epoch 807/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4195e-11 - mse: 3.4195e-11 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 808/1000\n",
      "60/60 [==============================] - 0s 982us/step - loss: 1.8085e-11 - mse: 1.8085e-11 - val_loss: 1.8794e-09 - val_mse: 1.8794e-09\n",
      "Epoch 809/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 4.8216e-10 - mse: 4.8216e-10 - val_loss: 1.0160e-08 - val_mse: 1.0160e-08\n",
      "Epoch 810/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 4.8367e-10 - mse: 4.8367e-10 - val_loss: 9.0949e-11 - val_mse: 9.0949e-11\n",
      "Epoch 811/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 9.6453e-10 - mse: 9.6453e-10 - val_loss: 7.9526e-10 - val_mse: 7.9526e-10\n",
      "Epoch 812/1000\n",
      "60/60 [==============================] - 0s 916us/step - loss: 6.7554e-08 - mse: 6.7554e-08 - val_loss: 1.1198e-06 - val_mse: 1.1198e-06\n",
      "Epoch 813/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 8.2057e-08 - mse: 8.2057e-08 - val_loss: 1.0160e-06 - val_mse: 1.0160e-06\n",
      "Epoch 814/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3783e-07 - mse: 1.3783e-07 - val_loss: 4.6240e-07 - val_mse: 4.6240e-07\n",
      "Epoch 815/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 1.7882e-05 - mse: 1.7882e-05 - val_loss: 2.0611e-08 - val_mse: 2.0611e-08\n",
      "Epoch 816/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 1.0683e-05 - mse: 1.0683e-05 - val_loss: 1.3454e-04 - val_mse: 1.3454e-04\n",
      "Epoch 817/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6950e-04 - mse: 1.6950e-04 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 818/1000\n",
      "60/60 [==============================] - 0s 925us/step - loss: 4.2663e-04 - mse: 4.2663e-04 - val_loss: 7.2537e-07 - val_mse: 7.2537e-07\n",
      "Epoch 819/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 6.2930e-06 - mse: 6.2930e-06 - val_loss: 6.9307e-07 - val_mse: 6.9307e-07\n",
      "Epoch 820/1000\n",
      "60/60 [==============================] - 0s 896us/step - loss: 4.2016e-07 - mse: 4.2016e-07 - val_loss: 1.7444e-04 - val_mse: 1.7444e-04\n",
      "Epoch 821/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 822/1000\n",
      "60/60 [==============================] - 0s 919us/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.9432 - val_mse: 0.9432\n",
      "Epoch 823/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 0.1499 - mse: 0.1499 - val_loss: 0.3037 - val_mse: 0.3037\n",
      "Epoch 824/1000\n",
      "60/60 [==============================] - 0s 909us/step - loss: 0.0211 - mse: 0.0211 - val_loss: 8.8066e-04 - val_mse: 8.8066e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 825/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 1.4079e-04 - mse: 1.4079e-04 - val_loss: 2.1114e-05 - val_mse: 2.1114e-05\n",
      "Epoch 826/1000\n",
      "60/60 [==============================] - 0s 944us/step - loss: 2.2922e-06 - mse: 2.2922e-06 - val_loss: 3.7105e-07 - val_mse: 3.7105e-07\n",
      "Epoch 827/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 3.0754e-08 - mse: 3.0754e-08 - val_loss: 4.7832e-09 - val_mse: 4.7832e-09\n",
      "Epoch 828/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 5.3288e-10 - mse: 5.3288e-10 - val_loss: 1.4821e-09 - val_mse: 1.4821e-09\n",
      "Epoch 829/1000\n",
      "60/60 [==============================] - 0s 962us/step - loss: 5.8071e-11 - mse: 5.8071e-11 - val_loss: 1.3824e-11 - val_mse: 1.3824e-11\n",
      "Epoch 830/1000\n",
      "60/60 [==============================] - 0s 945us/step - loss: 7.7039e-12 - mse: 7.7039e-12 - val_loss: 1.6735e-11 - val_mse: 1.6735e-11\n",
      "Epoch 831/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 4.7173e-12 - mse: 4.7173e-12 - val_loss: 1.6735e-11 - val_mse: 1.6735e-11\n",
      "Epoch 832/1000\n",
      "60/60 [==============================] - 0s 919us/step - loss: 7.0722e-12 - mse: 7.0722e-12 - val_loss: 1.6735e-11 - val_mse: 1.6735e-11\n",
      "Epoch 833/1000\n",
      "60/60 [==============================] - 0s 964us/step - loss: 4.6163e-12 - mse: 4.6163e-12 - val_loss: 1.6007e-11 - val_mse: 1.6007e-11\n",
      "Epoch 834/1000\n",
      "60/60 [==============================] - 0s 945us/step - loss: 6.1131e-12 - mse: 6.1131e-12 - val_loss: 1.6735e-11 - val_mse: 1.6735e-11\n",
      "Epoch 835/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 6.1312e-12 - mse: 6.1312e-12 - val_loss: 1.6007e-11 - val_mse: 1.6007e-11\n",
      "Epoch 836/1000\n",
      "60/60 [==============================] - 0s 944us/step - loss: 7.9339e-12 - mse: 7.9339e-12 - val_loss: 1.8917e-11 - val_mse: 1.8917e-11\n",
      "Epoch 837/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 5.7923e-12 - mse: 5.7923e-12 - val_loss: 1.8917e-11 - val_mse: 1.8917e-11\n",
      "Epoch 838/1000\n",
      "60/60 [==============================] - 0s 925us/step - loss: 6.7728e-12 - mse: 6.7728e-12 - val_loss: 1.0186e-11 - val_mse: 1.0186e-11\n",
      "Epoch 839/1000\n",
      "60/60 [==============================] - 0s 974us/step - loss: 6.3792e-12 - mse: 6.3792e-12 - val_loss: 4.5839e-11 - val_mse: 4.5839e-11\n",
      "Epoch 840/1000\n",
      "60/60 [==============================] - 0s 957us/step - loss: 5.8945e-12 - mse: 5.8945e-12 - val_loss: 9.2405e-11 - val_mse: 9.2405e-11\n",
      "Epoch 841/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 5.4875e-12 - mse: 5.4875e-12 - val_loss: 8.0036e-12 - val_mse: 8.0036e-12\n",
      "Epoch 842/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 4.6671e-12 - mse: 4.6671e-12 - val_loss: 1.0914e-11 - val_mse: 1.0914e-11\n",
      "Epoch 843/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 4.8673e-12 - mse: 4.8673e-12 - val_loss: 1.0914e-11 - val_mse: 1.0914e-11\n",
      "Epoch 844/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 8.7874e-12 - mse: 8.7874e-12 - val_loss: 1.6225e-10 - val_mse: 1.6225e-10\n",
      "Epoch 845/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 8.0508e-12 - mse: 8.0508e-12 - val_loss: 8.0036e-12 - val_mse: 8.0036e-12\n",
      "Epoch 846/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 4.1311e-12 - mse: 4.1311e-12 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
      "Epoch 847/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 8.7385e-12 - mse: 8.7385e-12 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 848/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 5.5575e-12 - mse: 5.5575e-12 - val_loss: 9.2405e-11 - val_mse: 9.2405e-11\n",
      "Epoch 849/1000\n",
      "60/60 [==============================] - 0s 895us/step - loss: 8.1148e-12 - mse: 8.1148e-12 - val_loss: 7.2760e-12 - val_mse: 7.2760e-12\n",
      "Epoch 850/1000\n",
      "60/60 [==============================] - 0s 944us/step - loss: 1.2809e-11 - mse: 1.2809e-11 - val_loss: 1.3824e-11 - val_mse: 1.3824e-11\n",
      "Epoch 851/1000\n",
      "60/60 [==============================] - 0s 924us/step - loss: 2.0945e-10 - mse: 2.0945e-10 - val_loss: 1.9645e-10 - val_mse: 1.9645e-10\n",
      "Epoch 852/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 1.3314e-09 - mse: 1.3314e-09 - val_loss: 8.8767e-11 - val_mse: 8.8767e-11\n",
      "Epoch 853/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 5.7050e-11 - mse: 5.7050e-11 - val_loss: 2.5830e-10 - val_mse: 2.5830e-10\n",
      "Epoch 854/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.6823e-11 - mse: 7.6823e-11 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
      "Epoch 855/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 3.0444e-10 - mse: 3.0444e-10 - val_loss: 6.5149e-09 - val_mse: 6.5149e-09\n",
      "Epoch 856/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 1.5216e-08 - mse: 1.5216e-08 - val_loss: 6.9893e-09 - val_mse: 6.9893e-09\n",
      "Epoch 857/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 9.1435e-08 - mse: 9.1435e-08 - val_loss: 1.2047e-07 - val_mse: 1.2047e-07\n",
      "Epoch 858/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 1.1586e-08 - mse: 1.1586e-08 - val_loss: 5.9091e-08 - val_mse: 5.9091e-08\n",
      "Epoch 859/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4726e-08 - mse: 2.4726e-08 - val_loss: 2.9085e-08 - val_mse: 2.9085e-08\n",
      "Epoch 860/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 7.9271e-08 - mse: 7.9271e-08 - val_loss: 6.9148e-07 - val_mse: 6.9148e-07\n",
      "Epoch 861/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2122e-06 - mse: 1.2122e-06 - val_loss: 9.6558e-06 - val_mse: 9.6558e-06\n",
      "Epoch 862/1000\n",
      "60/60 [==============================] - 0s 925us/step - loss: 3.7076e-05 - mse: 3.7076e-05 - val_loss: 1.3898e-05 - val_mse: 1.3898e-05\n",
      "Epoch 863/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 1.2112e-05 - mse: 1.2112e-05 - val_loss: 2.9584e-04 - val_mse: 2.9584e-04\n",
      "Epoch 864/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 7.5802e-04 - mse: 7.5802e-04 - val_loss: 0.2212 - val_mse: 0.2212\n",
      "Epoch 865/1000\n",
      "60/60 [==============================] - 0s 899us/step - loss: 0.0861 - mse: 0.0861 - val_loss: 0.0461 - val_mse: 0.0461\n",
      "Epoch 866/1000\n",
      "60/60 [==============================] - 0s 988us/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 867/1000\n",
      "60/60 [==============================] - 0s 945us/step - loss: 2.5663e-04 - mse: 2.5663e-04 - val_loss: 7.1966e-06 - val_mse: 7.1966e-06\n",
      "Epoch 868/1000\n",
      "60/60 [==============================] - 0s 914us/step - loss: 6.3698e-06 - mse: 6.3698e-06 - val_loss: 1.1725e-06 - val_mse: 1.1725e-06\n",
      "Epoch 869/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 7.3226e-08 - mse: 7.3226e-08 - val_loss: 3.6089e-10 - val_mse: 3.6089e-10\n",
      "Epoch 870/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 4.0700e-10 - mse: 4.0700e-10 - val_loss: 1.1496e-10 - val_mse: 1.1496e-10\n",
      "Epoch 871/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 1.0756e-11 - mse: 1.0756e-11 - val_loss: 3.9290e-11 - val_mse: 3.9290e-11\n",
      "Epoch 872/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 4.6746e-12 - mse: 4.6746e-12 - val_loss: 4.5111e-11 - val_mse: 4.5111e-11\n",
      "Epoch 873/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 3.3237e-12 - mse: 3.3237e-12 - val_loss: 4.2201e-11 - val_mse: 4.2201e-11\n",
      "Epoch 874/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 3.1542e-12 - mse: 3.1542e-12 - val_loss: 4.1473e-11 - val_mse: 4.1473e-11\n",
      "Epoch 875/1000\n",
      "60/60 [==============================] - 0s 902us/step - loss: 3.2487e-12 - mse: 3.2487e-12 - val_loss: 4.0745e-11 - val_mse: 4.0745e-11\n",
      "Epoch 876/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 2.6130e-12 - mse: 2.6130e-12 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 877/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 6.9691e-12 - mse: 6.9691e-12 - val_loss: 4.8021e-11 - val_mse: 4.8021e-11\n",
      "Epoch 878/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 1.2008e-11 - mse: 1.2008e-11 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
      "Epoch 879/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 3.7809e-12 - mse: 3.7809e-12 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
      "Epoch 880/1000\n",
      "60/60 [==============================] - 0s 967us/step - loss: 5.1377e-12 - mse: 5.1377e-12 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 881/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 5.4632e-12 - mse: 5.4632e-12 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 882/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 2.9416e-12 - mse: 2.9416e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 883/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0681e-12 - mse: 3.0681e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 884/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 3.4099e-12 - mse: 3.4099e-12 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 885/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.7420e-12 - mse: 9.7420e-12 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
      "Epoch 886/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.6373e-12 - mse: 4.6373e-12 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
      "Epoch 887/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9374e-11 - mse: 1.9374e-11 - val_loss: 3.4925e-11 - val_mse: 3.4925e-11\n",
      "Epoch 888/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3389e-12 - mse: 7.3389e-12 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 889/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5185e-12 - mse: 2.5185e-12 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
      "Epoch 890/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.2910e-12 - mse: 5.2910e-12 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
      "Epoch 891/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.2261e-12 - mse: 5.2261e-12 - val_loss: 5.3114e-11 - val_mse: 5.3114e-11\n",
      "Epoch 892/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.9127e-12 - mse: 9.9127e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 893/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6224e-12 - mse: 3.6224e-12 - val_loss: 4.7294e-11 - val_mse: 4.7294e-11\n",
      "Epoch 894/1000\n",
      "60/60 [==============================] - 0s 965us/step - loss: 4.9274e-11 - mse: 4.9274e-11 - val_loss: 3.9676e-09 - val_mse: 3.9676e-09\n",
      "Epoch 895/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3896e-10 - mse: 2.3896e-10 - val_loss: 3.5652e-11 - val_mse: 3.5652e-11\n",
      "Epoch 896/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0750e-12 - mse: 2.0750e-12 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
      "Epoch 897/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4053e-12 - mse: 3.4053e-12 - val_loss: 4.4383e-11 - val_mse: 4.4383e-11\n",
      "Epoch 898/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2006e-12 - mse: 4.2006e-12 - val_loss: 4.7294e-11 - val_mse: 4.7294e-11\n",
      "Epoch 899/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9221e-12 - mse: 2.9221e-12 - val_loss: 2.3283e-11 - val_mse: 2.3283e-11\n",
      "Epoch 900/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3720e-10 - mse: 1.3720e-10 - val_loss: 1.6953e-10 - val_mse: 1.6953e-10\n",
      "Epoch 901/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6378e-10 - mse: 2.6378e-10 - val_loss: 3.0705e-10 - val_mse: 3.0705e-10\n",
      "Epoch 902/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6798e-08 - mse: 1.6798e-08 - val_loss: 4.2297e-07 - val_mse: 4.2297e-07\n",
      "Epoch 903/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.8224e-07 - mse: 6.8224e-07 - val_loss: 3.5874e-07 - val_mse: 3.5874e-07\n",
      "Epoch 904/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6865e-07 - mse: 3.6865e-07 - val_loss: 2.5632e-05 - val_mse: 2.5632e-05\n",
      "Epoch 905/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.2288 - val_mse: 0.2288\n",
      "Epoch 906/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0900 - val_mse: 0.0900\n",
      "Epoch 907/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.0777e-04 - mse: 8.0777e-04 - val_loss: 2.6898e-04 - val_mse: 2.6898e-04\n",
      "Epoch 908/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.3373e-05 - mse: 5.3373e-05 - val_loss: 1.3994e-05 - val_mse: 1.3994e-05\n",
      "Epoch 909/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9644e-07 - mse: 8.9644e-07 - val_loss: 9.4949e-08 - val_mse: 9.4949e-08\n",
      "Epoch 910/1000\n",
      "60/60 [==============================] - 0s 997us/step - loss: 6.3793e-09 - mse: 6.3793e-09 - val_loss: 4.7512e-10 - val_mse: 4.7512e-10\n",
      "Epoch 911/1000\n",
      "60/60 [==============================] - 0s 976us/step - loss: 3.8176e-10 - mse: 3.8176e-10 - val_loss: 4.4849e-09 - val_mse: 4.4849e-09\n",
      "Epoch 912/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6533e-09 - mse: 1.6533e-09 - val_loss: 1.1955e-08 - val_mse: 1.1955e-08\n",
      "Epoch 913/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7755e-08 - mse: 1.7755e-08 - val_loss: 1.0247e-06 - val_mse: 1.0247e-06\n",
      "Epoch 914/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9804e-07 - mse: 1.9804e-07 - val_loss: 3.4738e-07 - val_mse: 3.4738e-07\n",
      "Epoch 915/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5020e-08 - mse: 3.5020e-08 - val_loss: 1.7533e-08 - val_mse: 1.7533e-08\n",
      "Epoch 916/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.4909e-10 - mse: 7.4909e-10 - val_loss: 2.0227e-10 - val_mse: 2.0227e-10\n",
      "Epoch 917/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2681e-11 - mse: 3.2681e-11 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
      "Epoch 918/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8289e-10 - mse: 1.8289e-10 - val_loss: 3.1287e-11 - val_mse: 3.1287e-11\n",
      "Epoch 919/1000\n",
      "60/60 [==============================] - 0s 984us/step - loss: 9.3827e-12 - mse: 9.3827e-12 - val_loss: 2.8376e-11 - val_mse: 2.8376e-11\n",
      "Epoch 920/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7184e-10 - mse: 1.7184e-10 - val_loss: 1.2887e-08 - val_mse: 1.2887e-08\n",
      "Epoch 921/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0716e-08 - mse: 1.0716e-08 - val_loss: 2.0205e-09 - val_mse: 2.0205e-09\n",
      "Epoch 922/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7747e-08 - mse: 2.7747e-08 - val_loss: 1.3496e-07 - val_mse: 1.3496e-07\n",
      "Epoch 923/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.7016e-06 - mse: 5.7016e-06 - val_loss: 1.2480e-06 - val_mse: 1.2480e-06\n",
      "Epoch 924/1000\n",
      "60/60 [==============================] - 0s 970us/step - loss: 2.0249e-07 - mse: 2.0249e-07 - val_loss: 3.2531e-08 - val_mse: 3.2531e-08\n",
      "Epoch 925/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5765e-09 - mse: 4.5765e-09 - val_loss: 5.0534e-08 - val_mse: 5.0534e-08\n",
      "Epoch 926/1000\n",
      "60/60 [==============================] - 0s 974us/step - loss: 4.4898e-09 - mse: 4.4898e-09 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 927/1000\n",
      "60/60 [==============================] - 0s 991us/step - loss: 3.5277e-09 - mse: 3.5277e-09 - val_loss: 2.8717e-08 - val_mse: 2.8717e-08\n",
      "Epoch 928/1000\n",
      "60/60 [==============================] - 0s 970us/step - loss: 3.9250e-08 - mse: 3.9250e-08 - val_loss: 9.6008e-06 - val_mse: 9.6008e-06\n",
      "Epoch 929/1000\n",
      "60/60 [==============================] - 0s 917us/step - loss: 2.2744e-06 - mse: 2.2744e-06 - val_loss: 1.9419e-07 - val_mse: 1.9419e-07\n",
      "Epoch 930/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0132e-05 - mse: 1.0132e-05 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 931/1000\n",
      "60/60 [==============================] - 0s 982us/step - loss: 6.0290e-05 - mse: 6.0290e-05 - val_loss: 1.6481e-04 - val_mse: 1.6481e-04\n",
      "Epoch 932/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0843e-05 - mse: 4.0843e-05 - val_loss: 5.7158e-06 - val_mse: 5.7158e-06\n",
      "Epoch 933/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 2.4583e-05 - mse: 2.4583e-05 - val_loss: 1.1599e-05 - val_mse: 1.1599e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 934/1000\n",
      "60/60 [==============================] - 0s 993us/step - loss: 5.3504e-04 - mse: 5.3504e-04 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 935/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 936/1000\n",
      "60/60 [==============================] - 0s 957us/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 937/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 3.0326e-04 - mse: 3.0326e-04 - val_loss: 1.3956e-05 - val_mse: 1.3956e-05\n",
      "Epoch 938/1000\n",
      "60/60 [==============================] - 0s 976us/step - loss: 4.5741e-06 - mse: 4.5741e-06 - val_loss: 4.3212e-05 - val_mse: 4.3212e-05\n",
      "Epoch 939/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1874e-06 - mse: 4.1874e-06 - val_loss: 1.2280e-06 - val_mse: 1.2280e-06\n",
      "Epoch 940/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1351e-07 - mse: 1.1351e-07 - val_loss: 1.0852e-08 - val_mse: 1.0852e-08\n",
      "Epoch 941/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7759e-09 - mse: 3.7759e-09 - val_loss: 4.2659e-09 - val_mse: 4.2659e-09\n",
      "Epoch 942/1000\n",
      "60/60 [==============================] - 0s 982us/step - loss: 9.1700e-10 - mse: 9.1700e-10 - val_loss: 2.4883e-08 - val_mse: 2.4883e-08\n",
      "Epoch 943/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 1.4514e-07 - mse: 1.4514e-07 - val_loss: 1.6191e-05 - val_mse: 1.6191e-05\n",
      "Epoch 944/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 1.5322e-06 - mse: 1.5322e-06 - val_loss: 1.2341e-06 - val_mse: 1.2341e-06\n",
      "Epoch 945/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7042e-06 - mse: 2.7042e-06 - val_loss: 4.1605e-06 - val_mse: 4.1605e-06\n",
      "Epoch 946/1000\n",
      "60/60 [==============================] - 0s 972us/step - loss: 9.5531e-07 - mse: 9.5531e-07 - val_loss: 3.2354e-08 - val_mse: 3.2354e-08\n",
      "Epoch 947/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5558e-08 - mse: 5.5558e-08 - val_loss: 5.2314e-10 - val_mse: 5.2314e-10\n",
      "Epoch 948/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.8988e-08 - mse: 5.8988e-08 - val_loss: 1.9713e-05 - val_mse: 1.9713e-05\n",
      "Epoch 949/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.5365e-06 - mse: 7.5365e-06 - val_loss: 1.0202e-05 - val_mse: 1.0202e-05\n",
      "Epoch 950/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8188e-06 - mse: 3.8188e-06 - val_loss: 6.5990e-07 - val_mse: 6.5990e-07\n",
      "Epoch 951/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6389e-05 - mse: 1.6389e-05 - val_loss: 4.6919e-07 - val_mse: 4.6919e-07\n",
      "Epoch 952/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0487e-05 - mse: 1.0487e-05 - val_loss: 3.1071e-05 - val_mse: 3.1071e-05\n",
      "Epoch 953/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2963e-05 - mse: 3.2963e-05 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 954/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 955/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9176e-04 - mse: 3.9176e-04 - val_loss: 7.5613e-07 - val_mse: 7.5613e-07\n",
      "Epoch 956/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8851e-07 - mse: 3.8851e-07 - val_loss: 7.2978e-10 - val_mse: 7.2978e-10\n",
      "Epoch 957/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6592e-07 - mse: 6.6592e-07 - val_loss: 1.0122e-05 - val_mse: 1.0122e-05\n",
      "Epoch 958/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0817e-05 - mse: 1.0817e-05 - val_loss: 1.2887e-06 - val_mse: 1.2887e-06\n",
      "Epoch 959/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9758e-07 - mse: 2.9758e-07 - val_loss: 9.9553e-08 - val_mse: 9.9553e-08\n",
      "Epoch 960/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9173e-08 - mse: 8.9173e-08 - val_loss: 4.3889e-09 - val_mse: 4.3889e-09\n",
      "Epoch 961/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8778e-10 - mse: 2.8778e-10 - val_loss: 3.6525e-10 - val_mse: 3.6525e-10\n",
      "Epoch 962/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5413e-10 - mse: 2.5413e-10 - val_loss: 1.8183e-07 - val_mse: 1.8183e-07\n",
      "Epoch 963/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8938e-07 - mse: 2.8938e-07 - val_loss: 3.8147e-06 - val_mse: 3.8147e-06\n",
      "Epoch 964/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6469e-06 - mse: 1.6469e-06 - val_loss: 3.6016e-10 - val_mse: 3.6016e-10\n",
      "Epoch 965/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0807e-07 - mse: 1.0807e-07 - val_loss: 2.1581e-06 - val_mse: 2.1581e-06\n",
      "Epoch 966/1000\n",
      "60/60 [==============================] - 0s 944us/step - loss: 3.5220e-06 - mse: 3.5220e-06 - val_loss: 1.0056e-06 - val_mse: 1.0056e-06\n",
      "Epoch 967/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0843e-07 - mse: 1.0843e-07 - val_loss: 5.0363e-07 - val_mse: 5.0363e-07\n",
      "Epoch 968/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4021e-07 - mse: 1.4021e-07 - val_loss: 1.7825e-07 - val_mse: 1.7825e-07\n",
      "Epoch 969/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 5.7686e-07 - mse: 5.7686e-07 - val_loss: 1.9021e-07 - val_mse: 1.9021e-07\n",
      "Epoch 970/1000\n",
      "60/60 [==============================] - 0s 987us/step - loss: 2.5462e-06 - mse: 2.5462e-06 - val_loss: 4.3472e-06 - val_mse: 4.3472e-06\n",
      "Epoch 971/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9712e-05 - mse: 2.9712e-05 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 972/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 973/1000\n",
      "60/60 [==============================] - 0s 986us/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 974/1000\n",
      "60/60 [==============================] - 0s 970us/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 975/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 976/1000\n",
      "60/60 [==============================] - 0s 944us/step - loss: 0.0032 - mse: 0.0032 - val_loss: 4.0869e-04 - val_mse: 4.0869e-04\n",
      "Epoch 977/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1772e-04 - mse: 1.1772e-04 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 978/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1716e-04 - mse: 4.1716e-04 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 979/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 980/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 981/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 982/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3722e-04 - mse: 3.3722e-04 - val_loss: 1.0199e-07 - val_mse: 1.0199e-07\n",
      "Epoch 983/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3104e-05 - mse: 1.3104e-05 - val_loss: 3.5238e-06 - val_mse: 3.5238e-06\n",
      "Epoch 984/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3076e-07 - mse: 2.3076e-07 - val_loss: 2.6557e-10 - val_mse: 2.6557e-10\n",
      "Epoch 985/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6305e-09 - mse: 2.6305e-09 - val_loss: 6.0390e-11 - val_mse: 6.0390e-11\n",
      "Epoch 986/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5839e-10 - mse: 4.5839e-10 - val_loss: 1.5207e-10 - val_mse: 1.5207e-10\n",
      "Epoch 987/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.6607e-12 - mse: 5.6607e-12 - val_loss: 8.0036e-11 - val_mse: 8.0036e-11\n",
      "Epoch 988/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2537e-11 - mse: 1.2537e-11 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
      "Epoch 989/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9176e-11 - mse: 1.9176e-11 - val_loss: 1.5862e-10 - val_mse: 1.5862e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5467e-12 - mse: 5.5467e-12 - val_loss: 4.0018e-11 - val_mse: 4.0018e-11\n",
      "Epoch 991/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5445e-11 - mse: 1.5445e-11 - val_loss: 1.8917e-11 - val_mse: 1.8917e-11\n",
      "Epoch 992/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0432e-11 - mse: 1.0432e-11 - val_loss: 2.3138e-10 - val_mse: 2.3138e-10\n",
      "Epoch 993/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8665e-10 - mse: 1.8665e-10 - val_loss: 9.4864e-09 - val_mse: 9.4864e-09\n",
      "Epoch 994/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0351e-09 - mse: 2.0351e-09 - val_loss: 1.1902e-08 - val_mse: 1.1902e-08\n",
      "Epoch 995/1000\n",
      "60/60 [==============================] - 0s 974us/step - loss: 1.1011e-08 - mse: 1.1011e-08 - val_loss: 5.4111e-09 - val_mse: 5.4111e-09\n",
      "Epoch 996/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 2.5551e-08 - mse: 2.5551e-08 - val_loss: 9.2235e-07 - val_mse: 9.2235e-07\n",
      "Epoch 997/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.3819e-07 - mse: 9.3819e-07 - val_loss: 1.7023e-06 - val_mse: 1.7023e-06\n",
      "Epoch 998/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1242e-06 - mse: 2.1242e-06 - val_loss: 1.1334e-04 - val_mse: 1.1334e-04\n",
      "Epoch 999/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7993e-04 - mse: 1.7993e-04 - val_loss: 0.1379 - val_mse: 0.1379\n",
      "Epoch 1000/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.2551 - val_mse: 0.2551\n",
      "20/20 [==============================] - 0s 483us/step - loss: 0.4090 - mse: 0.4090\n",
      "mse :  [0.40896669030189514, 0.40896669030189514]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff9e9b0f4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[ 81.5743  ]\n",
      " [ 82.58104 ]\n",
      " [ 83.587776]\n",
      " [ 84.59451 ]\n",
      " [ 85.60126 ]\n",
      " [ 86.608   ]\n",
      " [ 87.61474 ]\n",
      " [ 88.62147 ]\n",
      " [ 89.62821 ]\n",
      " [ 90.63496 ]\n",
      " [ 91.64169 ]\n",
      " [ 92.64843 ]\n",
      " [ 93.655174]\n",
      " [ 94.6619  ]\n",
      " [ 95.668655]\n",
      " [ 96.67539 ]\n",
      " [ 97.68213 ]\n",
      " [ 98.688866]\n",
      " [ 99.69561 ]\n",
      " [100.70235 ]]\n"
     ]
    }
   ],
   "source": [
    "# 2. 모델 구성\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(3))\n",
    "model.add(Dense(4))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 3. 훈련\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "model.fit(x=x_train, y=y_train, batch_size=1, epochs=1000, validation_data=(x_val, y_val))\n",
    "\n",
    "# 4. 평가예측\n",
    "mse = model.evaluate(x_test, y_test, batch_size=1)\n",
    "print('mse : ', mse)\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  0.6395050415346918\n",
      "r2_score :  0.9877002496797508\n"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def RMSE(y_test, y_predict):\n",
    "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "print('RMSE : ', RMSE(y_test, y_predict))\n",
    "\n",
    "# R2\n",
    "from sklearn.metrics import r2_score\n",
    "print('r2_score : ', r2_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전까지는 x_test 값으로 predict를 해주었음, 가급적이면 test한 값보다는 새로운 데이터로 예측하는 것이 좋음.  \n",
    "x_predict를 새로 입력하여 예측함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 5)                 10        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2222.3101 - mse: 2222.3101 - val_loss: 7258.6929 - val_mse: 7258.6929\n",
      "Epoch 2/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1646.4352 - mse: 1646.4352 - val_loss: 4966.2354 - val_mse: 4966.2354\n",
      "Epoch 3/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 896.6206 - mse: 896.6206 - val_loss: 3136.3533 - val_mse: 3136.3533\n",
      "Epoch 4/1000\n",
      "60/60 [==============================] - 0s 945us/step - loss: 648.7412 - mse: 648.7412 - val_loss: 1349.0334 - val_mse: 1349.0334\n",
      "Epoch 5/1000\n",
      "60/60 [==============================] - 0s 985us/step - loss: 271.2059 - mse: 271.2059 - val_loss: 345.6123 - val_mse: 345.6123\n",
      "Epoch 6/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 49.6530 - mse: 49.6530 - val_loss: 48.7862 - val_mse: 48.7862\n",
      "Epoch 7/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 6.9492 - mse: 6.9492 - val_loss: 4.7046 - val_mse: 4.7046\n",
      "Epoch 8/1000\n",
      "60/60 [==============================] - 0s 991us/step - loss: 0.5701 - mse: 0.5701 - val_loss: 1.2090 - val_mse: 1.2090\n",
      "Epoch 9/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3060 - mse: 0.3060 - val_loss: 1.0111 - val_mse: 1.0111\n",
      "Epoch 10/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 0.4507 - mse: 0.4507 - val_loss: 0.9706 - val_mse: 0.9706\n",
      "Epoch 11/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4163 - mse: 0.4163 - val_loss: 0.8872 - val_mse: 0.8872\n",
      "Epoch 12/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3946 - mse: 0.3946 - val_loss: 0.9910 - val_mse: 0.9910\n",
      "Epoch 13/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3695 - mse: 0.3695 - val_loss: 0.9399 - val_mse: 0.9399\n",
      "Epoch 14/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3676 - mse: 0.3676 - val_loss: 1.0802 - val_mse: 1.0802\n",
      "Epoch 15/1000\n",
      "60/60 [==============================] - 0s 991us/step - loss: 0.3517 - mse: 0.3517 - val_loss: 0.8839 - val_mse: 0.8839\n",
      "Epoch 16/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 0.3823 - mse: 0.3823 - val_loss: 0.9202 - val_mse: 0.9202\n",
      "Epoch 17/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 0.4063 - mse: 0.4063 - val_loss: 0.8942 - val_mse: 0.8942\n",
      "Epoch 18/1000\n",
      "60/60 [==============================] - 0s 991us/step - loss: 0.5126 - mse: 0.5126 - val_loss: 0.8789 - val_mse: 0.8789\n",
      "Epoch 19/1000\n",
      "60/60 [==============================] - 0s 974us/step - loss: 0.3453 - mse: 0.3453 - val_loss: 0.6318 - val_mse: 0.6318\n",
      "Epoch 20/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3346 - mse: 0.3346 - val_loss: 0.8347 - val_mse: 0.8347\n",
      "Epoch 21/1000\n",
      "60/60 [==============================] - 0s 969us/step - loss: 0.3776 - mse: 0.3776 - val_loss: 0.6914 - val_mse: 0.6914\n",
      "Epoch 22/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2983 - mse: 0.2983 - val_loss: 0.9022 - val_mse: 0.9022\n",
      "Epoch 23/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2878 - mse: 0.2878 - val_loss: 0.8085 - val_mse: 0.8085\n",
      "Epoch 24/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2566 - mse: 0.2566 - val_loss: 0.7931 - val_mse: 0.7931\n",
      "Epoch 25/1000\n",
      "60/60 [==============================] - 0s 983us/step - loss: 0.3603 - mse: 0.3603 - val_loss: 0.5996 - val_mse: 0.5996\n",
      "Epoch 26/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 0.2764 - mse: 0.2764 - val_loss: 0.5865 - val_mse: 0.5865\n",
      "Epoch 27/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2982 - mse: 0.2982 - val_loss: 0.7816 - val_mse: 0.7816\n",
      "Epoch 28/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3264 - mse: 0.3264 - val_loss: 0.5053 - val_mse: 0.5053\n",
      "Epoch 29/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2532 - mse: 0.2532 - val_loss: 0.6008 - val_mse: 0.6008\n",
      "Epoch 30/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1980 - mse: 0.1980 - val_loss: 0.5061 - val_mse: 0.5061\n",
      "Epoch 31/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2306 - mse: 0.2306 - val_loss: 0.6503 - val_mse: 0.6503\n",
      "Epoch 32/1000\n",
      "60/60 [==============================] - 0s 979us/step - loss: 0.2291 - mse: 0.2291 - val_loss: 0.4323 - val_mse: 0.4323\n",
      "Epoch 33/1000\n",
      "60/60 [==============================] - 0s 962us/step - loss: 0.2404 - mse: 0.2404 - val_loss: 0.7205 - val_mse: 0.7205\n",
      "Epoch 34/1000\n",
      "60/60 [==============================] - 0s 919us/step - loss: 0.2452 - mse: 0.2452 - val_loss: 0.3993 - val_mse: 0.3993\n",
      "Epoch 35/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 0.2669 - mse: 0.2669 - val_loss: 0.5247 - val_mse: 0.5247\n",
      "Epoch 36/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 0.2121 - mse: 0.2121 - val_loss: 0.3636 - val_mse: 0.3636\n",
      "Epoch 37/1000\n",
      "60/60 [==============================] - 0s 983us/step - loss: 0.1757 - mse: 0.1757 - val_loss: 0.6193 - val_mse: 0.6193\n",
      "Epoch 38/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1532 - mse: 0.1532 - val_loss: 0.4918 - val_mse: 0.4918\n",
      "Epoch 39/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2513 - mse: 0.2513 - val_loss: 0.5378 - val_mse: 0.5378\n",
      "Epoch 40/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1624 - mse: 0.1624 - val_loss: 0.5732 - val_mse: 0.5732\n",
      "Epoch 41/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1968 - mse: 0.1968 - val_loss: 0.3107 - val_mse: 0.3107\n",
      "Epoch 42/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1902 - mse: 0.1902 - val_loss: 0.3588 - val_mse: 0.3588\n",
      "Epoch 43/1000\n",
      "60/60 [==============================] - 0s 971us/step - loss: 0.1405 - mse: 0.1405 - val_loss: 0.4345 - val_mse: 0.4345\n",
      "Epoch 44/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1432 - mse: 0.1432 - val_loss: 0.3942 - val_mse: 0.3942\n",
      "Epoch 45/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1356 - mse: 0.1356 - val_loss: 0.3497 - val_mse: 0.3497\n",
      "Epoch 46/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1516 - mse: 0.1516 - val_loss: 0.2941 - val_mse: 0.2941\n",
      "Epoch 47/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1137 - mse: 0.1137 - val_loss: 0.2575 - val_mse: 0.2575\n",
      "Epoch 48/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 0.1432 - mse: 0.1432 - val_loss: 0.2682 - val_mse: 0.2682\n",
      "Epoch 49/1000\n",
      "60/60 [==============================] - 0s 962us/step - loss: 0.1062 - mse: 0.1062 - val_loss: 0.2642 - val_mse: 0.2642\n",
      "Epoch 50/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 0.0981 - mse: 0.0981 - val_loss: 0.2496 - val_mse: 0.2496\n",
      "Epoch 51/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 0.1007 - mse: 0.1007 - val_loss: 0.2287 - val_mse: 0.2287\n",
      "Epoch 52/1000\n",
      "60/60 [==============================] - 0s 973us/step - loss: 0.1003 - mse: 0.1003 - val_loss: 0.1561 - val_mse: 0.1561\n",
      "Epoch 53/1000\n",
      "60/60 [==============================] - 0s 962us/step - loss: 0.0742 - mse: 0.0742 - val_loss: 0.2401 - val_mse: 0.2401\n",
      "Epoch 54/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0750 - mse: 0.0750 - val_loss: 0.0777 - val_mse: 0.0777\n",
      "Epoch 55/1000\n",
      "60/60 [==============================] - 0s 944us/step - loss: 0.0897 - mse: 0.0897 - val_loss: 0.2331 - val_mse: 0.2331\n",
      "Epoch 56/1000\n",
      "60/60 [==============================] - 0s 988us/step - loss: 0.0693 - mse: 0.0693 - val_loss: 0.3088 - val_mse: 0.3088\n",
      "Epoch 57/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0837 - mse: 0.0837 - val_loss: 0.1424 - val_mse: 0.1424\n",
      "Epoch 58/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.1457 - val_mse: 0.1457\n",
      "Epoch 59/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0626 - mse: 0.0626 - val_loss: 0.0813 - val_mse: 0.0813\n",
      "Epoch 60/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0507 - mse: 0.0507 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 61/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.1135 - val_mse: 0.1135\n",
      "Epoch 62/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0486 - mse: 0.0486 - val_loss: 0.0506 - val_mse: 0.0506\n",
      "Epoch 63/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.1581 - val_mse: 0.1581\n",
      "Epoch 64/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.1047 - val_mse: 0.1047\n",
      "Epoch 65/1000\n",
      "60/60 [==============================] - 0s 969us/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 66/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0595 - val_mse: 0.0595\n",
      "Epoch 67/1000\n",
      "60/60 [==============================] - 0s 995us/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 68/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 69/1000\n",
      "60/60 [==============================] - 0s 994us/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 70/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0697 - val_mse: 0.0697\n",
      "Epoch 71/1000\n",
      "60/60 [==============================] - 0s 961us/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 72/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0790 - val_mse: 0.0790\n",
      "Epoch 73/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 74/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 75/1000\n",
      "60/60 [==============================] - 0s 954us/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 76/1000\n",
      "60/60 [==============================] - 0s 967us/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 77/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 78/1000\n",
      "60/60 [==============================] - 0s 972us/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 79/1000\n",
      "60/60 [==============================] - 0s 982us/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 80/1000\n",
      "60/60 [==============================] - 0s 997us/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 81/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 82/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 83/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.0031 - mse: 0.0031 - val_loss: 2.5503e-04 - val_mse: 2.5503e-04\n",
      "Epoch 84/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 85/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.7299e-04 - val_mse: 1.7299e-04\n",
      "Epoch 86/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0070 - val_mse: 0.0070\n",
      "Epoch 87/1000\n",
      "60/60 [==============================] - 0s 913us/step - loss: 0.0013 - mse: 0.0013 - val_loss: 4.7496e-04 - val_mse: 4.7496e-04\n",
      "Epoch 88/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 0.0012 - mse: 0.0012 - val_loss: 5.3404e-04 - val_mse: 5.3404e-04\n",
      "Epoch 89/1000\n",
      "60/60 [==============================] - 0s 979us/step - loss: 8.5901e-04 - mse: 8.5901e-04 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 90/1000\n",
      "60/60 [==============================] - 0s 944us/step - loss: 7.7855e-04 - mse: 7.7855e-04 - val_loss: 8.8158e-04 - val_mse: 8.8158e-04\n",
      "Epoch 91/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 6.6494e-04 - mse: 6.6494e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 92/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.2547e-04 - mse: 5.2547e-04 - val_loss: 5.8128e-04 - val_mse: 5.8128e-04\n",
      "Epoch 93/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 4.1539e-04 - mse: 4.1539e-04 - val_loss: 1.8014e-04 - val_mse: 1.8014e-04\n",
      "Epoch 94/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 3.6473e-04 - mse: 3.6473e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 95/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 2.3671e-04 - mse: 2.3671e-04 - val_loss: 2.4048e-04 - val_mse: 2.4048e-04\n",
      "Epoch 96/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 2.1181e-04 - mse: 2.1181e-04 - val_loss: 2.6199e-04 - val_mse: 2.6199e-04\n",
      "Epoch 97/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 1.5091e-04 - mse: 1.5091e-04 - val_loss: 4.2086e-04 - val_mse: 4.2086e-04\n",
      "Epoch 98/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 1.1711e-04 - mse: 1.1711e-04 - val_loss: 3.6534e-04 - val_mse: 3.6534e-04\n",
      "Epoch 99/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 7.4558e-05 - mse: 7.4558e-05 - val_loss: 8.4670e-06 - val_mse: 8.4670e-06\n",
      "Epoch 100/1000\n",
      "60/60 [==============================] - 0s 926us/step - loss: 6.8475e-05 - mse: 6.8475e-05 - val_loss: 1.2565e-06 - val_mse: 1.2565e-06\n",
      "Epoch 101/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 5.9204e-05 - mse: 5.9204e-05 - val_loss: 6.9618e-06 - val_mse: 6.9618e-06\n",
      "Epoch 102/1000\n",
      "60/60 [==============================] - 0s 954us/step - loss: 2.7966e-05 - mse: 2.7966e-05 - val_loss: 4.7304e-05 - val_mse: 4.7304e-05\n",
      "Epoch 103/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 2.2718e-05 - mse: 2.2718e-05 - val_loss: 1.8668e-04 - val_mse: 1.8668e-04\n",
      "Epoch 104/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 2.2869e-05 - mse: 2.2869e-05 - val_loss: 6.8912e-06 - val_mse: 6.8912e-06\n",
      "Epoch 105/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 1.3032e-05 - mse: 1.3032e-05 - val_loss: 7.1864e-06 - val_mse: 7.1864e-06\n",
      "Epoch 106/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 9.1274e-06 - mse: 9.1274e-06 - val_loss: 3.1646e-05 - val_mse: 3.1646e-05\n",
      "Epoch 107/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3903e-06 - mse: 7.3903e-06 - val_loss: 6.5385e-06 - val_mse: 6.5385e-06\n",
      "Epoch 108/1000\n",
      "60/60 [==============================] - 0s 993us/step - loss: 3.2474e-06 - mse: 3.2474e-06 - val_loss: 4.3248e-06 - val_mse: 4.3248e-06\n",
      "Epoch 109/1000\n",
      "60/60 [==============================] - 0s 961us/step - loss: 1.9963e-06 - mse: 1.9963e-06 - val_loss: 3.4165e-06 - val_mse: 3.4165e-06\n",
      "Epoch 110/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6165e-06 - mse: 1.6165e-06 - val_loss: 1.5562e-06 - val_mse: 1.5562e-06\n",
      "Epoch 111/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 1.2352e-06 - mse: 1.2352e-06 - val_loss: 2.2980e-06 - val_mse: 2.2980e-06\n",
      "Epoch 112/1000\n",
      "60/60 [==============================] - 0s 918us/step - loss: 8.0008e-07 - mse: 8.0008e-07 - val_loss: 6.7546e-07 - val_mse: 6.7546e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 6.0796e-07 - mse: 6.0796e-07 - val_loss: 2.2518e-07 - val_mse: 2.2518e-07\n",
      "Epoch 114/1000\n",
      "60/60 [==============================] - 0s 957us/step - loss: 2.9424e-07 - mse: 2.9424e-07 - val_loss: 2.6088e-07 - val_mse: 2.6088e-07\n",
      "Epoch 115/1000\n",
      "60/60 [==============================] - 0s 971us/step - loss: 2.0220e-07 - mse: 2.0220e-07 - val_loss: 1.9861e-07 - val_mse: 1.9861e-07\n",
      "Epoch 116/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 1.4235e-07 - mse: 1.4235e-07 - val_loss: 2.9883e-07 - val_mse: 2.9883e-07\n",
      "Epoch 117/1000\n",
      "60/60 [==============================] - 0s 967us/step - loss: 6.2751e-08 - mse: 6.2751e-08 - val_loss: 3.1389e-08 - val_mse: 3.1389e-08\n",
      "Epoch 118/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.6240e-08 - mse: 5.6240e-08 - val_loss: 5.8682e-07 - val_mse: 5.8682e-07\n",
      "Epoch 119/1000\n",
      "60/60 [==============================] - 0s 972us/step - loss: 3.6481e-08 - mse: 3.6481e-08 - val_loss: 8.4656e-08 - val_mse: 8.4656e-08\n",
      "Epoch 120/1000\n",
      "60/60 [==============================] - 0s 990us/step - loss: 2.2625e-08 - mse: 2.2625e-08 - val_loss: 5.2014e-08 - val_mse: 5.2014e-08\n",
      "Epoch 121/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 1.3216e-08 - mse: 1.3216e-08 - val_loss: 9.1386e-09 - val_mse: 9.1386e-09\n",
      "Epoch 122/1000\n",
      "60/60 [==============================] - 0s 960us/step - loss: 6.3992e-09 - mse: 6.3992e-09 - val_loss: 1.6225e-10 - val_mse: 1.6225e-10\n",
      "Epoch 123/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 4.2029e-09 - mse: 4.2029e-09 - val_loss: 2.3283e-10 - val_mse: 2.3283e-10\n",
      "Epoch 124/1000\n",
      "60/60 [==============================] - 0s 976us/step - loss: 1.9557e-09 - mse: 1.9557e-09 - val_loss: 2.3458e-09 - val_mse: 2.3458e-09\n",
      "Epoch 125/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.0231e-10 - mse: 8.0231e-10 - val_loss: 8.2946e-10 - val_mse: 8.2946e-10\n",
      "Epoch 126/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.6693e-10 - mse: 7.6693e-10 - val_loss: 2.3501e-10 - val_mse: 2.3501e-10\n",
      "Epoch 127/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6873e-10 - mse: 1.6873e-10 - val_loss: 2.7067e-10 - val_mse: 2.7067e-10\n",
      "Epoch 128/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2142e-10 - mse: 1.2142e-10 - val_loss: 6.1846e-11 - val_mse: 6.1846e-11\n",
      "Epoch 129/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 5.0477e-11 - mse: 5.0477e-11 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 130/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 2.5666e-11 - mse: 2.5666e-11 - val_loss: 4.6566e-11 - val_mse: 4.6566e-11\n",
      "Epoch 131/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 1.6473e-11 - mse: 1.6473e-11 - val_loss: 2.8376e-11 - val_mse: 2.8376e-11\n",
      "Epoch 132/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 1.1386e-11 - mse: 1.1386e-11 - val_loss: 6.7666e-11 - val_mse: 6.7666e-11\n",
      "Epoch 133/1000\n",
      "60/60 [==============================] - 0s 965us/step - loss: 4.8521e-12 - mse: 4.8521e-12 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
      "Epoch 134/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.3963e-12 - mse: 9.3963e-12 - val_loss: 3.1287e-11 - val_mse: 3.1287e-11\n",
      "Epoch 135/1000\n",
      "60/60 [==============================] - 0s 924us/step - loss: 7.7968e-12 - mse: 7.7968e-12 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
      "Epoch 136/1000\n",
      "60/60 [==============================] - 0s 954us/step - loss: 8.2720e-12 - mse: 8.2720e-12 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
      "Epoch 137/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.0659e-12 - mse: 7.0659e-12 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
      "Epoch 138/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3154e-12 - mse: 6.3154e-12 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
      "Epoch 139/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4213e-12 - mse: 2.4213e-12 - val_loss: 5.0932e-11 - val_mse: 5.0932e-11\n",
      "Epoch 140/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.6750e-12 - mse: 8.6750e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 141/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0830e-11 - mse: 1.0830e-11 - val_loss: 5.6025e-11 - val_mse: 5.6025e-11\n",
      "Epoch 142/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5917e-12 - mse: 5.5917e-12 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
      "Epoch 143/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8954e-12 - mse: 4.8954e-12 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
      "Epoch 144/1000\n",
      "60/60 [==============================] - 0s 1000us/step - loss: 6.9167e-12 - mse: 6.9167e-12 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
      "Epoch 145/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 6.4245e-12 - mse: 6.4245e-12 - val_loss: 1.6735e-10 - val_mse: 1.6735e-10\n",
      "Epoch 146/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4667e-11 - mse: 1.4667e-11 - val_loss: 3.4925e-11 - val_mse: 3.4925e-11\n",
      "Epoch 147/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 7.7649e-12 - mse: 7.7649e-12 - val_loss: 1.2878e-10 - val_mse: 1.2878e-10\n",
      "Epoch 148/1000\n",
      "60/60 [==============================] - 0s 962us/step - loss: 1.1096e-11 - mse: 1.1096e-11 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 149/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 6.7108e-12 - mse: 6.7108e-12 - val_loss: 1.3388e-10 - val_mse: 1.3388e-10\n",
      "Epoch 150/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0555e-11 - mse: 2.0555e-11 - val_loss: 5.8208e-11 - val_mse: 5.8208e-11\n",
      "Epoch 151/1000\n",
      "60/60 [==============================] - 0s 971us/step - loss: 1.1255e-11 - mse: 1.1255e-11 - val_loss: 5.3114e-11 - val_mse: 5.3114e-11\n",
      "Epoch 152/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.5686e-12 - mse: 8.5686e-12 - val_loss: 3.8563e-11 - val_mse: 3.8563e-11\n",
      "Epoch 153/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.2038e-12 - mse: 8.2038e-12 - val_loss: 2.3283e-11 - val_mse: 2.3283e-11\n",
      "Epoch 154/1000\n",
      "60/60 [==============================] - 0s 925us/step - loss: 5.6713e-12 - mse: 5.6713e-12 - val_loss: 4.7294e-11 - val_mse: 4.7294e-11\n",
      "Epoch 155/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9451e-12 - mse: 5.9451e-12 - val_loss: 5.0204e-11 - val_mse: 5.0204e-11\n",
      "Epoch 156/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 6.3709e-12 - mse: 6.3709e-12 - val_loss: 1.7462e-11 - val_mse: 1.7462e-11\n",
      "Epoch 157/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2919e-12 - mse: 7.2919e-12 - val_loss: 2.3283e-11 - val_mse: 2.3283e-11\n",
      "Epoch 158/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2879e-11 - mse: 2.2879e-11 - val_loss: 6.1118e-11 - val_mse: 6.1118e-11\n",
      "Epoch 159/1000\n",
      "60/60 [==============================] - 0s 945us/step - loss: 8.1729e-11 - mse: 8.1729e-11 - val_loss: 5.0131e-10 - val_mse: 5.0131e-10\n",
      "Epoch 160/1000\n",
      "60/60 [==============================] - 0s 982us/step - loss: 1.9564e-10 - mse: 1.9564e-10 - val_loss: 1.1718e-08 - val_mse: 1.1718e-08\n",
      "Epoch 161/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4483e-10 - mse: 4.4483e-10 - val_loss: 6.1846e-11 - val_mse: 6.1846e-11\n",
      "Epoch 162/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4618e-11 - mse: 2.4618e-11 - val_loss: 3.9290e-10 - val_mse: 3.9290e-10\n",
      "Epoch 163/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 3.1859e-11 - mse: 3.1859e-11 - val_loss: 4.7294e-11 - val_mse: 4.7294e-11\n",
      "Epoch 164/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9331e-10 - mse: 3.9331e-10 - val_loss: 2.7734e-07 - val_mse: 2.7734e-07\n",
      "Epoch 165/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0235e-08 - mse: 2.0235e-08 - val_loss: 6.5673e-09 - val_mse: 6.5673e-09\n",
      "Epoch 166/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.1620e-08 - mse: 6.1620e-08 - val_loss: 1.5558e-06 - val_mse: 1.5558e-06\n",
      "Epoch 167/1000\n",
      "60/60 [==============================] - 0s 957us/step - loss: 4.6888e-07 - mse: 4.6888e-07 - val_loss: 2.3819e-08 - val_mse: 2.3819e-08\n",
      "Epoch 168/1000\n",
      "60/60 [==============================] - 0s 973us/step - loss: 2.1148e-08 - mse: 2.1148e-08 - val_loss: 6.7519e-08 - val_mse: 6.7519e-08\n",
      "Epoch 169/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8634e-06 - mse: 2.8634e-06 - val_loss: 3.1026e-04 - val_mse: 3.1026e-04\n",
      "Epoch 170/1000\n",
      "60/60 [==============================] - 0s 963us/step - loss: 2.4957e-04 - mse: 2.4957e-04 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 171/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 172/1000\n",
      "60/60 [==============================] - 0s 984us/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 173/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.2438e-05 - val_mse: 1.2438e-05\n",
      "Epoch 174/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0304e-05 - mse: 1.0304e-05 - val_loss: 1.0530e-06 - val_mse: 1.0530e-06\n",
      "Epoch 175/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.9815e-08 - mse: 7.9815e-08 - val_loss: 7.2840e-07 - val_mse: 7.2840e-07\n",
      "Epoch 176/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3983e-07 - mse: 4.3983e-07 - val_loss: 1.2984e-06 - val_mse: 1.2984e-06\n",
      "Epoch 177/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 1.6938e-07 - mse: 1.6938e-07 - val_loss: 1.5065e-06 - val_mse: 1.5065e-06\n",
      "Epoch 178/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 9.3663e-08 - mse: 9.3663e-08 - val_loss: 9.7154e-08 - val_mse: 9.7154e-08\n",
      "Epoch 179/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 4.9333e-07 - mse: 4.9333e-07 - val_loss: 7.0935e-07 - val_mse: 7.0935e-07\n",
      "Epoch 180/1000\n",
      "60/60 [==============================] - 0s 954us/step - loss: 9.4950e-06 - mse: 9.4950e-06 - val_loss: 2.8080e-04 - val_mse: 2.8080e-04\n",
      "Epoch 181/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1677e-05 - mse: 5.1677e-05 - val_loss: 1.9632e-05 - val_mse: 1.9632e-05\n",
      "Epoch 182/1000\n",
      "60/60 [==============================] - 0s 952us/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 183/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.4165 - val_mse: 0.4165\n",
      "Epoch 184/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6263 - mse: 0.6263 - val_loss: 1.2531 - val_mse: 1.2531\n",
      "Epoch 185/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0819 - mse: 0.0819 - val_loss: 0.0727 - val_mse: 0.0727\n",
      "Epoch 186/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 3.6355e-04 - val_mse: 3.6355e-04\n",
      "Epoch 187/1000\n",
      "60/60 [==============================] - 0s 981us/step - loss: 4.5535e-05 - mse: 4.5535e-05 - val_loss: 4.3464e-06 - val_mse: 4.3464e-06\n",
      "Epoch 188/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9713e-06 - mse: 2.9713e-06 - val_loss: 5.5787e-06 - val_mse: 5.5787e-06\n",
      "Epoch 189/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.7766e-07 - mse: 9.7766e-07 - val_loss: 7.9477e-07 - val_mse: 7.9477e-07\n",
      "Epoch 190/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9100e-07 - mse: 3.9100e-07 - val_loss: 7.1145e-08 - val_mse: 7.1145e-08\n",
      "Epoch 191/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.1147e-08 - mse: 6.1147e-08 - val_loss: 7.9686e-09 - val_mse: 7.9686e-09\n",
      "Epoch 192/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3145e-08 - mse: 2.3145e-08 - val_loss: 2.4731e-09 - val_mse: 2.4731e-09\n",
      "Epoch 193/1000\n",
      "60/60 [==============================] - 0s 984us/step - loss: 1.2523e-08 - mse: 1.2523e-08 - val_loss: 4.9270e-08 - val_mse: 4.9270e-08\n",
      "Epoch 194/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8807e-09 - mse: 2.8807e-09 - val_loss: 2.0693e-09 - val_mse: 2.0693e-09\n",
      "Epoch 195/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.8865e-10 - mse: 8.8865e-10 - val_loss: 3.8417e-10 - val_mse: 3.8417e-10\n",
      "Epoch 196/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4731e-10 - mse: 1.4731e-10 - val_loss: 9.3642e-10 - val_mse: 9.3642e-10\n",
      "Epoch 197/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3156e-11 - mse: 8.3156e-11 - val_loss: 4.8167e-10 - val_mse: 4.8167e-10\n",
      "Epoch 198/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 4.5591e-11 - mse: 4.5591e-11 - val_loss: 1.2515e-10 - val_mse: 1.2515e-10\n",
      "Epoch 199/1000\n",
      "60/60 [==============================] - 0s 932us/step - loss: 1.5109e-11 - mse: 1.5109e-11 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
      "Epoch 200/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3627e-11 - mse: 1.3627e-11 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
      "Epoch 201/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4870e-11 - mse: 1.4870e-11 - val_loss: 3.5652e-11 - val_mse: 3.5652e-11\n",
      "Epoch 202/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.2781e-12 - mse: 6.2781e-12 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 203/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3550e-11 - mse: 1.3550e-11 - val_loss: 1.8190e-11 - val_mse: 1.8190e-11\n",
      "Epoch 204/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.8851e-12 - mse: 9.8851e-12 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 205/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2228e-11 - mse: 1.2228e-11 - val_loss: 3.8563e-11 - val_mse: 3.8563e-11\n",
      "Epoch 206/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 1.3512e-11 - mse: 1.3512e-11 - val_loss: 2.3283e-11 - val_mse: 2.3283e-11\n",
      "Epoch 207/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9198e-12 - mse: 6.9198e-12 - val_loss: 1.7462e-11 - val_mse: 1.7462e-11\n",
      "Epoch 208/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4514e-11 - mse: 1.4514e-11 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 209/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4639e-11 - mse: 1.4639e-11 - val_loss: 1.8917e-11 - val_mse: 1.8917e-11\n",
      "Epoch 210/1000\n",
      "60/60 [==============================] - 0s 986us/step - loss: 1.0831e-11 - mse: 1.0831e-11 - val_loss: 9.4587e-12 - val_mse: 9.4587e-12\n",
      "Epoch 211/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.7234e-12 - mse: 7.7234e-12 - val_loss: 2.6193e-11 - val_mse: 2.6193e-11\n",
      "Epoch 212/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5542e-11 - mse: 4.5542e-11 - val_loss: 1.7462e-11 - val_mse: 1.7462e-11\n",
      "Epoch 213/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 9.3493e-12 - mse: 9.3493e-12 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
      "Epoch 214/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.0664e-12 - mse: 8.0664e-12 - val_loss: 4.1473e-11 - val_mse: 4.1473e-11\n",
      "Epoch 215/1000\n",
      "60/60 [==============================] - 0s 973us/step - loss: 1.1347e-11 - mse: 1.1347e-11 - val_loss: 4.1473e-11 - val_mse: 4.1473e-11\n",
      "Epoch 216/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3957e-11 - mse: 1.3957e-11 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
      "Epoch 217/1000\n",
      "60/60 [==============================] - 0s 957us/step - loss: 1.4206e-11 - mse: 1.4206e-11 - val_loss: 7.6398e-11 - val_mse: 7.6398e-11\n",
      "Epoch 218/1000\n",
      "60/60 [==============================] - 0s 945us/step - loss: 1.2185e-11 - mse: 1.2185e-11 - val_loss: 5.2387e-11 - val_mse: 5.2387e-11\n",
      "Epoch 219/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.2124e-12 - mse: 8.2124e-12 - val_loss: 2.3283e-11 - val_mse: 2.3283e-11\n",
      "Epoch 220/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1975e-11 - mse: 3.1975e-11 - val_loss: 7.5452e-10 - val_mse: 7.5452e-10\n",
      "Epoch 221/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0546e-10 - mse: 1.0546e-10 - val_loss: 5.3114e-11 - val_mse: 5.3114e-11\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9650e-10 - mse: 5.9650e-10 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 223/1000\n",
      "60/60 [==============================] - 0s 994us/step - loss: 2.3087e-11 - mse: 2.3087e-11 - val_loss: 4.5111e-11 - val_mse: 4.5111e-11\n",
      "Epoch 224/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 2.1216e-11 - mse: 2.1216e-11 - val_loss: 1.0841e-10 - val_mse: 1.0841e-10\n",
      "Epoch 225/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3248e-11 - mse: 2.3248e-11 - val_loss: 2.9759e-10 - val_mse: 2.9759e-10\n",
      "Epoch 226/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2730e-11 - mse: 3.2730e-11 - val_loss: 6.9849e-11 - val_mse: 6.9849e-11\n",
      "Epoch 227/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1664e-11 - mse: 1.1664e-11 - val_loss: 4.6566e-11 - val_mse: 4.6566e-11\n",
      "Epoch 228/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.2085e-12 - mse: 6.2085e-12 - val_loss: 4.0600e-10 - val_mse: 4.0600e-10\n",
      "Epoch 229/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8415e-11 - mse: 7.8415e-11 - val_loss: 8.8185e-10 - val_mse: 8.8185e-10\n",
      "Epoch 230/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0510e-08 - mse: 2.0510e-08 - val_loss: 4.1400e-09 - val_mse: 4.1400e-09\n",
      "Epoch 231/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 2.4790e-06 - mse: 2.4790e-06 - val_loss: 3.5691e-06 - val_mse: 3.5691e-06\n",
      "Epoch 232/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.2311e-06 - mse: 6.2311e-06 - val_loss: 4.7745e-09 - val_mse: 4.7745e-09\n",
      "Epoch 233/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3697e-06 - mse: 1.3697e-06 - val_loss: 1.0711e-07 - val_mse: 1.0711e-07\n",
      "Epoch 234/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9167e-09 - mse: 3.9167e-09 - val_loss: 2.1961e-08 - val_mse: 2.1961e-08\n",
      "Epoch 235/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5250e-08 - mse: 1.5250e-08 - val_loss: 3.1260e-08 - val_mse: 3.1260e-08\n",
      "Epoch 236/1000\n",
      "60/60 [==============================] - 0s 973us/step - loss: 4.3755e-09 - mse: 4.3755e-09 - val_loss: 3.0414e-10 - val_mse: 3.0414e-10\n",
      "Epoch 237/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2721e-08 - mse: 1.2721e-08 - val_loss: 3.7562e-07 - val_mse: 3.7562e-07\n",
      "Epoch 238/1000\n",
      "60/60 [==============================] - 0s 967us/step - loss: 8.3966e-07 - mse: 8.3966e-07 - val_loss: 3.2400e-04 - val_mse: 3.2400e-04\n",
      "Epoch 239/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.1040 - val_mse: 0.1040\n",
      "Epoch 240/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 0.0055 - mse: 0.0055 - val_loss: 1.3057e-04 - val_mse: 1.3057e-04\n",
      "Epoch 241/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 1.7995e-04 - mse: 1.7995e-04 - val_loss: 1.7627e-05 - val_mse: 1.7627e-05\n",
      "Epoch 242/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0703e-04 - mse: 1.0703e-04 - val_loss: 0.0708 - val_mse: 0.0708\n",
      "Epoch 243/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 0.0025 - mse: 0.0025 - val_loss: 5.9588e-05 - val_mse: 5.9588e-05\n",
      "Epoch 244/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 1.4939 - val_mse: 1.4939\n",
      "Epoch 245/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 0.1215 - mse: 0.1215 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 246/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 247/1000\n",
      "60/60 [==============================] - 0s 901us/step - loss: 0.0028 - mse: 0.0028 - val_loss: 5.4376e-04 - val_mse: 5.4376e-04\n",
      "Epoch 248/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 1.3879e-04 - mse: 1.3879e-04 - val_loss: 8.0468e-05 - val_mse: 8.0468e-05\n",
      "Epoch 249/1000\n",
      "60/60 [==============================] - 0s 985us/step - loss: 8.2169e-06 - mse: 8.2169e-06 - val_loss: 1.0050e-05 - val_mse: 1.0050e-05\n",
      "Epoch 250/1000\n",
      "60/60 [==============================] - 0s 962us/step - loss: 9.5591e-05 - mse: 9.5591e-05 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 251/1000\n",
      "60/60 [==============================] - 0s 970us/step - loss: 6.9142e-04 - mse: 6.9142e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 252/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 2.3972e-04 - mse: 2.3972e-04 - val_loss: 3.7491e-05 - val_mse: 3.7491e-05\n",
      "Epoch 253/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 9.9906e-06 - mse: 9.9906e-06 - val_loss: 1.2490e-08 - val_mse: 1.2490e-08\n",
      "Epoch 254/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 1.1382e-07 - mse: 1.1382e-07 - val_loss: 2.8460e-08 - val_mse: 2.8460e-08\n",
      "Epoch 255/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1640e-08 - mse: 1.1640e-08 - val_loss: 9.2819e-09 - val_mse: 9.2819e-09\n",
      "Epoch 256/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5076e-08 - mse: 5.5076e-08 - val_loss: 5.8493e-08 - val_mse: 5.8493e-08\n",
      "Epoch 257/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1368e-08 - mse: 2.1368e-08 - val_loss: 4.3484e-07 - val_mse: 4.3484e-07\n",
      "Epoch 258/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0940e-07 - mse: 2.0940e-07 - val_loss: 3.2476e-07 - val_mse: 3.2476e-07\n",
      "Epoch 259/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0423e-07 - mse: 3.0423e-07 - val_loss: 1.2066e-08 - val_mse: 1.2066e-08\n",
      "Epoch 260/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.7009e-09 - mse: 4.7009e-09 - val_loss: 3.1789e-09 - val_mse: 3.1789e-09\n",
      "Epoch 261/1000\n",
      "60/60 [==============================] - 0s 986us/step - loss: 1.0252e-10 - mse: 1.0252e-10 - val_loss: 2.0664e-10 - val_mse: 2.0664e-10\n",
      "Epoch 262/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 3.0377e-11 - mse: 3.0377e-11 - val_loss: 3.4925e-11 - val_mse: 3.4925e-11\n",
      "Epoch 263/1000\n",
      "60/60 [==============================] - 0s 978us/step - loss: 2.8997e-11 - mse: 2.8997e-11 - val_loss: 5.4133e-10 - val_mse: 5.4133e-10\n",
      "Epoch 264/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 5.2930e-11 - mse: 5.2930e-11 - val_loss: 1.3169e-10 - val_mse: 1.3169e-10\n",
      "Epoch 265/1000\n",
      "60/60 [==============================] - 0s 986us/step - loss: 4.4616e-11 - mse: 4.4616e-11 - val_loss: 3.4925e-11 - val_mse: 3.4925e-11\n",
      "Epoch 266/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 9.8371e-11 - mse: 9.8371e-11 - val_loss: 1.5571e-10 - val_mse: 1.5571e-10\n",
      "Epoch 267/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7436e-10 - mse: 1.7436e-10 - val_loss: 1.2296e-10 - val_mse: 1.2296e-10\n",
      "Epoch 268/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 3.0717e-09 - mse: 3.0717e-09 - val_loss: 3.0397e-08 - val_mse: 3.0397e-08\n",
      "Epoch 269/1000\n",
      "60/60 [==============================] - 0s 979us/step - loss: 1.5623e-06 - mse: 1.5623e-06 - val_loss: 4.1595e-06 - val_mse: 4.1595e-06\n",
      "Epoch 270/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0187e-06 - mse: 2.0187e-06 - val_loss: 1.6839e-04 - val_mse: 1.6839e-04\n",
      "Epoch 271/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1854e-04 - mse: 7.1854e-04 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 272/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.3882 - val_mse: 0.3882\n",
      "Epoch 273/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0443 - mse: 0.0443 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 274/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 275/1000\n",
      "60/60 [==============================] - 0s 960us/step - loss: 7.0769e-04 - mse: 7.0769e-04 - val_loss: 6.1996e-04 - val_mse: 6.1996e-04\n",
      "Epoch 276/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8720e-05 - mse: 7.8720e-05 - val_loss: 2.6136e-06 - val_mse: 2.6136e-06\n",
      "Epoch 277/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 2.3718e-06 - mse: 2.3718e-06 - val_loss: 6.1511e-06 - val_mse: 6.1511e-06\n",
      "Epoch 278/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 4.3134e-06 - mse: 4.3134e-06 - val_loss: 9.5656e-06 - val_mse: 9.5656e-06\n",
      "Epoch 279/1000\n",
      "60/60 [==============================] - 0s 995us/step - loss: 6.5106e-07 - mse: 6.5106e-07 - val_loss: 2.4302e-10 - val_mse: 2.4302e-10\n",
      "Epoch 280/1000\n",
      "60/60 [==============================] - 0s 945us/step - loss: 8.5430e-08 - mse: 8.5430e-08 - val_loss: 7.7125e-10 - val_mse: 7.7125e-10\n",
      "Epoch 281/1000\n",
      "60/60 [==============================] - 0s 917us/step - loss: 5.3746e-09 - mse: 5.3746e-09 - val_loss: 1.0327e-08 - val_mse: 1.0327e-08\n",
      "Epoch 282/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2989e-09 - mse: 1.2989e-09 - val_loss: 3.7733e-09 - val_mse: 3.7733e-09\n",
      "Epoch 283/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.7714e-10 - mse: 4.7714e-10 - val_loss: 3.1287e-11 - val_mse: 3.1287e-11\n",
      "Epoch 284/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0767e-10 - mse: 2.0767e-10 - val_loss: 1.4261e-10 - val_mse: 1.4261e-10\n",
      "Epoch 285/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1104e-11 - mse: 5.1104e-11 - val_loss: 1.8117e-10 - val_mse: 1.8117e-10\n",
      "Epoch 286/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4604e-10 - mse: 3.4604e-10 - val_loss: 8.0751e-08 - val_mse: 8.0751e-08\n",
      "Epoch 287/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1960e-07 - mse: 3.1960e-07 - val_loss: 3.7396e-05 - val_mse: 3.7396e-05\n",
      "Epoch 288/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 2.3928e-04 - mse: 2.3928e-04 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 289/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1382 - mse: 0.1382 - val_loss: 0.1765 - val_mse: 0.1765\n",
      "Epoch 290/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 291/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 3.0318e-04 - val_mse: 3.0318e-04\n",
      "Epoch 292/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3690e-05 - mse: 7.3690e-05 - val_loss: 6.9257e-06 - val_mse: 6.9257e-06\n",
      "Epoch 293/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0981e-05 - mse: 1.0981e-05 - val_loss: 1.2663e-05 - val_mse: 1.2663e-05\n",
      "Epoch 294/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3346e-07 - mse: 7.3346e-07 - val_loss: 3.3179e-06 - val_mse: 3.3179e-06\n",
      "Epoch 295/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5390e-07 - mse: 4.5390e-07 - val_loss: 1.6051e-09 - val_mse: 1.6051e-09\n",
      "Epoch 296/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5003e-07 - mse: 4.5003e-07 - val_loss: 2.2000e-07 - val_mse: 2.2000e-07\n",
      "Epoch 297/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6215e-07 - mse: 1.6215e-07 - val_loss: 2.8364e-08 - val_mse: 2.8364e-08\n",
      "Epoch 298/1000\n",
      "60/60 [==============================] - 0s 952us/step - loss: 4.2353e-09 - mse: 4.2353e-09 - val_loss: 1.1276e-08 - val_mse: 1.1276e-08\n",
      "Epoch 299/1000\n",
      "60/60 [==============================] - 0s 989us/step - loss: 2.5357e-08 - mse: 2.5357e-08 - val_loss: 2.5104e-08 - val_mse: 2.5104e-08\n",
      "Epoch 300/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 2.3472e-08 - mse: 2.3472e-08 - val_loss: 7.2978e-10 - val_mse: 7.2978e-10\n",
      "Epoch 301/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 1.9765e-08 - mse: 1.9765e-08 - val_loss: 6.2864e-10 - val_mse: 6.2864e-10\n",
      "Epoch 302/1000\n",
      "60/60 [==============================] - 0s 977us/step - loss: 3.5866e-09 - mse: 3.5866e-09 - val_loss: 9.3635e-08 - val_mse: 9.3635e-08\n",
      "Epoch 303/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1727e-07 - mse: 1.1727e-07 - val_loss: 6.5694e-06 - val_mse: 6.5694e-06\n",
      "Epoch 304/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0047e-06 - mse: 1.0047e-06 - val_loss: 1.5046e-06 - val_mse: 1.5046e-06\n",
      "Epoch 305/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0350e-07 - mse: 1.0350e-07 - val_loss: 3.0122e-10 - val_mse: 3.0122e-10\n",
      "Epoch 306/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3411e-10 - mse: 1.3411e-10 - val_loss: 3.5943e-10 - val_mse: 3.5943e-10\n",
      "Epoch 307/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2958e-11 - mse: 3.2958e-11 - val_loss: 2.1289e-09 - val_mse: 2.1289e-09\n",
      "Epoch 308/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.3803e-10 - mse: 5.3803e-10 - val_loss: 1.3533e-10 - val_mse: 1.3533e-10\n",
      "Epoch 309/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4310e-11 - mse: 3.4310e-11 - val_loss: 5.3114e-11 - val_mse: 5.3114e-11\n",
      "Epoch 310/1000\n",
      "60/60 [==============================] - 0s 996us/step - loss: 4.3713e-11 - mse: 4.3713e-11 - val_loss: 3.6089e-10 - val_mse: 3.6089e-10\n",
      "Epoch 311/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.9188e-10 - mse: 4.9188e-10 - val_loss: 4.9477e-10 - val_mse: 4.9477e-10\n",
      "Epoch 312/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2533e-11 - mse: 3.2533e-11 - val_loss: 3.3251e-10 - val_mse: 3.3251e-10\n",
      "Epoch 313/1000\n",
      "60/60 [==============================] - 0s 982us/step - loss: 5.3242e-11 - mse: 5.3242e-11 - val_loss: 1.3970e-10 - val_mse: 1.3970e-10\n",
      "Epoch 314/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8953e-11 - mse: 2.8953e-11 - val_loss: 5.8208e-11 - val_mse: 5.8208e-11\n",
      "Epoch 315/1000\n",
      "60/60 [==============================] - 0s 985us/step - loss: 8.4224e-12 - mse: 8.4224e-12 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
      "Epoch 316/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2179e-11 - mse: 7.2179e-11 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
      "Epoch 317/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2704e-09 - mse: 1.2704e-09 - val_loss: 1.0659e-09 - val_mse: 1.0659e-09\n",
      "Epoch 318/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8128e-09 - mse: 1.8128e-09 - val_loss: 2.9941e-09 - val_mse: 2.9941e-09\n",
      "Epoch 319/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0186e-10 - mse: 3.0186e-10 - val_loss: 3.7689e-10 - val_mse: 3.7689e-10\n",
      "Epoch 320/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5267e-10 - mse: 1.5267e-10 - val_loss: 1.3097e-10 - val_mse: 1.3097e-10\n",
      "Epoch 321/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3985e-09 - mse: 1.3985e-09 - val_loss: 3.7835e-11 - val_mse: 3.7835e-11\n",
      "Epoch 322/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3829e-10 - mse: 1.3829e-10 - val_loss: 9.2266e-09 - val_mse: 9.2266e-09\n",
      "Epoch 323/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8664e-09 - mse: 4.8664e-09 - val_loss: 1.5365e-07 - val_mse: 1.5365e-07\n",
      "Epoch 324/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6170e-07 - mse: 2.6170e-07 - val_loss: 1.9507e-06 - val_mse: 1.9507e-06\n",
      "Epoch 325/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 2.7936e-07 - mse: 2.7936e-07 - val_loss: 9.6588e-08 - val_mse: 9.6588e-08\n",
      "Epoch 326/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 3.6732e-07 - mse: 3.6732e-07 - val_loss: 1.3447e-06 - val_mse: 1.3447e-06\n",
      "Epoch 327/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 1.4237e-04 - mse: 1.4237e-04 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 328/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 0.1882 - mse: 0.1882 - val_loss: 0.4305 - val_mse: 0.4305\n",
      "Epoch 329/1000\n",
      "60/60 [==============================] - 0s 968us/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 330/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 331/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 0.0020 - mse: 0.0020 - val_loss: 6.1661e-04 - val_mse: 6.1661e-04\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 947us/step - loss: 1.0737e-04 - mse: 1.0737e-04 - val_loss: 5.4003e-04 - val_mse: 5.4003e-04\n",
      "Epoch 333/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.0793e-05 - mse: 6.0793e-05 - val_loss: 1.0613e-05 - val_mse: 1.0613e-05\n",
      "Epoch 334/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0657e-05 - mse: 5.0657e-05 - val_loss: 3.6958e-06 - val_mse: 3.6958e-06\n",
      "Epoch 335/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3146e-06 - mse: 1.3146e-06 - val_loss: 3.2943e-06 - val_mse: 3.2943e-06\n",
      "Epoch 336/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0355e-07 - mse: 2.0355e-07 - val_loss: 1.6475e-07 - val_mse: 1.6475e-07\n",
      "Epoch 337/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9882e-08 - mse: 3.9882e-08 - val_loss: 1.4566e-08 - val_mse: 1.4566e-08\n",
      "Epoch 338/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0967e-09 - mse: 1.0967e-09 - val_loss: 3.0195e-10 - val_mse: 3.0195e-10\n",
      "Epoch 339/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.2839e-10 - mse: 9.2839e-10 - val_loss: 7.5743e-09 - val_mse: 7.5743e-09\n",
      "Epoch 340/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4850e-09 - mse: 1.4850e-09 - val_loss: 3.8090e-09 - val_mse: 3.8090e-09\n",
      "Epoch 341/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1096e-10 - mse: 3.1096e-10 - val_loss: 5.8062e-10 - val_mse: 5.8062e-10\n",
      "Epoch 342/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2659e-10 - mse: 3.2659e-10 - val_loss: 4.4199e-08 - val_mse: 4.4199e-08\n",
      "Epoch 343/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0796e-09 - mse: 1.0796e-09 - val_loss: 8.5856e-11 - val_mse: 8.5856e-11\n",
      "Epoch 344/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5808e-11 - mse: 4.5808e-11 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 345/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1772e-11 - mse: 1.1772e-11 - val_loss: 1.0114e-10 - val_mse: 1.0114e-10\n",
      "Epoch 346/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 2.6680e-11 - mse: 2.6680e-11 - val_loss: 1.1860e-10 - val_mse: 1.1860e-10\n",
      "Epoch 347/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3683e-11 - mse: 3.3683e-11 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
      "Epoch 348/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0564e-11 - mse: 1.0564e-11 - val_loss: 2.2555e-11 - val_mse: 2.2555e-11\n",
      "Epoch 349/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4993e-11 - mse: 2.4993e-11 - val_loss: 7.2032e-11 - val_mse: 7.2032e-11\n",
      "Epoch 350/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0566e-11 - mse: 1.0566e-11 - val_loss: 4.9477e-11 - val_mse: 4.9477e-11\n",
      "Epoch 351/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4239e-11 - mse: 1.4239e-11 - val_loss: 3.4197e-11 - val_mse: 3.4197e-11\n",
      "Epoch 352/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2505e-10 - mse: 1.2505e-10 - val_loss: 1.4479e-10 - val_mse: 1.4479e-10\n",
      "Epoch 353/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6878e-10 - mse: 1.6878e-10 - val_loss: 1.3824e-11 - val_mse: 1.3824e-11\n",
      "Epoch 354/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4039e-10 - mse: 2.4039e-10 - val_loss: 8.2000e-10 - val_mse: 8.2000e-10\n",
      "Epoch 355/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4512e-06 - mse: 1.4512e-06 - val_loss: 5.1615e-05 - val_mse: 5.1615e-05\n",
      "Epoch 356/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3539e-06 - mse: 7.3539e-06 - val_loss: 8.7394e-05 - val_mse: 8.7394e-05\n",
      "Epoch 357/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.5449e-06 - mse: 9.5449e-06 - val_loss: 1.7730e-07 - val_mse: 1.7730e-07\n",
      "Epoch 358/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0288e-05 - mse: 1.0288e-05 - val_loss: 9.6720e-05 - val_mse: 9.6720e-05\n",
      "Epoch 359/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.7720e-04 - mse: 7.7720e-04 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 360/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0991 - mse: 0.0991 - val_loss: 0.2067 - val_mse: 0.2067\n",
      "Epoch 361/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0486 - mse: 0.0486 - val_loss: 0.1289 - val_mse: 0.1289\n",
      "Epoch 362/1000\n",
      "60/60 [==============================] - 0s 963us/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 363/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 364/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 5.7503e-05 - val_mse: 5.7503e-05\n",
      "Epoch 365/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9259e-04 - mse: 2.9259e-04 - val_loss: 5.5319e-05 - val_mse: 5.5319e-05\n",
      "Epoch 366/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2116e-05 - mse: 1.2116e-05 - val_loss: 3.3488e-08 - val_mse: 3.3488e-08\n",
      "Epoch 367/1000\n",
      "60/60 [==============================] - 0s 981us/step - loss: 2.0678e-08 - mse: 2.0678e-08 - val_loss: 6.7084e-10 - val_mse: 6.7084e-10\n",
      "Epoch 368/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5556e-10 - mse: 5.5556e-10 - val_loss: 5.4242e-09 - val_mse: 5.4242e-09\n",
      "Epoch 369/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 1.3910e-09 - mse: 1.3910e-09 - val_loss: 3.6162e-10 - val_mse: 3.6162e-10\n",
      "Epoch 370/1000\n",
      "60/60 [==============================] - 0s 919us/step - loss: 3.2622e-11 - mse: 3.2622e-11 - val_loss: 4.9477e-11 - val_mse: 4.9477e-11\n",
      "Epoch 371/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 2.2655e-11 - mse: 2.2655e-11 - val_loss: 6.4756e-11 - val_mse: 6.4756e-11\n",
      "Epoch 372/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 7.7865e-12 - mse: 7.7865e-12 - val_loss: 1.5207e-10 - val_mse: 1.5207e-10\n",
      "Epoch 373/1000\n",
      "60/60 [==============================] - 0s 932us/step - loss: 2.5167e-11 - mse: 2.5167e-11 - val_loss: 3.9290e-11 - val_mse: 3.9290e-11\n",
      "Epoch 374/1000\n",
      "60/60 [==============================] - 0s 952us/step - loss: 5.4324e-12 - mse: 5.4324e-12 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 375/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.1426e-12 - mse: 6.1426e-12 - val_loss: 2.1100e-11 - val_mse: 2.1100e-11\n",
      "Epoch 376/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 1.7315e-11 - mse: 1.7315e-11 - val_loss: 2.0373e-11 - val_mse: 2.0373e-11\n",
      "Epoch 377/1000\n",
      "60/60 [==============================] - 0s 926us/step - loss: 1.3306e-11 - mse: 1.3306e-11 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 378/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 4.4822e-10 - mse: 4.4822e-10 - val_loss: 2.6761e-09 - val_mse: 2.6761e-09\n",
      "Epoch 379/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1457e-08 - mse: 1.1457e-08 - val_loss: 8.7748e-10 - val_mse: 8.7748e-10\n",
      "Epoch 380/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 2.5203e-10 - mse: 2.5203e-10 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 381/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 2.1619e-11 - mse: 2.1619e-11 - val_loss: 6.1118e-11 - val_mse: 6.1118e-11\n",
      "Epoch 382/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5245e-11 - mse: 1.5245e-11 - val_loss: 6.1191e-10 - val_mse: 6.1191e-10\n",
      "Epoch 383/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.6003e-11 - mse: 5.6003e-11 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
      "Epoch 384/1000\n",
      "60/60 [==============================] - 0s 959us/step - loss: 3.0699e-11 - mse: 3.0699e-11 - val_loss: 3.3251e-10 - val_mse: 3.3251e-10\n",
      "Epoch 385/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 1.6927e-10 - mse: 1.6927e-10 - val_loss: 9.5410e-09 - val_mse: 9.5410e-09\n",
      "Epoch 386/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.2728e-09 - mse: 9.2728e-09 - val_loss: 4.4438e-06 - val_mse: 4.4438e-06\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 943us/step - loss: 2.7674e-07 - mse: 2.7674e-07 - val_loss: 4.0473e-07 - val_mse: 4.0473e-07\n",
      "Epoch 388/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 1.8946e-07 - mse: 1.8946e-07 - val_loss: 8.0350e-05 - val_mse: 8.0350e-05\n",
      "Epoch 389/1000\n",
      "60/60 [==============================] - 0s 975us/step - loss: 2.4931e-05 - mse: 2.4931e-05 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 390/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.1444 - val_mse: 0.1444\n",
      "Epoch 391/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 392/1000\n",
      "60/60 [==============================] - 0s 987us/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 393/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8060e-04 - mse: 3.8060e-04 - val_loss: 1.0255e-04 - val_mse: 1.0255e-04\n",
      "Epoch 394/1000\n",
      "60/60 [==============================] - 0s 972us/step - loss: 5.3532e-05 - mse: 5.3532e-05 - val_loss: 9.1593e-07 - val_mse: 9.1593e-07\n",
      "Epoch 395/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4937e-06 - mse: 3.4937e-06 - val_loss: 1.6443e-07 - val_mse: 1.6443e-07\n",
      "Epoch 396/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1136e-06 - mse: 2.1136e-06 - val_loss: 1.9998e-05 - val_mse: 1.9998e-05\n",
      "Epoch 397/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5658e-06 - mse: 2.5658e-06 - val_loss: 1.2462e-05 - val_mse: 1.2462e-05\n",
      "Epoch 398/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0049e-05 - mse: 2.0049e-05 - val_loss: 5.0074e-04 - val_mse: 5.0074e-04\n",
      "Epoch 399/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6775e-04 - mse: 2.6775e-04 - val_loss: 4.3211e-06 - val_mse: 4.3211e-06\n",
      "Epoch 400/1000\n",
      "60/60 [==============================] - 0s 999us/step - loss: 1.0975e-05 - mse: 1.0975e-05 - val_loss: 9.1371e-04 - val_mse: 9.1371e-04\n",
      "Epoch 401/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6348e-05 - mse: 6.6348e-05 - val_loss: 2.4440e-05 - val_mse: 2.4440e-05\n",
      "Epoch 402/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6196e-06 - mse: 6.6196e-06 - val_loss: 7.7265e-06 - val_mse: 7.7265e-06\n",
      "Epoch 403/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0682e-04 - mse: 1.0682e-04 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 404/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4290e-04 - mse: 4.4290e-04 - val_loss: 1.2547e-04 - val_mse: 1.2547e-04\n",
      "Epoch 405/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3583e-04 - mse: 6.3583e-04 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 406/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0542 - val_mse: 0.0542\n",
      "Epoch 407/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 408/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 409/1000\n",
      "60/60 [==============================] - 0s 924us/step - loss: 2.8269e-04 - mse: 2.8269e-04 - val_loss: 1.0323e-05 - val_mse: 1.0323e-05\n",
      "Epoch 410/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 3.5298e-06 - mse: 3.5298e-06 - val_loss: 3.4143e-07 - val_mse: 3.4143e-07\n",
      "Epoch 411/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 1.2147e-06 - mse: 1.2147e-06 - val_loss: 5.4861e-10 - val_mse: 5.4861e-10\n",
      "Epoch 412/1000\n",
      "60/60 [==============================] - 0s 985us/step - loss: 4.6272e-10 - mse: 4.6272e-10 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 413/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.2016e-12 - mse: 9.2016e-12 - val_loss: 5.6752e-11 - val_mse: 5.6752e-11\n",
      "Epoch 414/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9691e-11 - mse: 3.9691e-11 - val_loss: 2.1610e-10 - val_mse: 2.1610e-10\n",
      "Epoch 415/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3710e-11 - mse: 1.3710e-11 - val_loss: 1.1933e-10 - val_mse: 1.1933e-10\n",
      "Epoch 416/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3489e-10 - mse: 1.3489e-10 - val_loss: 2.6732e-09 - val_mse: 2.6732e-09\n",
      "Epoch 417/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.6517e-10 - mse: 7.6517e-10 - val_loss: 4.3656e-11 - val_mse: 4.3656e-11\n",
      "Epoch 418/1000\n",
      "60/60 [==============================] - 0s 984us/step - loss: 1.1324e-10 - mse: 1.1324e-10 - val_loss: 1.5498e-10 - val_mse: 1.5498e-10\n",
      "Epoch 419/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 5.0274e-09 - mse: 5.0274e-09 - val_loss: 1.5999e-06 - val_mse: 1.5999e-06\n",
      "Epoch 420/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3461e-08 - mse: 6.3461e-08 - val_loss: 7.6179e-10 - val_mse: 7.6179e-10\n",
      "Epoch 421/1000\n",
      "60/60 [==============================] - 0s 999us/step - loss: 1.5501e-08 - mse: 1.5501e-08 - val_loss: 2.4978e-07 - val_mse: 2.4978e-07\n",
      "Epoch 422/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3250e-07 - mse: 2.3250e-07 - val_loss: 1.1032e-07 - val_mse: 1.1032e-07\n",
      "Epoch 423/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5347e-07 - mse: 5.5347e-07 - val_loss: 3.3622e-06 - val_mse: 3.3622e-06\n",
      "Epoch 424/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 3.3403e-06 - mse: 3.3403e-06 - val_loss: 1.6131e-04 - val_mse: 1.6131e-04\n",
      "Epoch 425/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8931e-05 - mse: 7.8931e-05 - val_loss: 6.8524e-05 - val_mse: 6.8524e-05\n",
      "Epoch 426/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4922e-05 - mse: 2.4922e-05 - val_loss: 4.6509e-05 - val_mse: 4.6509e-05\n",
      "Epoch 427/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 428/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.1384 - val_mse: 0.1384\n",
      "Epoch 429/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 430/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 2.9934e-04 - val_mse: 2.9934e-04\n",
      "Epoch 431/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1101e-04 - mse: 7.1101e-04 - val_loss: 1.3065e-05 - val_mse: 1.3065e-05\n",
      "Epoch 432/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.0599e-06 - mse: 6.0599e-06 - val_loss: 6.1960e-06 - val_mse: 6.1960e-06\n",
      "Epoch 433/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2364e-06 - mse: 1.2364e-06 - val_loss: 1.7446e-07 - val_mse: 1.7446e-07\n",
      "Epoch 434/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9408e-07 - mse: 2.9408e-07 - val_loss: 2.1556e-05 - val_mse: 2.1556e-05\n",
      "Epoch 435/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3910e-06 - mse: 8.3910e-06 - val_loss: 2.8085e-06 - val_mse: 2.8085e-06\n",
      "Epoch 436/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 1.3109e-06 - mse: 1.3109e-06 - val_loss: 2.4533e-07 - val_mse: 2.4533e-07\n",
      "Epoch 437/1000\n",
      "60/60 [==============================] - 0s 965us/step - loss: 5.2391e-08 - mse: 5.2391e-08 - val_loss: 3.5076e-07 - val_mse: 3.5076e-07\n",
      "Epoch 438/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.6235e-08 - mse: 9.6235e-08 - val_loss: 5.8826e-08 - val_mse: 5.8826e-08\n",
      "Epoch 439/1000\n",
      "60/60 [==============================] - 0s 970us/step - loss: 6.0055e-07 - mse: 6.0055e-07 - val_loss: 1.0603e-04 - val_mse: 1.0603e-04\n",
      "Epoch 440/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3627e-05 - mse: 1.3627e-05 - val_loss: 1.8061e-04 - val_mse: 1.8061e-04\n",
      "Epoch 441/1000\n",
      "60/60 [==============================] - 0s 944us/step - loss: 1.2089e-05 - mse: 1.2089e-05 - val_loss: 1.6578e-04 - val_mse: 1.6578e-04\n",
      "Epoch 442/1000\n",
      "60/60 [==============================] - 0s 986us/step - loss: 1.7919e-05 - mse: 1.7919e-05 - val_loss: 2.7710e-06 - val_mse: 2.7710e-06\n",
      "Epoch 443/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 1.0971e-06 - mse: 1.0971e-06 - val_loss: 3.0346e-05 - val_mse: 3.0346e-05\n",
      "Epoch 444/1000\n",
      "60/60 [==============================] - 0s 969us/step - loss: 2.9998e-05 - mse: 2.9998e-05 - val_loss: 3.9206e-06 - val_mse: 3.9206e-06\n",
      "Epoch 445/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 1.7370e-04 - mse: 1.7370e-04 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 446/1000\n",
      "60/60 [==============================] - 0s 972us/step - loss: 0.0016 - mse: 0.0016 - val_loss: 7.4355e-05 - val_mse: 7.4355e-05\n",
      "Epoch 447/1000\n",
      "60/60 [==============================] - 0s 899us/step - loss: 8.2052e-04 - mse: 8.2052e-04 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 448/1000\n",
      "60/60 [==============================] - 0s 999us/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0979 - val_mse: 0.0979\n",
      "Epoch 449/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.1108 - val_mse: 0.1108\n",
      "Epoch 450/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0438 - mse: 0.0438 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 451/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.0328e-05 - mse: 7.0328e-05 - val_loss: 3.2681e-04 - val_mse: 3.2681e-04\n",
      "Epoch 452/1000\n",
      "60/60 [==============================] - 0s 968us/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 453/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 8.6982e-07 - val_mse: 8.6982e-07\n",
      "Epoch 454/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8070e-05 - mse: 1.8070e-05 - val_loss: 6.0434e-06 - val_mse: 6.0434e-06\n",
      "Epoch 455/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1485e-05 - mse: 2.1485e-05 - val_loss: 5.1468e-04 - val_mse: 5.1468e-04\n",
      "Epoch 456/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1205e-04 - mse: 1.1205e-04 - val_loss: 2.3193e-04 - val_mse: 2.3193e-04\n",
      "Epoch 457/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8901e-05 - mse: 1.8901e-05 - val_loss: 1.9187e-05 - val_mse: 1.9187e-05\n",
      "Epoch 458/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6403e-06 - mse: 6.6403e-06 - val_loss: 7.6365e-06 - val_mse: 7.6365e-06\n",
      "Epoch 459/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4264e-06 - mse: 1.4264e-06 - val_loss: 1.6553e-07 - val_mse: 1.6553e-07\n",
      "Epoch 460/1000\n",
      "60/60 [==============================] - 0s 914us/step - loss: 5.8333e-08 - mse: 5.8333e-08 - val_loss: 3.9755e-07 - val_mse: 3.9755e-07\n",
      "Epoch 461/1000\n",
      "60/60 [==============================] - 0s 977us/step - loss: 1.6719e-08 - mse: 1.6719e-08 - val_loss: 2.0194e-08 - val_mse: 2.0194e-08\n",
      "Epoch 462/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 5.5510e-08 - mse: 5.5510e-08 - val_loss: 9.0550e-08 - val_mse: 9.0550e-08\n",
      "Epoch 463/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 1.4293e-07 - mse: 1.4293e-07 - val_loss: 3.5039e-07 - val_mse: 3.5039e-07\n",
      "Epoch 464/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 3.7798e-07 - mse: 3.7798e-07 - val_loss: 1.6499e-08 - val_mse: 1.6499e-08\n",
      "Epoch 465/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.7656e-08 - mse: 4.7656e-08 - val_loss: 2.5553e-05 - val_mse: 2.5553e-05\n",
      "Epoch 466/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3557e-06 - mse: 2.3557e-06 - val_loss: 5.5444e-08 - val_mse: 5.5444e-08\n",
      "Epoch 467/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 1.2811e-04 - mse: 1.2811e-04 - val_loss: 0.1367 - val_mse: 0.1367\n",
      "Epoch 468/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 0.0077 - mse: 0.0077 - val_loss: 6.5983e-04 - val_mse: 6.5983e-04\n",
      "Epoch 469/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 470/1000\n",
      "60/60 [==============================] - 0s 915us/step - loss: 6.5601e-04 - mse: 6.5601e-04 - val_loss: 2.4486e-04 - val_mse: 2.4486e-04\n",
      "Epoch 471/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 1.5658e-04 - mse: 1.5658e-04 - val_loss: 5.4018e-05 - val_mse: 5.4018e-05\n",
      "Epoch 472/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 1.3670e-05 - mse: 1.3670e-05 - val_loss: 1.1063e-05 - val_mse: 1.1063e-05\n",
      "Epoch 473/1000\n",
      "60/60 [==============================] - 0s 971us/step - loss: 1.5926e-05 - mse: 1.5926e-05 - val_loss: 6.4846e-06 - val_mse: 6.4846e-06\n",
      "Epoch 474/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2649e-06 - mse: 4.2649e-06 - val_loss: 1.0199e-07 - val_mse: 1.0199e-07\n",
      "Epoch 475/1000\n",
      "60/60 [==============================] - 0s 971us/step - loss: 2.8238e-06 - mse: 2.8238e-06 - val_loss: 5.9104e-07 - val_mse: 5.9104e-07\n",
      "Epoch 476/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 7.2903e-08 - mse: 7.2903e-08 - val_loss: 9.4296e-10 - val_mse: 9.4296e-10\n",
      "Epoch 477/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 1.4680e-08 - mse: 1.4680e-08 - val_loss: 1.6513e-07 - val_mse: 1.6513e-07\n",
      "Epoch 478/1000\n",
      "60/60 [==============================] - 0s 897us/step - loss: 2.5158e-08 - mse: 2.5158e-08 - val_loss: 6.3046e-09 - val_mse: 6.3046e-09\n",
      "Epoch 479/1000\n",
      "60/60 [==============================] - 0s 959us/step - loss: 3.9297e-07 - mse: 3.9297e-07 - val_loss: 8.8244e-07 - val_mse: 8.8244e-07\n",
      "Epoch 480/1000\n",
      "60/60 [==============================] - 0s 996us/step - loss: 1.4985e-06 - mse: 1.4985e-06 - val_loss: 9.4228e-08 - val_mse: 9.4228e-08\n",
      "Epoch 481/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1570e-08 - mse: 2.1570e-08 - val_loss: 1.4305e-08 - val_mse: 1.4305e-08\n",
      "Epoch 482/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 1.7675e-09 - mse: 1.7675e-09 - val_loss: 1.1241e-08 - val_mse: 1.1241e-08\n",
      "Epoch 483/1000\n",
      "60/60 [==============================] - 0s 976us/step - loss: 1.4776e-08 - mse: 1.4776e-08 - val_loss: 3.9759e-08 - val_mse: 3.9759e-08\n",
      "Epoch 484/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 4.7902e-08 - mse: 4.7902e-08 - val_loss: 1.2388e-07 - val_mse: 1.2388e-07\n",
      "Epoch 485/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 1.0514e-06 - mse: 1.0514e-06 - val_loss: 7.1398e-06 - val_mse: 7.1398e-06\n",
      "Epoch 486/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 9.5644e-07 - mse: 9.5644e-07 - val_loss: 1.3191e-05 - val_mse: 1.3191e-05\n",
      "Epoch 487/1000\n",
      "60/60 [==============================] - 0s 992us/step - loss: 4.6051e-06 - mse: 4.6051e-06 - val_loss: 9.7227e-05 - val_mse: 9.7227e-05\n",
      "Epoch 488/1000\n",
      "60/60 [==============================] - 0s 988us/step - loss: 1.7410e-04 - mse: 1.7410e-04 - val_loss: 5.8220e-06 - val_mse: 5.8220e-06\n",
      "Epoch 489/1000\n",
      "60/60 [==============================] - 0s 926us/step - loss: 0.0074 - mse: 0.0074 - val_loss: 1.4558 - val_mse: 1.4558\n",
      "Epoch 490/1000\n",
      "60/60 [==============================] - 0s 952us/step - loss: 0.2181 - mse: 0.2181 - val_loss: 0.0655 - val_mse: 0.0655\n",
      "Epoch 491/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 492/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 5.0694e-04 - mse: 5.0694e-04 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 493/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.0994e-04 - mse: 9.0994e-04 - val_loss: 2.2258e-04 - val_mse: 2.2258e-04\n",
      "Epoch 494/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7027e-05 - mse: 1.7027e-05 - val_loss: 4.6085e-05 - val_mse: 4.6085e-05\n",
      "Epoch 495/1000\n",
      "60/60 [==============================] - 0s 957us/step - loss: 1.1661e-05 - mse: 1.1661e-05 - val_loss: 1.1804e-06 - val_mse: 1.1804e-06\n",
      "Epoch 496/1000\n",
      "60/60 [==============================] - 0s 918us/step - loss: 4.4171e-07 - mse: 4.4171e-07 - val_loss: 4.7755e-08 - val_mse: 4.7755e-08\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 952us/step - loss: 1.7652e-08 - mse: 1.7652e-08 - val_loss: 2.5640e-09 - val_mse: 2.5640e-09\n",
      "Epoch 498/1000\n",
      "60/60 [==============================] - 0s 903us/step - loss: 4.6067e-09 - mse: 4.6067e-09 - val_loss: 1.3199e-09 - val_mse: 1.3199e-09\n",
      "Epoch 499/1000\n",
      "60/60 [==============================] - 0s 964us/step - loss: 5.5331e-10 - mse: 5.5331e-10 - val_loss: 4.4754e-09 - val_mse: 4.4754e-09\n",
      "Epoch 500/1000\n",
      "60/60 [==============================] - 0s 957us/step - loss: 5.3602e-09 - mse: 5.3602e-09 - val_loss: 1.0768e-10 - val_mse: 1.0768e-10\n",
      "Epoch 501/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9334e-10 - mse: 1.9334e-10 - val_loss: 2.3283e-11 - val_mse: 2.3283e-11\n",
      "Epoch 502/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3359e-11 - mse: 1.3359e-11 - val_loss: 2.3283e-11 - val_mse: 2.3283e-11\n",
      "Epoch 503/1000\n",
      "60/60 [==============================] - 0s 997us/step - loss: 1.1562e-11 - mse: 1.1562e-11 - val_loss: 3.4779e-10 - val_mse: 3.4779e-10\n",
      "Epoch 504/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 1.9949e-10 - mse: 1.9949e-10 - val_loss: 5.3114e-11 - val_mse: 5.3114e-11\n",
      "Epoch 505/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4276e-11 - mse: 5.4276e-11 - val_loss: 3.0414e-10 - val_mse: 3.0414e-10\n",
      "Epoch 506/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8974e-11 - mse: 1.8974e-11 - val_loss: 1.8073e-09 - val_mse: 1.8073e-09\n",
      "Epoch 507/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1536e-10 - mse: 1.1536e-10 - val_loss: 1.0259e-10 - val_mse: 1.0259e-10\n",
      "Epoch 508/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.5758e-12 - mse: 6.5758e-12 - val_loss: 1.2078e-10 - val_mse: 1.2078e-10\n",
      "Epoch 509/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2697e-12 - mse: 7.2697e-12 - val_loss: 1.8626e-10 - val_mse: 1.8626e-10\n",
      "Epoch 510/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6045e-11 - mse: 1.6045e-11 - val_loss: 9.4587e-11 - val_mse: 9.4587e-11\n",
      "Epoch 511/1000\n",
      "60/60 [==============================] - 0s 991us/step - loss: 1.0205e-11 - mse: 1.0205e-11 - val_loss: 6.1118e-11 - val_mse: 6.1118e-11\n",
      "Epoch 512/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5028e-11 - mse: 1.5028e-11 - val_loss: 2.2119e-10 - val_mse: 2.2119e-10\n",
      "Epoch 513/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4289e-10 - mse: 1.4289e-10 - val_loss: 5.7837e-09 - val_mse: 5.7837e-09\n",
      "Epoch 514/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6316e-09 - mse: 3.6316e-09 - val_loss: 2.7867e-10 - val_mse: 2.7867e-10\n",
      "Epoch 515/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5584e-10 - mse: 1.5584e-10 - val_loss: 8.2218e-11 - val_mse: 8.2218e-11\n",
      "Epoch 516/1000\n",
      "60/60 [==============================] - 0s 925us/step - loss: 2.6302e-09 - mse: 2.6302e-09 - val_loss: 8.4547e-10 - val_mse: 8.4547e-10\n",
      "Epoch 517/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0134e-10 - mse: 5.0134e-10 - val_loss: 2.3283e-11 - val_mse: 2.3283e-11\n",
      "Epoch 518/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9006e-11 - mse: 1.9006e-11 - val_loss: 5.0204e-11 - val_mse: 5.0204e-11\n",
      "Epoch 519/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1745e-10 - mse: 2.1745e-10 - val_loss: 2.1362e-09 - val_mse: 2.1362e-09\n",
      "Epoch 520/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7952e-10 - mse: 2.7952e-10 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 521/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0869e-11 - mse: 1.0869e-11 - val_loss: 9.8444e-10 - val_mse: 9.8444e-10\n",
      "Epoch 522/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0726e-10 - mse: 2.0726e-10 - val_loss: 3.6249e-09 - val_mse: 3.6249e-09\n",
      "Epoch 523/1000\n",
      "60/60 [==============================] - 0s 994us/step - loss: 6.8772e-10 - mse: 6.8772e-10 - val_loss: 9.0295e-10 - val_mse: 9.0295e-10\n",
      "Epoch 524/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6108e-08 - mse: 1.6108e-08 - val_loss: 3.6864e-08 - val_mse: 3.6864e-08\n",
      "Epoch 525/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.6611e-07 - mse: 8.6611e-07 - val_loss: 1.1510e-05 - val_mse: 1.1510e-05\n",
      "Epoch 526/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6512e-06 - mse: 3.6512e-06 - val_loss: 3.2744e-04 - val_mse: 3.2744e-04\n",
      "Epoch 527/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 528/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 529/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 0.0021 - mse: 0.0021 - val_loss: 6.7870e-04 - val_mse: 6.7870e-04\n",
      "Epoch 530/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 531/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1798 - mse: 0.1798 - val_loss: 0.4538 - val_mse: 0.4538\n",
      "Epoch 532/1000\n",
      "60/60 [==============================] - 0s 960us/step - loss: 0.1468 - mse: 0.1468 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 533/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 1.0895e-04 - val_mse: 1.0895e-04\n",
      "Epoch 534/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3456e-05 - mse: 2.3456e-05 - val_loss: 2.6592e-07 - val_mse: 2.6592e-07\n",
      "Epoch 535/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8844e-06 - mse: 7.8844e-06 - val_loss: 1.2919e-07 - val_mse: 1.2919e-07\n",
      "Epoch 536/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1127e-06 - mse: 3.1127e-06 - val_loss: 4.8938e-06 - val_mse: 4.8938e-06\n",
      "Epoch 537/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.1559e-07 - mse: 9.1559e-07 - val_loss: 4.6950e-07 - val_mse: 4.6950e-07\n",
      "Epoch 538/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4350e-07 - mse: 2.4350e-07 - val_loss: 3.1435e-06 - val_mse: 3.1435e-06\n",
      "Epoch 539/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2018e-07 - mse: 1.2018e-07 - val_loss: 4.0705e-08 - val_mse: 4.0705e-08\n",
      "Epoch 540/1000\n",
      "60/60 [==============================] - 0s 923us/step - loss: 4.1919e-08 - mse: 4.1919e-08 - val_loss: 6.4205e-08 - val_mse: 6.4205e-08\n",
      "Epoch 541/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 1.2748e-08 - mse: 1.2748e-08 - val_loss: 1.3519e-08 - val_mse: 1.3519e-08\n",
      "Epoch 542/1000\n",
      "60/60 [==============================] - 0s 986us/step - loss: 5.2763e-09 - mse: 5.2763e-09 - val_loss: 3.3186e-09 - val_mse: 3.3186e-09\n",
      "Epoch 543/1000\n",
      "60/60 [==============================] - 0s 917us/step - loss: 6.4126e-10 - mse: 6.4126e-10 - val_loss: 1.0659e-09 - val_mse: 1.0659e-09\n",
      "Epoch 544/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 2.8099e-10 - mse: 2.8099e-10 - val_loss: 5.6752e-11 - val_mse: 5.6752e-11\n",
      "Epoch 545/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9183e-11 - mse: 8.9183e-11 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
      "Epoch 546/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.7673e-11 - mse: 4.7673e-11 - val_loss: 3.7107e-11 - val_mse: 3.7107e-11\n",
      "Epoch 547/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4042e-11 - mse: 1.4042e-11 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
      "Epoch 548/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1088e-11 - mse: 1.1088e-11 - val_loss: 3.1287e-11 - val_mse: 3.1287e-11\n",
      "Epoch 549/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1846e-12 - mse: 5.1846e-12 - val_loss: 4.7294e-11 - val_mse: 4.7294e-11\n",
      "Epoch 550/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.0929e-12 - mse: 6.0929e-12 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
      "Epoch 551/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.6849e-12 - mse: 4.6849e-12 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
      "Epoch 552/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3153e-11 - mse: 4.3153e-11 - val_loss: 9.6043e-11 - val_mse: 9.6043e-11\n",
      "Epoch 553/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0856e-11 - mse: 1.0856e-11 - val_loss: 4.0745e-11 - val_mse: 4.0745e-11\n",
      "Epoch 554/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9754e-12 - mse: 6.9754e-12 - val_loss: 4.1473e-11 - val_mse: 4.1473e-11\n",
      "Epoch 555/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.5482e-12 - mse: 6.5482e-12 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
      "Epoch 556/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.5111e-12 - mse: 7.5111e-12 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
      "Epoch 557/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.5640e-12 - mse: 7.5640e-12 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 558/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3165e-11 - mse: 1.3165e-11 - val_loss: 2.7285e-10 - val_mse: 2.7285e-10\n",
      "Epoch 559/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4174e-11 - mse: 5.4174e-11 - val_loss: 1.7462e-10 - val_mse: 1.7462e-10\n",
      "Epoch 560/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4274e-11 - mse: 4.4274e-11 - val_loss: 3.8563e-11 - val_mse: 3.8563e-11\n",
      "Epoch 561/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 1.3534e-11 - mse: 1.3534e-11 - val_loss: 3.4925e-11 - val_mse: 3.4925e-11\n",
      "Epoch 562/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 6.7544e-12 - mse: 6.7544e-12 - val_loss: 9.6043e-11 - val_mse: 9.6043e-11\n",
      "Epoch 563/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4391e-11 - mse: 1.4391e-11 - val_loss: 4.5839e-11 - val_mse: 4.5839e-11\n",
      "Epoch 564/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2844e-11 - mse: 1.2844e-11 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 565/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.8420e-12 - mse: 5.8420e-12 - val_loss: 1.2515e-10 - val_mse: 1.2515e-10\n",
      "Epoch 566/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0802e-11 - mse: 2.0802e-11 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
      "Epoch 567/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.7958e-11 - mse: 9.7958e-11 - val_loss: 5.6752e-11 - val_mse: 5.6752e-11\n",
      "Epoch 568/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7557e-10 - mse: 2.7557e-10 - val_loss: 3.4925e-11 - val_mse: 3.4925e-11\n",
      "Epoch 569/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4071e-11 - mse: 1.4071e-11 - val_loss: 4.2855e-10 - val_mse: 4.2855e-10\n",
      "Epoch 570/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4449e-10 - mse: 4.4449e-10 - val_loss: 3.8526e-09 - val_mse: 3.8526e-09\n",
      "Epoch 571/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 3.5150e-09 - mse: 3.5150e-09 - val_loss: 4.1975e-09 - val_mse: 4.1975e-09\n",
      "Epoch 572/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.2707e-10 - mse: 6.2707e-10 - val_loss: 4.2710e-10 - val_mse: 4.2710e-10\n",
      "Epoch 573/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4861e-10 - mse: 2.4861e-10 - val_loss: 2.4943e-08 - val_mse: 2.4943e-08\n",
      "Epoch 574/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.2712e-09 - mse: 5.2712e-09 - val_loss: 2.3733e-08 - val_mse: 2.3733e-08\n",
      "Epoch 575/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4505e-08 - mse: 2.4505e-08 - val_loss: 6.8572e-08 - val_mse: 6.8572e-08\n",
      "Epoch 576/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3736e-08 - mse: 1.3736e-08 - val_loss: 4.7982e-07 - val_mse: 4.7982e-07\n",
      "Epoch 577/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3533e-08 - mse: 4.3533e-08 - val_loss: 2.2192e-10 - val_mse: 2.2192e-10\n",
      "Epoch 578/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3416e-10 - mse: 2.3416e-10 - val_loss: 7.4069e-10 - val_mse: 7.4069e-10\n",
      "Epoch 579/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0928e-10 - mse: 1.0928e-10 - val_loss: 1.2638e-09 - val_mse: 1.2638e-09\n",
      "Epoch 580/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0712e-09 - mse: 4.0712e-09 - val_loss: 2.2919e-08 - val_mse: 2.2919e-08\n",
      "Epoch 581/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 4.7351e-08 - mse: 4.7351e-08 - val_loss: 3.2006e-07 - val_mse: 3.2006e-07\n",
      "Epoch 582/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0951e-07 - mse: 4.0951e-07 - val_loss: 1.1294e-05 - val_mse: 1.1294e-05\n",
      "Epoch 583/1000\n",
      "60/60 [==============================] - 0s 957us/step - loss: 6.4127e-06 - mse: 6.4127e-06 - val_loss: 1.2240e-04 - val_mse: 1.2240e-04\n",
      "Epoch 584/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9646e-05 - mse: 1.9646e-05 - val_loss: 1.0907e-08 - val_mse: 1.0907e-08\n",
      "Epoch 585/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9421e-07 - mse: 3.9421e-07 - val_loss: 2.0460e-05 - val_mse: 2.0460e-05\n",
      "Epoch 586/1000\n",
      "60/60 [==============================] - 0s 965us/step - loss: 4.0013e-05 - mse: 4.0013e-05 - val_loss: 1.4123e-04 - val_mse: 1.4123e-04\n",
      "Epoch 587/1000\n",
      "60/60 [==============================] - 0s 964us/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0977 - val_mse: 0.0977\n",
      "Epoch 588/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 589/1000\n",
      "60/60 [==============================] - 0s 976us/step - loss: 5.0269e-04 - mse: 5.0269e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 590/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 2.7420e-04 - val_mse: 2.7420e-04\n",
      "Epoch 591/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 2.5344e-05 - mse: 2.5344e-05 - val_loss: 2.7723e-06 - val_mse: 2.7723e-06\n",
      "Epoch 592/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 1.1198e-06 - mse: 1.1198e-06 - val_loss: 5.9077e-05 - val_mse: 5.9077e-05\n",
      "Epoch 593/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 9.9146e-05 - mse: 9.9146e-05 - val_loss: 1.6394e-04 - val_mse: 1.6394e-04\n",
      "Epoch 594/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2620e-05 - mse: 2.2620e-05 - val_loss: 9.7290e-05 - val_mse: 9.7290e-05\n",
      "Epoch 595/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 1.4598e-05 - mse: 1.4598e-05 - val_loss: 1.1247e-06 - val_mse: 1.1247e-06\n",
      "Epoch 596/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 9.4993e-06 - mse: 9.4993e-06 - val_loss: 1.6519e-04 - val_mse: 1.6519e-04\n",
      "Epoch 597/1000\n",
      "60/60 [==============================] - 0s 962us/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 598/1000\n",
      "60/60 [==============================] - 0s 985us/step - loss: 0.1223 - mse: 0.1223 - val_loss: 0.0433 - val_mse: 0.0433\n",
      "Epoch 599/1000\n",
      "60/60 [==============================] - 0s 967us/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 600/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 601/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 1.6668e-04 - mse: 1.6668e-04 - val_loss: 5.0411e-05 - val_mse: 5.0411e-05\n",
      "Epoch 602/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 2.3053e-06 - mse: 2.3053e-06 - val_loss: 1.5489e-07 - val_mse: 1.5489e-07\n",
      "Epoch 603/1000\n",
      "60/60 [==============================] - 0s 972us/step - loss: 1.9216e-07 - mse: 1.9216e-07 - val_loss: 4.0750e-07 - val_mse: 4.0750e-07\n",
      "Epoch 604/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 1.2474e-07 - mse: 1.2474e-07 - val_loss: 3.1505e-10 - val_mse: 3.1505e-10\n",
      "Epoch 605/1000\n",
      "60/60 [==============================] - 0s 902us/step - loss: 4.8885e-10 - mse: 4.8885e-10 - val_loss: 1.7244e-10 - val_mse: 1.7244e-10\n",
      "Epoch 606/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 4.3751e-11 - mse: 4.3751e-11 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 953us/step - loss: 1.1312e-11 - mse: 1.1312e-11 - val_loss: 2.0373e-11 - val_mse: 2.0373e-11\n",
      "Epoch 608/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 9.2061e-12 - mse: 9.2061e-12 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
      "Epoch 609/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 1.0778e-11 - mse: 1.0778e-11 - val_loss: 2.6193e-11 - val_mse: 2.6193e-11\n",
      "Epoch 610/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.8353e-12 - mse: 9.8353e-12 - val_loss: 4.0018e-11 - val_mse: 4.0018e-11\n",
      "Epoch 611/1000\n",
      "60/60 [==============================] - 0s 967us/step - loss: 1.6862e-11 - mse: 1.6862e-11 - val_loss: 5.6752e-11 - val_mse: 5.6752e-11\n",
      "Epoch 612/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3622e-11 - mse: 1.3622e-11 - val_loss: 8.7311e-11 - val_mse: 8.7311e-11\n",
      "Epoch 613/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 1.1723e-11 - mse: 1.1723e-11 - val_loss: 1.3679e-10 - val_mse: 1.3679e-10\n",
      "Epoch 614/1000\n",
      "60/60 [==============================] - 0s 954us/step - loss: 3.0734e-11 - mse: 3.0734e-11 - val_loss: 1.8917e-11 - val_mse: 1.8917e-11\n",
      "Epoch 615/1000\n",
      "60/60 [==============================] - 0s 990us/step - loss: 1.6063e-11 - mse: 1.6063e-11 - val_loss: 2.2555e-11 - val_mse: 2.2555e-11\n",
      "Epoch 616/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 5.7574e-12 - mse: 5.7574e-12 - val_loss: 2.5466e-11 - val_mse: 2.5466e-11\n",
      "Epoch 617/1000\n",
      "60/60 [==============================] - 0s 926us/step - loss: 7.8880e-12 - mse: 7.8880e-12 - val_loss: 4.8021e-11 - val_mse: 4.8021e-11\n",
      "Epoch 618/1000\n",
      "60/60 [==============================] - 0s 894us/step - loss: 1.6102e-11 - mse: 1.6102e-11 - val_loss: 8.3965e-10 - val_mse: 8.3965e-10\n",
      "Epoch 619/1000\n",
      "60/60 [==============================] - 0s 930us/step - loss: 6.2766e-11 - mse: 6.2766e-11 - val_loss: 1.1091e-08 - val_mse: 1.1091e-08\n",
      "Epoch 620/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 6.6498e-10 - mse: 6.6498e-10 - val_loss: 1.7805e-07 - val_mse: 1.7805e-07\n",
      "Epoch 621/1000\n",
      "60/60 [==============================] - 0s 960us/step - loss: 2.8102e-08 - mse: 2.8102e-08 - val_loss: 1.0591e-08 - val_mse: 1.0591e-08\n",
      "Epoch 622/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 5.5040e-09 - mse: 5.5040e-09 - val_loss: 3.8228e-09 - val_mse: 3.8228e-09\n",
      "Epoch 623/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 2.7146e-09 - mse: 2.7146e-09 - val_loss: 4.9396e-09 - val_mse: 4.9396e-09\n",
      "Epoch 624/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.0190e-10 - mse: 6.0190e-10 - val_loss: 1.0550e-10 - val_mse: 1.0550e-10\n",
      "Epoch 625/1000\n",
      "60/60 [==============================] - 0s 954us/step - loss: 5.3551e-11 - mse: 5.3551e-11 - val_loss: 3.0814e-09 - val_mse: 3.0814e-09\n",
      "Epoch 626/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7585e-09 - mse: 3.7585e-09 - val_loss: 2.8376e-10 - val_mse: 2.8376e-10\n",
      "Epoch 627/1000\n",
      "60/60 [==============================] - 0s 995us/step - loss: 3.5458e-09 - mse: 3.5458e-09 - val_loss: 8.8731e-07 - val_mse: 8.8731e-07\n",
      "Epoch 628/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 8.7715e-08 - mse: 8.7715e-08 - val_loss: 1.3122e-07 - val_mse: 1.3122e-07\n",
      "Epoch 629/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 1.5075e-07 - mse: 1.5075e-07 - val_loss: 7.5778e-06 - val_mse: 7.5778e-06\n",
      "Epoch 630/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 1.4328e-05 - mse: 1.4328e-05 - val_loss: 9.9057e-05 - val_mse: 9.9057e-05\n",
      "Epoch 631/1000\n",
      "60/60 [==============================] - 0s 952us/step - loss: 2.8620e-04 - mse: 2.8620e-04 - val_loss: 7.8249e-06 - val_mse: 7.8249e-06\n",
      "Epoch 632/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 4.4172e-06 - mse: 4.4172e-06 - val_loss: 2.2444e-04 - val_mse: 2.2444e-04\n",
      "Epoch 633/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.1154 - val_mse: 0.1154\n",
      "Epoch 634/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 635/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 636/1000\n",
      "60/60 [==============================] - 0s 919us/step - loss: 9.5492e-04 - mse: 9.5492e-04 - val_loss: 2.2381e-05 - val_mse: 2.2381e-05\n",
      "Epoch 637/1000\n",
      "60/60 [==============================] - 0s 945us/step - loss: 9.9576e-06 - mse: 9.9576e-06 - val_loss: 5.4981e-06 - val_mse: 5.4981e-06\n",
      "Epoch 638/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 4.6921e-06 - mse: 4.6921e-06 - val_loss: 3.6606e-06 - val_mse: 3.6606e-06\n",
      "Epoch 639/1000\n",
      "60/60 [==============================] - 0s 967us/step - loss: 4.5888e-07 - mse: 4.5888e-07 - val_loss: 7.6842e-07 - val_mse: 7.6842e-07\n",
      "Epoch 640/1000\n",
      "60/60 [==============================] - 0s 932us/step - loss: 3.3022e-07 - mse: 3.3022e-07 - val_loss: 1.2166e-06 - val_mse: 1.2166e-06\n",
      "Epoch 641/1000\n",
      "60/60 [==============================] - 0s 978us/step - loss: 1.8893e-06 - mse: 1.8893e-06 - val_loss: 1.1072e-07 - val_mse: 1.1072e-07\n",
      "Epoch 642/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 1.5242e-06 - mse: 1.5242e-06 - val_loss: 9.5770e-07 - val_mse: 9.5770e-07\n",
      "Epoch 643/1000\n",
      "60/60 [==============================] - 0s 975us/step - loss: 6.9427e-07 - mse: 6.9427e-07 - val_loss: 4.6134e-06 - val_mse: 4.6134e-06\n",
      "Epoch 644/1000\n",
      "60/60 [==============================] - 0s 992us/step - loss: 5.4894e-06 - mse: 5.4894e-06 - val_loss: 2.0458e-07 - val_mse: 2.0458e-07\n",
      "Epoch 645/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 9.9599e-07 - mse: 9.9599e-07 - val_loss: 4.5070e-08 - val_mse: 4.5070e-08\n",
      "Epoch 646/1000\n",
      "60/60 [==============================] - 0s 958us/step - loss: 6.0610e-08 - mse: 6.0610e-08 - val_loss: 6.9101e-06 - val_mse: 6.9101e-06\n",
      "Epoch 647/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 1.2196e-06 - mse: 1.2196e-06 - val_loss: 1.8984e-06 - val_mse: 1.8984e-06\n",
      "Epoch 648/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 3.1865e-06 - mse: 3.1865e-06 - val_loss: 5.3641e-08 - val_mse: 5.3641e-08\n",
      "Epoch 649/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.2073e-06 - mse: 9.2073e-06 - val_loss: 8.8207e-07 - val_mse: 8.8207e-07\n",
      "Epoch 650/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4956e-06 - mse: 1.4956e-06 - val_loss: 3.1554e-05 - val_mse: 3.1554e-05\n",
      "Epoch 651/1000\n",
      "60/60 [==============================] - 0s 932us/step - loss: 2.5241e-06 - mse: 2.5241e-06 - val_loss: 2.1327e-07 - val_mse: 2.1327e-07\n",
      "Epoch 652/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 1.3895e-06 - mse: 1.3895e-06 - val_loss: 7.6449e-07 - val_mse: 7.6449e-07\n",
      "Epoch 653/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 9.7277e-06 - mse: 9.7277e-06 - val_loss: 1.1445e-05 - val_mse: 1.1445e-05\n",
      "Epoch 654/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9045e-05 - mse: 5.9045e-05 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 655/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 656/1000\n",
      "60/60 [==============================] - 0s 913us/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.1452 - val_mse: 0.1452\n",
      "Epoch 657/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1235 - mse: 0.1235 - val_loss: 0.5489 - val_mse: 0.5489\n",
      "Epoch 658/1000\n",
      "60/60 [==============================] - 0s 960us/step - loss: 0.1176 - mse: 0.1176 - val_loss: 0.0535 - val_mse: 0.0535\n",
      "Epoch 659/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 660/1000\n",
      "60/60 [==============================] - 0s 944us/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 661/1000\n",
      "60/60 [==============================] - 0s 908us/step - loss: 2.2275e-04 - mse: 2.2275e-04 - val_loss: 1.6961e-04 - val_mse: 1.6961e-04\n",
      "Epoch 662/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 3.8981e-05 - mse: 3.8981e-05 - val_loss: 3.0821e-07 - val_mse: 3.0821e-07\n",
      "Epoch 663/1000\n",
      "60/60 [==============================] - 0s 952us/step - loss: 1.0537e-05 - mse: 1.0537e-05 - val_loss: 2.2644e-06 - val_mse: 2.2644e-06\n",
      "Epoch 664/1000\n",
      "60/60 [==============================] - 0s 962us/step - loss: 3.1792e-06 - mse: 3.1792e-06 - val_loss: 1.0651e-05 - val_mse: 1.0651e-05\n",
      "Epoch 665/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 5.3175e-06 - mse: 5.3175e-06 - val_loss: 4.2251e-07 - val_mse: 4.2251e-07\n",
      "Epoch 666/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4849e-07 - mse: 1.4849e-07 - val_loss: 8.7464e-09 - val_mse: 8.7464e-09\n",
      "Epoch 667/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9980e-08 - mse: 2.9980e-08 - val_loss: 7.4646e-08 - val_mse: 7.4646e-08\n",
      "Epoch 668/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0297e-08 - mse: 1.0297e-08 - val_loss: 7.1035e-09 - val_mse: 7.1035e-09\n",
      "Epoch 669/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8603e-09 - mse: 3.8603e-09 - val_loss: 3.8126e-10 - val_mse: 3.8126e-10\n",
      "Epoch 670/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6600e-10 - mse: 3.6600e-10 - val_loss: 2.6193e-11 - val_mse: 2.6193e-11\n",
      "Epoch 671/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8746e-11 - mse: 4.8746e-11 - val_loss: 3.0341e-10 - val_mse: 3.0341e-10\n",
      "Epoch 672/1000\n",
      "60/60 [==============================] - 0s 921us/step - loss: 2.8008e-11 - mse: 2.8008e-11 - val_loss: 6.7666e-11 - val_mse: 6.7666e-11\n",
      "Epoch 673/1000\n",
      "60/60 [==============================] - 0s 954us/step - loss: 1.3957e-11 - mse: 1.3957e-11 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 674/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5000e-11 - mse: 1.5000e-11 - val_loss: 4.8021e-11 - val_mse: 4.8021e-11\n",
      "Epoch 675/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2936e-11 - mse: 1.2936e-11 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 676/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 4.0159e-12 - mse: 4.0159e-12 - val_loss: 3.7835e-11 - val_mse: 3.7835e-11\n",
      "Epoch 677/1000\n",
      "60/60 [==============================] - 0s 971us/step - loss: 4.8802e-12 - mse: 4.8802e-12 - val_loss: 2.6193e-11 - val_mse: 2.6193e-11\n",
      "Epoch 678/1000\n",
      "60/60 [==============================] - 0s 945us/step - loss: 4.6038e-12 - mse: 4.6038e-12 - val_loss: 1.0259e-10 - val_mse: 1.0259e-10\n",
      "Epoch 679/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5219e-11 - mse: 1.5219e-11 - val_loss: 1.7826e-10 - val_mse: 1.7826e-10\n",
      "Epoch 680/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 4.7421e-11 - mse: 4.7421e-11 - val_loss: 1.4552e-10 - val_mse: 1.4552e-10\n",
      "Epoch 681/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 1.6350e-11 - mse: 1.6350e-11 - val_loss: 4.5839e-11 - val_mse: 4.5839e-11\n",
      "Epoch 682/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.6492e-12 - mse: 4.6492e-12 - val_loss: 3.1287e-11 - val_mse: 3.1287e-11\n",
      "Epoch 683/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.4443e-12 - mse: 9.4443e-12 - val_loss: 4.0745e-11 - val_mse: 4.0745e-11\n",
      "Epoch 684/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 3.0347e-11 - mse: 3.0347e-11 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 685/1000\n",
      "60/60 [==============================] - 0s 974us/step - loss: 6.1589e-12 - mse: 6.1589e-12 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
      "Epoch 686/1000\n",
      "60/60 [==============================] - 0s 945us/step - loss: 2.7897e-11 - mse: 2.7897e-11 - val_loss: 1.8408e-10 - val_mse: 1.8408e-10\n",
      "Epoch 687/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 1.1171e-11 - mse: 1.1171e-11 - val_loss: 9.5315e-11 - val_mse: 9.5315e-11\n",
      "Epoch 688/1000\n",
      "60/60 [==============================] - 0s 968us/step - loss: 1.5442e-11 - mse: 1.5442e-11 - val_loss: 1.7462e-11 - val_mse: 1.7462e-11\n",
      "Epoch 689/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0731e-11 - mse: 1.0731e-11 - val_loss: 5.8208e-11 - val_mse: 5.8208e-11\n",
      "Epoch 690/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6853e-12 - mse: 2.6853e-12 - val_loss: 4.3656e-11 - val_mse: 4.3656e-11\n",
      "Epoch 691/1000\n",
      "60/60 [==============================] - 0s 962us/step - loss: 3.7911e-11 - mse: 3.7911e-11 - val_loss: 9.3059e-10 - val_mse: 9.3059e-10\n",
      "Epoch 692/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1054e-10 - mse: 2.1054e-10 - val_loss: 9.6770e-11 - val_mse: 9.6770e-11\n",
      "Epoch 693/1000\n",
      "60/60 [==============================] - 0s 927us/step - loss: 1.9551e-10 - mse: 1.9551e-10 - val_loss: 7.5161e-10 - val_mse: 7.5161e-10\n",
      "Epoch 694/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 2.4824e-10 - mse: 2.4824e-10 - val_loss: 5.4570e-10 - val_mse: 5.4570e-10\n",
      "Epoch 695/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 6.4674e-10 - mse: 6.4674e-10 - val_loss: 4.5499e-08 - val_mse: 4.5499e-08\n",
      "Epoch 696/1000\n",
      "60/60 [==============================] - 0s 991us/step - loss: 1.0971e-08 - mse: 1.0971e-08 - val_loss: 2.1066e-08 - val_mse: 2.1066e-08\n",
      "Epoch 697/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 1.0959e-05 - mse: 1.0959e-05 - val_loss: 4.0745e-07 - val_mse: 4.0745e-07\n",
      "Epoch 698/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2575e-08 - mse: 1.2575e-08 - val_loss: 6.4209e-07 - val_mse: 6.4209e-07\n",
      "Epoch 699/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4665e-07 - mse: 1.4665e-07 - val_loss: 1.6567e-06 - val_mse: 1.6567e-06\n",
      "Epoch 700/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8194e-06 - mse: 1.8194e-06 - val_loss: 2.6388e-06 - val_mse: 2.6388e-06\n",
      "Epoch 701/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0344e-06 - mse: 1.0344e-06 - val_loss: 1.0543e-04 - val_mse: 1.0543e-04\n",
      "Epoch 702/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.7352e-05 - mse: 8.7352e-05 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 703/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6865e-04 - mse: 2.6865e-04 - val_loss: 1.0102e-06 - val_mse: 1.0102e-06\n",
      "Epoch 704/1000\n",
      "60/60 [==============================] - 0s 965us/step - loss: 5.9553e-05 - mse: 5.9553e-05 - val_loss: 1.2335e-06 - val_mse: 1.2335e-06\n",
      "Epoch 705/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 6.8862e-06 - mse: 6.8862e-06 - val_loss: 4.3192e-04 - val_mse: 4.3192e-04\n",
      "Epoch 706/1000\n",
      "60/60 [==============================] - 0s 956us/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.1432 - val_mse: 0.1432\n",
      "Epoch 707/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 708/1000\n",
      "60/60 [==============================] - 0s 961us/step - loss: 0.0016 - mse: 0.0016 - val_loss: 3.6214e-04 - val_mse: 3.6214e-04\n",
      "Epoch 709/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.3588e-05 - mse: 5.3588e-05 - val_loss: 4.0314e-05 - val_mse: 4.0314e-05\n",
      "Epoch 710/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 3.7196e-06 - mse: 3.7196e-06 - val_loss: 4.6100e-06 - val_mse: 4.6100e-06\n",
      "Epoch 711/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 4.2033e-07 - mse: 4.2033e-07 - val_loss: 9.6923e-07 - val_mse: 9.6923e-07\n",
      "Epoch 712/1000\n",
      "60/60 [==============================] - 0s 970us/step - loss: 4.9374e-07 - mse: 4.9374e-07 - val_loss: 8.6094e-07 - val_mse: 8.6094e-07\n",
      "Epoch 713/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8093e-05 - mse: 4.8093e-05 - val_loss: 6.1696e-05 - val_mse: 6.1696e-05\n",
      "Epoch 714/1000\n",
      "60/60 [==============================] - 0s 969us/step - loss: 8.2787e-06 - mse: 8.2787e-06 - val_loss: 3.3256e-06 - val_mse: 3.3256e-06\n",
      "Epoch 715/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9755e-04 - mse: 3.9755e-04 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 716/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 0.1593 - mse: 0.1593 - val_loss: 0.5254 - val_mse: 0.5254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 717/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 0.1111 - mse: 0.1111 - val_loss: 0.1247 - val_mse: 0.1247\n",
      "Epoch 718/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 719/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 1.1391e-04 - mse: 1.1391e-04 - val_loss: 4.3210e-05 - val_mse: 4.3210e-05\n",
      "Epoch 720/1000\n",
      "60/60 [==============================] - 0s 974us/step - loss: 5.8180e-05 - mse: 5.8180e-05 - val_loss: 2.7362e-05 - val_mse: 2.7362e-05\n",
      "Epoch 721/1000\n",
      "60/60 [==============================] - 0s 981us/step - loss: 1.9251e-05 - mse: 1.9251e-05 - val_loss: 1.4048e-07 - val_mse: 1.4048e-07\n",
      "Epoch 722/1000\n",
      "60/60 [==============================] - 0s 995us/step - loss: 5.9202e-06 - mse: 5.9202e-06 - val_loss: 5.2086e-06 - val_mse: 5.2086e-06\n",
      "Epoch 723/1000\n",
      "60/60 [==============================] - 0s 991us/step - loss: 1.4927e-06 - mse: 1.4927e-06 - val_loss: 2.9592e-06 - val_mse: 2.9592e-06\n",
      "Epoch 724/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5906e-07 - mse: 3.5906e-07 - val_loss: 5.9554e-09 - val_mse: 5.9554e-09\n",
      "Epoch 725/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 1.5822e-07 - mse: 1.5822e-07 - val_loss: 2.5573e-08 - val_mse: 2.5573e-08\n",
      "Epoch 726/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0431e-08 - mse: 3.0431e-08 - val_loss: 3.7355e-08 - val_mse: 3.7355e-08\n",
      "Epoch 727/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5818e-08 - mse: 1.5818e-08 - val_loss: 2.7416e-09 - val_mse: 2.7416e-09\n",
      "Epoch 728/1000\n",
      "60/60 [==============================] - 0s 967us/step - loss: 2.6451e-08 - mse: 2.6451e-08 - val_loss: 7.9875e-09 - val_mse: 7.9875e-09\n",
      "Epoch 729/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4782e-09 - mse: 1.4782e-09 - val_loss: 1.8365e-09 - val_mse: 1.8365e-09\n",
      "Epoch 730/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 1.7209e-10 - mse: 1.7209e-10 - val_loss: 2.2046e-10 - val_mse: 2.2046e-10\n",
      "Epoch 731/1000\n",
      "60/60 [==============================] - 0s 994us/step - loss: 1.4446e-11 - mse: 1.4446e-11 - val_loss: 1.6516e-10 - val_mse: 1.6516e-10\n",
      "Epoch 732/1000\n",
      "60/60 [==============================] - 0s 932us/step - loss: 8.2114e-12 - mse: 8.2114e-12 - val_loss: 7.7125e-11 - val_mse: 7.7125e-11\n",
      "Epoch 733/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 1.4383e-11 - mse: 1.4383e-11 - val_loss: 8.7311e-11 - val_mse: 8.7311e-11\n",
      "Epoch 734/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 1.5052e-11 - mse: 1.5052e-11 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 735/1000\n",
      "60/60 [==============================] - 0s 999us/step - loss: 7.1467e-12 - mse: 7.1467e-12 - val_loss: 7.4215e-11 - val_mse: 7.4215e-11\n",
      "Epoch 736/1000\n",
      "60/60 [==============================] - 0s 995us/step - loss: 1.2543e-11 - mse: 1.2543e-11 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
      "Epoch 737/1000\n",
      "60/60 [==============================] - 0s 944us/step - loss: 9.0159e-12 - mse: 9.0159e-12 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
      "Epoch 738/1000\n",
      "60/60 [==============================] - 0s 928us/step - loss: 2.1555e-11 - mse: 2.1555e-11 - val_loss: 4.2201e-11 - val_mse: 4.2201e-11\n",
      "Epoch 739/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 2.2225e-11 - mse: 2.2225e-11 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
      "Epoch 740/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8729e-11 - mse: 1.8729e-11 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 741/1000\n",
      "60/60 [==============================] - 0s 919us/step - loss: 5.0984e-12 - mse: 5.0984e-12 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
      "Epoch 742/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 1.6609e-11 - mse: 1.6609e-11 - val_loss: 9.4587e-11 - val_mse: 9.4587e-11\n",
      "Epoch 743/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 2.5069e-11 - mse: 2.5069e-11 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
      "Epoch 744/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 1.1732e-11 - mse: 1.1732e-11 - val_loss: 8.8257e-10 - val_mse: 8.8257e-10\n",
      "Epoch 745/1000\n",
      "60/60 [==============================] - 0s 907us/step - loss: 1.7998e-10 - mse: 1.7998e-10 - val_loss: 1.1787e-10 - val_mse: 1.1787e-10\n",
      "Epoch 746/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 1.3575e-11 - mse: 1.3575e-11 - val_loss: 3.5652e-11 - val_mse: 3.5652e-11\n",
      "Epoch 747/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 8.8490e-12 - mse: 8.8490e-12 - val_loss: 4.1473e-11 - val_mse: 4.1473e-11\n",
      "Epoch 748/1000\n",
      "60/60 [==============================] - 0s 999us/step - loss: 1.7943e-11 - mse: 1.7943e-11 - val_loss: 4.2201e-11 - val_mse: 4.2201e-11\n",
      "Epoch 749/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0585e-12 - mse: 3.0585e-12 - val_loss: 1.0550e-10 - val_mse: 1.0550e-10\n",
      "Epoch 750/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0942e-11 - mse: 2.0942e-11 - val_loss: 1.2442e-10 - val_mse: 1.2442e-10\n",
      "Epoch 751/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3531e-10 - mse: 2.3531e-10 - val_loss: 1.8162e-08 - val_mse: 1.8162e-08\n",
      "Epoch 752/1000\n",
      "60/60 [==============================] - 0s 964us/step - loss: 1.9666e-09 - mse: 1.9666e-09 - val_loss: 9.8225e-11 - val_mse: 9.8225e-11\n",
      "Epoch 753/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 1.9299e-11 - mse: 1.9299e-11 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
      "Epoch 754/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 8.6649e-12 - mse: 8.6649e-12 - val_loss: 3.2014e-11 - val_mse: 3.2014e-11\n",
      "Epoch 755/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 1.1709e-11 - mse: 1.1709e-11 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
      "Epoch 756/1000\n",
      "60/60 [==============================] - 0s 986us/step - loss: 3.8935e-11 - mse: 3.8935e-11 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
      "Epoch 757/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 2.6502e-11 - mse: 2.6502e-11 - val_loss: 2.4011e-11 - val_mse: 2.4011e-11\n",
      "Epoch 758/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 1.0827e-11 - mse: 1.0827e-11 - val_loss: 3.1505e-10 - val_mse: 3.1505e-10\n",
      "Epoch 759/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0996e-10 - mse: 2.0996e-10 - val_loss: 2.3450e-09 - val_mse: 2.3450e-09\n",
      "Epoch 760/1000\n",
      "60/60 [==============================] - 0s 922us/step - loss: 2.0571e-08 - mse: 2.0571e-08 - val_loss: 9.2914e-10 - val_mse: 9.2914e-10\n",
      "Epoch 761/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 4.4358e-08 - mse: 4.4358e-08 - val_loss: 5.0722e-07 - val_mse: 5.0722e-07\n",
      "Epoch 762/1000\n",
      "60/60 [==============================] - 0s 945us/step - loss: 1.1403e-07 - mse: 1.1403e-07 - val_loss: 1.5982e-07 - val_mse: 1.5982e-07\n",
      "Epoch 763/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 3.0446e-08 - mse: 3.0446e-08 - val_loss: 1.4249e-08 - val_mse: 1.4249e-08\n",
      "Epoch 764/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3068e-09 - mse: 4.3068e-09 - val_loss: 3.6744e-10 - val_mse: 3.6744e-10\n",
      "Epoch 765/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.4223e-10 - mse: 8.4223e-10 - val_loss: 8.8621e-10 - val_mse: 8.8621e-10\n",
      "Epoch 766/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0523e-07 - mse: 3.0523e-07 - val_loss: 5.6348e-06 - val_mse: 5.6348e-06\n",
      "Epoch 767/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6768e-05 - mse: 1.6768e-05 - val_loss: 2.5480e-05 - val_mse: 2.5480e-05\n",
      "Epoch 768/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9851e-06 - mse: 5.9851e-06 - val_loss: 7.6857e-08 - val_mse: 7.6857e-08\n",
      "Epoch 769/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5167e-05 - mse: 4.5167e-05 - val_loss: 4.1312e-04 - val_mse: 4.1312e-04\n",
      "Epoch 770/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 771/1000\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.1379 - mse: 0.1379 - val_loss: 0.1384 - val_mse: 0.1384\n",
      "Epoch 772/1000\n",
      "60/60 [==============================] - 0s 896us/step - loss: 0.0877 - mse: 0.0877 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 773/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 0.0024 - mse: 0.0024 - val_loss: 9.9366e-04 - val_mse: 9.9366e-04\n",
      "Epoch 774/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 2.7111e-04 - mse: 2.7111e-04 - val_loss: 6.1555e-05 - val_mse: 6.1555e-05\n",
      "Epoch 775/1000\n",
      "60/60 [==============================] - 0s 981us/step - loss: 2.4464e-05 - mse: 2.4464e-05 - val_loss: 3.5232e-06 - val_mse: 3.5232e-06\n",
      "Epoch 776/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 3.8709e-06 - mse: 3.8709e-06 - val_loss: 3.9259e-05 - val_mse: 3.9259e-05\n",
      "Epoch 777/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 4.8217e-06 - mse: 4.8217e-06 - val_loss: 2.1660e-06 - val_mse: 2.1660e-06\n",
      "Epoch 778/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.2094e-07 - mse: 8.2094e-07 - val_loss: 6.7288e-06 - val_mse: 6.7288e-06\n",
      "Epoch 779/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4220e-06 - mse: 1.4220e-06 - val_loss: 1.8052e-09 - val_mse: 1.8052e-09\n",
      "Epoch 780/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 3.7093e-07 - mse: 3.7093e-07 - val_loss: 1.8600e-06 - val_mse: 1.8600e-06\n",
      "Epoch 781/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2470e-07 - mse: 1.2470e-07 - val_loss: 4.0214e-09 - val_mse: 4.0214e-09\n",
      "Epoch 782/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 8.5325e-10 - mse: 8.5325e-10 - val_loss: 3.6969e-09 - val_mse: 3.6969e-09\n",
      "Epoch 783/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 3.3009e-10 - mse: 3.3009e-10 - val_loss: 1.6880e-10 - val_mse: 1.6880e-10\n",
      "Epoch 784/1000\n",
      "60/60 [==============================] - 0s 968us/step - loss: 9.9335e-12 - mse: 9.9335e-12 - val_loss: 1.2515e-10 - val_mse: 1.2515e-10\n",
      "Epoch 785/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 1.4420e-11 - mse: 1.4420e-11 - val_loss: 3.8563e-11 - val_mse: 3.8563e-11\n",
      "Epoch 786/1000\n",
      "60/60 [==============================] - 0s 949us/step - loss: 1.0024e-11 - mse: 1.0024e-11 - val_loss: 3.1287e-11 - val_mse: 3.1287e-11\n",
      "Epoch 787/1000\n",
      "60/60 [==============================] - 0s 961us/step - loss: 7.6898e-12 - mse: 7.6898e-12 - val_loss: 3.6380e-11 - val_mse: 3.6380e-11\n",
      "Epoch 788/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2589e-11 - mse: 1.2589e-11 - val_loss: 1.7899e-10 - val_mse: 1.7899e-10\n",
      "Epoch 789/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 9.8092e-12 - mse: 9.8092e-12 - val_loss: 6.5484e-11 - val_mse: 6.5484e-11\n",
      "Epoch 790/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 1.4439e-11 - mse: 1.4439e-11 - val_loss: 1.4552e-11 - val_mse: 1.4552e-11\n",
      "Epoch 791/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 7.7673e-12 - mse: 7.7673e-12 - val_loss: 8.8767e-11 - val_mse: 8.8767e-11\n",
      "Epoch 792/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7671e-11 - mse: 1.7671e-11 - val_loss: 2.2555e-11 - val_mse: 2.2555e-11\n",
      "Epoch 793/1000\n",
      "60/60 [==============================] - 0s 974us/step - loss: 1.9196e-11 - mse: 1.9196e-11 - val_loss: 1.5280e-10 - val_mse: 1.5280e-10\n",
      "Epoch 794/1000\n",
      "60/60 [==============================] - 0s 960us/step - loss: 2.1377e-11 - mse: 2.1377e-11 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
      "Epoch 795/1000\n",
      "60/60 [==============================] - 0s 933us/step - loss: 5.4056e-11 - mse: 5.4056e-11 - val_loss: 2.1828e-11 - val_mse: 2.1828e-11\n",
      "Epoch 796/1000\n",
      "60/60 [==============================] - 0s 971us/step - loss: 6.3731e-12 - mse: 6.3731e-12 - val_loss: 2.5466e-10 - val_mse: 2.5466e-10\n",
      "Epoch 797/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 2.2821e-11 - mse: 2.2821e-11 - val_loss: 1.0259e-10 - val_mse: 1.0259e-10\n",
      "Epoch 798/1000\n",
      "60/60 [==============================] - 0s 977us/step - loss: 3.2142e-11 - mse: 3.2142e-11 - val_loss: 1.8248e-09 - val_mse: 1.8248e-09\n",
      "Epoch 799/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6324e-10 - mse: 1.6324e-10 - val_loss: 3.0996e-10 - val_mse: 3.0996e-10\n",
      "Epoch 800/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4967e-11 - mse: 1.4967e-11 - val_loss: 4.0745e-11 - val_mse: 4.0745e-11\n",
      "Epoch 801/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3420e-11 - mse: 2.3420e-11 - val_loss: 1.1714e-10 - val_mse: 1.1714e-10\n",
      "Epoch 802/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.5963e-10 - mse: 6.5963e-10 - val_loss: 1.3242e-10 - val_mse: 1.3242e-10\n",
      "Epoch 803/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9863e-10 - mse: 1.9863e-10 - val_loss: 3.9887e-09 - val_mse: 3.9887e-09\n",
      "Epoch 804/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7429e-09 - mse: 1.7429e-09 - val_loss: 8.8257e-10 - val_mse: 8.8257e-10\n",
      "Epoch 805/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4027e-11 - mse: 4.4027e-11 - val_loss: 2.4520e-10 - val_mse: 2.4520e-10\n",
      "Epoch 806/1000\n",
      "60/60 [==============================] - 0s 924us/step - loss: 1.9996e-11 - mse: 1.9996e-11 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 807/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2220e-11 - mse: 2.2220e-11 - val_loss: 7.1304e-11 - val_mse: 7.1304e-11\n",
      "Epoch 808/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 8.2631e-11 - mse: 8.2631e-11 - val_loss: 2.4505e-09 - val_mse: 2.4505e-09\n",
      "Epoch 809/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 2.7930e-08 - mse: 2.7930e-08 - val_loss: 1.1681e-08 - val_mse: 1.1681e-08\n",
      "Epoch 810/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 4.3797e-10 - mse: 4.3797e-10 - val_loss: 1.1787e-10 - val_mse: 1.1787e-10\n",
      "Epoch 811/1000\n",
      "60/60 [==============================] - 0s 954us/step - loss: 6.8832e-11 - mse: 6.8832e-11 - val_loss: 7.8580e-11 - val_mse: 7.8580e-11\n",
      "Epoch 812/1000\n",
      "60/60 [==============================] - 0s 943us/step - loss: 3.3560e-10 - mse: 3.3560e-10 - val_loss: 6.2275e-09 - val_mse: 6.2275e-09\n",
      "Epoch 813/1000\n",
      "60/60 [==============================] - 0s 938us/step - loss: 2.0556e-08 - mse: 2.0556e-08 - val_loss: 2.4361e-08 - val_mse: 2.4361e-08\n",
      "Epoch 814/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1105e-08 - mse: 7.1105e-08 - val_loss: 3.2221e-06 - val_mse: 3.2221e-06\n",
      "Epoch 815/1000\n",
      "60/60 [==============================] - 0s 931us/step - loss: 2.3195e-06 - mse: 2.3195e-06 - val_loss: 1.3807e-04 - val_mse: 1.3807e-04\n",
      "Epoch 816/1000\n",
      "60/60 [==============================] - 0s 977us/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.6806 - val_mse: 0.6806\n",
      "Epoch 817/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1403 - mse: 0.1403 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 818/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 2.7873e-05 - val_mse: 2.7873e-05\n",
      "Epoch 819/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2886e-05 - mse: 4.2886e-05 - val_loss: 1.6492e-04 - val_mse: 1.6492e-04\n",
      "Epoch 820/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4938e-05 - mse: 1.4938e-05 - val_loss: 2.1592e-07 - val_mse: 2.1592e-07\n",
      "Epoch 821/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5638e-06 - mse: 1.5638e-06 - val_loss: 1.2392e-05 - val_mse: 1.2392e-05\n",
      "Epoch 822/1000\n",
      "60/60 [==============================] - 0s 977us/step - loss: 1.2241e-06 - mse: 1.2241e-06 - val_loss: 6.3340e-08 - val_mse: 6.3340e-08\n",
      "Epoch 823/1000\n",
      "60/60 [==============================] - 0s 941us/step - loss: 1.7237e-07 - mse: 1.7237e-07 - val_loss: 3.0490e-07 - val_mse: 3.0490e-07\n",
      "Epoch 824/1000\n",
      "60/60 [==============================] - 0s 977us/step - loss: 1.1057e-07 - mse: 1.1057e-07 - val_loss: 4.9949e-09 - val_mse: 4.9949e-09\n",
      "Epoch 825/1000\n",
      "60/60 [==============================] - 0s 979us/step - loss: 9.0008e-10 - mse: 9.0008e-10 - val_loss: 1.4552e-11 - val_mse: 1.4552e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 826/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3256e-10 - mse: 3.3256e-10 - val_loss: 2.0373e-11 - val_mse: 2.0373e-11\n",
      "Epoch 827/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.4216e-12 - mse: 8.4216e-12 - val_loss: 4.0745e-11 - val_mse: 4.0745e-11\n",
      "Epoch 828/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1709e-11 - mse: 2.1709e-11 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 829/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3730e-12 - mse: 7.3730e-12 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
      "Epoch 830/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2961e-11 - mse: 1.2961e-11 - val_loss: 8.5856e-11 - val_mse: 8.5856e-11\n",
      "Epoch 831/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9884e-11 - mse: 1.9884e-11 - val_loss: 3.3469e-11 - val_mse: 3.3469e-11\n",
      "Epoch 832/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2203e-11 - mse: 1.2203e-11 - val_loss: 1.8190e-11 - val_mse: 1.8190e-11\n",
      "Epoch 833/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0609e-12 - mse: 5.0609e-12 - val_loss: 4.0018e-11 - val_mse: 4.0018e-11\n",
      "Epoch 834/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8839e-12 - mse: 7.8839e-12 - val_loss: 1.8917e-11 - val_mse: 1.8917e-11\n",
      "Epoch 835/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.0730e-12 - mse: 6.0730e-12 - val_loss: 5.6752e-11 - val_mse: 5.6752e-11\n",
      "Epoch 836/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3996e-12 - mse: 6.3996e-12 - val_loss: 2.7649e-11 - val_mse: 2.7649e-11\n",
      "Epoch 837/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4608e-11 - mse: 1.4608e-11 - val_loss: 5.8135e-10 - val_mse: 5.8135e-10\n",
      "Epoch 838/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6706e-10 - mse: 2.6706e-10 - val_loss: 4.5140e-09 - val_mse: 4.5140e-09\n",
      "Epoch 839/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 6.5505e-09 - mse: 6.5505e-09 - val_loss: 5.1732e-10 - val_mse: 5.1732e-10\n",
      "Epoch 840/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3324e-10 - mse: 3.3324e-10 - val_loss: 3.1563e-09 - val_mse: 3.1563e-09\n",
      "Epoch 841/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6734e-09 - mse: 3.6734e-09 - val_loss: 4.4362e-09 - val_mse: 4.4362e-09\n",
      "Epoch 842/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 1.0786e-09 - mse: 1.0786e-09 - val_loss: 1.4843e-10 - val_mse: 1.4843e-10\n",
      "Epoch 843/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4022e-10 - mse: 1.4022e-10 - val_loss: 6.1118e-11 - val_mse: 6.1118e-11\n",
      "Epoch 844/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7662e-11 - mse: 2.7662e-11 - val_loss: 2.6193e-11 - val_mse: 2.6193e-11\n",
      "Epoch 845/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7282e-10 - mse: 6.7282e-10 - val_loss: 1.3710e-08 - val_mse: 1.3710e-08\n",
      "Epoch 846/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0391e-09 - mse: 2.0391e-09 - val_loss: 1.5789e-09 - val_mse: 1.5789e-09\n",
      "Epoch 847/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.0807e-10 - mse: 8.0807e-10 - val_loss: 1.2951e-10 - val_mse: 1.2951e-10\n",
      "Epoch 848/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6247e-10 - mse: 1.6247e-10 - val_loss: 3.2451e-10 - val_mse: 3.2451e-10\n",
      "Epoch 849/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0864e-08 - mse: 1.0864e-08 - val_loss: 3.7937e-09 - val_mse: 3.7937e-09\n",
      "Epoch 850/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2743e-09 - mse: 1.2743e-09 - val_loss: 6.5338e-10 - val_mse: 6.5338e-10\n",
      "Epoch 851/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0371e-09 - mse: 1.0371e-09 - val_loss: 3.0341e-10 - val_mse: 3.0341e-10\n",
      "Epoch 852/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1442e-10 - mse: 1.1442e-10 - val_loss: 4.8749e-10 - val_mse: 4.8749e-10\n",
      "Epoch 853/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1790e-08 - mse: 5.1790e-08 - val_loss: 2.7629e-07 - val_mse: 2.7629e-07\n",
      "Epoch 854/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3222e-07 - mse: 2.3222e-07 - val_loss: 2.0398e-06 - val_mse: 2.0398e-06\n",
      "Epoch 855/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2587e-07 - mse: 1.2587e-07 - val_loss: 1.5085e-08 - val_mse: 1.5085e-08\n",
      "Epoch 856/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.7635e-04 - mse: 4.7635e-04 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 857/1000\n",
      "60/60 [==============================] - 0s 978us/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0573 - val_mse: 0.0573\n",
      "Epoch 858/1000\n",
      "60/60 [==============================] - 0s 936us/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 859/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6471e-04 - mse: 6.6471e-04 - val_loss: 5.2987e-05 - val_mse: 5.2987e-05\n",
      "Epoch 860/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9218e-05 - mse: 3.9218e-05 - val_loss: 3.3342e-04 - val_mse: 3.3342e-04\n",
      "Epoch 861/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 862/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 2.4253e-05 - val_mse: 2.4253e-05\n",
      "Epoch 863/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1669e-06 - mse: 2.1669e-06 - val_loss: 5.6178e-06 - val_mse: 5.6178e-06\n",
      "Epoch 864/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.3772e-07 - mse: 9.3772e-07 - val_loss: 1.3855e-06 - val_mse: 1.3855e-06\n",
      "Epoch 865/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.9935e-07 - mse: 4.9935e-07 - val_loss: 4.8310e-06 - val_mse: 4.8310e-06\n",
      "Epoch 866/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5765e-07 - mse: 2.5765e-07 - val_loss: 5.2865e-08 - val_mse: 5.2865e-08\n",
      "Epoch 867/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.0497e-09 - mse: 9.0497e-09 - val_loss: 3.1031e-08 - val_mse: 3.1031e-08\n",
      "Epoch 868/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3902e-07 - mse: 1.3902e-07 - val_loss: 8.7770e-06 - val_mse: 8.7770e-06\n",
      "Epoch 869/1000\n",
      "60/60 [==============================] - 0s 916us/step - loss: 8.3151e-07 - mse: 8.3151e-07 - val_loss: 3.3288e-07 - val_mse: 3.3288e-07\n",
      "Epoch 870/1000\n",
      "60/60 [==============================] - 0s 979us/step - loss: 3.4453e-07 - mse: 3.4453e-07 - val_loss: 3.6368e-05 - val_mse: 3.6368e-05\n",
      "Epoch 871/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3228e-06 - mse: 7.3228e-06 - val_loss: 3.5620e-06 - val_mse: 3.5620e-06\n",
      "Epoch 872/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0408e-07 - mse: 1.0408e-07 - val_loss: 1.6718e-07 - val_mse: 1.6718e-07\n",
      "Epoch 873/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2849e-07 - mse: 1.2849e-07 - val_loss: 4.3465e-06 - val_mse: 4.3465e-06\n",
      "Epoch 874/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0176e-06 - mse: 2.0176e-06 - val_loss: 2.7232e-05 - val_mse: 2.7232e-05\n",
      "Epoch 875/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0965e-04 - mse: 1.0965e-04 - val_loss: 4.6354e-04 - val_mse: 4.6354e-04\n",
      "Epoch 876/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8360e-05 - mse: 1.8360e-05 - val_loss: 5.3631e-04 - val_mse: 5.3631e-04\n",
      "Epoch 877/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 878/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.2999 - val_mse: 0.2999\n",
      "Epoch 879/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0627 - mse: 0.0627 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 880/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 881/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2798e-04 - mse: 1.2798e-04 - val_loss: 1.6437e-05 - val_mse: 1.6437e-05\n",
      "Epoch 882/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1366e-06 - mse: 5.1366e-06 - val_loss: 3.2973e-05 - val_mse: 3.2973e-05\n",
      "Epoch 883/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4665e-06 - mse: 2.4665e-06 - val_loss: 2.3443e-09 - val_mse: 2.3443e-09\n",
      "Epoch 884/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2207e-06 - mse: 1.2207e-06 - val_loss: 6.0665e-05 - val_mse: 6.0665e-05\n",
      "Epoch 885/1000\n",
      "60/60 [==============================] - 0s 977us/step - loss: 1.3655e-05 - mse: 1.3655e-05 - val_loss: 4.2928e-11 - val_mse: 4.2928e-11\n",
      "Epoch 886/1000\n",
      "60/60 [==============================] - 0s 973us/step - loss: 1.8712e-06 - mse: 1.8712e-06 - val_loss: 3.3185e-06 - val_mse: 3.3185e-06\n",
      "Epoch 887/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1403e-07 - mse: 7.1403e-07 - val_loss: 2.1536e-07 - val_mse: 2.1536e-07\n",
      "Epoch 888/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4060e-08 - mse: 3.4060e-08 - val_loss: 1.9167e-08 - val_mse: 1.9167e-08\n",
      "Epoch 889/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.6177e-09 - mse: 5.6177e-09 - val_loss: 1.3607e-08 - val_mse: 1.3607e-08\n",
      "Epoch 890/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.5370e-09 - mse: 7.5370e-09 - val_loss: 1.7353e-09 - val_mse: 1.7353e-09\n",
      "Epoch 891/1000\n",
      "60/60 [==============================] - 0s 925us/step - loss: 8.4584e-10 - mse: 8.4584e-10 - val_loss: 6.6066e-10 - val_mse: 6.6066e-10\n",
      "Epoch 892/1000\n",
      "60/60 [==============================] - 0s 969us/step - loss: 3.5942e-11 - mse: 3.5942e-11 - val_loss: 3.1505e-10 - val_mse: 3.1505e-10\n",
      "Epoch 893/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.4017e-12 - mse: 9.4017e-12 - val_loss: 1.7681e-10 - val_mse: 1.7681e-10\n",
      "Epoch 894/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2744e-10 - mse: 1.2744e-10 - val_loss: 3.8344e-10 - val_mse: 3.8344e-10\n",
      "Epoch 895/1000\n",
      "60/60 [==============================] - 0s 959us/step - loss: 9.8209e-11 - mse: 9.8209e-11 - val_loss: 9.7643e-10 - val_mse: 9.7643e-10\n",
      "Epoch 896/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5903e-09 - mse: 2.5903e-09 - val_loss: 1.7717e-09 - val_mse: 1.7717e-09\n",
      "Epoch 897/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0677e-08 - mse: 5.0677e-08 - val_loss: 1.5432e-08 - val_mse: 1.5432e-08\n",
      "Epoch 898/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 1.0344e-06 - mse: 1.0344e-06 - val_loss: 7.2376e-05 - val_mse: 7.2376e-05\n",
      "Epoch 899/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1071e-05 - mse: 1.1071e-05 - val_loss: 1.0428e-04 - val_mse: 1.0428e-04\n",
      "Epoch 900/1000\n",
      "60/60 [==============================] - 0s 955us/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.1414 - val_mse: 0.1414\n",
      "Epoch 901/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 902/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.7661e-04 - mse: 9.7661e-04 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 903/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 8.0442e-04 - mse: 8.0442e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 904/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.8859e-04 - val_mse: 1.8859e-04\n",
      "Epoch 905/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2034e-05 - mse: 7.2034e-05 - val_loss: 8.4600e-06 - val_mse: 8.4600e-06\n",
      "Epoch 906/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4390e-05 - mse: 1.4390e-05 - val_loss: 6.4653e-06 - val_mse: 6.4653e-06\n",
      "Epoch 907/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 1.1696e-06 - mse: 1.1696e-06 - val_loss: 1.3582e-07 - val_mse: 1.3582e-07\n",
      "Epoch 908/1000\n",
      "60/60 [==============================] - 0s 972us/step - loss: 1.3553e-07 - mse: 1.3553e-07 - val_loss: 4.9709e-09 - val_mse: 4.9709e-09\n",
      "Epoch 909/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.4709e-10 - mse: 9.4709e-10 - val_loss: 1.0332e-10 - val_mse: 1.0332e-10\n",
      "Epoch 910/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7730e-10 - mse: 2.7730e-10 - val_loss: 1.4547e-08 - val_mse: 1.4547e-08\n",
      "Epoch 911/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7720e-09 - mse: 1.7720e-09 - val_loss: 8.8839e-10 - val_mse: 8.8839e-10\n",
      "Epoch 912/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.1101e-10 - mse: 6.1101e-10 - val_loss: 1.9863e-10 - val_mse: 1.9863e-10\n",
      "Epoch 913/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.8320e-10 - mse: 5.8320e-10 - val_loss: 6.6211e-10 - val_mse: 6.6211e-10\n",
      "Epoch 914/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4379e-10 - mse: 3.4379e-10 - val_loss: 5.5297e-11 - val_mse: 5.5297e-11\n",
      "Epoch 915/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2116e-10 - mse: 7.2116e-10 - val_loss: 4.0840e-09 - val_mse: 4.0840e-09\n",
      "Epoch 916/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.4690e-09 - mse: 8.4690e-09 - val_loss: 4.3444e-08 - val_mse: 4.3444e-08\n",
      "Epoch 917/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1539e-08 - mse: 1.1539e-08 - val_loss: 5.4614e-08 - val_mse: 5.4614e-08\n",
      "Epoch 918/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9839e-08 - mse: 2.9839e-08 - val_loss: 1.3313e-07 - val_mse: 1.3313e-07\n",
      "Epoch 919/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8446e-08 - mse: 1.8446e-08 - val_loss: 4.7010e-07 - val_mse: 4.7010e-07\n",
      "Epoch 920/1000\n",
      "60/60 [==============================] - 0s 934us/step - loss: 9.9415e-08 - mse: 9.9415e-08 - val_loss: 1.1866e-06 - val_mse: 1.1866e-06\n",
      "Epoch 921/1000\n",
      "60/60 [==============================] - 0s 969us/step - loss: 5.7601e-07 - mse: 5.7601e-07 - val_loss: 9.3940e-09 - val_mse: 9.3940e-09\n",
      "Epoch 922/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9222e-07 - mse: 2.9222e-07 - val_loss: 1.9702e-05 - val_mse: 1.9702e-05\n",
      "Epoch 923/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2033e-04 - mse: 1.2033e-04 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 924/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.6809e-04 - mse: 8.6809e-04 - val_loss: 1.5168e-04 - val_mse: 1.5168e-04\n",
      "Epoch 925/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 926/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.1957 - val_mse: 0.1957\n",
      "Epoch 927/1000\n",
      "60/60 [==============================] - 0s 939us/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.4024 - val_mse: 0.4024\n",
      "Epoch 928/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 0.0912 - mse: 0.0912 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 929/1000\n",
      "60/60 [==============================] - 0s 964us/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.0065e-07 - val_mse: 1.0065e-07\n",
      "Epoch 930/1000\n",
      "60/60 [==============================] - 0s 950us/step - loss: 3.3584e-05 - mse: 3.3584e-05 - val_loss: 1.6089e-08 - val_mse: 1.6089e-08\n",
      "Epoch 931/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5740e-08 - mse: 2.5740e-08 - val_loss: 3.5070e-10 - val_mse: 3.5070e-10\n",
      "Epoch 932/1000\n",
      "60/60 [==============================] - 0s 937us/step - loss: 1.1486e-09 - mse: 1.1486e-09 - val_loss: 1.6007e-11 - val_mse: 1.6007e-11\n",
      "Epoch 933/1000\n",
      "60/60 [==============================] - 0s 921us/step - loss: 2.2231e-11 - mse: 2.2231e-11 - val_loss: 6.4028e-11 - val_mse: 6.4028e-11\n",
      "Epoch 934/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3560e-11 - mse: 1.3560e-11 - val_loss: 1.4988e-10 - val_mse: 1.4988e-10\n",
      "Epoch 935/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.7231e-12 - mse: 8.7231e-12 - val_loss: 6.9849e-11 - val_mse: 6.9849e-11\n",
      "Epoch 936/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0039e-12 - mse: 4.0039e-12 - val_loss: 2.4738e-11 - val_mse: 2.4738e-11\n",
      "Epoch 937/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1742e-12 - mse: 5.1742e-12 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
      "Epoch 938/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0262e-12 - mse: 5.0262e-12 - val_loss: 3.4197e-11 - val_mse: 3.4197e-11\n",
      "Epoch 939/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 3.4464e-12 - mse: 3.4464e-12 - val_loss: 2.0373e-11 - val_mse: 2.0373e-11\n",
      "Epoch 940/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7746e-12 - mse: 3.7746e-12 - val_loss: 2.3283e-11 - val_mse: 2.3283e-11\n",
      "Epoch 941/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5283e-12 - mse: 4.5283e-12 - val_loss: 2.3283e-11 - val_mse: 2.3283e-11\n",
      "Epoch 942/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.6612e-12 - mse: 5.6612e-12 - val_loss: 1.4479e-10 - val_mse: 1.4479e-10\n",
      "Epoch 943/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4803e-11 - mse: 5.4803e-11 - val_loss: 7.4215e-11 - val_mse: 7.4215e-11\n",
      "Epoch 944/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2956e-11 - mse: 4.2956e-11 - val_loss: 4.3656e-11 - val_mse: 4.3656e-11\n",
      "Epoch 945/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.3043e-12 - mse: 9.3043e-12 - val_loss: 7.2032e-10 - val_mse: 7.2032e-10\n",
      "Epoch 946/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5669e-10 - mse: 1.5669e-10 - val_loss: 8.5493e-10 - val_mse: 8.5493e-10\n",
      "Epoch 947/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6727e-10 - mse: 1.6727e-10 - val_loss: 1.7462e-11 - val_mse: 1.7462e-11\n",
      "Epoch 948/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0278e-11 - mse: 2.0278e-11 - val_loss: 2.8376e-11 - val_mse: 2.8376e-11\n",
      "Epoch 949/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.3190e-12 - mse: 9.3190e-12 - val_loss: 3.9290e-11 - val_mse: 3.9290e-11\n",
      "Epoch 950/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.4992e-12 - mse: 9.4992e-12 - val_loss: 6.2573e-11 - val_mse: 6.2573e-11\n",
      "Epoch 951/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3581e-11 - mse: 1.3581e-11 - val_loss: 3.9290e-11 - val_mse: 3.9290e-11\n",
      "Epoch 952/1000\n",
      "60/60 [==============================] - 0s 981us/step - loss: 1.1033e-10 - mse: 1.1033e-10 - val_loss: 1.3890e-09 - val_mse: 1.3890e-09\n",
      "Epoch 953/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.6903e-10 - mse: 4.6903e-10 - val_loss: 2.6193e-11 - val_mse: 2.6193e-11\n",
      "Epoch 954/1000\n",
      "60/60 [==============================] - 0s 989us/step - loss: 1.2231e-11 - mse: 1.2231e-11 - val_loss: 8.0472e-10 - val_mse: 8.0472e-10\n",
      "Epoch 955/1000\n",
      "60/60 [==============================] - 0s 970us/step - loss: 7.3752e-11 - mse: 7.3752e-11 - val_loss: 4.2928e-11 - val_mse: 4.2928e-11\n",
      "Epoch 956/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.6652e-12 - mse: 8.6652e-12 - val_loss: 2.8376e-11 - val_mse: 2.8376e-11\n",
      "Epoch 957/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9810e-11 - mse: 8.9810e-11 - val_loss: 1.6560e-09 - val_mse: 1.6560e-09\n",
      "Epoch 958/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3612e-09 - mse: 2.3612e-09 - val_loss: 1.2515e-09 - val_mse: 1.2515e-09\n",
      "Epoch 959/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0343e-10 - mse: 3.0343e-10 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 960/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5377e-10 - mse: 1.5377e-10 - val_loss: 1.1860e-10 - val_mse: 1.1860e-10\n",
      "Epoch 961/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3652e-11 - mse: 6.3652e-11 - val_loss: 3.6089e-10 - val_mse: 3.6089e-10\n",
      "Epoch 962/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8648e-10 - mse: 4.8648e-10 - val_loss: 7.9308e-11 - val_mse: 7.9308e-11\n",
      "Epoch 963/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1959e-11 - mse: 4.1959e-11 - val_loss: 5.0932e-11 - val_mse: 5.0932e-11\n",
      "Epoch 964/1000\n",
      "60/60 [==============================] - 0s 951us/step - loss: 2.7144e-10 - mse: 2.7144e-10 - val_loss: 1.6633e-09 - val_mse: 1.6633e-09\n",
      "Epoch 965/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1857e-10 - mse: 7.1857e-10 - val_loss: 2.3734e-09 - val_mse: 2.3734e-09\n",
      "Epoch 966/1000\n",
      "60/60 [==============================] - 0s 966us/step - loss: 1.2285e-10 - mse: 1.2285e-10 - val_loss: 4.4965e-10 - val_mse: 4.4965e-10\n",
      "Epoch 967/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.6719e-10 - mse: 4.6719e-10 - val_loss: 5.3915e-10 - val_mse: 5.3915e-10\n",
      "Epoch 968/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7028e-09 - mse: 1.7028e-09 - val_loss: 1.6225e-10 - val_mse: 1.6225e-10\n",
      "Epoch 969/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6541e-11 - mse: 2.6541e-11 - val_loss: 3.4241e-09 - val_mse: 3.4241e-09\n",
      "Epoch 970/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9221e-08 - mse: 2.9221e-08 - val_loss: 1.0169e-07 - val_mse: 1.0169e-07\n",
      "Epoch 971/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5185e-08 - mse: 2.5185e-08 - val_loss: 1.1676e-08 - val_mse: 1.1676e-08\n",
      "Epoch 972/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9189e-06 - mse: 1.9189e-06 - val_loss: 3.4340e-04 - val_mse: 3.4340e-04\n",
      "Epoch 973/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3566e-04 - mse: 1.3566e-04 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 974/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 2.2751 - val_mse: 2.2751\n",
      "Epoch 975/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6113 - mse: 1.6113 - val_loss: 0.3237 - val_mse: 0.3237\n",
      "Epoch 976/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 3.2805e-04 - val_mse: 3.2805e-04\n",
      "Epoch 977/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.4037e-05 - mse: 6.4037e-05 - val_loss: 4.5033e-06 - val_mse: 4.5033e-06\n",
      "Epoch 978/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2138e-06 - mse: 1.2138e-06 - val_loss: 8.4569e-07 - val_mse: 8.4569e-07\n",
      "Epoch 979/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6999e-07 - mse: 6.6999e-07 - val_loss: 3.5840e-07 - val_mse: 3.5840e-07\n",
      "Epoch 980/1000\n",
      "60/60 [==============================] - 0s 986us/step - loss: 3.0926e-07 - mse: 3.0926e-07 - val_loss: 2.2445e-08 - val_mse: 2.2445e-08\n",
      "Epoch 981/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1731e-07 - mse: 2.1731e-07 - val_loss: 1.4573e-07 - val_mse: 1.4573e-07\n",
      "Epoch 982/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8555e-07 - mse: 1.8555e-07 - val_loss: 3.6086e-07 - val_mse: 3.6086e-07\n",
      "Epoch 983/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3018e-08 - mse: 7.3018e-08 - val_loss: 6.6459e-09 - val_mse: 6.6459e-09\n",
      "Epoch 984/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2234e-08 - mse: 4.2234e-08 - val_loss: 1.7774e-08 - val_mse: 1.7774e-08\n",
      "Epoch 985/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5644e-08 - mse: 1.5644e-08 - val_loss: 1.1249e-07 - val_mse: 1.1249e-07\n",
      "Epoch 986/1000\n",
      "60/60 [==============================] - 0s 973us/step - loss: 9.6176e-09 - mse: 9.6176e-09 - val_loss: 4.0905e-08 - val_mse: 4.0905e-08\n",
      "Epoch 987/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 6.4929e-09 - mse: 6.4929e-09 - val_loss: 2.5993e-08 - val_mse: 2.5993e-08\n",
      "Epoch 988/1000\n",
      "60/60 [==============================] - 0s 935us/step - loss: 1.8222e-09 - mse: 1.8222e-09 - val_loss: 2.8420e-09 - val_mse: 2.8420e-09\n",
      "Epoch 989/1000\n",
      "60/60 [==============================] - 0s 968us/step - loss: 1.2305e-09 - mse: 1.2305e-09 - val_loss: 7.4579e-10 - val_mse: 7.4579e-10\n",
      "Epoch 990/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8877e-10 - mse: 2.8877e-10 - val_loss: 4.6057e-10 - val_mse: 4.6057e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 991/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 2.0554e-10 - mse: 2.0554e-10 - val_loss: 1.8626e-10 - val_mse: 1.8626e-10\n",
      "Epoch 992/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8642e-11 - mse: 7.8642e-11 - val_loss: 9.0222e-11 - val_mse: 9.0222e-11\n",
      "Epoch 993/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3699e-11 - mse: 3.3699e-11 - val_loss: 9.6770e-11 - val_mse: 9.6770e-11\n",
      "Epoch 994/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8481e-11 - mse: 1.8481e-11 - val_loss: 4.8021e-11 - val_mse: 4.8021e-11\n",
      "Epoch 995/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6586e-11 - mse: 1.6586e-11 - val_loss: 4.4383e-11 - val_mse: 4.4383e-11\n",
      "Epoch 996/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.3388e-12 - mse: 9.3388e-12 - val_loss: 4.4383e-11 - val_mse: 4.4383e-11\n",
      "Epoch 997/1000\n",
      "60/60 [==============================] - 0s 960us/step - loss: 1.0446e-11 - mse: 1.0446e-11 - val_loss: 4.4383e-11 - val_mse: 4.4383e-11\n",
      "Epoch 998/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.8790e-12 - mse: 8.8790e-12 - val_loss: 4.1473e-11 - val_mse: 4.1473e-11\n",
      "Epoch 999/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.9102e-12 - mse: 7.9102e-12 - val_loss: 3.4925e-11 - val_mse: 3.4925e-11\n",
      "Epoch 1000/1000\n",
      "60/60 [==============================] - 0s 962us/step - loss: 1.1018e-11 - mse: 1.1018e-11 - val_loss: 2.9831e-11 - val_mse: 2.9831e-11\n",
      "20/20 [==============================] - 0s 426us/step - loss: 4.9477e-11 - mse: 4.9477e-11\n",
      "mse :  [4.947651316422608e-11, 4.947651316422608e-11]\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 준비\n",
    "import numpy as np\n",
    "x = np.array(range(1, 101))\n",
    "y = np.array(range(1, 101))\n",
    "\n",
    "# 6:2:2 의 비율로 train:valid:test 로 나누어 봄\n",
    "x_train = x[:60]\n",
    "y_train = y[:60]\n",
    "\n",
    "x_val = x[60:80]\n",
    "y_val = y[60:80]\n",
    "\n",
    "x_test = x[80:]\n",
    "y_test = y[80:]\n",
    "\n",
    "x_predict = np.array(range(101, 111))\n",
    "\n",
    "# 2. 모델 구성\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(3))\n",
    "model.add(Dense(4))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 3. 훈련\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "model.fit(x=x_train, y=y_train, batch_size=1, epochs=1000, validation_data=(x_val, y_val))\n",
    "\n",
    "# 4. 평가예측\n",
    "mse = model.evaluate(x_test, y_test, batch_size=1)\n",
    "print('mse : ', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101.000015]\n",
      " [101.99999 ]\n",
      " [103.      ]\n",
      " [104.00001 ]\n",
      " [105.00001 ]\n",
      " [105.99999 ]\n",
      " [107.00001 ]\n",
      " [108.00001 ]\n",
      " [109.      ]\n",
      " [109.99999 ]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(x_predict)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, test에서 제공된 데이터가 아닌 전혀 다른 데이터로 예측시켰으나 거의 정확하게 예측됨. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split\n",
    "여태까지는 직접 수작업으로 데이터를 분할해서 사용했지만, 사이킷 런에서는 이것을 일일이 하지 않아도 되는 편리한 함수를 제공함  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=66, test_size=0.4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_split는 인잣값으로 `x` input 데이터와 `y` output 데이터를 받음  \n",
    "옵션값으로는 `test_size`, `train_size`, `random_state`, `shuffle`등의 옵션이 있음  \n",
    "* `test_size` : float 로 받으며 0.0~1.0까지 입력, 정수를 입력하면 데이터의 절대 수를 의미함.  옵션값이 지정되지 않았을 경우 train_size에 따라 결정되는데, train_size도 None 이면 0.25로 맞춰짐\n",
    "* `train_size` :  float 로 받으며 0.0~1.0까지 입력, 정수를 입력하면 데이터의 절대 수를 의미함.  옵션값이 지정되지 않았을 경우 test_size 따라 자동 결정됨.\n",
    "* `random_state` : 재현가능(for reproducibility)하도록 난수의 초기값을 설정해주는 것\n",
    "* `shuffle` : 분할하기 전에 데이터를 섞을 것인지를 의미함. 기본값은 True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 987.9536 - mse: 987.9536 - val_loss: 3893.8718 - val_mse: 3893.8718\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 0s 985us/step - loss: 930.7028 - mse: 930.7028 - val_loss: 2860.8513 - val_mse: 2860.8513\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 543.1207 - mse: 543.1207 - val_loss: 1570.0930 - val_mse: 1570.0930\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 336.1484 - mse: 336.1484 - val_loss: 553.8442 - val_mse: 553.8442\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 94.7034 - mse: 94.7034 - val_loss: 99.4323 - val_mse: 99.4323\n",
      "Epoch 6/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3702 - mse: 7.3702 - val_loss: 10.6248 - val_mse: 10.6248\n",
      "Epoch 7/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4536 - mse: 1.4536 - val_loss: 3.7217 - val_mse: 3.7217\n",
      "Epoch 8/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1139 - mse: 1.1139 - val_loss: 3.0212 - val_mse: 3.0212\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3887 - mse: 1.3887 - val_loss: 3.4178 - val_mse: 3.4178\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3766 - mse: 1.3766 - val_loss: 3.0789 - val_mse: 3.0789\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2692 - mse: 1.2692 - val_loss: 2.7471 - val_mse: 2.7471\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3209 - mse: 1.3209 - val_loss: 2.9277 - val_mse: 2.9277\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0439 - mse: 1.0439 - val_loss: 2.1413 - val_mse: 2.1413\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2031 - mse: 1.2031 - val_loss: 2.5605 - val_mse: 2.5605\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.9320 - mse: 0.9320 - val_loss: 2.7265 - val_mse: 2.7265\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.8975 - mse: 0.8975 - val_loss: 2.0918 - val_mse: 2.0918\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.7987 - mse: 0.7987 - val_loss: 1.9688 - val_mse: 1.9688\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.9508 - mse: 0.9508 - val_loss: 2.9133 - val_mse: 2.9133\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0707 - mse: 1.0707 - val_loss: 1.7414 - val_mse: 1.7414\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6656 - mse: 0.6656 - val_loss: 2.5252 - val_mse: 2.5252\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.7826 - mse: 0.7826 - val_loss: 1.7404 - val_mse: 1.7404\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.7018 - mse: 0.7018 - val_loss: 1.3193 - val_mse: 1.3193\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.7532 - mse: 0.7532 - val_loss: 1.4252 - val_mse: 1.4252\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6184 - mse: 0.6184 - val_loss: 1.1291 - val_mse: 1.1291\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6399 - mse: 0.6399 - val_loss: 1.1543 - val_mse: 1.1543\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5906 - mse: 0.5906 - val_loss: 1.4019 - val_mse: 1.4019\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4606 - mse: 0.4606 - val_loss: 0.8324 - val_mse: 0.8324\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6137 - mse: 0.6137 - val_loss: 1.1012 - val_mse: 1.1012\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3652 - mse: 0.3652 - val_loss: 0.8217 - val_mse: 0.8217\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4289 - mse: 0.4289 - val_loss: 1.2813 - val_mse: 1.2813\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4248 - mse: 0.4248 - val_loss: 0.8033 - val_mse: 0.8033\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2974 - mse: 0.2974 - val_loss: 0.9192 - val_mse: 0.9192\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4173 - mse: 0.4173 - val_loss: 0.8150 - val_mse: 0.8150\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2916 - mse: 0.2916 - val_loss: 0.7724 - val_mse: 0.7724\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2099 - mse: 0.2099 - val_loss: 0.8123 - val_mse: 0.8123\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2612 - mse: 0.2612 - val_loss: 0.6105 - val_mse: 0.6105\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2098 - mse: 0.2098 - val_loss: 0.5162 - val_mse: 0.5162\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2207 - mse: 0.2207 - val_loss: 0.2360 - val_mse: 0.2360\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1980 - mse: 0.1980 - val_loss: 0.3906 - val_mse: 0.3906\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1995 - mse: 0.1995 - val_loss: 0.3841 - val_mse: 0.3841\n",
      "Epoch 41/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1719 - mse: 0.1719 - val_loss: 0.3216 - val_mse: 0.3216\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1586 - mse: 0.1586 - val_loss: 0.1435 - val_mse: 0.1435\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1126 - mse: 0.1126 - val_loss: 0.2491 - val_mse: 0.2491\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 0s 954us/step - loss: 0.0923 - mse: 0.0923 - val_loss: 0.2178 - val_mse: 0.2178\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0980 - mse: 0.0980 - val_loss: 0.1201 - val_mse: 0.1201\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1042 - mse: 0.1042 - val_loss: 0.0820 - val_mse: 0.0820\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0630 - mse: 0.0630 - val_loss: 0.1683 - val_mse: 0.1683\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0766 - mse: 0.0766 - val_loss: 0.2254 - val_mse: 0.2254\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - 0s 989us/step - loss: 0.0541 - mse: 0.0541 - val_loss: 0.1402 - val_mse: 0.1402\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.1518 - val_mse: 0.1518\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 0s 985us/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0537 - val_mse: 0.0537\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 0s 933us/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 0s 944us/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0801 - val_mse: 0.0801\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0878 - val_mse: 0.0878\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 0s 999us/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0462 - val_mse: 0.0462\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 0s 955us/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 58/300\n",
      "60/60 [==============================] - 0s 978us/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 0s 977us/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 0s 924us/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - 0s 940us/step - loss: 9.7634e-04 - mse: 9.7634e-04 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 0s 928us/step - loss: 8.5889e-04 - mse: 8.5889e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 0s 935us/step - loss: 7.9304e-04 - mse: 7.9304e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.3033e-04 - mse: 5.3033e-04 - val_loss: 7.4041e-04 - val_mse: 7.4041e-04\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9908e-04 - mse: 3.9908e-04 - val_loss: 6.5621e-04 - val_mse: 6.5621e-04\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8840e-04 - mse: 2.8840e-04 - val_loss: 4.4355e-04 - val_mse: 4.4355e-04\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9324e-04 - mse: 1.9324e-04 - val_loss: 3.8950e-04 - val_mse: 3.8950e-04\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1640e-04 - mse: 1.1640e-04 - val_loss: 2.7358e-04 - val_mse: 2.7358e-04\n",
      "Epoch 76/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2237e-04 - mse: 1.2237e-04 - val_loss: 2.2655e-04 - val_mse: 2.2655e-04\n",
      "Epoch 77/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6937e-05 - mse: 6.6937e-05 - val_loss: 1.2328e-04 - val_mse: 1.2328e-04\n",
      "Epoch 78/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0340e-05 - mse: 4.0340e-05 - val_loss: 7.4254e-05 - val_mse: 7.4254e-05\n",
      "Epoch 79/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3315e-05 - mse: 3.3315e-05 - val_loss: 6.1171e-05 - val_mse: 6.1171e-05\n",
      "Epoch 80/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5514e-05 - mse: 2.5514e-05 - val_loss: 1.8778e-05 - val_mse: 1.8778e-05\n",
      "Epoch 81/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8195e-05 - mse: 1.8195e-05 - val_loss: 5.2207e-05 - val_mse: 5.2207e-05\n",
      "Epoch 82/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.9358e-06 - mse: 9.9358e-06 - val_loss: 2.2790e-05 - val_mse: 2.2790e-05\n",
      "Epoch 83/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6666e-06 - mse: 6.6666e-06 - val_loss: 3.4365e-06 - val_mse: 3.4365e-06\n",
      "Epoch 84/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7110e-06 - mse: 3.7110e-06 - val_loss: 3.9588e-06 - val_mse: 3.9588e-06\n",
      "Epoch 85/300\n",
      "60/60 [==============================] - 0s 925us/step - loss: 2.0754e-06 - mse: 2.0754e-06 - val_loss: 2.3823e-06 - val_mse: 2.3823e-06\n",
      "Epoch 86/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8011e-06 - mse: 1.8011e-06 - val_loss: 9.9087e-08 - val_mse: 9.9087e-08\n",
      "Epoch 87/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2443e-06 - mse: 1.2443e-06 - val_loss: 1.1517e-07 - val_mse: 1.1517e-07\n",
      "Epoch 88/300\n",
      "60/60 [==============================] - 0s 998us/step - loss: 6.2060e-07 - mse: 6.2060e-07 - val_loss: 4.1263e-07 - val_mse: 4.1263e-07\n",
      "Epoch 89/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1698e-07 - mse: 3.1698e-07 - val_loss: 5.0680e-07 - val_mse: 5.0680e-07\n",
      "Epoch 90/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9402e-07 - mse: 1.9402e-07 - val_loss: 8.8307e-07 - val_mse: 8.8307e-07\n",
      "Epoch 91/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3394e-07 - mse: 1.3394e-07 - val_loss: 2.0530e-07 - val_mse: 2.0530e-07\n",
      "Epoch 92/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.0541e-08 - mse: 6.0541e-08 - val_loss: 3.7665e-07 - val_mse: 3.7665e-07\n",
      "Epoch 93/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4802e-08 - mse: 5.4802e-08 - val_loss: 5.3324e-08 - val_mse: 5.3324e-08\n",
      "Epoch 94/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8528e-08 - mse: 1.8528e-08 - val_loss: 6.9010e-08 - val_mse: 6.9010e-08\n",
      "Epoch 95/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.3423e-09 - mse: 9.3423e-09 - val_loss: 3.2821e-08 - val_mse: 3.2821e-08\n",
      "Epoch 96/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8316e-09 - mse: 4.8316e-09 - val_loss: 1.4181e-08 - val_mse: 1.4181e-08\n",
      "Epoch 97/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0891e-09 - mse: 2.0891e-09 - val_loss: 1.5658e-09 - val_mse: 1.5658e-09\n",
      "Epoch 98/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0364e-09 - mse: 1.0364e-09 - val_loss: 1.3613e-09 - val_mse: 1.3613e-09\n",
      "Epoch 99/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.7012e-10 - mse: 4.7012e-10 - val_loss: 1.2296e-09 - val_mse: 1.2296e-09\n",
      "Epoch 100/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0900e-10 - mse: 3.0900e-10 - val_loss: 6.9122e-10 - val_mse: 6.9122e-10\n",
      "Epoch 101/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3260e-10 - mse: 1.3260e-10 - val_loss: 1.2078e-10 - val_mse: 1.2078e-10\n",
      "Epoch 102/300\n",
      "60/60 [==============================] - 0s 992us/step - loss: 5.6756e-11 - mse: 5.6756e-11 - val_loss: 4.2128e-10 - val_mse: 4.2128e-10\n",
      "Epoch 103/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3008e-11 - mse: 3.3008e-11 - val_loss: 3.0486e-10 - val_mse: 3.0486e-10\n",
      "Epoch 104/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7323e-11 - mse: 1.7323e-11 - val_loss: 2.6484e-10 - val_mse: 2.6484e-10\n",
      "Epoch 105/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1778e-11 - mse: 1.1778e-11 - val_loss: 2.2555e-10 - val_mse: 2.2555e-10\n",
      "Epoch 106/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3237e-11 - mse: 1.3237e-11 - val_loss: 1.4188e-10 - val_mse: 1.4188e-10\n",
      "Epoch 107/300\n",
      "60/60 [==============================] - 0s 983us/step - loss: 1.6661e-11 - mse: 1.6661e-11 - val_loss: 9.0949e-11 - val_mse: 9.0949e-11\n",
      "Epoch 108/300\n",
      "60/60 [==============================] - 0s 949us/step - loss: 1.8473e-11 - mse: 1.8473e-11 - val_loss: 2.6921e-11 - val_mse: 2.6921e-11\n",
      "Epoch 109/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1592e-11 - mse: 1.1592e-11 - val_loss: 7.2760e-12 - val_mse: 7.2760e-12\n",
      "Epoch 110/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.4709e-12 - mse: 9.4709e-12 - val_loss: 6.5484e-12 - val_mse: 6.5484e-12\n",
      "Epoch 111/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0208e-12 - mse: 3.0208e-12 - val_loss: 9.4587e-12 - val_mse: 9.4587e-12\n",
      "Epoch 112/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3342e-12 - mse: 2.3342e-12 - val_loss: 5.8208e-12 - val_mse: 5.8208e-12\n",
      "Epoch 113/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1251e-12 - mse: 3.1251e-12 - val_loss: 6.5484e-12 - val_mse: 6.5484e-12\n",
      "Epoch 114/300\n",
      "60/60 [==============================] - 0s 980us/step - loss: 4.4395e-12 - mse: 4.4395e-12 - val_loss: 6.5484e-12 - val_mse: 6.5484e-12\n",
      "Epoch 115/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7556e-12 - mse: 3.7556e-12 - val_loss: 6.5484e-12 - val_mse: 6.5484e-12\n",
      "Epoch 116/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9628e-12 - mse: 1.9628e-12 - val_loss: 6.5484e-12 - val_mse: 6.5484e-12\n",
      "Epoch 117/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3359e-12 - mse: 2.3359e-12 - val_loss: 6.5484e-12 - val_mse: 6.5484e-12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5154e-12 - mse: 3.5154e-12 - val_loss: 6.5484e-12 - val_mse: 6.5484e-12\n",
      "Epoch 119/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8169e-12 - mse: 3.8169e-12 - val_loss: 6.5484e-12 - val_mse: 6.5484e-12\n",
      "Epoch 120/300\n",
      "60/60 [==============================] - 0s 978us/step - loss: 2.4953e-12 - mse: 2.4953e-12 - val_loss: 6.5484e-12 - val_mse: 6.5484e-12\n",
      "Epoch 121/300\n",
      "60/60 [==============================] - 0s 944us/step - loss: 2.7370e-12 - mse: 2.7370e-12 - val_loss: 6.5484e-12 - val_mse: 6.5484e-12\n",
      "Epoch 122/300\n",
      "60/60 [==============================] - 0s 978us/step - loss: 2.8687e-12 - mse: 2.8687e-12 - val_loss: 6.5484e-12 - val_mse: 6.5484e-12\n",
      "Epoch 123/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4984e-12 - mse: 4.4984e-12 - val_loss: 7.2760e-12 - val_mse: 7.2760e-12\n",
      "Epoch 124/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2432e-12 - mse: 3.2432e-12 - val_loss: 7.2760e-12 - val_mse: 7.2760e-12\n",
      "Epoch 125/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2324e-12 - mse: 2.2324e-12 - val_loss: 5.8208e-12 - val_mse: 5.8208e-12\n",
      "Epoch 126/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4411e-12 - mse: 4.4411e-12 - val_loss: 5.8208e-12 - val_mse: 5.8208e-12\n",
      "Epoch 127/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8988e-12 - mse: 2.8988e-12 - val_loss: 5.8208e-12 - val_mse: 5.8208e-12\n",
      "Epoch 128/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7338e-12 - mse: 3.7338e-12 - val_loss: 6.5484e-12 - val_mse: 6.5484e-12\n",
      "Epoch 129/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1679e-12 - mse: 2.1679e-12 - val_loss: 6.5484e-12 - val_mse: 6.5484e-12\n",
      "Epoch 130/300\n",
      "60/60 [==============================] - 0s 990us/step - loss: 4.4929e-12 - mse: 4.4929e-12 - val_loss: 6.5484e-12 - val_mse: 6.5484e-12\n",
      "Epoch 131/300\n",
      "60/60 [==============================] - 0s 952us/step - loss: 3.9034e-12 - mse: 3.9034e-12 - val_loss: 4.3656e-12 - val_mse: 4.3656e-12\n",
      "Epoch 132/300\n",
      "60/60 [==============================] - 0s 993us/step - loss: 2.5179e-12 - mse: 2.5179e-12 - val_loss: 7.2760e-12 - val_mse: 7.2760e-12\n",
      "Epoch 133/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3266e-12 - mse: 3.3266e-12 - val_loss: 3.6380e-12 - val_mse: 3.6380e-12\n",
      "Epoch 134/300\n",
      "60/60 [==============================] - 0s 941us/step - loss: 4.4021e-12 - mse: 4.4021e-12 - val_loss: 7.2760e-12 - val_mse: 7.2760e-12\n",
      "Epoch 135/300\n",
      "60/60 [==============================] - 0s 986us/step - loss: 2.7413e-12 - mse: 2.7413e-12 - val_loss: 6.5484e-12 - val_mse: 6.5484e-12\n",
      "Epoch 136/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3982e-12 - mse: 4.3982e-12 - val_loss: 7.2760e-12 - val_mse: 7.2760e-12\n",
      "Epoch 137/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.4897e-12 - mse: 8.4897e-12 - val_loss: 2.6193e-11 - val_mse: 2.6193e-11\n",
      "Epoch 138/300\n",
      "60/60 [==============================] - 0s 921us/step - loss: 4.3438e-12 - mse: 4.3438e-12 - val_loss: 1.6007e-11 - val_mse: 1.6007e-11\n",
      "Epoch 139/300\n",
      "60/60 [==============================] - 0s 962us/step - loss: 3.3627e-12 - mse: 3.3627e-12 - val_loss: 1.3097e-11 - val_mse: 1.3097e-11\n",
      "Epoch 140/300\n",
      "60/60 [==============================] - 0s 962us/step - loss: 3.6959e-12 - mse: 3.6959e-12 - val_loss: 1.3097e-11 - val_mse: 1.3097e-11\n",
      "Epoch 141/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2500e-12 - mse: 2.2500e-12 - val_loss: 1.6007e-11 - val_mse: 1.6007e-11\n",
      "Epoch 142/300\n",
      "60/60 [==============================] - 0s 986us/step - loss: 3.8728e-12 - mse: 3.8728e-12 - val_loss: 1.2369e-11 - val_mse: 1.2369e-11\n",
      "Epoch 143/300\n",
      "60/60 [==============================] - 0s 956us/step - loss: 2.9663e-12 - mse: 2.9663e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
      "Epoch 144/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9310e-12 - mse: 1.9310e-12 - val_loss: 1.8190e-11 - val_mse: 1.8190e-11\n",
      "Epoch 145/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1908e-12 - mse: 4.1908e-12 - val_loss: 1.7462e-11 - val_mse: 1.7462e-11\n",
      "Epoch 146/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2505e-12 - mse: 2.2505e-12 - val_loss: 1.6007e-11 - val_mse: 1.6007e-11\n",
      "Epoch 147/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1179e-12 - mse: 3.1179e-12 - val_loss: 9.4587e-12 - val_mse: 9.4587e-12\n",
      "Epoch 148/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3607e-12 - mse: 2.3607e-12 - val_loss: 9.4587e-12 - val_mse: 9.4587e-12\n",
      "Epoch 149/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9082e-12 - mse: 2.9082e-12 - val_loss: 1.4552e-11 - val_mse: 1.4552e-11\n",
      "Epoch 150/300\n",
      "60/60 [==============================] - 0s 924us/step - loss: 5.7708e-12 - mse: 5.7708e-12 - val_loss: 9.7134e-10 - val_mse: 9.7134e-10\n",
      "Epoch 151/300\n",
      "60/60 [==============================] - 0s 984us/step - loss: 2.2776e-10 - mse: 2.2776e-10 - val_loss: 1.2078e-10 - val_mse: 1.2078e-10\n",
      "Epoch 152/300\n",
      "60/60 [==============================] - 0s 960us/step - loss: 4.8335e-11 - mse: 4.8335e-11 - val_loss: 1.1933e-10 - val_mse: 1.1933e-10\n",
      "Epoch 153/300\n",
      "60/60 [==============================] - 0s 955us/step - loss: 1.7342e-11 - mse: 1.7342e-11 - val_loss: 1.4770e-10 - val_mse: 1.4770e-10\n",
      "Epoch 154/300\n",
      "60/60 [==============================] - 0s 955us/step - loss: 9.6817e-12 - mse: 9.6817e-12 - val_loss: 1.5280e-11 - val_mse: 1.5280e-11\n",
      "Epoch 155/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8146e-12 - mse: 4.8146e-12 - val_loss: 7.6398e-11 - val_mse: 7.6398e-11\n",
      "Epoch 156/300\n",
      "60/60 [==============================] - 0s 997us/step - loss: 1.6878e-11 - mse: 1.6878e-11 - val_loss: 5.3842e-11 - val_mse: 5.3842e-11\n",
      "Epoch 157/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1928e-11 - mse: 5.1928e-11 - val_loss: 4.2637e-10 - val_mse: 4.2637e-10\n",
      "Epoch 158/300\n",
      "60/60 [==============================] - 0s 977us/step - loss: 5.2562e-11 - mse: 5.2562e-11 - val_loss: 1.4552e-11 - val_mse: 1.4552e-11\n",
      "Epoch 159/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3949e-11 - mse: 8.3949e-11 - val_loss: 1.3717e-08 - val_mse: 1.3717e-08\n",
      "Epoch 160/300\n",
      "60/60 [==============================] - 0s 991us/step - loss: 1.0492e-08 - mse: 1.0492e-08 - val_loss: 2.5258e-08 - val_mse: 2.5258e-08\n",
      "Epoch 161/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2888e-08 - mse: 1.2888e-08 - val_loss: 1.4967e-09 - val_mse: 1.4967e-09\n",
      "Epoch 162/300\n",
      "60/60 [==============================] - 0s 947us/step - loss: 5.1769e-07 - mse: 5.1769e-07 - val_loss: 1.7699e-06 - val_mse: 1.7699e-06\n",
      "Epoch 163/300\n",
      "60/60 [==============================] - 0s 946us/step - loss: 2.1187e-07 - mse: 2.1187e-07 - val_loss: 5.7715e-07 - val_mse: 5.7715e-07\n",
      "Epoch 164/300\n",
      "60/60 [==============================] - 0s 910us/step - loss: 1.8743e-06 - mse: 1.8743e-06 - val_loss: 1.0327e-04 - val_mse: 1.0327e-04\n",
      "Epoch 165/300\n",
      "60/60 [==============================] - 0s 951us/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 166/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 7.2217e-04 - val_mse: 7.2217e-04\n",
      "Epoch 167/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 168/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 169/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 1.4267 - val_mse: 1.4267\n",
      "Epoch 170/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0908 - mse: 0.0908 - val_loss: 0.0439 - val_mse: 0.0439\n",
      "Epoch 171/300\n",
      "60/60 [==============================] - 0s 975us/step - loss: 0.0067 - mse: 0.0067 - val_loss: 2.0839e-04 - val_mse: 2.0839e-04\n",
      "Epoch 172/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5155e-04 - mse: 3.5155e-04 - val_loss: 1.4434e-05 - val_mse: 1.4434e-05\n",
      "Epoch 173/300\n",
      "60/60 [==============================] - 0s 937us/step - loss: 1.0275e-06 - mse: 1.0275e-06 - val_loss: 1.5229e-06 - val_mse: 1.5229e-06\n",
      "Epoch 174/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9785e-07 - mse: 1.9785e-07 - val_loss: 2.1481e-07 - val_mse: 2.1481e-07\n",
      "Epoch 175/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3608e-08 - mse: 4.3608e-08 - val_loss: 3.4488e-10 - val_mse: 3.4488e-10\n",
      "Epoch 176/300\n",
      "60/60 [==============================] - 0s 955us/step - loss: 1.4318e-09 - mse: 1.4318e-09 - val_loss: 4.3656e-11 - val_mse: 4.3656e-11\n",
      "Epoch 177/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3629e-11 - mse: 1.3629e-11 - val_loss: 7.6398e-11 - val_mse: 7.6398e-11\n",
      "Epoch 178/300\n",
      "60/60 [==============================] - 0s 949us/step - loss: 6.4107e-11 - mse: 6.4107e-11 - val_loss: 3.8344e-10 - val_mse: 3.8344e-10\n",
      "Epoch 179/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6041e-11 - mse: 1.6041e-11 - val_loss: 2.1173e-10 - val_mse: 2.1173e-10\n",
      "Epoch 180/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4562e-11 - mse: 1.4562e-11 - val_loss: 4.8749e-11 - val_mse: 4.8749e-11\n",
      "Epoch 181/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.3595e-12 - mse: 9.3595e-12 - val_loss: 2.5175e-10 - val_mse: 2.5175e-10\n",
      "Epoch 182/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8394e-10 - mse: 1.8394e-10 - val_loss: 1.5476e-09 - val_mse: 1.5476e-09\n",
      "Epoch 183/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1517e-10 - mse: 5.1517e-10 - val_loss: 2.9104e-11 - val_mse: 2.9104e-11\n",
      "Epoch 184/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8053e-11 - mse: 2.8053e-11 - val_loss: 4.2928e-11 - val_mse: 4.2928e-11\n",
      "Epoch 185/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4107e-11 - mse: 3.4107e-11 - val_loss: 2.5546e-09 - val_mse: 2.5546e-09\n",
      "Epoch 186/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.0434e-10 - mse: 6.0434e-10 - val_loss: 8.0036e-11 - val_mse: 8.0036e-11\n",
      "Epoch 187/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0836e-09 - mse: 1.0836e-09 - val_loss: 1.9063e-10 - val_mse: 1.9063e-10\n",
      "Epoch 188/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5355e-11 - mse: 5.5355e-11 - val_loss: 2.1319e-10 - val_mse: 2.1319e-10\n",
      "Epoch 189/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3924e-09 - mse: 1.3924e-09 - val_loss: 6.7361e-09 - val_mse: 6.7361e-09\n",
      "Epoch 190/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5304e-09 - mse: 1.5304e-09 - val_loss: 5.4642e-09 - val_mse: 5.4642e-09\n",
      "Epoch 191/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.3899e-09 - mse: 9.3899e-09 - val_loss: 9.5026e-08 - val_mse: 9.5026e-08\n",
      "Epoch 192/300\n",
      "60/60 [==============================] - 0s 941us/step - loss: 2.9267e-08 - mse: 2.9267e-08 - val_loss: 2.5242e-08 - val_mse: 2.5242e-08\n",
      "Epoch 193/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3713e-08 - mse: 6.3713e-08 - val_loss: 1.1479e-08 - val_mse: 1.1479e-08\n",
      "Epoch 194/300\n",
      "60/60 [==============================] - 0s 931us/step - loss: 3.7377e-08 - mse: 3.7377e-08 - val_loss: 3.2451e-10 - val_mse: 3.2451e-10\n",
      "Epoch 195/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1937e-09 - mse: 1.1937e-09 - val_loss: 1.0572e-09 - val_mse: 1.0572e-09\n",
      "Epoch 196/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1096e-10 - mse: 1.1096e-10 - val_loss: 1.8314e-09 - val_mse: 1.8314e-09\n",
      "Epoch 197/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9733e-10 - mse: 1.9733e-10 - val_loss: 4.4165e-10 - val_mse: 4.4165e-10\n",
      "Epoch 198/300\n",
      "60/60 [==============================] - 0s 959us/step - loss: 6.2950e-10 - mse: 6.2950e-10 - val_loss: 1.8389e-08 - val_mse: 1.8389e-08\n",
      "Epoch 199/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2939e-09 - mse: 4.2939e-09 - val_loss: 1.9136e-10 - val_mse: 1.9136e-10\n",
      "Epoch 200/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5685e-09 - mse: 5.5685e-09 - val_loss: 9.8149e-07 - val_mse: 9.8149e-07\n",
      "Epoch 201/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5931e-05 - mse: 5.5931e-05 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 202/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.3456e-04 - val_mse: 1.3456e-04\n",
      "Epoch 203/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1344e-04 - mse: 5.1344e-04 - val_loss: 3.2599e-04 - val_mse: 3.2599e-04\n",
      "Epoch 204/300\n",
      "60/60 [==============================] - 0s 979us/step - loss: 4.3969e-04 - mse: 4.3969e-04 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 205/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0733 - val_mse: 0.0733\n",
      "Epoch 206/300\n",
      "60/60 [==============================] - 0s 940us/step - loss: 0.0607 - mse: 0.0607 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 207/300\n",
      "60/60 [==============================] - 0s 937us/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 208/300\n",
      "60/60 [==============================] - 0s 933us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 209/300\n",
      "60/60 [==============================] - 0s 928us/step - loss: 0.0018 - mse: 0.0018 - val_loss: 6.8471e-05 - val_mse: 6.8471e-05\n",
      "Epoch 210/300\n",
      "60/60 [==============================] - 0s 980us/step - loss: 2.0455e-05 - mse: 2.0455e-05 - val_loss: 1.0483e-05 - val_mse: 1.0483e-05\n",
      "Epoch 211/300\n",
      "60/60 [==============================] - 0s 959us/step - loss: 1.2323e-06 - mse: 1.2323e-06 - val_loss: 9.8602e-06 - val_mse: 9.8602e-06\n",
      "Epoch 212/300\n",
      "60/60 [==============================] - 0s 927us/step - loss: 1.4252e-06 - mse: 1.4252e-06 - val_loss: 6.0636e-08 - val_mse: 6.0636e-08\n",
      "Epoch 213/300\n",
      "60/60 [==============================] - 0s 990us/step - loss: 4.6610e-09 - mse: 4.6610e-09 - val_loss: 1.9645e-10 - val_mse: 1.9645e-10\n",
      "Epoch 214/300\n",
      "60/60 [==============================] - 0s 937us/step - loss: 9.3734e-11 - mse: 9.3734e-11 - val_loss: 7.7853e-11 - val_mse: 7.7853e-11\n",
      "Epoch 215/300\n",
      "60/60 [==============================] - 0s 937us/step - loss: 6.4870e-11 - mse: 6.4870e-11 - val_loss: 1.0841e-10 - val_mse: 1.0841e-10\n",
      "Epoch 216/300\n",
      "60/60 [==============================] - 0s 940us/step - loss: 4.9556e-11 - mse: 4.9556e-11 - val_loss: 1.4770e-10 - val_mse: 1.4770e-10\n",
      "Epoch 217/300\n",
      "60/60 [==============================] - 0s 982us/step - loss: 2.8500e-11 - mse: 2.8500e-11 - val_loss: 7.4215e-11 - val_mse: 7.4215e-11\n",
      "Epoch 218/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5300e-11 - mse: 2.5300e-11 - val_loss: 2.1391e-10 - val_mse: 2.1391e-10\n",
      "Epoch 219/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6863e-10 - mse: 1.6863e-10 - val_loss: 2.7248e-09 - val_mse: 2.7248e-09\n",
      "Epoch 220/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1897e-09 - mse: 1.1897e-09 - val_loss: 3.8373e-09 - val_mse: 3.8373e-09\n",
      "Epoch 221/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3543e-10 - mse: 7.3543e-10 - val_loss: 1.2078e-10 - val_mse: 1.2078e-10\n",
      "Epoch 222/300\n",
      "60/60 [==============================] - 0s 936us/step - loss: 6.6834e-11 - mse: 6.6834e-11 - val_loss: 5.0932e-11 - val_mse: 5.0932e-11\n",
      "Epoch 223/300\n",
      "60/60 [==============================] - 0s 945us/step - loss: 2.0110e-11 - mse: 2.0110e-11 - val_loss: 4.8021e-11 - val_mse: 4.8021e-11\n",
      "Epoch 224/300\n",
      "60/60 [==============================] - 0s 944us/step - loss: 2.8834e-11 - mse: 2.8834e-11 - val_loss: 7.4142e-10 - val_mse: 7.4142e-10\n",
      "Epoch 225/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0972e-11 - mse: 5.0972e-11 - val_loss: 2.1180e-09 - val_mse: 2.1180e-09\n",
      "Epoch 226/300\n",
      "60/60 [==============================] - 0s 949us/step - loss: 1.0865e-10 - mse: 1.0865e-10 - val_loss: 1.1459e-08 - val_mse: 1.1459e-08\n",
      "Epoch 227/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4613e-09 - mse: 1.4613e-09 - val_loss: 1.0608e-09 - val_mse: 1.0608e-09\n",
      "Epoch 228/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step - loss: 6.0605e-09 - mse: 6.0605e-09 - val_loss: 2.5798e-08 - val_mse: 2.5798e-08\n",
      "Epoch 229/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8116e-08 - mse: 3.8116e-08 - val_loss: 1.2602e-09 - val_mse: 1.2602e-09\n",
      "Epoch 230/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8023e-07 - mse: 3.8023e-07 - val_loss: 3.7501e-05 - val_mse: 3.7501e-05\n",
      "Epoch 231/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0050e-04 - mse: 2.0050e-04 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 232/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 233/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3196 - mse: 0.3196 - val_loss: 0.3352 - val_mse: 0.3352\n",
      "Epoch 234/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 2.6019e-06 - val_mse: 2.6019e-06\n",
      "Epoch 235/300\n",
      "60/60 [==============================] - 0s 977us/step - loss: 7.3535e-05 - mse: 7.3535e-05 - val_loss: 2.2924e-04 - val_mse: 2.2924e-04\n",
      "Epoch 236/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3503e-05 - mse: 4.3503e-05 - val_loss: 1.4025e-04 - val_mse: 1.4025e-04\n",
      "Epoch 237/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.0790e-06 - mse: 8.0790e-06 - val_loss: 3.9458e-07 - val_mse: 3.9458e-07\n",
      "Epoch 238/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6412e-08 - mse: 3.6412e-08 - val_loss: 1.3239e-07 - val_mse: 1.3239e-07\n",
      "Epoch 239/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7403e-08 - mse: 1.7403e-08 - val_loss: 3.5507e-10 - val_mse: 3.5507e-10\n",
      "Epoch 240/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.6823e-11 - mse: 5.6823e-11 - val_loss: 3.7835e-11 - val_mse: 3.7835e-11\n",
      "Epoch 241/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0003e-11 - mse: 1.0003e-11 - val_loss: 3.0559e-11 - val_mse: 3.0559e-11\n",
      "Epoch 242/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.1095e-12 - mse: 9.1095e-12 - val_loss: 5.3114e-11 - val_mse: 5.3114e-11\n",
      "Epoch 243/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.4421e-12 - mse: 7.4421e-12 - val_loss: 4.1473e-11 - val_mse: 4.1473e-11\n",
      "Epoch 244/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.2021e-12 - mse: 5.2021e-12 - val_loss: 4.8021e-11 - val_mse: 4.8021e-11\n",
      "Epoch 245/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4767e-12 - mse: 3.4767e-12 - val_loss: 5.6752e-11 - val_mse: 5.6752e-11\n",
      "Epoch 246/300\n",
      "60/60 [==============================] - 0s 937us/step - loss: 6.5239e-12 - mse: 6.5239e-12 - val_loss: 5.0204e-11 - val_mse: 5.0204e-11\n",
      "Epoch 247/300\n",
      "60/60 [==============================] - 0s 953us/step - loss: 5.3408e-12 - mse: 5.3408e-12 - val_loss: 4.8021e-11 - val_mse: 4.8021e-11\n",
      "Epoch 248/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.1521e-12 - mse: 9.1521e-12 - val_loss: 3.2742e-11 - val_mse: 3.2742e-11\n",
      "Epoch 249/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4752e-11 - mse: 1.4752e-11 - val_loss: 7.5670e-11 - val_mse: 7.5670e-11\n",
      "Epoch 250/300\n",
      "60/60 [==============================] - 0s 975us/step - loss: 1.7668e-11 - mse: 1.7668e-11 - val_loss: 1.2005e-10 - val_mse: 1.2005e-10\n",
      "Epoch 251/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5101e-10 - mse: 1.5101e-10 - val_loss: 9.4587e-11 - val_mse: 9.4587e-11\n",
      "Epoch 252/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0775e-11 - mse: 4.0775e-11 - val_loss: 5.7989e-10 - val_mse: 5.7989e-10\n",
      "Epoch 253/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1354e-11 - mse: 3.1354e-11 - val_loss: 1.9281e-10 - val_mse: 1.9281e-10\n",
      "Epoch 254/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0778e-09 - mse: 1.0778e-09 - val_loss: 3.7704e-09 - val_mse: 3.7704e-09\n",
      "Epoch 255/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4283e-10 - mse: 4.4283e-10 - val_loss: 2.8376e-09 - val_mse: 2.8376e-09\n",
      "Epoch 256/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.2383e-10 - mse: 6.2383e-10 - val_loss: 5.2532e-10 - val_mse: 5.2532e-10\n",
      "Epoch 257/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.3146e-11 - mse: 5.3146e-11 - val_loss: 2.8376e-11 - val_mse: 2.8376e-11\n",
      "Epoch 258/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2654e-11 - mse: 1.2654e-11 - val_loss: 8.0036e-11 - val_mse: 8.0036e-11\n",
      "Epoch 259/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3789e-11 - mse: 8.3789e-11 - val_loss: 5.9663e-11 - val_mse: 5.9663e-11\n",
      "Epoch 260/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3258e-11 - mse: 1.3258e-11 - val_loss: 6.4028e-11 - val_mse: 6.4028e-11\n",
      "Epoch 261/300\n",
      "60/60 [==============================] - 0s 964us/step - loss: 1.4847e-11 - mse: 1.4847e-11 - val_loss: 6.4028e-11 - val_mse: 6.4028e-11\n",
      "Epoch 262/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3493e-11 - mse: 8.3493e-11 - val_loss: 7.5146e-09 - val_mse: 7.5146e-09\n",
      "Epoch 263/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9030e-10 - mse: 3.9030e-10 - val_loss: 1.2357e-08 - val_mse: 1.2357e-08\n",
      "Epoch 264/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.0071e-09 - mse: 7.0071e-09 - val_loss: 1.1828e-08 - val_mse: 1.1828e-08\n",
      "Epoch 265/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.6878e-09 - mse: 7.6878e-09 - val_loss: 1.8248e-09 - val_mse: 1.8248e-09\n",
      "Epoch 266/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9653e-09 - mse: 1.9653e-09 - val_loss: 7.9277e-07 - val_mse: 7.9277e-07\n",
      "Epoch 267/300\n",
      "60/60 [==============================] - 0s 998us/step - loss: 9.3802e-08 - mse: 9.3802e-08 - val_loss: 4.5547e-08 - val_mse: 4.5547e-08\n",
      "Epoch 268/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.0654e-09 - mse: 6.0654e-09 - val_loss: 9.9688e-09 - val_mse: 9.9688e-09\n",
      "Epoch 269/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3650e-09 - mse: 2.3650e-09 - val_loss: 3.3090e-07 - val_mse: 3.3090e-07\n",
      "Epoch 270/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1670e-08 - mse: 3.1670e-08 - val_loss: 2.6203e-07 - val_mse: 2.6203e-07\n",
      "Epoch 271/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2107e-08 - mse: 1.2107e-08 - val_loss: 1.3139e-08 - val_mse: 1.3139e-08\n",
      "Epoch 272/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5544e-08 - mse: 4.5544e-08 - val_loss: 2.7663e-08 - val_mse: 2.7663e-08\n",
      "Epoch 273/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5140e-09 - mse: 3.5140e-09 - val_loss: 7.8726e-10 - val_mse: 7.8726e-10\n",
      "Epoch 274/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8725e-10 - mse: 1.8725e-10 - val_loss: 8.0981e-10 - val_mse: 8.0981e-10\n",
      "Epoch 275/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1033e-10 - mse: 1.1033e-10 - val_loss: 2.3283e-10 - val_mse: 2.3283e-10\n",
      "Epoch 276/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3042e-10 - mse: 3.3042e-10 - val_loss: 1.2376e-09 - val_mse: 1.2376e-09\n",
      "Epoch 277/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4140e-09 - mse: 1.4140e-09 - val_loss: 2.6281e-09 - val_mse: 2.6281e-09\n",
      "Epoch 278/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.0606e-09 - mse: 7.0606e-09 - val_loss: 2.1749e-08 - val_mse: 2.1749e-08\n",
      "Epoch 279/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3504e-08 - mse: 2.3504e-08 - val_loss: 2.3098e-06 - val_mse: 2.3098e-06\n",
      "Epoch 280/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.2357e-06 - mse: 6.2357e-06 - val_loss: 9.5207e-04 - val_mse: 9.5207e-04\n",
      "Epoch 281/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.2986e-04 - mse: 5.2986e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 282/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.5459 - val_mse: 0.5459\n",
      "Epoch 283/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0629 - mse: 0.0629 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 284/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 285/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1328e-04 - mse: 5.1328e-04 - val_loss: 1.9973e-04 - val_mse: 1.9973e-04\n",
      "Epoch 286/300\n",
      "60/60 [==============================] - 0s 998us/step - loss: 1.7228e-05 - mse: 1.7228e-05 - val_loss: 1.9760e-05 - val_mse: 1.9760e-05\n",
      "Epoch 287/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1099e-06 - mse: 3.1099e-06 - val_loss: 4.1902e-07 - val_mse: 4.1902e-07\n",
      "Epoch 288/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6237e-08 - mse: 1.6237e-08 - val_loss: 4.8487e-09 - val_mse: 4.8487e-09\n",
      "Epoch 289/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3954e-09 - mse: 3.3954e-09 - val_loss: 2.5450e-08 - val_mse: 2.5450e-08\n",
      "Epoch 290/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4017e-09 - mse: 1.4017e-09 - val_loss: 9.3860e-11 - val_mse: 9.3860e-11\n",
      "Epoch 291/300\n",
      "60/60 [==============================] - 0s 976us/step - loss: 1.3169e-10 - mse: 1.3169e-10 - val_loss: 1.0435e-08 - val_mse: 1.0435e-08\n",
      "Epoch 292/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.9779e-09 - mse: 4.9779e-09 - val_loss: 2.3756e-09 - val_mse: 2.3756e-09\n",
      "Epoch 293/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6775e-08 - mse: 2.6775e-08 - val_loss: 7.7125e-11 - val_mse: 7.7125e-11\n",
      "Epoch 294/300\n",
      "60/60 [==============================] - 0s 961us/step - loss: 4.2635e-09 - mse: 4.2635e-09 - val_loss: 1.2363e-07 - val_mse: 1.2363e-07\n",
      "Epoch 295/300\n",
      "60/60 [==============================] - 0s 974us/step - loss: 1.0423e-08 - mse: 1.0423e-08 - val_loss: 5.1296e-10 - val_mse: 5.1296e-10\n",
      "Epoch 296/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4186e-09 - mse: 1.4186e-09 - val_loss: 1.4456e-07 - val_mse: 1.4456e-07\n",
      "Epoch 297/300\n",
      "60/60 [==============================] - 0s 950us/step - loss: 6.5779e-09 - mse: 6.5779e-09 - val_loss: 6.5280e-08 - val_mse: 6.5280e-08\n",
      "Epoch 298/300\n",
      "60/60 [==============================] - 0s 987us/step - loss: 1.5052e-06 - mse: 1.5052e-06 - val_loss: 1.7652e-04 - val_mse: 1.7652e-04\n",
      "Epoch 299/300\n",
      "60/60 [==============================] - 0s 981us/step - loss: 2.9420e-05 - mse: 2.9420e-05 - val_loss: 5.1777e-06 - val_mse: 5.1777e-06\n",
      "Epoch 300/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1146e-05 - mse: 1.1146e-05 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "20/20 [==============================] - 0s 535us/step - loss: 0.0027 - mse: 0.0027\n",
      "mse : [0.0026885417755693197, 0.0026885417755693197]\n",
      "WARNING:tensorflow:8 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff9d8f653a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[ 81.04637 ]\n",
      " [ 82.046936]\n",
      " [ 83.0475  ]\n",
      " [ 84.04807 ]\n",
      " [ 85.04864 ]\n",
      " [ 86.0492  ]\n",
      " [ 87.04977 ]\n",
      " [ 88.05034 ]\n",
      " [ 89.0509  ]\n",
      " [ 90.05146 ]\n",
      " [ 91.052025]\n",
      " [ 92.052605]\n",
      " [ 93.05317 ]\n",
      " [ 94.053734]\n",
      " [ 95.05429 ]\n",
      " [ 96.05486 ]\n",
      " [ 97.05543 ]\n",
      " [ 98.05599 ]\n",
      " [ 99.05656 ]\n",
      " [100.05713 ]]\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 준비 \n",
    "import numpy as np\n",
    "x = np.array(range(1, 101))\n",
    "y = np.array(range(1, 101))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=66, shuffle=False)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=66, shuffle=False)\n",
    "\n",
    "# 2. 모델 구성\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(4))\n",
    "model.add(Dense(3))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 훈련\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=300, validation_data=(x_val, y_val))\n",
    "\n",
    "# 4. 평가 예측\n",
    "mse = model.evaluate(x_test, y_test, batch_size=1)\n",
    "print('mse :', mse)\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  0.0518518603601866\n",
      "r2_score :  0.99991913938578\n"
     ]
    }
   ],
   "source": [
    "# RMSE \n",
    "from sklearn.metrics import mean_squared_error\n",
    "def RMSE(y_test, y_predict):\n",
    "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "print('RMSE : ', RMSE(y_test, y_predict))\n",
    "\n",
    "# r2\n",
    "from sklearn.metrics import r2_score\n",
    "print('r2_score : ', r2_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수형 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1:1\n",
    "지금까지 모델을 만들때 model=Sequential()을 이용하여 순차적 모델만을 만들어왔음.  \n",
    "케라스에는 모델을 만드는 2가지 방법이 있음. 기존에 사용했던 Sequential을 사용하여 순차적으로 쌓는 방법과, 함수형으로 모델을 만드는 방법이 있음.   \n",
    "순차적 모델은 비교적 간결하게 짤 수 있다는 장점이 있지만,  \n",
    "모델이 길어지고, 앙상블 등의 여러가지 기법을 사용하고자 할때는 함수형 모델이 필수적으로 사용됨.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞의 예제를 사용, 모델을 구성하는 부분만 Sequential -> functional 로 변환함  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 준비\n",
    "import numpy as np \n",
    "\n",
    "x = np.array(range(1, 101))\n",
    "y = np.array(range(1, 101))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=66, shuffle=False)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.4, random_state=66, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models 에서 `Model` 을 불러오고, layers 에서 `Input`을 불러와줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 5)                 10        \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2. 모델 구성\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "input1 = Input(shape=(1, ))\n",
    "dense1 = Dense(5, activation='relu')(input1)\n",
    "dense2 = Dense(3)(dense1)\n",
    "dense3 = Dense(4)(dense2)\n",
    "output1 = Dense(1)(dense3)\n",
    "\n",
    "model = Model(inputs=input1, outputs=output1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수형 모델을 통해 49개의 파라미터를 가지는 간단한 심층신경망을 구성함\n",
    "* input layer를 구성하여 `Input` 값의 shape을 지정해줌.\n",
    "* 상위층에서 출력된 레이어의 이름을 그 다음층의 끝부분에 곱해(?), 연결해줌\n",
    "* 마지막으로 `Model` 을 통해 input layer, output layer의 이름을 전달해주면 model이 완성됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 3447.9283 - mse: 3447.9283 - val_loss: 12280.9502 - val_mse: 12280.9502\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2787.2641 - mse: 2787.2641 - val_loss: 9037.2822 - val_mse: 9037.2822\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2310.3088 - mse: 2310.3088 - val_loss: 7090.2129 - val_mse: 7090.2129\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1643.8774 - mse: 1643.8774 - val_loss: 5478.5527 - val_mse: 5478.5527\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1172.7804 - mse: 1172.7804 - val_loss: 4129.3599 - val_mse: 4129.3599\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 813.9492 - mse: 813.9492 - val_loss: 2780.2346 - val_mse: 2780.2346\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 590.7151 - mse: 590.7151 - val_loss: 1573.7533 - val_mse: 1573.7533\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 269.2514 - mse: 269.2514 - val_loss: 706.6329 - val_mse: 706.6329\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 110.4139 - mse: 110.4139 - val_loss: 198.8624 - val_mse: 198.8624\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 35.5219 - mse: 35.5219 - val_loss: 42.7905 - val_mse: 42.7905\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.5819 - mse: 7.5819 - val_loss: 8.6172 - val_mse: 8.6172\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.9403 - mse: 0.9403 - val_loss: 2.5561 - val_mse: 2.5561\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4312 - mse: 0.4312 - val_loss: 1.4259 - val_mse: 1.4259\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3555 - mse: 0.3555 - val_loss: 1.2503 - val_mse: 1.2503\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3199 - mse: 0.3199 - val_loss: 1.1443 - val_mse: 1.1443\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5537 - mse: 0.5537 - val_loss: 1.0893 - val_mse: 1.0893\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5259 - mse: 0.5259 - val_loss: 1.0966 - val_mse: 1.0966\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2912 - mse: 0.2912 - val_loss: 1.0031 - val_mse: 1.0031\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4730 - mse: 0.4730 - val_loss: 1.0167 - val_mse: 1.0167\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3442 - mse: 0.3442 - val_loss: 0.9912 - val_mse: 0.9912\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3685 - mse: 0.3685 - val_loss: 1.0201 - val_mse: 1.0201\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3674 - mse: 0.3674 - val_loss: 0.9379 - val_mse: 0.9379\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3989 - mse: 0.3989 - val_loss: 0.9475 - val_mse: 0.9475\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3897 - mse: 0.3897 - val_loss: 0.9591 - val_mse: 0.9591\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3258 - mse: 0.3258 - val_loss: 0.9148 - val_mse: 0.9148\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2868 - mse: 0.2868 - val_loss: 0.9023 - val_mse: 0.9023\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3675 - mse: 0.3675 - val_loss: 0.9335 - val_mse: 0.9335\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3388 - mse: 0.3388 - val_loss: 0.8351 - val_mse: 0.8351\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2868 - mse: 0.2868 - val_loss: 0.9148 - val_mse: 0.9148\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2542 - mse: 0.2542 - val_loss: 0.8303 - val_mse: 0.8303\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2956 - mse: 0.2956 - val_loss: 0.9203 - val_mse: 0.9203\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3666 - mse: 0.3666 - val_loss: 0.8397 - val_mse: 0.8397\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3247 - mse: 0.3247 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2695 - mse: 0.2695 - val_loss: 0.9451 - val_mse: 0.9451\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3062 - mse: 0.3062 - val_loss: 0.6835 - val_mse: 0.6835\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3230 - mse: 0.3230 - val_loss: 0.7449 - val_mse: 0.7449\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2444 - mse: 0.2444 - val_loss: 0.8356 - val_mse: 0.8356\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2510 - mse: 0.2510 - val_loss: 0.7656 - val_mse: 0.7656\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2647 - mse: 0.2647 - val_loss: 0.7292 - val_mse: 0.7292\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2565 - mse: 0.2565 - val_loss: 0.8957 - val_mse: 0.8957\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2329 - mse: 0.2329 - val_loss: 0.6819 - val_mse: 0.6819\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2355 - mse: 0.2355 - val_loss: 0.7711 - val_mse: 0.7711\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2805 - mse: 0.2805 - val_loss: 0.6540 - val_mse: 0.6540\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2272 - mse: 0.2272 - val_loss: 0.5671 - val_mse: 0.5671\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2447 - mse: 0.2447 - val_loss: 0.5682 - val_mse: 0.5682\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2496 - mse: 0.2496 - val_loss: 0.8495 - val_mse: 0.8495\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2302 - mse: 0.2302 - val_loss: 0.5324 - val_mse: 0.5324\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2184 - mse: 0.2184 - val_loss: 0.5171 - val_mse: 0.5171\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2040 - mse: 0.2040 - val_loss: 0.4819 - val_mse: 0.4819\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1842 - mse: 0.1842 - val_loss: 0.4135 - val_mse: 0.4135\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2095 - mse: 0.2095 - val_loss: 0.6877 - val_mse: 0.6877\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1999 - mse: 0.1999 - val_loss: 0.6706 - val_mse: 0.6706\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1795 - mse: 0.1795 - val_loss: 0.5924 - val_mse: 0.5924\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2031 - mse: 0.2031 - val_loss: 0.4925 - val_mse: 0.4925\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1941 - mse: 0.1941 - val_loss: 0.4399 - val_mse: 0.4399\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1644 - mse: 0.1644 - val_loss: 0.4434 - val_mse: 0.4434\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2136 - mse: 0.2136 - val_loss: 0.3481 - val_mse: 0.3481\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1196 - mse: 0.1196 - val_loss: 0.3387 - val_mse: 0.3387\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1088 - mse: 0.1088 - val_loss: 0.3296 - val_mse: 0.3296\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1525 - mse: 0.1525 - val_loss: 0.3664 - val_mse: 0.3664\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1050 - mse: 0.1050 - val_loss: 0.3177 - val_mse: 0.3177\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1312 - mse: 0.1312 - val_loss: 0.2711 - val_mse: 0.2711\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0848 - mse: 0.0848 - val_loss: 0.3024 - val_mse: 0.3024\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0940 - mse: 0.0940 - val_loss: 0.2572 - val_mse: 0.2572\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1029 - mse: 0.1029 - val_loss: 0.1995 - val_mse: 0.1995\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1058 - mse: 0.1058 - val_loss: 0.1499 - val_mse: 0.1499\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0886 - mse: 0.0886 - val_loss: 0.1205 - val_mse: 0.1205\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0862 - mse: 0.0862 - val_loss: 0.1274 - val_mse: 0.1274\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0626 - mse: 0.0626 - val_loss: 0.0895 - val_mse: 0.0895\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0770 - mse: 0.0770 - val_loss: 0.1589 - val_mse: 0.1589\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0663 - mse: 0.0663 - val_loss: 0.1701 - val_mse: 0.1701\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0726 - mse: 0.0726 - val_loss: 0.2517 - val_mse: 0.2517\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0754 - val_mse: 0.0754\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0657 - mse: 0.0657 - val_loss: 0.1506 - val_mse: 0.1506\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0535 - mse: 0.0535 - val_loss: 0.0935 - val_mse: 0.0935\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0375 - mse: 0.0375 - val_loss: 0.1543 - val_mse: 0.1543\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.1856 - val_mse: 0.1856\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0467 - val_mse: 0.0467\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0561 - val_mse: 0.0561\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.1268 - val_mse: 0.1268\n",
      "Epoch 81/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0621 - val_mse: 0.0621\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.1124 - val_mse: 0.1124\n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0437 - val_mse: 0.0437\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0665 - val_mse: 0.0665\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0512 - val_mse: 0.0512\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "16/16 [==============================] - 0s 487us/step - loss: 0.0068 - mse: 0.0068\n",
      "mse : [0.006773693487048149, 0.006773693487048149]\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff9d91aed30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[84.93273 ]\n",
      " [85.930786]\n",
      " [86.928856]\n",
      " [87.9269  ]\n",
      " [88.924965]\n",
      " [89.92303 ]\n",
      " [90.9211  ]\n",
      " [91.91915 ]\n",
      " [92.91721 ]\n",
      " [93.915276]\n",
      " [94.91334 ]\n",
      " [95.91139 ]\n",
      " [96.90946 ]\n",
      " [97.907524]\n",
      " [98.90559 ]\n",
      " [99.90365 ]]\n"
     ]
    }
   ],
   "source": [
    "# 3. 훈련\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=100, validation_data=(x_val, y_val))\n",
    "\n",
    "# 4. 평가 예측\n",
    "mse = model.evaluate(x_test, y_test, batch_size=1)\n",
    "print('mse :', mse)\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  0.08230190734577011\n",
      "r2_score :  0.9996812421669293\n"
     ]
    }
   ],
   "source": [
    "# RMSE \n",
    "from sklearn.metrics import mean_squared_error\n",
    "def RMSE(y_test, y_predict):\n",
    "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "print('RMSE : ', RMSE(y_test, y_predict))\n",
    "\n",
    "# r2\n",
    "from sklearn.metrics import r2_score\n",
    "print('r2_score : ', r2_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다:다\n",
    "지금까지는 입력되는 컬럼의 수가 1개 였음.  input_dim=1, input_shape=(1,)  \n",
    "지금부터는 입력되는 데이터의 컬럼이 2이상인 경우에 대한 코드  \n",
    "모델에 입력하기 위해서는 행과 열의 shape 이 일치해야함.  \n",
    "DNN 구조에서는 차원이 가장 중요하며, 열이 우선시 됨.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100) (2, 100)\n"
     ]
    }
   ],
   "source": [
    "# 1.데이터 준비\n",
    "import numpy as np \n",
    "\n",
    "x = np.array([range(100), range(301, 401)])\n",
    "y = np.array([range(100), range(301, 401)])\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2행 100열의 데이터가 만들어짐  \n",
    "100행 2열의 데이터를 만들고 싶을때는 행과 열의 데이터를 바꿔주면됨.  \n",
    "넘파이에서 행과 열을 바꾸는 함수는 transpose()임  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "x = np.transpose(x)\n",
    "y = np.transpose(y)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_dim=2 로 가능하게 데이터의 구조를 변경하고 최종아웃풋을 1에서 2로 변경함.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 30716.9445 - mse: 30716.9445 - val_loss: 14542.0996 - val_mse: 14542.0996\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9828.2811 - mse: 9828.2811 - val_loss: 635.3197 - val_mse: 635.3197\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 789.9469 - mse: 789.9469 - val_loss: 519.5998 - val_mse: 519.5998\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 110.6744 - mse: 110.6744 - val_loss: 573.3846 - val_mse: 573.3846\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 108.0288 - mse: 108.0288 - val_loss: 545.8978 - val_mse: 545.8978\n",
      "Epoch 6/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 103.2959 - mse: 103.2959 - val_loss: 472.5314 - val_mse: 472.5314\n",
      "Epoch 7/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 125.7740 - mse: 125.7740 - val_loss: 401.5300 - val_mse: 401.5300\n",
      "Epoch 8/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 106.8856 - mse: 106.8856 - val_loss: 567.6253 - val_mse: 567.6253\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 93.6918 - mse: 93.6918 - val_loss: 372.8791 - val_mse: 372.8791\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 121.3467 - mse: 121.3467 - val_loss: 456.0458 - val_mse: 456.0458\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 104.6563 - mse: 104.6563 - val_loss: 538.2935 - val_mse: 538.2935\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 96.0016 - mse: 96.0016 - val_loss: 453.5733 - val_mse: 453.5733\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 106.7751 - mse: 106.7751 - val_loss: 446.4863 - val_mse: 446.4863\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 108.7076 - mse: 108.7076 - val_loss: 501.9046 - val_mse: 501.9046\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 105.5162 - mse: 105.5162 - val_loss: 590.6913 - val_mse: 590.6913\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 74.8113 - mse: 74.8113 - val_loss: 548.2728 - val_mse: 548.2728\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 90.2893 - mse: 90.2893 - val_loss: 509.1817 - val_mse: 509.1817\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 80.0458 - mse: 80.0458 - val_loss: 528.3671 - val_mse: 528.3671\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 95.4320 - mse: 95.4320 - val_loss: 397.2004 - val_mse: 397.2004\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 92.4461 - mse: 92.4461 - val_loss: 513.6349 - val_mse: 513.6349\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 85.4997 - mse: 85.4997 - val_loss: 393.6307 - val_mse: 393.6307\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 73.9273 - mse: 73.9273 - val_loss: 373.6372 - val_mse: 373.6372\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 86.0472 - mse: 86.0472 - val_loss: 337.2590 - val_mse: 337.2590\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 70.3558 - mse: 70.3558 - val_loss: 460.5292 - val_mse: 460.5292\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 91.4500 - mse: 91.4500 - val_loss: 349.5587 - val_mse: 349.5587\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 52.2130 - mse: 52.2130 - val_loss: 545.7577 - val_mse: 545.7577\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 61.5752 - mse: 61.5752 - val_loss: 415.2539 - val_mse: 415.2539\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 69.5608 - mse: 69.5608 - val_loss: 335.7421 - val_mse: 335.7421\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 76.8433 - mse: 76.8433 - val_loss: 301.7353 - val_mse: 301.7353\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 56.4208 - mse: 56.4208 - val_loss: 224.2630 - val_mse: 224.2630\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 64.6287 - mse: 64.6287 - val_loss: 170.5645 - val_mse: 170.5645\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 43.6167 - mse: 43.6167 - val_loss: 281.1721 - val_mse: 281.1721\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 50.6821 - mse: 50.6821 - val_loss: 260.0221 - val_mse: 260.0221\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 36.4205 - mse: 36.4205 - val_loss: 208.2157 - val_mse: 208.2157\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 44.3375 - mse: 44.3375 - val_loss: 170.5277 - val_mse: 170.5277\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 36.0089 - mse: 36.0089 - val_loss: 207.5394 - val_mse: 207.5394\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 47.2789 - mse: 47.2789 - val_loss: 249.4998 - val_mse: 249.4998\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 40.4456 - mse: 40.4456 - val_loss: 172.2065 - val_mse: 172.2065\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 36.0832 - mse: 36.0832 - val_loss: 189.2396 - val_mse: 189.2396\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 36.8202 - mse: 36.8202 - val_loss: 139.8807 - val_mse: 139.8807\n",
      "Epoch 41/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 32.0069 - mse: 32.0069 - val_loss: 146.9124 - val_mse: 146.9124\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 24.8774 - mse: 24.8774 - val_loss: 140.2771 - val_mse: 140.2771\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 19.1224 - mse: 19.1224 - val_loss: 75.2915 - val_mse: 75.2915\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 26.9813 - mse: 26.9813 - val_loss: 67.6715 - val_mse: 67.6715\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 19.5515 - mse: 19.5515 - val_loss: 93.8004 - val_mse: 93.8004\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 15.2168 - mse: 15.2168 - val_loss: 54.5474 - val_mse: 54.5474\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 15.1926 - mse: 15.1926 - val_loss: 80.4022 - val_mse: 80.4022\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 13.5193 - mse: 13.5193 - val_loss: 96.8491 - val_mse: 96.8491\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 14.8115 - mse: 14.8115 - val_loss: 64.2408 - val_mse: 64.2408\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 10.6009 - mse: 10.6009 - val_loss: 40.6683 - val_mse: 40.6683\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 10.6979 - mse: 10.6979 - val_loss: 41.4950 - val_mse: 41.4950\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.1986 - mse: 8.1986 - val_loss: 36.6754 - val_mse: 36.6754\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3620 - mse: 6.3620 - val_loss: 51.8693 - val_mse: 51.8693\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3275 - mse: 8.3275 - val_loss: 23.0954 - val_mse: 23.0954\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4942 - mse: 5.4942 - val_loss: 21.1622 - val_mse: 21.1622\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5123 - mse: 4.5123 - val_loss: 14.8584 - val_mse: 14.8584\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5746 - mse: 3.5746 - val_loss: 16.2873 - val_mse: 16.2873\n",
      "Epoch 58/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6727 - mse: 2.6727 - val_loss: 12.7424 - val_mse: 12.7424\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7121 - mse: 2.7121 - val_loss: 13.3398 - val_mse: 13.3398\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8301 - mse: 1.8301 - val_loss: 3.1509 - val_mse: 3.1509\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6530 - mse: 1.6530 - val_loss: 6.3161 - val_mse: 6.3161\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.9253 - mse: 0.9253 - val_loss: 5.1703 - val_mse: 5.1703\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.9643 - mse: 0.9643 - val_loss: 3.8346 - val_mse: 3.8346\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.8703 - mse: 0.8703 - val_loss: 2.0566 - val_mse: 2.0566\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6212 - mse: 0.6212 - val_loss: 2.9740 - val_mse: 2.9740\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4335 - mse: 0.4335 - val_loss: 2.3015 - val_mse: 2.3015\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5077 - mse: 0.5077 - val_loss: 1.3037 - val_mse: 1.3037\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2439 - mse: 0.2439 - val_loss: 1.2474 - val_mse: 1.2474\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1685 - mse: 0.1685 - val_loss: 1.0045 - val_mse: 1.0045\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1306 - mse: 0.1306 - val_loss: 0.4651 - val_mse: 0.4651\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0831 - mse: 0.0831 - val_loss: 0.4298 - val_mse: 0.4298\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0710 - mse: 0.0710 - val_loss: 0.1593 - val_mse: 0.1593\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.1111 - val_mse: 0.1111\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0362 - val_mse: 0.0362\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 76/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0517 - val_mse: 0.0517\n",
      "Epoch 77/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 78/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 79/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 80/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 81/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 82/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 83/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6502e-04 - mse: 6.6502e-04 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 84/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8489e-04 - mse: 3.8489e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 85/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3668e-04 - mse: 2.3668e-04 - val_loss: 3.2502e-04 - val_mse: 3.2502e-04\n",
      "Epoch 86/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7560e-04 - mse: 1.7560e-04 - val_loss: 1.9870e-04 - val_mse: 1.9870e-04\n",
      "Epoch 87/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9879e-05 - mse: 6.9879e-05 - val_loss: 4.4017e-04 - val_mse: 4.4017e-04\n",
      "Epoch 88/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5195e-05 - mse: 3.5195e-05 - val_loss: 7.0562e-05 - val_mse: 7.0562e-05\n",
      "Epoch 89/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3177e-05 - mse: 2.3177e-05 - val_loss: 4.9592e-06 - val_mse: 4.9592e-06\n",
      "Epoch 90/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3949e-05 - mse: 2.3949e-05 - val_loss: 3.1224e-06 - val_mse: 3.1224e-06\n",
      "Epoch 91/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3120e-05 - mse: 1.3120e-05 - val_loss: 1.4394e-05 - val_mse: 1.4394e-05\n",
      "Epoch 92/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5442e-06 - mse: 3.5442e-06 - val_loss: 1.8211e-07 - val_mse: 1.8211e-07\n",
      "Epoch 93/300\n",
      "60/60 [==============================] - 0s 919us/step - loss: 6.1193e-06 - mse: 6.1193e-06 - val_loss: 7.2731e-06 - val_mse: 7.2731e-06\n",
      "Epoch 94/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.6515e-07 - mse: 7.6515e-07 - val_loss: 1.9847e-06 - val_mse: 1.9847e-06\n",
      "Epoch 95/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.6184e-07 - mse: 4.6184e-07 - val_loss: 1.1361e-06 - val_mse: 1.1361e-06\n",
      "Epoch 96/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1841e-07 - mse: 2.1841e-07 - val_loss: 7.6743e-07 - val_mse: 7.6743e-07\n",
      "Epoch 97/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2579e-07 - mse: 1.2579e-07 - val_loss: 1.0330e-07 - val_mse: 1.0330e-07\n",
      "Epoch 98/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7010e-08 - mse: 3.7010e-08 - val_loss: 1.1980e-07 - val_mse: 1.1980e-07\n",
      "Epoch 99/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9868e-08 - mse: 1.9868e-08 - val_loss: 2.4779e-08 - val_mse: 2.4779e-08\n",
      "Epoch 100/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.4324e-09 - mse: 9.4324e-09 - val_loss: 1.6490e-08 - val_mse: 1.6490e-08\n",
      "Epoch 101/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1591e-09 - mse: 5.1591e-09 - val_loss: 9.4005e-09 - val_mse: 9.4005e-09\n",
      "Epoch 102/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5977e-09 - mse: 3.5977e-09 - val_loss: 6.4669e-09 - val_mse: 6.4669e-09\n",
      "Epoch 103/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5499e-09 - mse: 2.5499e-09 - val_loss: 9.6450e-09 - val_mse: 9.6450e-09\n",
      "Epoch 104/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2828e-09 - mse: 2.2828e-09 - val_loss: 4.5227e-09 - val_mse: 4.5227e-09\n",
      "Epoch 105/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4294e-09 - mse: 1.4294e-09 - val_loss: 7.7474e-09 - val_mse: 7.7474e-09\n",
      "Epoch 106/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4843e-09 - mse: 1.4843e-09 - val_loss: 7.3633e-09 - val_mse: 7.3633e-09\n",
      "Epoch 107/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0865e-09 - mse: 2.0865e-09 - val_loss: 8.7603e-09 - val_mse: 8.7603e-09\n",
      "Epoch 108/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5434e-09 - mse: 1.5434e-09 - val_loss: 5.1281e-09 - val_mse: 5.1281e-09\n",
      "Epoch 109/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.5037e-10 - mse: 7.5037e-10 - val_loss: 2.8464e-09 - val_mse: 2.8464e-09\n",
      "Epoch 110/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3802e-10 - mse: 7.3802e-10 - val_loss: 1.9616e-09 - val_mse: 1.9616e-09\n",
      "Epoch 111/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0914e-09 - mse: 1.0914e-09 - val_loss: 4.1153e-09 - val_mse: 4.1153e-09\n",
      "Epoch 112/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0187e-09 - mse: 1.0187e-09 - val_loss: 4.0920e-09 - val_mse: 4.0920e-09\n",
      "Epoch 113/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0375e-09 - mse: 1.0375e-09 - val_loss: 2.9861e-09 - val_mse: 2.9861e-09\n",
      "Epoch 114/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.4696e-10 - mse: 8.4696e-10 - val_loss: 4.0338e-09 - val_mse: 4.0338e-09\n",
      "Epoch 115/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.0965e-10 - mse: 8.0965e-10 - val_loss: 2.8696e-09 - val_mse: 2.8696e-09\n",
      "Epoch 116/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.6440e-10 - mse: 9.6440e-10 - val_loss: 3.3935e-09 - val_mse: 3.3935e-09\n",
      "Epoch 117/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0405e-09 - mse: 1.0405e-09 - val_loss: 1.5774e-09 - val_mse: 1.5774e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.6667e-10 - mse: 9.6667e-10 - val_loss: 2.5786e-09 - val_mse: 2.5786e-09\n",
      "Epoch 119/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8245e-10 - mse: 7.8245e-10 - val_loss: 6.9267e-10 - val_mse: 6.9267e-10\n",
      "Epoch 120/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.9224e-10 - mse: 9.9224e-10 - val_loss: 1.5658e-09 - val_mse: 1.5658e-09\n",
      "Epoch 121/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.8035e-10 - mse: 5.8035e-10 - val_loss: 8.3237e-10 - val_mse: 8.3237e-10\n",
      "Epoch 122/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2410e-10 - mse: 7.2410e-10 - val_loss: 1.7521e-09 - val_mse: 1.7521e-09\n",
      "Epoch 123/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.1587e-10 - mse: 9.1587e-10 - val_loss: 1.0186e-09 - val_mse: 1.0186e-09\n",
      "Epoch 124/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3829e-10 - mse: 7.3829e-10 - val_loss: 9.3714e-10 - val_mse: 9.3714e-10\n",
      "Epoch 125/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.2258e-10 - mse: 8.2258e-10 - val_loss: 7.3924e-10 - val_mse: 7.3924e-10\n",
      "Epoch 126/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3961e-10 - mse: 8.3961e-10 - val_loss: 1.1583e-09 - val_mse: 1.1583e-09\n",
      "Epoch 127/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.8395e-10 - mse: 6.8395e-10 - val_loss: 2.3923e-09 - val_mse: 2.3923e-09\n",
      "Epoch 128/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9064e-10 - mse: 8.9064e-10 - val_loss: 6.4611e-10 - val_mse: 6.4611e-10\n",
      "Epoch 129/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4949e-10 - mse: 5.4949e-10 - val_loss: 7.3924e-10 - val_mse: 7.3924e-10\n",
      "Epoch 130/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.4136e-10 - mse: 8.4136e-10 - val_loss: 8.3237e-10 - val_mse: 8.3237e-10\n",
      "Epoch 131/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.9113e-10 - mse: 4.9113e-10 - val_loss: 1.8801e-09 - val_mse: 1.8801e-09\n",
      "Epoch 132/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.7587e-10 - mse: 8.7587e-10 - val_loss: 5.6461e-10 - val_mse: 5.6461e-10\n",
      "Epoch 133/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1318e-10 - mse: 5.1318e-10 - val_loss: 1.1816e-09 - val_mse: 1.1816e-09\n",
      "Epoch 134/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.3866e-10 - mse: 5.3866e-10 - val_loss: 8.5565e-10 - val_mse: 8.5565e-10\n",
      "Epoch 135/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5341e-10 - mse: 5.5341e-10 - val_loss: 2.4971e-09 - val_mse: 2.4971e-09\n",
      "Epoch 136/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.5222e-10 - mse: 9.5222e-10 - val_loss: 5.9954e-10 - val_mse: 5.9954e-10\n",
      "Epoch 137/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.8581e-10 - mse: 6.8581e-10 - val_loss: 5.9954e-10 - val_mse: 5.9954e-10\n",
      "Epoch 138/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1554e-10 - mse: 7.1554e-10 - val_loss: 1.6589e-09 - val_mse: 1.6589e-09\n",
      "Epoch 139/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.7518e-10 - mse: 8.7518e-10 - val_loss: 2.2061e-09 - val_mse: 2.2061e-09\n",
      "Epoch 140/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3448e-09 - mse: 1.3448e-09 - val_loss: 8.3237e-10 - val_mse: 8.3237e-10\n",
      "Epoch 141/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.5475e-10 - mse: 8.5475e-10 - val_loss: 4.8953e-09 - val_mse: 4.8953e-09\n",
      "Epoch 142/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1396e-09 - mse: 1.1396e-09 - val_loss: 6.4902e-09 - val_mse: 6.4902e-09\n",
      "Epoch 143/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2125e-09 - mse: 4.2125e-09 - val_loss: 3.2887e-09 - val_mse: 3.2887e-09\n",
      "Epoch 144/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1251e-09 - mse: 4.1251e-09 - val_loss: 1.7521e-09 - val_mse: 1.7521e-09\n",
      "Epoch 145/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4511e-09 - mse: 3.4511e-09 - val_loss: 9.1386e-10 - val_mse: 9.1386e-10\n",
      "Epoch 146/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0921e-09 - mse: 1.0921e-09 - val_loss: 1.6124e-09 - val_mse: 1.6124e-09\n",
      "Epoch 147/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4774e-09 - mse: 1.4774e-09 - val_loss: 8.4401e-10 - val_mse: 8.4401e-10\n",
      "Epoch 148/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.6995e-10 - mse: 8.6995e-10 - val_loss: 2.7881e-09 - val_mse: 2.7881e-09\n",
      "Epoch 149/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4787e-09 - mse: 2.4787e-09 - val_loss: 1.1834e-08 - val_mse: 1.1834e-08\n",
      "Epoch 150/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0372e-08 - mse: 1.0372e-08 - val_loss: 5.2969e-10 - val_mse: 5.2969e-10\n",
      "Epoch 151/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0226e-09 - mse: 3.0226e-09 - val_loss: 1.9267e-09 - val_mse: 1.9267e-09\n",
      "Epoch 152/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9565e-09 - mse: 2.9565e-09 - val_loss: 2.0367e-08 - val_mse: 2.0367e-08\n",
      "Epoch 153/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.5857e-09 - mse: 6.5857e-09 - val_loss: 2.1595e-09 - val_mse: 2.1595e-09\n",
      "Epoch 154/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9646e-09 - mse: 3.9646e-09 - val_loss: 7.2236e-09 - val_mse: 7.2236e-09\n",
      "Epoch 155/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7799e-09 - mse: 1.7799e-09 - val_loss: 5.1805e-10 - val_mse: 5.1805e-10\n",
      "Epoch 156/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8958e-09 - mse: 2.8958e-09 - val_loss: 1.3097e-09 - val_mse: 1.3097e-09\n",
      "Epoch 157/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1759e-09 - mse: 1.1759e-09 - val_loss: 2.0082e-09 - val_mse: 2.0082e-09\n",
      "Epoch 158/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0803e-09 - mse: 5.0803e-09 - val_loss: 1.6339e-08 - val_mse: 1.6339e-08\n",
      "Epoch 159/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5628e-09 - mse: 4.5628e-09 - val_loss: 4.4762e-09 - val_mse: 4.4762e-09\n",
      "Epoch 160/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6745e-09 - mse: 1.6745e-09 - val_loss: 2.7067e-09 - val_mse: 2.7067e-09\n",
      "Epoch 161/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6353e-09 - mse: 1.6353e-09 - val_loss: 5.3726e-09 - val_mse: 5.3726e-09\n",
      "Epoch 162/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0183e-09 - mse: 5.0183e-09 - val_loss: 1.7055e-09 - val_mse: 1.7055e-09\n",
      "Epoch 163/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2851e-09 - mse: 4.2851e-09 - val_loss: 8.5041e-09 - val_mse: 8.5041e-09\n",
      "Epoch 164/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4513e-09 - mse: 3.4513e-09 - val_loss: 6.8103e-10 - val_mse: 6.8103e-10\n",
      "Epoch 165/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7971e-09 - mse: 3.7971e-09 - val_loss: 3.4150e-08 - val_mse: 3.4150e-08\n",
      "Epoch 166/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1308e-09 - mse: 5.1308e-09 - val_loss: 2.2020e-08 - val_mse: 2.2020e-08\n",
      "Epoch 167/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2117e-08 - mse: 1.2117e-08 - val_loss: 2.9179e-08 - val_mse: 2.9179e-08\n",
      "Epoch 168/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9955e-08 - mse: 3.9955e-08 - val_loss: 4.9651e-09 - val_mse: 4.9651e-09\n",
      "Epoch 169/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7000e-08 - mse: 3.7000e-08 - val_loss: 1.1424e-07 - val_mse: 1.1424e-07\n",
      "Epoch 170/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.9449e-08 - mse: 9.9449e-08 - val_loss: 3.7660e-09 - val_mse: 3.7660e-09\n",
      "Epoch 171/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9868e-08 - mse: 3.9868e-08 - val_loss: 8.3965e-08 - val_mse: 8.3965e-08\n",
      "Epoch 172/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.5945e-08 - mse: 7.5945e-08 - val_loss: 1.3695e-07 - val_mse: 1.3695e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2721e-08 - mse: 7.2721e-08 - val_loss: 1.0914e-08 - val_mse: 1.0914e-08\n",
      "Epoch 174/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5382e-08 - mse: 2.5382e-08 - val_loss: 2.3766e-08 - val_mse: 2.3766e-08\n",
      "Epoch 175/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7099e-08 - mse: 1.7099e-08 - val_loss: 1.9267e-09 - val_mse: 1.9267e-09\n",
      "Epoch 176/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0888e-08 - mse: 2.0888e-08 - val_loss: 3.9290e-09 - val_mse: 3.9290e-09\n",
      "Epoch 177/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3362e-07 - mse: 1.3362e-07 - val_loss: 1.5799e-07 - val_mse: 1.5799e-07\n",
      "Epoch 178/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3266e-07 - mse: 1.3266e-07 - val_loss: 9.1951e-08 - val_mse: 9.1951e-08\n",
      "Epoch 179/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2400e-08 - mse: 3.2400e-08 - val_loss: 2.7806e-08 - val_mse: 2.7806e-08\n",
      "Epoch 180/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7137e-08 - mse: 2.7137e-08 - val_loss: 5.1531e-08 - val_mse: 5.1531e-08\n",
      "Epoch 181/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4078e-08 - mse: 5.4078e-08 - val_loss: 5.3493e-09 - val_mse: 5.3493e-09\n",
      "Epoch 182/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.0130e-09 - mse: 7.0130e-09 - val_loss: 3.5099e-09 - val_mse: 3.5099e-09\n",
      "Epoch 183/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6931e-08 - mse: 6.6931e-08 - val_loss: 1.1795e-07 - val_mse: 1.1795e-07\n",
      "Epoch 184/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2047e-08 - mse: 3.2047e-08 - val_loss: 8.6433e-08 - val_mse: 8.6433e-08\n",
      "Epoch 185/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1596e-07 - mse: 1.1596e-07 - val_loss: 5.6438e-07 - val_mse: 5.6438e-07\n",
      "Epoch 186/300\n",
      "60/60 [==============================] - 0s 867us/step - loss: 4.6837e-07 - mse: 4.6837e-07 - val_loss: 4.8869e-07 - val_mse: 4.8869e-07\n",
      "Epoch 187/300\n",
      "60/60 [==============================] - 0s 886us/step - loss: 1.2949e-07 - mse: 1.2949e-07 - val_loss: 3.3323e-07 - val_mse: 3.3323e-07\n",
      "Epoch 188/300\n",
      "60/60 [==============================] - 0s 880us/step - loss: 7.4715e-07 - mse: 7.4715e-07 - val_loss: 2.3696e-07 - val_mse: 2.3696e-07\n",
      "Epoch 189/300\n",
      "60/60 [==============================] - 0s 864us/step - loss: 3.0620e-07 - mse: 3.0620e-07 - val_loss: 8.7731e-06 - val_mse: 8.7731e-06\n",
      "Epoch 190/300\n",
      "60/60 [==============================] - 0s 844us/step - loss: 1.7903e-06 - mse: 1.7903e-06 - val_loss: 3.0506e-07 - val_mse: 3.0506e-07\n",
      "Epoch 191/300\n",
      "60/60 [==============================] - 0s 864us/step - loss: 8.9384e-06 - mse: 8.9384e-06 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 192/300\n",
      "60/60 [==============================] - 0s 872us/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 193/300\n",
      "60/60 [==============================] - 0s 992us/step - loss: 0.0229 - mse: 0.0229 - val_loss: 1.3484e-04 - val_mse: 1.3484e-04\n",
      "Epoch 194/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9244e-04 - mse: 1.9244e-04 - val_loss: 5.7973e-05 - val_mse: 5.7973e-05\n",
      "Epoch 195/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.7308e-04 - mse: 9.7308e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 196/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 2.2307e-04 - val_mse: 2.2307e-04\n",
      "Epoch 197/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0511 - mse: 0.0511 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 198/300\n",
      "60/60 [==============================] - 0s 847us/step - loss: 0.0619 - mse: 0.0619 - val_loss: 3.9621e-04 - val_mse: 3.9621e-04\n",
      "Epoch 199/300\n",
      "60/60 [==============================] - 0s 861us/step - loss: 0.0666 - mse: 0.0666 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 200/300\n",
      "60/60 [==============================] - 0s 860us/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 201/300\n",
      "60/60 [==============================] - 0s 861us/step - loss: 0.0042 - mse: 0.0042 - val_loss: 3.2530e-05 - val_mse: 3.2530e-05\n",
      "Epoch 202/300\n",
      "60/60 [==============================] - 0s 869us/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 203/300\n",
      "60/60 [==============================] - 0s 922us/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 204/300\n",
      "60/60 [==============================] - 0s 892us/step - loss: 0.0104 - mse: 0.0104 - val_loss: 5.1194e-04 - val_mse: 5.1194e-04\n",
      "Epoch 205/300\n",
      "60/60 [==============================] - 0s 939us/step - loss: 9.1350e-05 - mse: 9.1350e-05 - val_loss: 1.3699e-05 - val_mse: 1.3699e-05\n",
      "Epoch 206/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.2489e-06 - mse: 9.2489e-06 - val_loss: 5.1340e-06 - val_mse: 5.1340e-06\n",
      "Epoch 207/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0011e-06 - mse: 1.0011e-06 - val_loss: 1.4764e-05 - val_mse: 1.4764e-05\n",
      "Epoch 208/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0300e-05 - mse: 2.0300e-05 - val_loss: 4.7945e-07 - val_mse: 4.7945e-07\n",
      "Epoch 209/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0586e-05 - mse: 1.0586e-05 - val_loss: 1.8218e-05 - val_mse: 1.8218e-05\n",
      "Epoch 210/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9990e-04 - mse: 2.9990e-04 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 211/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0754 - val_mse: 0.0754\n",
      "Epoch 212/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.1705 - val_mse: 0.1705\n",
      "Epoch 213/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0651 - mse: 0.0651 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 214/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 215/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 5.6268e-04 - val_mse: 5.6268e-04\n",
      "Epoch 216/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.6341e-04 - mse: 9.6341e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 217/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 218/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.1317 - val_mse: 0.1317\n",
      "Epoch 219/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0532 - mse: 0.0532 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 220/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 221/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.7937e-04 - mse: 7.7937e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 222/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.5977e-04 - mse: 7.5977e-04 - val_loss: 1.0206e-04 - val_mse: 1.0206e-04\n",
      "Epoch 223/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 224/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9669e-04 - mse: 1.9669e-04 - val_loss: 1.1304e-04 - val_mse: 1.1304e-04\n",
      "Epoch 225/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0070 - val_mse: 0.0070\n",
      "Epoch 226/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.2935 - val_mse: 0.2935\n",
      "Epoch 227/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1607 - mse: 0.1607 - val_loss: 0.0853 - val_mse: 0.0853\n",
      "Epoch 228/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 229/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 230/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 2.8655e-05 - val_mse: 2.8655e-05\n",
      "Epoch 231/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1321e-04 - mse: 1.1321e-04 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 232/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 1.5726e-04 - val_mse: 1.5726e-04\n",
      "Epoch 233/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3439e-04 - mse: 4.3439e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 234/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7082e-04 - mse: 3.7082e-04 - val_loss: 1.8762e-04 - val_mse: 1.8762e-04\n",
      "Epoch 235/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1179e-05 - mse: 7.1179e-05 - val_loss: 3.1250e-04 - val_mse: 3.1250e-04\n",
      "Epoch 236/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3013e-04 - mse: 8.3013e-04 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 237/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 238/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 4.6101e-06 - val_mse: 4.6101e-06\n",
      "Epoch 239/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7629e-04 - mse: 2.7629e-04 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 240/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 2.4069e-05 - val_mse: 2.4069e-05\n",
      "Epoch 241/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 242/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 243/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0721 - mse: 0.0721 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 244/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1196 - mse: 0.1196 - val_loss: 0.2593 - val_mse: 0.2593\n",
      "Epoch 245/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 6.3731e-04 - val_mse: 6.3731e-04\n",
      "Epoch 246/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 5.9399e-05 - val_mse: 5.9399e-05\n",
      "Epoch 247/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3206e-04 - mse: 1.3206e-04 - val_loss: 5.8300e-05 - val_mse: 5.8300e-05\n",
      "Epoch 248/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.1437e-06 - mse: 8.1437e-06 - val_loss: 2.5016e-07 - val_mse: 2.5016e-07\n",
      "Epoch 249/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4190e-05 - mse: 2.4190e-05 - val_loss: 1.6862e-04 - val_mse: 1.6862e-04\n",
      "Epoch 250/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.0065e-05 - mse: 7.0065e-05 - val_loss: 4.2111e-05 - val_mse: 4.2111e-05\n",
      "Epoch 251/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.5136e-05 - mse: 8.5136e-05 - val_loss: 5.4696e-04 - val_mse: 5.4696e-04\n",
      "Epoch 252/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8085e-04 - mse: 1.8085e-04 - val_loss: 2.2807e-05 - val_mse: 2.2807e-05\n",
      "Epoch 253/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5167e-05 - mse: 2.5167e-05 - val_loss: 2.7051e-04 - val_mse: 2.7051e-04\n",
      "Epoch 254/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2048e-04 - mse: 2.2048e-04 - val_loss: 1.8213e-04 - val_mse: 1.8213e-04\n",
      "Epoch 255/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.6245e-04 - mse: 5.6245e-04 - val_loss: 6.2075e-04 - val_mse: 6.2075e-04\n",
      "Epoch 256/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 1.0059 - val_mse: 1.0059\n",
      "Epoch 257/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2768 - mse: 0.2768 - val_loss: 0.6020 - val_mse: 0.6020\n",
      "Epoch 258/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2912 - mse: 0.2912 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "Epoch 259/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 3.4858e-04 - val_mse: 3.4858e-04\n",
      "Epoch 260/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.0947e-05 - val_mse: 1.0947e-05\n",
      "Epoch 261/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9020e-05 - mse: 6.9020e-05 - val_loss: 4.6761e-07 - val_mse: 4.6761e-07\n",
      "Epoch 262/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5069e-06 - mse: 4.5069e-06 - val_loss: 2.3781e-07 - val_mse: 2.3781e-07\n",
      "Epoch 263/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5549e-07 - mse: 1.5549e-07 - val_loss: 1.6956e-08 - val_mse: 1.6956e-08\n",
      "Epoch 264/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5911e-08 - mse: 5.5911e-08 - val_loss: 1.2311e-08 - val_mse: 1.2311e-08\n",
      "Epoch 265/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3584e-08 - mse: 1.3584e-08 - val_loss: 3.4861e-08 - val_mse: 3.4861e-08\n",
      "Epoch 266/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8914e-08 - mse: 3.8914e-08 - val_loss: 2.6013e-08 - val_mse: 2.6013e-08\n",
      "Epoch 267/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.0034e-07 - mse: 8.0034e-07 - val_loss: 4.7084e-08 - val_mse: 4.7084e-08\n",
      "Epoch 268/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4588e-08 - mse: 4.4588e-08 - val_loss: 4.4046e-08 - val_mse: 4.4046e-08\n",
      "Epoch 269/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1675e-08 - mse: 2.1675e-08 - val_loss: 2.2753e-08 - val_mse: 2.2753e-08\n",
      "Epoch 270/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.4213e-09 - mse: 7.4213e-09 - val_loss: 2.3801e-08 - val_mse: 2.3801e-08\n",
      "Epoch 271/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4847e-08 - mse: 3.4847e-08 - val_loss: 1.5151e-08 - val_mse: 1.5151e-08\n",
      "Epoch 272/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3153e-08 - mse: 4.3153e-08 - val_loss: 4.0332e-08 - val_mse: 4.0332e-08\n",
      "Epoch 273/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0407e-07 - mse: 1.0407e-07 - val_loss: 4.0642e-07 - val_mse: 4.0642e-07\n",
      "Epoch 274/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1280e-07 - mse: 1.1280e-07 - val_loss: 2.2614e-08 - val_mse: 2.2614e-08\n",
      "Epoch 275/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.7253e-08 - mse: 4.7253e-08 - val_loss: 3.0681e-08 - val_mse: 3.0681e-08\n",
      "Epoch 276/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1633e-06 - mse: 1.1633e-06 - val_loss: 3.6911e-06 - val_mse: 3.6911e-06\n",
      "Epoch 277/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.5848e-06 - mse: 6.5848e-06 - val_loss: 6.0404e-06 - val_mse: 6.0404e-06\n",
      "Epoch 278/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1214e-05 - mse: 4.1214e-05 - val_loss: 1.4431e-05 - val_mse: 1.4431e-05\n",
      "Epoch 279/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7351e-04 - mse: 2.7351e-04 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 280/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 281/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 282/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0771 - mse: 0.0771 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 283/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3008 - mse: 0.3008 - val_loss: 0.6629 - val_mse: 0.6629\n",
      "Epoch 284/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5278 - mse: 0.5278 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 285/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 3.2783e-05 - val_mse: 3.2783e-05\n",
      "Epoch 286/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2821e-04 - mse: 2.2821e-04 - val_loss: 3.1309e-05 - val_mse: 3.1309e-05\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0337e-06 - mse: 4.0337e-06 - val_loss: 6.2203e-07 - val_mse: 6.2203e-07\n",
      "Epoch 288/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.4403e-08 - mse: 9.4403e-08 - val_loss: 9.2911e-08 - val_mse: 9.2911e-08\n",
      "Epoch 289/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3364e-08 - mse: 2.3364e-08 - val_loss: 3.3910e-09 - val_mse: 3.3910e-09\n",
      "Epoch 290/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4338e-09 - mse: 4.4338e-09 - val_loss: 1.7040e-09 - val_mse: 1.7040e-09\n",
      "Epoch 291/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3922e-09 - mse: 3.3922e-09 - val_loss: 2.7630e-08 - val_mse: 2.7630e-08\n",
      "Epoch 292/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0484e-08 - mse: 4.0484e-08 - val_loss: 4.8889e-08 - val_mse: 4.8889e-08\n",
      "Epoch 293/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.6473e-08 - mse: 7.6473e-08 - val_loss: 3.4452e-08 - val_mse: 3.4452e-08\n",
      "Epoch 294/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.4651e-08 - mse: 6.4651e-08 - val_loss: 2.7736e-08 - val_mse: 2.7736e-08\n",
      "Epoch 295/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4983e-08 - mse: 2.4983e-08 - val_loss: 2.0318e-08 - val_mse: 2.0318e-08\n",
      "Epoch 296/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6981e-08 - mse: 1.6981e-08 - val_loss: 4.5358e-09 - val_mse: 4.5358e-09\n",
      "Epoch 297/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4843e-09 - mse: 5.4843e-09 - val_loss: 6.4174e-10 - val_mse: 6.4174e-10\n",
      "Epoch 298/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.4151e-09 - mse: 8.4151e-09 - val_loss: 1.3347e-08 - val_mse: 1.3347e-08\n",
      "Epoch 299/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9571e-08 - mse: 1.9571e-08 - val_loss: 3.8317e-08 - val_mse: 3.8317e-08\n",
      "Epoch 300/300\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0040e-08 - mse: 1.0040e-08 - val_loss: 4.4378e-08 - val_mse: 4.4378e-08\n",
      "20/20 [==============================] - 0s 512us/step - loss: 4.2323e-08 - mse: 4.2323e-08\n",
      "mse : [4.232278882909668e-08, 4.232278882909668e-08]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=False, test_size=0.4)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, shuffle=False, test_size=0.5)\n",
    "\n",
    "# 2. 모델 구성\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "input_layer = Input(shape=(2, ))\n",
    "d = Dense(5, activation='relu')(input_layer)\n",
    "d = Dense(3)(d)\n",
    "d = Dense(4)(d)\n",
    "output_layer = Dense(2)(d)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# 3. 훈련\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=300, validation_data=(x_val, y_val))\n",
    "\n",
    "# 4. 평가 예측\n",
    "mse = model.evaluate(x_test, y_test, batch_size=1)\n",
    "print('mse :', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 79.99987  381.00024 ]\n",
      " [ 80.99992  382.0003  ]\n",
      " [ 81.99986  383.00027 ]\n",
      " [ 82.999886 384.0002  ]\n",
      " [ 83.999855 385.0002  ]\n",
      " [ 84.9999   386.0002  ]\n",
      " [ 85.99989  387.00024 ]\n",
      " [ 86.99988  388.00024 ]\n",
      " [ 87.99988  389.00027 ]\n",
      " [ 88.999886 390.00027 ]\n",
      " [ 89.99988  391.00027 ]\n",
      " [ 90.999886 392.00027 ]\n",
      " [ 91.99989  393.00027 ]\n",
      " [ 92.9999   394.00027 ]\n",
      " [ 93.99988  395.00027 ]\n",
      " [ 94.99989  396.00027 ]\n",
      " [ 95.99986  397.00024 ]\n",
      " [ 96.99992  398.00027 ]\n",
      " [ 97.99986  399.00027 ]\n",
      " [ 98.99986  400.00027 ]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  0.0002031876932651178\n",
      "r2_score :  0.9999999987583387\n"
     ]
    }
   ],
   "source": [
    "# RMSE \n",
    "from sklearn.metrics import mean_squared_error\n",
    "def RMSE(y_test, y_predict):\n",
    "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "print('RMSE : ', RMSE(y_test, y_predict))\n",
    "\n",
    "# r2\n",
    "from sklearn.metrics import r2_score\n",
    "print('r2_score : ', r2_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다 : 1\n",
    "다 : 1 모델은 다:다 모델에서 아웃풋만 1개인 경우를 의미함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100) (100,)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "# 1.데이터 준비\n",
    "import numpy as np \n",
    "\n",
    "x = np.array([range(100), range(301, 401)])\n",
    "y = np.array(range(201, 301))\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "# 행,열 변환\n",
    "x = np.transpose(x)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 12842.1670 - mse: 12842.1670 - val_loss: 1251.2972 - val_mse: 1251.2972\n",
      "Epoch 2/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 393.4104 - mse: 393.4104 - val_loss: 10.2927 - val_mse: 10.2927\n",
      "Epoch 3/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3878 - mse: 1.3878 - val_loss: 2.8329 - val_mse: 2.8329\n",
      "Epoch 4/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5885 - mse: 0.5885 - val_loss: 2.4881 - val_mse: 2.4881\n",
      "Epoch 5/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5397 - mse: 0.5397 - val_loss: 2.1792 - val_mse: 2.1792\n",
      "Epoch 6/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4494 - mse: 0.4494 - val_loss: 2.5498 - val_mse: 2.5498\n",
      "Epoch 7/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4683 - mse: 0.4683 - val_loss: 2.6303 - val_mse: 2.6303\n",
      "Epoch 8/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4726 - mse: 0.4726 - val_loss: 2.1154 - val_mse: 2.1154\n",
      "Epoch 9/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3287 - mse: 0.3287 - val_loss: 1.6683 - val_mse: 1.6683\n",
      "Epoch 10/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3445 - mse: 0.3445 - val_loss: 2.5204 - val_mse: 2.5204\n",
      "Epoch 11/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3665 - mse: 0.3665 - val_loss: 1.4632 - val_mse: 1.4632\n",
      "Epoch 12/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2268 - mse: 0.2268 - val_loss: 1.0867 - val_mse: 1.0867\n",
      "Epoch 13/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2301 - mse: 0.2301 - val_loss: 0.8514 - val_mse: 0.8514\n",
      "Epoch 14/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1790 - mse: 0.1790 - val_loss: 0.5696 - val_mse: 0.5696\n",
      "Epoch 15/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1314 - mse: 0.1314 - val_loss: 0.8562 - val_mse: 0.8562\n",
      "Epoch 16/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1243 - mse: 0.1243 - val_loss: 0.1677 - val_mse: 0.1677\n",
      "Epoch 17/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1240 - mse: 0.1240 - val_loss: 0.4071 - val_mse: 0.4071\n",
      "Epoch 18/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0807 - mse: 0.0807 - val_loss: 0.3777 - val_mse: 0.3777\n",
      "Epoch 19/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0671 - mse: 0.0671 - val_loss: 0.3665 - val_mse: 0.3665\n",
      "Epoch 20/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0523 - mse: 0.0523 - val_loss: 0.2909 - val_mse: 0.2909\n",
      "Epoch 21/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.1704 - val_mse: 0.1704\n",
      "Epoch 22/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0676 - val_mse: 0.0676\n",
      "Epoch 23/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0427 - mse: 0.0427 - val_loss: 0.1158 - val_mse: 0.1158\n",
      "Epoch 24/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0680 - val_mse: 0.0680\n",
      "Epoch 25/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.1056 - val_mse: 0.1056\n",
      "Epoch 26/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 27/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 28/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 29/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 30/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 31/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 32/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 33/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 34/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.4937e-04 - mse: 8.4937e-04 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 35/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.2255e-04 - mse: 6.2255e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 36/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2745e-04 - mse: 4.2745e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 37/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1025e-04 - mse: 3.1025e-04 - val_loss: 7.1218e-04 - val_mse: 7.1218e-04\n",
      "Epoch 38/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2297e-04 - mse: 2.2297e-04 - val_loss: 7.7488e-04 - val_mse: 7.7488e-04\n",
      "Epoch 39/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2061e-04 - mse: 1.2061e-04 - val_loss: 3.0015e-04 - val_mse: 3.0015e-04\n",
      "Epoch 40/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9766e-05 - mse: 6.9766e-05 - val_loss: 5.0826e-05 - val_mse: 5.0826e-05\n",
      "Epoch 41/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1683e-05 - mse: 7.1683e-05 - val_loss: 1.6873e-04 - val_mse: 1.6873e-04\n",
      "Epoch 42/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3285e-05 - mse: 2.3285e-05 - val_loss: 3.2277e-05 - val_mse: 3.2277e-05\n",
      "Epoch 43/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8567e-05 - mse: 1.8567e-05 - val_loss: 7.5630e-05 - val_mse: 7.5630e-05\n",
      "Epoch 44/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.7915e-06 - mse: 7.7915e-06 - val_loss: 6.2971e-05 - val_mse: 6.2971e-05\n",
      "Epoch 45/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3237e-06 - mse: 8.3237e-06 - val_loss: 1.0043e-05 - val_mse: 1.0043e-05\n",
      "Epoch 46/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0925e-06 - mse: 3.0925e-06 - val_loss: 1.6589e-05 - val_mse: 1.6589e-05\n",
      "Epoch 47/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1511e-06 - mse: 2.1511e-06 - val_loss: 3.0749e-06 - val_mse: 3.0749e-06\n",
      "Epoch 48/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2583e-06 - mse: 1.2583e-06 - val_loss: 2.1791e-06 - val_mse: 2.1791e-06\n",
      "Epoch 49/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1815e-07 - mse: 4.1815e-07 - val_loss: 2.0438e-07 - val_mse: 2.0438e-07\n",
      "Epoch 50/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0335e-07 - mse: 4.0335e-07 - val_loss: 6.8964e-07 - val_mse: 6.8964e-07\n",
      "Epoch 51/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8028e-07 - mse: 1.8028e-07 - val_loss: 5.7891e-07 - val_mse: 5.7891e-07\n",
      "Epoch 52/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5606e-07 - mse: 1.5606e-07 - val_loss: 6.0303e-08 - val_mse: 6.0303e-08\n",
      "Epoch 53/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8227e-08 - mse: 4.8227e-08 - val_loss: 1.3970e-08 - val_mse: 1.3970e-08\n",
      "Epoch 54/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8291e-08 - mse: 3.8291e-08 - val_loss: 5.4995e-08 - val_mse: 5.4995e-08\n",
      "Epoch 55/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4683e-08 - mse: 2.4683e-08 - val_loss: 6.8080e-08 - val_mse: 6.8080e-08\n",
      "Epoch 56/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4606e-08 - mse: 1.4606e-08 - val_loss: 6.7847e-08 - val_mse: 6.7847e-08\n",
      "Epoch 57/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1410e-08 - mse: 1.1410e-08 - val_loss: 4.7218e-08 - val_mse: 4.7218e-08\n",
      "Epoch 58/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.8370e-09 - mse: 5.8370e-09 - val_loss: 4.7870e-08 - val_mse: 4.7870e-08\n",
      "Epoch 59/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3391e-09 - mse: 8.3391e-09 - val_loss: 2.0815e-08 - val_mse: 2.0815e-08\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step - loss: 6.4055e-09 - mse: 6.4055e-09 - val_loss: 2.4959e-08 - val_mse: 2.4959e-08\n",
      "Epoch 61/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8495e-09 - mse: 4.8495e-09 - val_loss: 8.3353e-09 - val_mse: 8.3353e-09\n",
      "Epoch 62/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9924e-09 - mse: 3.9924e-09 - val_loss: 1.8813e-08 - val_mse: 1.8813e-08\n",
      "Epoch 63/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7809e-09 - mse: 2.7809e-09 - val_loss: 1.3132e-08 - val_mse: 1.3132e-08\n",
      "Epoch 64/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7016e-09 - mse: 2.7016e-09 - val_loss: 7.3574e-09 - val_mse: 7.3574e-09\n",
      "Epoch 65/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0802e-09 - mse: 2.0802e-09 - val_loss: 9.2201e-09 - val_mse: 9.2201e-09\n",
      "Epoch 66/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2488e-09 - mse: 2.2488e-09 - val_loss: 1.1735e-08 - val_mse: 1.1735e-08\n",
      "Epoch 67/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7061e-09 - mse: 1.7061e-09 - val_loss: 3.7719e-09 - val_mse: 3.7719e-09\n",
      "Epoch 68/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6456e-09 - mse: 1.6456e-09 - val_loss: 5.0291e-09 - val_mse: 5.0291e-09\n",
      "Epoch 69/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7408e-09 - mse: 1.7408e-09 - val_loss: 6.5658e-09 - val_mse: 6.5658e-09\n",
      "Epoch 70/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2239e-09 - mse: 1.2239e-09 - val_loss: 4.8894e-09 - val_mse: 4.8894e-09\n",
      "Epoch 71/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0782e-09 - mse: 1.0782e-09 - val_loss: 4.6566e-09 - val_mse: 4.6566e-09\n",
      "Epoch 72/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0716e-09 - mse: 1.0716e-09 - val_loss: 1.7229e-09 - val_mse: 1.7229e-09\n",
      "Epoch 73/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1662e-09 - mse: 1.1662e-09 - val_loss: 2.5611e-09 - val_mse: 2.5611e-09\n",
      "Epoch 74/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.5933e-10 - mse: 7.5933e-10 - val_loss: 3.2131e-09 - val_mse: 3.2131e-09\n",
      "Epoch 75/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1131e-09 - mse: 1.1131e-09 - val_loss: 2.7008e-09 - val_mse: 2.7008e-09\n",
      "Epoch 76/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0214e-09 - mse: 1.0214e-09 - val_loss: 2.5611e-09 - val_mse: 2.5611e-09\n",
      "Epoch 77/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3190e-10 - mse: 6.3190e-10 - val_loss: 2.6543e-09 - val_mse: 2.6543e-09\n",
      "Epoch 78/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6727e-10 - mse: 6.6727e-10 - val_loss: 1.7229e-09 - val_mse: 1.7229e-09\n",
      "Epoch 79/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1925e-10 - mse: 4.1925e-10 - val_loss: 1.2573e-09 - val_mse: 1.2573e-09\n",
      "Epoch 80/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2825e-10 - mse: 4.2825e-10 - val_loss: 4.6566e-10 - val_mse: 4.6566e-10\n",
      "Epoch 81/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4254e-10 - mse: 5.4254e-10 - val_loss: 1.5832e-09 - val_mse: 1.5832e-09\n",
      "Epoch 82/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.0246e-10 - mse: 6.0246e-10 - val_loss: 1.1176e-09 - val_mse: 1.1176e-09\n",
      "Epoch 83/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.6894e-10 - mse: 4.6894e-10 - val_loss: 1.2107e-09 - val_mse: 1.2107e-09\n",
      "Epoch 84/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6169e-10 - mse: 3.6169e-10 - val_loss: 9.3132e-10 - val_mse: 9.3132e-10\n",
      "Epoch 85/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9708e-10 - mse: 2.9708e-10 - val_loss: 1.1642e-09 - val_mse: 1.1642e-09\n",
      "Epoch 86/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2727e-10 - mse: 3.2727e-10 - val_loss: 1.9092e-09 - val_mse: 1.9092e-09\n",
      "Epoch 87/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8730e-10 - mse: 7.8730e-10 - val_loss: 3.2596e-10 - val_mse: 3.2596e-10\n",
      "Epoch 88/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6991e-10 - mse: 2.6991e-10 - val_loss: 7.4506e-10 - val_mse: 7.4506e-10\n",
      "Epoch 89/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0919e-10 - mse: 3.0919e-10 - val_loss: 6.0536e-10 - val_mse: 6.0536e-10\n",
      "Epoch 90/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1014e-10 - mse: 4.1014e-10 - val_loss: 6.5193e-10 - val_mse: 6.5193e-10\n",
      "Epoch 91/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0066e-10 - mse: 3.0066e-10 - val_loss: 6.9849e-10 - val_mse: 6.9849e-10\n",
      "Epoch 92/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6495e-10 - mse: 2.6495e-10 - val_loss: 6.0536e-10 - val_mse: 6.0536e-10\n",
      "Epoch 93/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5104e-10 - mse: 3.5104e-10 - val_loss: 6.0536e-10 - val_mse: 6.0536e-10\n",
      "Epoch 94/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2365e-10 - mse: 3.2365e-10 - val_loss: 9.7789e-10 - val_mse: 9.7789e-10\n",
      "Epoch 95/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4555e-10 - mse: 4.4555e-10 - val_loss: 6.9849e-10 - val_mse: 6.9849e-10\n",
      "Epoch 96/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7895e-10 - mse: 2.7895e-10 - val_loss: 6.0536e-10 - val_mse: 6.0536e-10\n",
      "Epoch 97/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7340e-10 - mse: 2.7340e-10 - val_loss: 4.1910e-10 - val_mse: 4.1910e-10\n",
      "Epoch 98/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8262e-10 - mse: 4.8262e-10 - val_loss: 6.9849e-10 - val_mse: 6.9849e-10\n",
      "Epoch 99/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8815e-10 - mse: 4.8815e-10 - val_loss: 5.1223e-10 - val_mse: 5.1223e-10\n",
      "Epoch 100/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0287e-10 - mse: 3.0287e-10 - val_loss: 5.1223e-10 - val_mse: 5.1223e-10\n",
      "Epoch 101/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6490e-10 - mse: 2.6490e-10 - val_loss: 5.5879e-10 - val_mse: 5.5879e-10\n",
      "Epoch 102/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9136e-10 - mse: 3.9136e-10 - val_loss: 7.9162e-10 - val_mse: 7.9162e-10\n",
      "Epoch 103/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2179e-10 - mse: 3.2179e-10 - val_loss: 5.5879e-10 - val_mse: 5.5879e-10\n",
      "Epoch 104/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8468e-10 - mse: 3.8468e-10 - val_loss: 6.9849e-10 - val_mse: 6.9849e-10\n",
      "Epoch 105/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8412e-10 - mse: 4.8412e-10 - val_loss: 5.5879e-10 - val_mse: 5.5879e-10\n",
      "Epoch 106/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8002e-10 - mse: 2.8002e-10 - val_loss: 4.1910e-10 - val_mse: 4.1910e-10\n",
      "Epoch 107/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1819e-10 - mse: 4.1819e-10 - val_loss: 6.0536e-10 - val_mse: 6.0536e-10\n",
      "Epoch 108/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5926e-10 - mse: 4.5926e-10 - val_loss: 7.4506e-10 - val_mse: 7.4506e-10\n",
      "Epoch 109/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0613e-10 - mse: 4.0613e-10 - val_loss: 1.7695e-09 - val_mse: 1.7695e-09\n",
      "Epoch 110/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9578e-10 - mse: 5.9578e-10 - val_loss: 2.7940e-10 - val_mse: 2.7940e-10\n",
      "Epoch 111/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0267e-10 - mse: 2.0267e-10 - val_loss: 4.1910e-10 - val_mse: 4.1910e-10\n",
      "Epoch 112/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3667e-10 - mse: 4.3667e-10 - val_loss: 7.4506e-10 - val_mse: 7.4506e-10\n",
      "Epoch 113/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9380e-10 - mse: 6.9380e-10 - val_loss: 4.1910e-10 - val_mse: 4.1910e-10\n",
      "Epoch 114/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.3877e-10 - mse: 5.3877e-10 - val_loss: 1.8626e-10 - val_mse: 1.8626e-10\n",
      "Epoch 115/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1840e-10 - mse: 4.1840e-10 - val_loss: 5.5879e-10 - val_mse: 5.5879e-10\n",
      "Epoch 116/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0799e-10 - mse: 3.0799e-10 - val_loss: 7.9162e-10 - val_mse: 7.9162e-10\n",
      "Epoch 117/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7381e-10 - mse: 6.7381e-10 - val_loss: 1.1176e-09 - val_mse: 1.1176e-09\n",
      "Epoch 118/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8823e-10 - mse: 3.8823e-10 - val_loss: 3.2131e-09 - val_mse: 3.2131e-09\n",
      "Epoch 119/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3000e-09 - mse: 1.3000e-09 - val_loss: 5.1223e-10 - val_mse: 5.1223e-10\n",
      "Epoch 120/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7033e-09 - mse: 1.7033e-09 - val_loss: 5.1223e-10 - val_mse: 5.1223e-10\n",
      "Epoch 121/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.2883e-10 - mse: 8.2883e-10 - val_loss: 3.2596e-10 - val_mse: 3.2596e-10\n",
      "Epoch 122/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1395e-10 - mse: 7.1395e-10 - val_loss: 1.7229e-09 - val_mse: 1.7229e-09\n",
      "Epoch 123/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9080e-10 - mse: 5.9080e-10 - val_loss: 2.7940e-10 - val_mse: 2.7940e-10\n",
      "Epoch 124/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5171e-10 - mse: 4.5171e-10 - val_loss: 7.9162e-10 - val_mse: 7.9162e-10\n",
      "Epoch 125/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.4980e-10 - mse: 6.4980e-10 - val_loss: 1.6764e-09 - val_mse: 1.6764e-09\n",
      "Epoch 126/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.8492e-10 - mse: 6.8492e-10 - val_loss: 6.0536e-10 - val_mse: 6.0536e-10\n",
      "Epoch 127/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2943e-09 - mse: 2.2943e-09 - val_loss: 1.9791e-08 - val_mse: 1.9791e-08\n",
      "Epoch 128/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9763e-09 - mse: 1.9763e-09 - val_loss: 3.2596e-10 - val_mse: 3.2596e-10\n",
      "Epoch 129/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1673e-10 - mse: 7.1673e-10 - val_loss: 1.8626e-10 - val_mse: 1.8626e-10\n",
      "Epoch 130/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0220e-10 - mse: 4.0220e-10 - val_loss: 3.7253e-10 - val_mse: 3.7253e-10\n",
      "Epoch 131/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8637e-10 - mse: 3.8637e-10 - val_loss: 1.9558e-09 - val_mse: 1.9558e-09\n",
      "Epoch 132/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.4431e-10 - mse: 7.4431e-10 - val_loss: 4.6566e-10 - val_mse: 4.6566e-10\n",
      "Epoch 133/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1509e-09 - mse: 1.1509e-09 - val_loss: 4.3307e-09 - val_mse: 4.3307e-09\n",
      "Epoch 134/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.9968e-10 - mse: 7.9968e-10 - val_loss: 2.0489e-09 - val_mse: 2.0489e-09\n",
      "Epoch 135/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7188e-09 - mse: 1.7188e-09 - val_loss: 3.2596e-10 - val_mse: 3.2596e-10\n",
      "Epoch 136/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3039e-10 - mse: 7.3039e-10 - val_loss: 2.7008e-09 - val_mse: 2.7008e-09\n",
      "Epoch 137/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9589e-09 - mse: 3.9589e-09 - val_loss: 1.9092e-09 - val_mse: 1.9092e-09\n",
      "Epoch 138/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3983e-09 - mse: 1.3983e-09 - val_loss: 8.8476e-10 - val_mse: 8.8476e-10\n",
      "Epoch 139/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0385e-09 - mse: 3.0385e-09 - val_loss: 2.4214e-09 - val_mse: 2.4214e-09\n",
      "Epoch 140/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4551e-09 - mse: 1.4551e-09 - val_loss: 5.4482e-09 - val_mse: 5.4482e-09\n",
      "Epoch 141/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0721e-09 - mse: 4.0721e-09 - val_loss: 1.3039e-09 - val_mse: 1.3039e-09\n",
      "Epoch 142/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7188e-10 - mse: 6.7188e-10 - val_loss: 6.0536e-10 - val_mse: 6.0536e-10\n",
      "Epoch 143/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4547e-09 - mse: 2.4547e-09 - val_loss: 8.6147e-09 - val_mse: 8.6147e-09\n",
      "Epoch 144/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.8722e-09 - mse: 6.8722e-09 - val_loss: 3.0268e-09 - val_mse: 3.0268e-09\n",
      "Epoch 145/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7031e-09 - mse: 2.7031e-09 - val_loss: 1.2154e-08 - val_mse: 1.2154e-08\n",
      "Epoch 146/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.0236e-09 - mse: 7.0236e-09 - val_loss: 6.7987e-09 - val_mse: 6.7987e-09\n",
      "Epoch 147/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7034e-09 - mse: 1.7034e-09 - val_loss: 4.1910e-10 - val_mse: 4.1910e-10\n",
      "Epoch 148/500\n",
      "60/60 [==============================] - 0s 861us/step - loss: 4.1489e-09 - mse: 4.1489e-09 - val_loss: 8.3819e-10 - val_mse: 8.3819e-10\n",
      "Epoch 149/500\n",
      "60/60 [==============================] - 0s 984us/step - loss: 6.3345e-09 - mse: 6.3345e-09 - val_loss: 6.5193e-10 - val_mse: 6.5193e-10\n",
      "Epoch 150/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5652e-08 - mse: 1.5652e-08 - val_loss: 1.5851e-07 - val_mse: 1.5851e-07\n",
      "Epoch 151/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.2267e-08 - mse: 6.2267e-08 - val_loss: 2.0023e-09 - val_mse: 2.0023e-09\n",
      "Epoch 152/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6917e-09 - mse: 6.6917e-09 - val_loss: 2.4540e-08 - val_mse: 2.4540e-08\n",
      "Epoch 153/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2599e-08 - mse: 7.2599e-08 - val_loss: 1.3136e-07 - val_mse: 1.3136e-07\n",
      "Epoch 154/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.7247e-08 - mse: 7.7247e-08 - val_loss: 1.3798e-07 - val_mse: 1.3798e-07\n",
      "Epoch 155/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3874e-08 - mse: 7.3874e-08 - val_loss: 1.0477e-08 - val_mse: 1.0477e-08\n",
      "Epoch 156/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3305e-07 - mse: 4.3305e-07 - val_loss: 7.2382e-07 - val_mse: 7.2382e-07\n",
      "Epoch 157/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3888e-07 - mse: 6.3888e-07 - val_loss: 4.0899e-07 - val_mse: 4.0899e-07\n",
      "Epoch 158/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3126e-07 - mse: 1.3126e-07 - val_loss: 4.3400e-08 - val_mse: 4.3400e-08\n",
      "Epoch 159/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3436e-07 - mse: 1.3436e-07 - val_loss: 8.4564e-08 - val_mse: 8.4564e-08\n",
      "Epoch 160/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.1346e-08 - mse: 8.1346e-08 - val_loss: 9.0338e-09 - val_mse: 9.0338e-09\n",
      "Epoch 161/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1809e-07 - mse: 3.1809e-07 - val_loss: 9.1386e-07 - val_mse: 9.1386e-07\n",
      "Epoch 162/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9994e-06 - mse: 1.9994e-06 - val_loss: 6.2165e-06 - val_mse: 6.2165e-06\n",
      "Epoch 163/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5535e-06 - mse: 1.5535e-06 - val_loss: 2.4168e-07 - val_mse: 2.4168e-07\n",
      "Epoch 164/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3532e-07 - mse: 1.3532e-07 - val_loss: 4.2841e-09 - val_mse: 4.2841e-09\n",
      "Epoch 165/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.6514e-09 - mse: 8.6514e-09 - val_loss: 7.4506e-10 - val_mse: 7.4506e-10\n",
      "Epoch 166/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3391e-07 - mse: 1.3391e-07 - val_loss: 4.6228e-06 - val_mse: 4.6228e-06\n",
      "Epoch 167/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2867e-05 - mse: 2.2867e-05 - val_loss: 6.9143e-05 - val_mse: 6.9143e-05\n",
      "Epoch 168/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9651e-05 - mse: 2.9651e-05 - val_loss: 7.9355e-05 - val_mse: 7.9355e-05\n",
      "Epoch 169/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0919e-04 - mse: 4.0919e-04 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 171/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1379 - mse: 0.1379 - val_loss: 0.1544 - val_mse: 0.1544\n",
      "Epoch 172/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4650 - mse: 0.4650 - val_loss: 5.0024 - val_mse: 5.0024\n",
      "Epoch 173/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3648 - mse: 0.3648 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 174/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 4.3475e-04 - val_mse: 4.3475e-04\n",
      "Epoch 175/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 6.5682e-07 - val_mse: 6.5682e-07\n",
      "Epoch 176/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4970e-05 - mse: 3.4970e-05 - val_loss: 2.7180e-06 - val_mse: 2.7180e-06\n",
      "Epoch 177/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3112e-06 - mse: 1.3112e-06 - val_loss: 3.1767e-07 - val_mse: 3.1767e-07\n",
      "Epoch 178/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7876e-08 - mse: 3.7876e-08 - val_loss: 8.3819e-09 - val_mse: 8.3819e-09\n",
      "Epoch 179/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5651e-09 - mse: 3.5651e-09 - val_loss: 8.3819e-10 - val_mse: 8.3819e-10\n",
      "Epoch 180/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.5689e-10 - mse: 9.5689e-10 - val_loss: 7.4506e-10 - val_mse: 7.4506e-10\n",
      "Epoch 181/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5994e-09 - mse: 3.5994e-09 - val_loss: 6.7987e-09 - val_mse: 6.7987e-09\n",
      "Epoch 182/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3628e-09 - mse: 7.3628e-09 - val_loss: 1.3970e-08 - val_mse: 1.3970e-08\n",
      "Epoch 183/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9913e-09 - mse: 1.9913e-09 - val_loss: 1.2107e-09 - val_mse: 1.2107e-09\n",
      "Epoch 184/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6315e-09 - mse: 3.6315e-09 - val_loss: 1.9744e-08 - val_mse: 1.9744e-08\n",
      "Epoch 185/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6496e-08 - mse: 3.6496e-08 - val_loss: 1.6298e-09 - val_mse: 1.6298e-09\n",
      "Epoch 186/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0660e-08 - mse: 3.0660e-08 - val_loss: 5.4482e-09 - val_mse: 5.4482e-09\n",
      "Epoch 187/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.8102e-09 - mse: 5.8102e-09 - val_loss: 3.7253e-10 - val_mse: 3.7253e-10\n",
      "Epoch 188/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9336e-09 - mse: 1.9336e-09 - val_loss: 4.1910e-09 - val_mse: 4.1910e-09\n",
      "Epoch 189/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.6194e-09 - mse: 5.6194e-09 - val_loss: 7.7765e-09 - val_mse: 7.7765e-09\n",
      "Epoch 190/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4453e-09 - mse: 3.4453e-09 - val_loss: 7.9628e-09 - val_mse: 7.9628e-09\n",
      "Epoch 191/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2502e-08 - mse: 1.2502e-08 - val_loss: 6.2399e-09 - val_mse: 6.2399e-09\n",
      "Epoch 192/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5284e-08 - mse: 3.5284e-08 - val_loss: 1.9930e-08 - val_mse: 1.9930e-08\n",
      "Epoch 193/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3997e-08 - mse: 1.3997e-08 - val_loss: 5.5693e-08 - val_mse: 5.5693e-08\n",
      "Epoch 194/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.9253e-08 - mse: 7.9253e-08 - val_loss: 8.6287e-08 - val_mse: 8.6287e-08\n",
      "Epoch 195/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3576e-06 - mse: 3.3576e-06 - val_loss: 1.4543e-05 - val_mse: 1.4543e-05\n",
      "Epoch 196/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6410e-05 - mse: 1.6410e-05 - val_loss: 3.6427e-05 - val_mse: 3.6427e-05\n",
      "Epoch 197/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3808e-05 - mse: 2.3808e-05 - val_loss: 5.8122e-06 - val_mse: 5.8122e-06\n",
      "Epoch 198/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1317e-04 - mse: 1.1317e-04 - val_loss: 1.8626e-05 - val_mse: 1.8626e-05\n",
      "Epoch 199/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1118e-05 - mse: 1.1118e-05 - val_loss: 3.1754e-06 - val_mse: 3.1754e-06\n",
      "Epoch 200/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7112e-05 - mse: 2.7112e-05 - val_loss: 4.5285e-05 - val_mse: 4.5285e-05\n",
      "Epoch 201/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1226e-05 - mse: 3.1226e-05 - val_loss: 1.6031e-04 - val_mse: 1.6031e-04\n",
      "Epoch 202/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 203/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 204/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 205/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0799 - val_mse: 0.0799\n",
      "Epoch 206/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 207/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.1040 - val_mse: 0.1040\n",
      "Epoch 208/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.2164 - val_mse: 0.2164\n",
      "Epoch 209/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 210/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 8.6484e-04 - val_mse: 8.6484e-04\n",
      "Epoch 211/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9917e-04 - mse: 6.9917e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 212/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0393e-04 - mse: 4.0393e-04 - val_loss: 8.1887e-07 - val_mse: 8.1887e-07\n",
      "Epoch 213/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4925e-05 - mse: 1.4925e-05 - val_loss: 1.0584e-07 - val_mse: 1.0584e-07\n",
      "Epoch 214/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8207e-07 - mse: 2.8207e-07 - val_loss: 1.1013e-07 - val_mse: 1.1013e-07\n",
      "Epoch 215/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1768e-07 - mse: 3.1768e-07 - val_loss: 4.5635e-08 - val_mse: 4.5635e-08\n",
      "Epoch 216/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5979e-07 - mse: 1.5979e-07 - val_loss: 3.1511e-07 - val_mse: 3.1511e-07\n",
      "Epoch 217/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6268e-07 - mse: 1.6268e-07 - val_loss: 2.8548e-06 - val_mse: 2.8548e-06\n",
      "Epoch 218/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2425e-05 - mse: 2.2425e-05 - val_loss: 9.3519e-07 - val_mse: 9.3519e-07\n",
      "Epoch 219/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 7.2533e-04 - val_mse: 7.2533e-04\n",
      "Epoch 220/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0375 - mse: 0.0375 - val_loss: 1.5326e-04 - val_mse: 1.5326e-04\n",
      "Epoch 221/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.2576 - val_mse: 0.2576\n",
      "Epoch 222/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3225 - mse: 0.3225 - val_loss: 0.1537 - val_mse: 0.1537\n",
      "Epoch 223/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0673 - mse: 0.0673 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 224/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7816e-04 - mse: 6.7816e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 225/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.0678e-05 - mse: 6.0678e-05 - val_loss: 1.8878e-06 - val_mse: 1.8878e-06\n",
      "Epoch 226/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3909e-05 - mse: 3.3909e-05 - val_loss: 1.7912e-06 - val_mse: 1.7912e-06\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2639e-07 - mse: 7.2639e-07 - val_loss: 9.1130e-08 - val_mse: 9.1130e-08\n",
      "Epoch 228/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4928e-08 - mse: 2.4928e-08 - val_loss: 2.7427e-08 - val_mse: 2.7427e-08\n",
      "Epoch 229/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.1865e-08 - mse: 9.1865e-08 - val_loss: 3.1977e-07 - val_mse: 3.1977e-07\n",
      "Epoch 230/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2817e-06 - mse: 2.2817e-06 - val_loss: 7.4133e-08 - val_mse: 7.4133e-08\n",
      "Epoch 231/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1345e-06 - mse: 1.1345e-06 - val_loss: 6.9130e-06 - val_mse: 6.9130e-06\n",
      "Epoch 232/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8786e-06 - mse: 1.8786e-06 - val_loss: 9.3412e-08 - val_mse: 9.3412e-08\n",
      "Epoch 233/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6513e-05 - mse: 1.6513e-05 - val_loss: 4.4032e-06 - val_mse: 4.4032e-06\n",
      "Epoch 234/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.5829e-06 - mse: 8.5829e-06 - val_loss: 1.1448e-05 - val_mse: 1.1448e-05\n",
      "Epoch 235/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.9520e-05 - mse: 7.9520e-05 - val_loss: 7.1979e-04 - val_mse: 7.1979e-04\n",
      "Epoch 236/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4884e-04 - mse: 2.4884e-04 - val_loss: 3.0545e-06 - val_mse: 3.0545e-06\n",
      "Epoch 237/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7450e-05 - mse: 3.7450e-05 - val_loss: 5.7952e-06 - val_mse: 5.7952e-06\n",
      "Epoch 238/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8734e-05 - mse: 7.8734e-05 - val_loss: 7.9023e-07 - val_mse: 7.9023e-07\n",
      "Epoch 239/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.1339e-04 - mse: 8.1339e-04 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 240/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0694 - mse: 0.0694 - val_loss: 1.4280 - val_mse: 1.4280\n",
      "Epoch 241/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4437 - mse: 0.4437 - val_loss: 9.4347e-04 - val_mse: 9.4347e-04\n",
      "Epoch 242/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9095e-04 - mse: 8.9095e-04 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 243/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 244/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 3.1853e-05 - val_mse: 3.1853e-05\n",
      "Epoch 245/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.0202e-05 - mse: 9.0202e-05 - val_loss: 3.3158e-05 - val_mse: 3.3158e-05\n",
      "Epoch 246/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.8128e-06 - mse: 8.8128e-06 - val_loss: 2.8009e-06 - val_mse: 2.8009e-06\n",
      "Epoch 247/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.0394e-07 - mse: 7.0394e-07 - val_loss: 7.1572e-08 - val_mse: 7.1572e-08\n",
      "Epoch 248/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9454e-07 - mse: 5.9454e-07 - val_loss: 8.4704e-08 - val_mse: 8.4704e-08\n",
      "Epoch 249/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5806e-08 - mse: 5.5806e-08 - val_loss: 7.6694e-08 - val_mse: 7.6694e-08\n",
      "Epoch 250/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5876e-08 - mse: 2.5876e-08 - val_loss: 3.2596e-08 - val_mse: 3.2596e-08\n",
      "Epoch 251/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.4592e-09 - mse: 9.4592e-09 - val_loss: 8.8476e-10 - val_mse: 8.8476e-10\n",
      "Epoch 252/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9678e-09 - mse: 3.9678e-09 - val_loss: 3.5716e-08 - val_mse: 3.5716e-08\n",
      "Epoch 253/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1476e-08 - mse: 4.1476e-08 - val_loss: 1.7411e-07 - val_mse: 1.7411e-07\n",
      "Epoch 254/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.7646e-08 - mse: 8.7646e-08 - val_loss: 2.2650e-07 - val_mse: 2.2650e-07\n",
      "Epoch 255/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1734e-07 - mse: 1.1734e-07 - val_loss: 1.1502e-07 - val_mse: 1.1502e-07\n",
      "Epoch 256/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0999e-07 - mse: 1.0999e-07 - val_loss: 9.5926e-09 - val_mse: 9.5926e-09\n",
      "Epoch 257/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9942e-08 - mse: 2.9942e-08 - val_loss: 2.6012e-07 - val_mse: 2.6012e-07\n",
      "Epoch 258/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4486e-07 - mse: 3.4486e-07 - val_loss: 2.3388e-06 - val_mse: 2.3388e-06\n",
      "Epoch 259/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1656e-05 - mse: 1.1656e-05 - val_loss: 7.9115e-05 - val_mse: 7.9115e-05\n",
      "Epoch 260/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8083e-04 - mse: 1.8083e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 261/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 262/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 263/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0554 - val_mse: 0.0554\n",
      "Epoch 264/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 6.5401e-05 - val_mse: 6.5401e-05\n",
      "Epoch 265/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 266/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1048 - mse: 0.1048 - val_loss: 0.3774 - val_mse: 0.3774\n",
      "Epoch 267/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1671 - mse: 0.1671 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 268/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0427 - mse: 0.0427 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 269/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 9.0069e-04 - val_mse: 9.0069e-04\n",
      "Epoch 270/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 8.9453e-06 - val_mse: 8.9453e-06\n",
      "Epoch 271/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4245e-05 - mse: 2.4245e-05 - val_loss: 3.9582e-06 - val_mse: 3.9582e-06\n",
      "Epoch 272/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4627e-05 - mse: 5.4627e-05 - val_loss: 3.1559e-05 - val_mse: 3.1559e-05\n",
      "Epoch 273/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2058e-06 - mse: 4.2058e-06 - val_loss: 3.0710e-07 - val_mse: 3.0710e-07\n",
      "Epoch 274/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0854e-07 - mse: 1.0854e-07 - val_loss: 5.2992e-08 - val_mse: 5.2992e-08\n",
      "Epoch 275/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3178e-06 - mse: 1.3178e-06 - val_loss: 3.5529e-06 - val_mse: 3.5529e-06\n",
      "Epoch 276/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5879e-06 - mse: 5.5879e-06 - val_loss: 7.0222e-08 - val_mse: 7.0222e-08\n",
      "Epoch 277/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4430e-07 - mse: 3.4430e-07 - val_loss: 1.4435e-08 - val_mse: 1.4435e-08\n",
      "Epoch 278/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8049e-08 - mse: 2.8049e-08 - val_loss: 6.6124e-08 - val_mse: 6.6124e-08\n",
      "Epoch 279/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.1696e-08 - mse: 3.1696e-08 - val_loss: 5.9679e-07 - val_mse: 5.9679e-07\n",
      "Epoch 280/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8263e-07 - mse: 2.8263e-07 - val_loss: 6.7092e-07 - val_mse: 6.7092e-07\n",
      "Epoch 281/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6831e-07 - mse: 2.6831e-07 - val_loss: 5.2960e-06 - val_mse: 5.2960e-06\n",
      "Epoch 282/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8181e-06 - mse: 3.8181e-06 - val_loss: 1.5727e-05 - val_mse: 1.5727e-05\n",
      "Epoch 283/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9170e-06 - mse: 6.9170e-06 - val_loss: 1.7862e-05 - val_mse: 1.7862e-05\n",
      "Epoch 284/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7444e-05 - mse: 2.7444e-05 - val_loss: 2.4203e-05 - val_mse: 2.4203e-05\n",
      "Epoch 285/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5009e-06 - mse: 5.5009e-06 - val_loss: 2.3918e-05 - val_mse: 2.3918e-05\n",
      "Epoch 286/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4207e-05 - mse: 4.4207e-05 - val_loss: 8.1702e-06 - val_mse: 8.1702e-06\n",
      "Epoch 287/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7942e-04 - mse: 3.7942e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 288/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0609 - mse: 0.0609 - val_loss: 0.7633 - val_mse: 0.7633\n",
      "Epoch 289/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1523 - mse: 0.1523 - val_loss: 0.1108 - val_mse: 0.1108\n",
      "Epoch 290/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2759 - mse: 0.2759 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 291/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 292/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 3.0332e-04 - val_mse: 3.0332e-04\n",
      "Epoch 293/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.5333e-04 - mse: 8.5333e-04 - val_loss: 3.6801e-04 - val_mse: 3.6801e-04\n",
      "Epoch 294/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8283e-04 - mse: 1.8283e-04 - val_loss: 2.2441e-05 - val_mse: 2.2441e-05\n",
      "Epoch 295/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.7406e-06 - mse: 8.7406e-06 - val_loss: 1.5132e-05 - val_mse: 1.5132e-05\n",
      "Epoch 296/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2207e-06 - mse: 2.2207e-06 - val_loss: 5.3323e-07 - val_mse: 5.3323e-07\n",
      "Epoch 297/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4273e-06 - mse: 1.4273e-06 - val_loss: 1.5427e-07 - val_mse: 1.5427e-07\n",
      "Epoch 298/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5488e-07 - mse: 4.5488e-07 - val_loss: 6.0028e-07 - val_mse: 6.0028e-07\n",
      "Epoch 299/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7984e-06 - mse: 1.7984e-06 - val_loss: 4.6955e-06 - val_mse: 4.6955e-06\n",
      "Epoch 300/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3344e-05 - mse: 4.3344e-05 - val_loss: 2.0763e-06 - val_mse: 2.0763e-06\n",
      "Epoch 301/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6311e-04 - mse: 1.6311e-04 - val_loss: 9.1010e-06 - val_mse: 9.1010e-06\n",
      "Epoch 302/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6776e-04 - mse: 2.6776e-04 - val_loss: 2.5912e-04 - val_mse: 2.5912e-04\n",
      "Epoch 303/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.5038e-05 - mse: 8.5038e-05 - val_loss: 3.2352e-05 - val_mse: 3.2352e-05\n",
      "Epoch 304/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3877e-04 - mse: 1.3877e-04 - val_loss: 9.6278e-04 - val_mse: 9.6278e-04\n",
      "Epoch 305/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2017e-04 - mse: 4.2017e-04 - val_loss: 4.7530e-06 - val_mse: 4.7530e-06\n",
      "Epoch 306/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1212e-05 - mse: 2.1212e-05 - val_loss: 3.0758e-06 - val_mse: 3.0758e-06\n",
      "Epoch 307/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9254e-05 - mse: 2.9254e-05 - val_loss: 3.3179e-05 - val_mse: 3.3179e-05\n",
      "Epoch 308/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2742e-04 - mse: 1.2742e-04 - val_loss: 1.6723e-04 - val_mse: 1.6723e-04\n",
      "Epoch 309/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7297e-04 - mse: 1.7297e-04 - val_loss: 8.8903e-05 - val_mse: 8.8903e-05\n",
      "Epoch 310/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 7.5054e-04 - val_mse: 7.5054e-04\n",
      "Epoch 311/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.1026 - val_mse: 0.1026\n",
      "Epoch 312/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1981 - mse: 0.1981 - val_loss: 9.1845e-05 - val_mse: 9.1845e-05\n",
      "Epoch 313/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 314/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3356e-04 - mse: 8.3356e-04 - val_loss: 1.5205e-04 - val_mse: 1.5205e-04\n",
      "Epoch 315/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9119e-05 - mse: 8.9119e-05 - val_loss: 4.7049e-05 - val_mse: 4.7049e-05\n",
      "Epoch 316/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3110e-05 - mse: 1.3110e-05 - val_loss: 3.4119e-07 - val_mse: 3.4119e-07\n",
      "Epoch 317/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6621e-05 - mse: 3.6621e-05 - val_loss: 4.3582e-05 - val_mse: 4.3582e-05\n",
      "Epoch 318/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6637e-05 - mse: 3.6637e-05 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 319/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0939e-04 - mse: 2.0939e-04 - val_loss: 3.4020e-06 - val_mse: 3.4020e-06\n",
      "Epoch 320/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.0541e-04 - mse: 8.0541e-04 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 321/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0479 - val_mse: 0.0479\n",
      "Epoch 322/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0791 - mse: 0.0791 - val_loss: 1.8957 - val_mse: 1.8957\n",
      "Epoch 323/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2160 - mse: 0.2160 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 324/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 6.3014e-04 - val_mse: 6.3014e-04\n",
      "Epoch 325/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.6245e-05 - mse: 9.6245e-05 - val_loss: 4.4636e-04 - val_mse: 4.4636e-04\n",
      "Epoch 326/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6184e-04 - mse: 1.6184e-04 - val_loss: 3.4437e-05 - val_mse: 3.4437e-05\n",
      "Epoch 327/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.9906e-05 - mse: 9.9906e-05 - val_loss: 3.0394e-05 - val_mse: 3.0394e-05\n",
      "Epoch 328/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.8912e-06 - mse: 6.8912e-06 - val_loss: 4.1509e-07 - val_mse: 4.1509e-07\n",
      "Epoch 329/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.6983e-08 - mse: 8.6983e-08 - val_loss: 1.1036e-08 - val_mse: 1.1036e-08\n",
      "Epoch 330/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.8022e-09 - mse: 6.8022e-09 - val_loss: 1.8282e-07 - val_mse: 1.8282e-07\n",
      "Epoch 331/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0017e-07 - mse: 1.0017e-07 - val_loss: 2.3283e-10 - val_mse: 2.3283e-10\n",
      "Epoch 332/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4436e-09 - mse: 5.4436e-09 - val_loss: 1.3784e-08 - val_mse: 1.3784e-08\n",
      "Epoch 333/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0682e-09 - mse: 5.0682e-09 - val_loss: 4.9779e-08 - val_mse: 4.9779e-08\n",
      "Epoch 334/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3198e-08 - mse: 2.3198e-08 - val_loss: 9.3132e-10 - val_mse: 9.3132e-10\n",
      "Epoch 335/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1171e-08 - mse: 1.1171e-08 - val_loss: 4.4890e-08 - val_mse: 4.4890e-08\n",
      "Epoch 336/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6704e-08 - mse: 2.6704e-08 - val_loss: 1.2899e-08 - val_mse: 1.2899e-08\n",
      "Epoch 337/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9430e-07 - mse: 2.9430e-07 - val_loss: 4.5944e-06 - val_mse: 4.5944e-06\n",
      "Epoch 338/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3672e-05 - mse: 2.3672e-05 - val_loss: 1.2095e-04 - val_mse: 1.2095e-04\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step - loss: 8.7755e-05 - mse: 8.7755e-05 - val_loss: 1.0372e-04 - val_mse: 1.0372e-04\n",
      "Epoch 340/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 341/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1442 - mse: 0.1442 - val_loss: 0.8331 - val_mse: 0.8331\n",
      "Epoch 342/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8239 - mse: 1.8239 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 343/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0553 - mse: 0.0553 - val_loss: 3.5925e-04 - val_mse: 3.5925e-04\n",
      "Epoch 344/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0086e-05 - mse: 5.0086e-05 - val_loss: 4.1119e-06 - val_mse: 4.1119e-06\n",
      "Epoch 345/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.7353e-06 - mse: 4.7353e-06 - val_loss: 3.8580e-07 - val_mse: 3.8580e-07\n",
      "Epoch 346/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9182e-08 - mse: 8.9182e-08 - val_loss: 2.6962e-08 - val_mse: 2.6962e-08\n",
      "Epoch 347/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8849e-09 - mse: 3.8849e-09 - val_loss: 1.3551e-08 - val_mse: 1.3551e-08\n",
      "Epoch 348/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.4958e-09 - mse: 6.4958e-09 - val_loss: 6.5193e-10 - val_mse: 6.5193e-10\n",
      "Epoch 349/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3134e-10 - mse: 7.3134e-10 - val_loss: 9.7789e-10 - val_mse: 9.7789e-10\n",
      "Epoch 350/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9033e-09 - mse: 2.9033e-09 - val_loss: 4.5588e-08 - val_mse: 4.5588e-08\n",
      "Epoch 351/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0035e-08 - mse: 1.0035e-08 - val_loss: 3.7532e-08 - val_mse: 3.7532e-08\n",
      "Epoch 352/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1887e-08 - mse: 2.1887e-08 - val_loss: 4.7963e-09 - val_mse: 4.7963e-09\n",
      "Epoch 353/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2075e-09 - mse: 7.2075e-09 - val_loss: 1.2806e-08 - val_mse: 1.2806e-08\n",
      "Epoch 354/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4267e-09 - mse: 2.4267e-09 - val_loss: 1.9791e-08 - val_mse: 1.9791e-08\n",
      "Epoch 355/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3419e-09 - mse: 6.3419e-09 - val_loss: 2.7055e-08 - val_mse: 2.7055e-08\n",
      "Epoch 356/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9674e-09 - mse: 5.9674e-09 - val_loss: 4.5635e-09 - val_mse: 4.5635e-09\n",
      "Epoch 357/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9441e-09 - mse: 1.9441e-09 - val_loss: 1.8626e-10 - val_mse: 1.8626e-10\n",
      "Epoch 358/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8278e-09 - mse: 1.8278e-09 - val_loss: 1.3644e-08 - val_mse: 1.3644e-08\n",
      "Epoch 359/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1976e-09 - mse: 4.1976e-09 - val_loss: 1.6857e-08 - val_mse: 1.6857e-08\n",
      "Epoch 360/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8269e-09 - mse: 1.8269e-09 - val_loss: 5.3085e-09 - val_mse: 5.3085e-09\n",
      "Epoch 361/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9845e-09 - mse: 2.9845e-09 - val_loss: 2.5611e-08 - val_mse: 2.5611e-08\n",
      "Epoch 362/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.6757e-08 - mse: 7.6757e-08 - val_loss: 3.2270e-08 - val_mse: 3.2270e-08\n",
      "Epoch 363/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2857e-08 - mse: 2.2857e-08 - val_loss: 2.3283e-09 - val_mse: 2.3283e-09\n",
      "Epoch 364/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2927e-08 - mse: 1.2927e-08 - val_loss: 4.9826e-09 - val_mse: 4.9826e-09\n",
      "Epoch 365/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.4960e-09 - mse: 7.4960e-09 - val_loss: 1.3132e-08 - val_mse: 1.3132e-08\n",
      "Epoch 366/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7532e-08 - mse: 2.7532e-08 - val_loss: 2.7008e-09 - val_mse: 2.7008e-09\n",
      "Epoch 367/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4889e-09 - mse: 4.4889e-09 - val_loss: 4.8429e-09 - val_mse: 4.8429e-09\n",
      "Epoch 368/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0002e-08 - mse: 5.0002e-08 - val_loss: 1.3970e-09 - val_mse: 1.3970e-09\n",
      "Epoch 369/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4699e-08 - mse: 1.4699e-08 - val_loss: 1.9278e-08 - val_mse: 1.9278e-08\n",
      "Epoch 370/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6779e-08 - mse: 2.6779e-08 - val_loss: 6.0536e-10 - val_mse: 6.0536e-10\n",
      "Epoch 371/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.0142e-09 - mse: 7.0142e-09 - val_loss: 5.8627e-08 - val_mse: 5.8627e-08\n",
      "Epoch 372/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.2485e-08 - mse: 6.2485e-08 - val_loss: 4.0047e-09 - val_mse: 4.0047e-09\n",
      "Epoch 373/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3351e-07 - mse: 4.3351e-07 - val_loss: 1.1633e-06 - val_mse: 1.1633e-06\n",
      "Epoch 374/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9370e-06 - mse: 2.9370e-06 - val_loss: 3.6493e-04 - val_mse: 3.6493e-04\n",
      "Epoch 375/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1667e-04 - mse: 1.1667e-04 - val_loss: 1.8333e-04 - val_mse: 1.8333e-04\n",
      "Epoch 376/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.9919e-04 - mse: 4.9919e-04 - val_loss: 4.7826e-05 - val_mse: 4.7826e-05\n",
      "Epoch 377/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.6629e-04 - mse: 4.6629e-04 - val_loss: 4.6752e-07 - val_mse: 4.6752e-07\n",
      "Epoch 378/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 379/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2100 - mse: 0.2100 - val_loss: 7.1923 - val_mse: 7.1923\n",
      "Epoch 380/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5552 - mse: 3.5552 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 381/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0723 - mse: 0.0723 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 382/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8373e-04 - mse: 2.8373e-04 - val_loss: 8.3885e-05 - val_mse: 8.3885e-05\n",
      "Epoch 383/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1238e-05 - mse: 1.1238e-05 - val_loss: 1.5362e-06 - val_mse: 1.5362e-06\n",
      "Epoch 384/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.3965e-07 - mse: 5.3965e-07 - val_loss: 2.8093e-07 - val_mse: 2.8093e-07\n",
      "Epoch 385/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7568e-08 - mse: 6.7568e-08 - val_loss: 1.6345e-08 - val_mse: 1.6345e-08\n",
      "Epoch 386/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0438e-09 - mse: 3.0438e-09 - val_loss: 6.0536e-10 - val_mse: 6.0536e-10\n",
      "Epoch 387/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1018e-09 - mse: 1.1018e-09 - val_loss: 4.1910e-10 - val_mse: 4.1910e-10\n",
      "Epoch 388/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0736e-09 - mse: 1.0736e-09 - val_loss: 3.2131e-09 - val_mse: 3.2131e-09\n",
      "Epoch 389/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4048e-09 - mse: 1.4048e-09 - val_loss: 1.1735e-08 - val_mse: 1.1735e-08\n",
      "Epoch 390/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.9896e-09 - mse: 4.9896e-09 - val_loss: 9.7789e-10 - val_mse: 9.7789e-10\n",
      "Epoch 391/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0978e-09 - mse: 2.0978e-09 - val_loss: 4.1910e-10 - val_mse: 4.1910e-10\n",
      "Epoch 392/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3286e-09 - mse: 2.3286e-09 - val_loss: 7.4506e-10 - val_mse: 7.4506e-10\n",
      "Epoch 393/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3891e-10 - mse: 3.3891e-10 - val_loss: 1.8626e-10 - val_mse: 1.8626e-10\n",
      "Epoch 394/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.6953e-10 - mse: 8.6953e-10 - val_loss: 3.5856e-09 - val_mse: 3.5856e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0969e-09 - mse: 1.0969e-09 - val_loss: 7.0781e-09 - val_mse: 7.0781e-09\n",
      "Epoch 396/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0531e-09 - mse: 2.0531e-09 - val_loss: 5.1223e-10 - val_mse: 5.1223e-10\n",
      "Epoch 397/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0046e-09 - mse: 4.0046e-09 - val_loss: 1.7695e-08 - val_mse: 1.7695e-08\n",
      "Epoch 398/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.7329e-09 - mse: 5.7329e-09 - val_loss: 5.5879e-10 - val_mse: 5.5879e-10\n",
      "Epoch 399/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.8915e-10 - mse: 5.8915e-10 - val_loss: 7.2643e-09 - val_mse: 7.2643e-09\n",
      "Epoch 400/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9355e-09 - mse: 5.9355e-09 - val_loss: 2.2352e-09 - val_mse: 2.2352e-09\n",
      "Epoch 401/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.1625e-09 - mse: 6.1625e-09 - val_loss: 4.6566e-10 - val_mse: 4.6566e-10\n",
      "Epoch 402/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1089e-10 - mse: 4.1089e-10 - val_loss: 2.9337e-09 - val_mse: 2.9337e-09\n",
      "Epoch 403/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0195e-09 - mse: 3.0195e-09 - val_loss: 9.3132e-10 - val_mse: 9.3132e-10\n",
      "Epoch 404/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9181e-09 - mse: 5.9181e-09 - val_loss: 5.1688e-09 - val_mse: 5.1688e-09\n",
      "Epoch 405/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4793e-09 - mse: 1.4793e-09 - val_loss: 2.1141e-08 - val_mse: 2.1141e-08\n",
      "Epoch 406/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2712e-09 - mse: 3.2712e-09 - val_loss: 4.6566e-10 - val_mse: 4.6566e-10\n",
      "Epoch 407/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8625e-08 - mse: 1.8625e-08 - val_loss: 6.1421e-08 - val_mse: 6.1421e-08\n",
      "Epoch 408/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3636e-09 - mse: 8.3636e-09 - val_loss: 4.4098e-08 - val_mse: 4.4098e-08\n",
      "Epoch 409/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5918e-08 - mse: 2.5918e-08 - val_loss: 1.0757e-08 - val_mse: 1.0757e-08\n",
      "Epoch 410/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.8945e-09 - mse: 8.8945e-09 - val_loss: 3.2596e-10 - val_mse: 3.2596e-10\n",
      "Epoch 411/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6994e-09 - mse: 3.6994e-09 - val_loss: 1.8487e-08 - val_mse: 1.8487e-08\n",
      "Epoch 412/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3742e-08 - mse: 1.3742e-08 - val_loss: 8.7032e-08 - val_mse: 8.7032e-08\n",
      "Epoch 413/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4538e-07 - mse: 2.4538e-07 - val_loss: 6.6832e-07 - val_mse: 6.6832e-07\n",
      "Epoch 414/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3170e-07 - mse: 2.3170e-07 - val_loss: 1.0728e-06 - val_mse: 1.0728e-06\n",
      "Epoch 415/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1122e-07 - mse: 2.1122e-07 - val_loss: 4.9639e-08 - val_mse: 4.9639e-08\n",
      "Epoch 416/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.3368e-06 - mse: 5.3368e-06 - val_loss: 2.1466e-06 - val_mse: 2.1466e-06\n",
      "Epoch 417/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9623e-05 - mse: 1.9623e-05 - val_loss: 1.6871e-04 - val_mse: 1.6871e-04\n",
      "Epoch 418/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9300e-04 - mse: 1.9300e-04 - val_loss: 1.2758e-04 - val_mse: 1.2758e-04\n",
      "Epoch 419/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4530e-04 - mse: 5.4530e-04 - val_loss: 1.4361e-05 - val_mse: 1.4361e-05\n",
      "Epoch 420/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.9883e-04 - mse: 4.9883e-04 - val_loss: 5.0001e-04 - val_mse: 5.0001e-04\n",
      "Epoch 421/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6515e-04 - mse: 6.6515e-04 - val_loss: 1.0157e-04 - val_mse: 1.0157e-04\n",
      "Epoch 422/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4782e-04 - mse: 2.4782e-04 - val_loss: 6.1304e-07 - val_mse: 6.1304e-07\n",
      "Epoch 423/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1139e-05 - mse: 1.1139e-05 - val_loss: 4.5397e-05 - val_mse: 4.5397e-05\n",
      "Epoch 424/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5818e-05 - mse: 1.5818e-05 - val_loss: 2.1996e-05 - val_mse: 2.1996e-05\n",
      "Epoch 425/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3456e-05 - mse: 7.3456e-05 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 426/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 5.1137e-05 - val_mse: 5.1137e-05\n",
      "Epoch 427/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.6010e-05 - mse: 7.6010e-05 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 428/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 429/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1490 - mse: 0.1490 - val_loss: 0.9918 - val_mse: 0.9918\n",
      "Epoch 430/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6988 - mse: 0.6988 - val_loss: 0.6204 - val_mse: 0.6204\n",
      "Epoch 431/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3166 - mse: 0.3166 - val_loss: 0.0493 - val_mse: 0.0493\n",
      "Epoch 432/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 433/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 4.7919e-05 - val_mse: 4.7919e-05\n",
      "Epoch 434/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 435/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7109e-05 - mse: 3.7109e-05 - val_loss: 8.3633e-08 - val_mse: 8.3633e-08\n",
      "Epoch 436/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3946e-07 - mse: 2.3946e-07 - val_loss: 1.2824e-07 - val_mse: 1.2824e-07\n",
      "Epoch 437/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3694e-08 - mse: 2.3694e-08 - val_loss: 1.9092e-09 - val_mse: 1.9092e-09\n",
      "Epoch 438/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6221e-08 - mse: 6.6221e-08 - val_loss: 4.9360e-09 - val_mse: 4.9360e-09\n",
      "Epoch 439/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.8433e-10 - mse: 9.8433e-10 - val_loss: 6.5193e-10 - val_mse: 6.5193e-10\n",
      "Epoch 440/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4580e-09 - mse: 3.4580e-09 - val_loss: 2.2212e-08 - val_mse: 2.2212e-08\n",
      "Epoch 441/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3039e-08 - mse: 1.3039e-08 - val_loss: 1.1269e-08 - val_mse: 1.1269e-08\n",
      "Epoch 442/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.8331e-08 - mse: 5.8331e-08 - val_loss: 2.6543e-09 - val_mse: 2.6543e-09\n",
      "Epoch 443/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4976e-09 - mse: 5.4976e-09 - val_loss: 1.1083e-08 - val_mse: 1.1083e-08\n",
      "Epoch 444/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.6392e-09 - mse: 8.6392e-09 - val_loss: 1.3970e-10 - val_mse: 1.3970e-10\n",
      "Epoch 445/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6976e-08 - mse: 1.6976e-08 - val_loss: 4.6566e-10 - val_mse: 4.6566e-10\n",
      "Epoch 446/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2864e-09 - mse: 7.2864e-09 - val_loss: 1.5050e-07 - val_mse: 1.5050e-07\n",
      "Epoch 447/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2900e-08 - mse: 3.2900e-08 - val_loss: 2.9290e-08 - val_mse: 2.9290e-08\n",
      "Epoch 448/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1571e-08 - mse: 2.1571e-08 - val_loss: 9.2201e-09 - val_mse: 9.2201e-09\n",
      "Epoch 449/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3025e-08 - mse: 1.3025e-08 - val_loss: 1.9446e-07 - val_mse: 1.9446e-07\n",
      "Epoch 450/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0419e-07 - mse: 1.0419e-07 - val_loss: 1.1000e-06 - val_mse: 1.1000e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7469e-07 - mse: 6.7469e-07 - val_loss: 3.9111e-07 - val_mse: 3.9111e-07\n",
      "Epoch 452/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8035e-06 - mse: 1.8035e-06 - val_loss: 7.0548e-08 - val_mse: 7.0548e-08\n",
      "Epoch 453/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0737e-06 - mse: 4.0737e-06 - val_loss: 5.3306e-05 - val_mse: 5.3306e-05\n",
      "Epoch 454/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.6664e-04 - mse: 5.6664e-04 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 455/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0719 - val_mse: 0.0719\n",
      "Epoch 456/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0510 - mse: 0.0510 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 457/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 458/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 459/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 2.6200e-04 - val_mse: 2.6200e-04\n",
      "Epoch 460/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 6.7698e-06 - val_mse: 6.7698e-06\n",
      "Epoch 461/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.4323 - val_mse: 0.4323\n",
      "Epoch 462/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2407 - mse: 0.2407 - val_loss: 0.1019 - val_mse: 0.1019\n",
      "Epoch 463/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0445 - mse: 0.0445 - val_loss: 3.8230e-04 - val_mse: 3.8230e-04\n",
      "Epoch 464/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8316e-05 - mse: 7.8316e-05 - val_loss: 5.5388e-06 - val_mse: 5.5388e-06\n",
      "Epoch 465/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0321e-05 - mse: 1.0321e-05 - val_loss: 3.6925e-06 - val_mse: 3.6925e-06\n",
      "Epoch 466/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4438e-05 - mse: 2.4438e-05 - val_loss: 9.3104e-07 - val_mse: 9.3104e-07\n",
      "Epoch 467/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1506e-05 - mse: 1.1506e-05 - val_loss: 2.7055e-08 - val_mse: 2.7055e-08\n",
      "Epoch 468/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3211e-08 - mse: 2.3211e-08 - val_loss: 2.1192e-07 - val_mse: 2.1192e-07\n",
      "Epoch 469/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.1680e-07 - mse: 6.1680e-07 - val_loss: 2.7148e-08 - val_mse: 2.7148e-08\n",
      "Epoch 470/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0220e-08 - mse: 5.0220e-08 - val_loss: 1.1120e-07 - val_mse: 1.1120e-07\n",
      "Epoch 471/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5578e-08 - mse: 2.5578e-08 - val_loss: 2.7940e-10 - val_mse: 2.7940e-10\n",
      "Epoch 472/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3335e-08 - mse: 1.3335e-08 - val_loss: 3.4506e-08 - val_mse: 3.4506e-08\n",
      "Epoch 473/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4364e-08 - mse: 1.4364e-08 - val_loss: 4.2794e-08 - val_mse: 4.2794e-08\n",
      "Epoch 474/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2957e-07 - mse: 1.2957e-07 - val_loss: 1.5800e-05 - val_mse: 1.5800e-05\n",
      "Epoch 475/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0085e-05 - mse: 4.0085e-05 - val_loss: 8.6427e-06 - val_mse: 8.6427e-06\n",
      "Epoch 476/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.1392e-04 - mse: 4.1392e-04 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 477/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0563 - mse: 0.0563 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 478/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0718 - mse: 0.0718 - val_loss: 0.3563 - val_mse: 0.3563\n",
      "Epoch 479/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1396 - mse: 0.1396 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 480/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 481/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 482/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 483/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 484/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 485/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 486/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 6.7340e-04 - val_mse: 6.7340e-04\n",
      "Epoch 487/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 488/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 8.4789e-05 - val_mse: 8.4789e-05\n",
      "Epoch 489/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6449e-04 - mse: 1.6449e-04 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 490/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 491/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 492/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5365e-04 - mse: 3.5365e-04 - val_loss: 1.8068e-04 - val_mse: 1.8068e-04\n",
      "Epoch 493/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7459e-04 - mse: 6.7459e-04 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 494/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 495/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 496/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 497/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 498/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.4744 - val_mse: 0.4744\n",
      "Epoch 499/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4449 - mse: 0.4449 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 500/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1446 - mse: 0.1446 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "20/20 [==============================] - 0s 512us/step - loss: 0.4329 - mse: 0.4329\n",
      "mse : [0.43290072679519653, 0.43290072679519653]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=False, test_size=0.4)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, shuffle=False, test_size=0.5)\n",
    "\n",
    "# 2. 모델 구성\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "input_layer = Input(shape=(2, ))\n",
    "d = Dense(5, activation='relu')(input_layer)\n",
    "d = Dense(3)(d)\n",
    "d = Dense(4)(d)\n",
    "output_layer = Dense(1)(d)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# 3. 훈련\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=500, validation_data=(x_val, y_val))\n",
    "\n",
    "# 4. 평가 예측\n",
    "mse = model.evaluate(x_test, y_test, batch_size=1)\n",
    "print('mse :', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 80, 381],\n",
       "       [ 81, 382],\n",
       "       [ 82, 383],\n",
       "       [ 83, 384],\n",
       "       [ 84, 385]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[280.90585]\n",
      " [281.90472]\n",
      " [282.9036 ]\n",
      " [283.90247]\n",
      " [284.9014 ]\n",
      " [285.90027]\n",
      " [286.89914]\n",
      " [287.9752 ]\n",
      " [289.0931 ]\n",
      " [290.211  ]\n",
      " [291.32895]\n",
      " [292.4469 ]\n",
      " [293.56482]\n",
      " [294.68277]\n",
      " [295.8007 ]\n",
      " [296.9186 ]\n",
      " [298.0366 ]\n",
      " [299.1545 ]\n",
      " [300.2724 ]\n",
      " [301.39038]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  0.6579528627128542\n",
      "r2_score :  0.9869803918931718\n"
     ]
    }
   ],
   "source": [
    "# RMSE \n",
    "from sklearn.metrics import mean_squared_error\n",
    "def RMSE(y_test, y_predict):\n",
    "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "print('RMSE : ', RMSE(y_test, y_predict))\n",
    "\n",
    "# r2\n",
    "from sklearn.metrics import r2_score\n",
    "print('r2_score : ', r2_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지표모두 괜찮게 나옴. 3개 이상의 컬럼에 대해서도 위와 같은 방식으로 적용해서 모델링하면됨.  \n",
    "실제로 해커톤이나, 공모전 캐글 같은 경우에 수없이 많은 컬럼들이 제공되기도 함.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1:다\n",
    "1개의 컬럼이 입력되어 여러개의 컬럼으로 출력되는 경우가 있을 수 있음. 데이터 자체로 봐서는 다소 이상한 모델일 수 있지만  \n",
    "구현이 가능하다는 점을 짚고 넘어가면 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,) (2, 100)\n",
      "(100,)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "# 1.데이터 준비\n",
    "import numpy as np \n",
    "\n",
    "x = np.array(range(100))\n",
    "y = np.array([range(201, 301), range(301, 401)])\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "# 행,열 변환\n",
    "x = np.transpose(x)\n",
    "y = np.transpose(y)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x 는 (100,) y 는 (100,2)의 shape 을 가지고 있는 데이터임.  \n",
    "나머지 코드는 앞의 코드와 동일하고, 입력과 출력의 shape 부분만 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 81473.2818 - mse: 81473.2818 - val_loss: 101830.8438 - val_mse: 101830.8438\n",
      "Epoch 2/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 80676.4777 - mse: 80676.4777 - val_loss: 94796.3906 - val_mse: 94796.3906\n",
      "Epoch 3/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 75450.7468 - mse: 75450.7468 - val_loss: 79056.6172 - val_mse: 79056.6172\n",
      "Epoch 4/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 68695.8144 - mse: 68695.8144 - val_loss: 52924.9453 - val_mse: 52924.9453\n",
      "Epoch 5/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 55310.4569 - mse: 55310.4569 - val_loss: 22084.0117 - val_mse: 22084.0117\n",
      "Epoch 6/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 39971.4095 - mse: 39971.4095 - val_loss: 4267.7124 - val_mse: 4267.7124\n",
      "Epoch 7/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 26808.2976 - mse: 26808.2976 - val_loss: 15888.6699 - val_mse: 15888.6699\n",
      "Epoch 8/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 19432.4932 - mse: 19432.4932 - val_loss: 30841.0664 - val_mse: 30841.0664\n",
      "Epoch 9/500\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17785.5554 - mse: 17785.5554 - val_loss: 31853.4121 - val_mse: 31853.4121\n",
      "Epoch 10/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 16986.0912 - mse: 16986.0912 - val_loss: 36114.0625 - val_mse: 36114.0625\n",
      "Epoch 11/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 18069.5739 - mse: 18069.5739 - val_loss: 34438.6328 - val_mse: 34438.6328\n",
      "Epoch 12/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 12230.8203 - mse: 12230.8203 - val_loss: 35920.7656 - val_mse: 35920.7656\n",
      "Epoch 13/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 15364.0861 - mse: 15364.0861 - val_loss: 36927.0781 - val_mse: 36927.0781\n",
      "Epoch 14/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 14125.7183 - mse: 14125.7183 - val_loss: 38408.7070 - val_mse: 38408.7070\n",
      "Epoch 15/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 17264.8377 - mse: 17264.8377 - val_loss: 36420.9258 - val_mse: 36420.9258\n",
      "Epoch 16/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 15270.7116 - mse: 15270.7116 - val_loss: 36408.6250 - val_mse: 36408.6250\n",
      "Epoch 17/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 16067.0194 - mse: 16067.0194 - val_loss: 36335.9062 - val_mse: 36335.9062\n",
      "Epoch 18/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 10727.4029 - mse: 10727.4029 - val_loss: 34642.6211 - val_mse: 34642.6211\n",
      "Epoch 19/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 15017.3986 - mse: 15017.3986 - val_loss: 32323.6191 - val_mse: 32323.6191\n",
      "Epoch 20/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 16431.4190 - mse: 16431.4190 - val_loss: 33680.6719 - val_mse: 33680.6719\n",
      "Epoch 21/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 14605.7151 - mse: 14605.7151 - val_loss: 37389.5312 - val_mse: 37389.5312\n",
      "Epoch 22/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 13960.7762 - mse: 13960.7762 - val_loss: 34112.8516 - val_mse: 34112.8516\n",
      "Epoch 23/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 10962.3758 - mse: 10962.3758 - val_loss: 35642.5859 - val_mse: 35642.5859\n",
      "Epoch 24/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 13440.9735 - mse: 13440.9735 - val_loss: 35818.2539 - val_mse: 35818.2539\n",
      "Epoch 25/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 13813.0868 - mse: 13813.0868 - val_loss: 35356.4844 - val_mse: 35356.4844\n",
      "Epoch 26/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 15647.5375 - mse: 15647.5375 - val_loss: 32479.0820 - val_mse: 32479.0820\n",
      "Epoch 27/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 13816.1138 - mse: 13816.1138 - val_loss: 35345.0664 - val_mse: 35345.0664\n",
      "Epoch 28/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 15888.2148 - mse: 15888.2148 - val_loss: 35912.6016 - val_mse: 35912.6016\n",
      "Epoch 29/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 13410.7208 - mse: 13410.7208 - val_loss: 34418.5547 - val_mse: 34418.5547\n",
      "Epoch 30/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 15376.0783 - mse: 15376.0783 - val_loss: 31735.3652 - val_mse: 31735.3652\n",
      "Epoch 31/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 14142.5031 - mse: 14142.5031 - val_loss: 33548.0391 - val_mse: 33548.0391\n",
      "Epoch 32/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9899.0450 - mse: 9899.0450 - val_loss: 32620.0254 - val_mse: 32620.0254\n",
      "Epoch 33/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 12407.9619 - mse: 12407.9619 - val_loss: 35436.5469 - val_mse: 35436.5469\n",
      "Epoch 34/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 12479.3074 - mse: 12479.3074 - val_loss: 32470.1621 - val_mse: 32470.1621\n",
      "Epoch 35/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 11695.5131 - mse: 11695.5131 - val_loss: 34145.7266 - val_mse: 34145.7266\n",
      "Epoch 36/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 12269.6065 - mse: 12269.6065 - val_loss: 32858.0625 - val_mse: 32858.0625\n",
      "Epoch 37/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 11923.1944 - mse: 11923.1944 - val_loss: 31914.9785 - val_mse: 31914.9785\n",
      "Epoch 38/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 16272.8166 - mse: 16272.8166 - val_loss: 33491.8359 - val_mse: 33491.8359\n",
      "Epoch 39/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 11740.3353 - mse: 11740.3353 - val_loss: 32438.7129 - val_mse: 32438.7129\n",
      "Epoch 40/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 12320.0206 - mse: 12320.0206 - val_loss: 31700.9023 - val_mse: 31700.9023\n",
      "Epoch 41/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 10942.4640 - mse: 10942.4640 - val_loss: 31622.0508 - val_mse: 31622.0508\n",
      "Epoch 42/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 12544.8061 - mse: 12544.8061 - val_loss: 29924.1133 - val_mse: 29924.1133\n",
      "Epoch 43/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 10719.2029 - mse: 10719.2029 - val_loss: 30552.4648 - val_mse: 30552.4648\n",
      "Epoch 44/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 14285.5735 - mse: 14285.5735 - val_loss: 32306.7090 - val_mse: 32306.7090\n",
      "Epoch 45/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 13088.3281 - mse: 13088.3281 - val_loss: 30664.8223 - val_mse: 30664.8223\n",
      "Epoch 46/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 14446.9079 - mse: 14446.9079 - val_loss: 32094.4844 - val_mse: 32094.4844\n",
      "Epoch 47/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 10214.8719 - mse: 10214.8719 - val_loss: 31690.5039 - val_mse: 31690.5039\n",
      "Epoch 48/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8964.0304 - mse: 8964.0304 - val_loss: 30653.7344 - val_mse: 30653.7344\n",
      "Epoch 49/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 10417.3997 - mse: 10417.3997 - val_loss: 33379.1016 - val_mse: 33379.1016\n",
      "Epoch 50/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 11143.6432 - mse: 11143.6432 - val_loss: 33904.1016 - val_mse: 33904.1016\n",
      "Epoch 51/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 13973.7353 - mse: 13973.7353 - val_loss: 30130.2129 - val_mse: 30130.2129\n",
      "Epoch 52/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 12709.9206 - mse: 12709.9206 - val_loss: 30765.3496 - val_mse: 30765.3496\n",
      "Epoch 53/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 11934.8645 - mse: 11934.8645 - val_loss: 31950.9160 - val_mse: 31950.9160\n",
      "Epoch 54/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8299.8342 - mse: 8299.8342 - val_loss: 30002.4121 - val_mse: 30002.4121\n",
      "Epoch 55/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 11531.9630 - mse: 11531.9630 - val_loss: 30296.9062 - val_mse: 30296.9062\n",
      "Epoch 56/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 10751.5187 - mse: 10751.5187 - val_loss: 31187.6973 - val_mse: 31187.6973\n",
      "Epoch 57/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 11336.2328 - mse: 11336.2328 - val_loss: 28003.6719 - val_mse: 28003.6719\n",
      "Epoch 58/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 10899.6800 - mse: 10899.6800 - val_loss: 28771.1250 - val_mse: 28771.1250\n",
      "Epoch 59/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 12805.1906 - mse: 12805.1906 - val_loss: 29280.6660 - val_mse: 29280.6660\n",
      "Epoch 60/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 12137.4342 - mse: 12137.4342 - val_loss: 27892.7930 - val_mse: 27892.7930\n",
      "Epoch 61/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9920.7010 - mse: 9920.7010 - val_loss: 29905.6191 - val_mse: 29905.6191\n",
      "Epoch 62/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9041.9636 - mse: 9041.9636 - val_loss: 29423.0117 - val_mse: 29423.0117\n",
      "Epoch 63/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9330.3506 - mse: 9330.3506 - val_loss: 28564.8633 - val_mse: 28564.8633\n",
      "Epoch 64/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 10541.8646 - mse: 10541.8646 - val_loss: 29869.8379 - val_mse: 29869.8379\n",
      "Epoch 65/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9816.1258 - mse: 9816.1258 - val_loss: 28701.9434 - val_mse: 28701.9434\n",
      "Epoch 66/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 10412.5767 - mse: 10412.5767 - val_loss: 26492.1777 - val_mse: 26492.1777\n",
      "Epoch 67/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 12368.7004 - mse: 12368.7004 - val_loss: 26987.6348 - val_mse: 26987.6348\n",
      "Epoch 68/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 10805.3520 - mse: 10805.3520 - val_loss: 27278.1816 - val_mse: 27278.1816\n",
      "Epoch 69/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 13899.7933 - mse: 13899.7933 - val_loss: 27832.3340 - val_mse: 27832.3340\n",
      "Epoch 70/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7425.8887 - mse: 7425.8887 - val_loss: 26526.6055 - val_mse: 26526.6055\n",
      "Epoch 71/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 11077.0450 - mse: 11077.0450 - val_loss: 29387.1758 - val_mse: 29387.1758\n",
      "Epoch 72/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 11184.2332 - mse: 11184.2332 - val_loss: 25511.1523 - val_mse: 25511.1523\n",
      "Epoch 73/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9684.9559 - mse: 9684.9559 - val_loss: 25882.1562 - val_mse: 25882.1562\n",
      "Epoch 74/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 11254.1223 - mse: 11254.1223 - val_loss: 25194.9297 - val_mse: 25194.9297\n",
      "Epoch 75/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9500.5141 - mse: 9500.5141 - val_loss: 27463.4746 - val_mse: 27463.4746\n",
      "Epoch 76/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9937.0447 - mse: 9937.0447 - val_loss: 25593.9570 - val_mse: 25593.9570\n",
      "Epoch 77/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9468.5655 - mse: 9468.5655 - val_loss: 24860.4902 - val_mse: 24860.4902\n",
      "Epoch 78/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 11225.7067 - mse: 11225.7067 - val_loss: 25206.2930 - val_mse: 25206.2930\n",
      "Epoch 79/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8775.0659 - mse: 8775.0659 - val_loss: 24431.2773 - val_mse: 24431.2773\n",
      "Epoch 80/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9149.5292 - mse: 9149.5292 - val_loss: 25128.3379 - val_mse: 25128.3379\n",
      "Epoch 81/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8093.6215 - mse: 8093.6215 - val_loss: 25024.5762 - val_mse: 25024.5762\n",
      "Epoch 82/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8511.3582 - mse: 8511.3582 - val_loss: 23225.7500 - val_mse: 23225.7500\n",
      "Epoch 83/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8804.2535 - mse: 8804.2535 - val_loss: 23216.5742 - val_mse: 23216.5742\n",
      "Epoch 84/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8842.3044 - mse: 8842.3044 - val_loss: 22890.2773 - val_mse: 22890.2773\n",
      "Epoch 85/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6874.4581 - mse: 6874.4581 - val_loss: 22508.3242 - val_mse: 22508.3242\n",
      "Epoch 86/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9846.3873 - mse: 9846.3873 - val_loss: 23266.9590 - val_mse: 23266.9590\n",
      "Epoch 87/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9460.1468 - mse: 9460.1468 - val_loss: 21885.8945 - val_mse: 21885.8945\n",
      "Epoch 88/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8406.7014 - mse: 8406.7014 - val_loss: 21118.2852 - val_mse: 21118.2852\n",
      "Epoch 89/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7212.3376 - mse: 7212.3376 - val_loss: 21532.6211 - val_mse: 21532.6211\n",
      "Epoch 90/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6188.2283 - mse: 6188.2283 - val_loss: 21671.9062 - val_mse: 21671.9062\n",
      "Epoch 91/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8317.5456 - mse: 8317.5456 - val_loss: 19241.8262 - val_mse: 19241.8262\n",
      "Epoch 92/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6411.0475 - mse: 6411.0475 - val_loss: 19383.1289 - val_mse: 19383.1289\n",
      "Epoch 93/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6878.3404 - mse: 6878.3404 - val_loss: 20777.1738 - val_mse: 20777.1738\n",
      "Epoch 94/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9684.1702 - mse: 9684.1702 - val_loss: 19330.7148 - val_mse: 19330.7148\n",
      "Epoch 95/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5783.9404 - mse: 5783.9404 - val_loss: 19125.6523 - val_mse: 19125.6523\n",
      "Epoch 96/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6608.5819 - mse: 6608.5819 - val_loss: 17221.6543 - val_mse: 17221.6543\n",
      "Epoch 97/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6107.8933 - mse: 6107.8933 - val_loss: 16899.4727 - val_mse: 16899.4727\n",
      "Epoch 98/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6219.1543 - mse: 6219.1543 - val_loss: 17871.5566 - val_mse: 17871.5566\n",
      "Epoch 99/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6720.9754 - mse: 6720.9754 - val_loss: 17603.9414 - val_mse: 17603.9414\n",
      "Epoch 100/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6007.2007 - mse: 6007.2007 - val_loss: 15732.5449 - val_mse: 15732.5449\n",
      "Epoch 101/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7111.8933 - mse: 7111.8933 - val_loss: 15879.1152 - val_mse: 15879.1152\n",
      "Epoch 102/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6616.8815 - mse: 6616.8815 - val_loss: 14121.9688 - val_mse: 14121.9688\n",
      "Epoch 103/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5589.4185 - mse: 5589.4185 - val_loss: 16269.8691 - val_mse: 16269.8691\n",
      "Epoch 104/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5180.2220 - mse: 5180.2220 - val_loss: 15645.0420 - val_mse: 15645.0420\n",
      "Epoch 105/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5114.0262 - mse: 5114.0262 - val_loss: 15355.6172 - val_mse: 15355.6172\n",
      "Epoch 106/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4379.4904 - mse: 4379.4904 - val_loss: 16764.6934 - val_mse: 16764.6934\n",
      "Epoch 107/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4707.3876 - mse: 4707.3876 - val_loss: 13751.2627 - val_mse: 13751.2627\n",
      "Epoch 108/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4780.0118 - mse: 4780.0118 - val_loss: 13326.8535 - val_mse: 13326.8535\n",
      "Epoch 109/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3770.7639 - mse: 3770.7639 - val_loss: 13671.5986 - val_mse: 13671.5986\n",
      "Epoch 110/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3529.9994 - mse: 3529.9994 - val_loss: 13317.4092 - val_mse: 13317.4092\n",
      "Epoch 111/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3519.5740 - mse: 3519.5740 - val_loss: 11986.3770 - val_mse: 11986.3770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3255.3317 - mse: 3255.3317 - val_loss: 11237.5977 - val_mse: 11237.5977\n",
      "Epoch 113/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3183.9537 - mse: 3183.9537 - val_loss: 11026.8223 - val_mse: 11026.8223\n",
      "Epoch 114/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1875.9882 - mse: 1875.9882 - val_loss: 11036.7158 - val_mse: 11036.7158\n",
      "Epoch 115/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3071.4160 - mse: 3071.4160 - val_loss: 10457.8447 - val_mse: 10457.8447\n",
      "Epoch 116/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2922.2451 - mse: 2922.2451 - val_loss: 8820.3154 - val_mse: 8820.3154\n",
      "Epoch 117/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2257.9209 - mse: 2257.9209 - val_loss: 8790.4121 - val_mse: 8790.4121\n",
      "Epoch 118/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2468.7394 - mse: 2468.7394 - val_loss: 8409.7080 - val_mse: 8409.7080\n",
      "Epoch 119/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2203.6797 - mse: 2203.6797 - val_loss: 7591.8545 - val_mse: 7591.8545\n",
      "Epoch 120/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1916.0838 - mse: 1916.0838 - val_loss: 7581.9507 - val_mse: 7581.9507\n",
      "Epoch 121/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1546.4852 - mse: 1546.4852 - val_loss: 6620.9077 - val_mse: 6620.9077\n",
      "Epoch 122/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1705.5937 - mse: 1705.5937 - val_loss: 6081.9580 - val_mse: 6081.9580\n",
      "Epoch 123/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1303.2313 - mse: 1303.2313 - val_loss: 5914.4561 - val_mse: 5914.4561\n",
      "Epoch 124/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1030.3078 - mse: 1030.3078 - val_loss: 5938.5498 - val_mse: 5938.5498\n",
      "Epoch 125/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 897.1924 - mse: 897.1924 - val_loss: 5333.7104 - val_mse: 5333.7104\n",
      "Epoch 126/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 788.1841 - mse: 788.1841 - val_loss: 4448.7261 - val_mse: 4448.7261\n",
      "Epoch 127/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 722.1660 - mse: 722.1660 - val_loss: 4204.2334 - val_mse: 4204.2334\n",
      "Epoch 128/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 555.5143 - mse: 555.5143 - val_loss: 3853.1812 - val_mse: 3853.1812\n",
      "Epoch 129/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 605.1425 - mse: 605.1425 - val_loss: 3178.6079 - val_mse: 3178.6079\n",
      "Epoch 130/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 407.6510 - mse: 407.6510 - val_loss: 3074.1335 - val_mse: 3074.1335\n",
      "Epoch 131/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 378.6576 - mse: 378.6576 - val_loss: 2787.0757 - val_mse: 2787.0757\n",
      "Epoch 132/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 336.5352 - mse: 336.5352 - val_loss: 2487.1997 - val_mse: 2487.1997\n",
      "Epoch 133/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 204.2251 - mse: 204.2251 - val_loss: 2162.6587 - val_mse: 2162.6587\n",
      "Epoch 134/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 191.6839 - mse: 191.6839 - val_loss: 2050.1443 - val_mse: 2050.1443\n",
      "Epoch 135/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 160.7898 - mse: 160.7898 - val_loss: 1682.6165 - val_mse: 1682.6165\n",
      "Epoch 136/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 107.4914 - mse: 107.4914 - val_loss: 1568.3274 - val_mse: 1568.3274\n",
      "Epoch 137/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 91.5310 - mse: 91.5310 - val_loss: 1457.9801 - val_mse: 1457.9801\n",
      "Epoch 138/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 70.7995 - mse: 70.7995 - val_loss: 1248.8647 - val_mse: 1248.8647\n",
      "Epoch 139/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 56.0109 - mse: 56.0109 - val_loss: 1249.6830 - val_mse: 1249.6830\n",
      "Epoch 140/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 41.6306 - mse: 41.6306 - val_loss: 1147.2842 - val_mse: 1147.2842\n",
      "Epoch 141/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 33.9797 - mse: 33.9797 - val_loss: 993.1717 - val_mse: 993.1717\n",
      "Epoch 142/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 22.0715 - mse: 22.0715 - val_loss: 980.9678 - val_mse: 980.9678\n",
      "Epoch 143/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 20.8246 - mse: 20.8246 - val_loss: 903.2733 - val_mse: 903.2733\n",
      "Epoch 144/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 19.3321 - mse: 19.3321 - val_loss: 877.4022 - val_mse: 877.4022\n",
      "Epoch 145/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 14.0338 - mse: 14.0338 - val_loss: 785.5924 - val_mse: 785.5924\n",
      "Epoch 146/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 11.5468 - mse: 11.5468 - val_loss: 730.7806 - val_mse: 730.7806\n",
      "Epoch 147/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 13.0989 - mse: 13.0989 - val_loss: 734.8914 - val_mse: 734.8914\n",
      "Epoch 148/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 10.5094 - mse: 10.5094 - val_loss: 669.9471 - val_mse: 669.9471\n",
      "Epoch 149/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.9777 - mse: 9.9777 - val_loss: 655.2629 - val_mse: 655.2629\n",
      "Epoch 150/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.6543 - mse: 9.6543 - val_loss: 625.9645 - val_mse: 625.9645\n",
      "Epoch 151/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 10.4574 - mse: 10.4574 - val_loss: 612.0383 - val_mse: 612.0383\n",
      "Epoch 152/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.8924 - mse: 9.8924 - val_loss: 603.0129 - val_mse: 603.0129\n",
      "Epoch 153/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.2576 - mse: 8.2576 - val_loss: 573.5592 - val_mse: 573.5592\n",
      "Epoch 154/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.3332 - mse: 9.3332 - val_loss: 559.5709 - val_mse: 559.5709\n",
      "Epoch 155/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.8097 - mse: 8.8097 - val_loss: 547.2229 - val_mse: 547.2229\n",
      "Epoch 156/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9330 - mse: 8.9330 - val_loss: 542.1329 - val_mse: 542.1329\n",
      "Epoch 157/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3240 - mse: 8.3240 - val_loss: 524.9908 - val_mse: 524.9908\n",
      "Epoch 158/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2953 - mse: 7.2953 - val_loss: 516.6777 - val_mse: 516.6777\n",
      "Epoch 159/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9630 - mse: 8.9630 - val_loss: 509.2409 - val_mse: 509.2409\n",
      "Epoch 160/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9534 - mse: 8.9534 - val_loss: 504.5829 - val_mse: 504.5829\n",
      "Epoch 161/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.2968 - mse: 8.2968 - val_loss: 496.2082 - val_mse: 496.2082\n",
      "Epoch 162/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.7430 - mse: 7.7430 - val_loss: 491.7965 - val_mse: 491.7965\n",
      "Epoch 163/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.5739 - mse: 7.5739 - val_loss: 484.2267 - val_mse: 484.2267\n",
      "Epoch 164/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.8517 - mse: 8.8517 - val_loss: 482.3022 - val_mse: 482.3022\n",
      "Epoch 165/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9664 - mse: 6.9664 - val_loss: 480.5229 - val_mse: 480.5229\n",
      "Epoch 166/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.3143 - mse: 9.3143 - val_loss: 474.3560 - val_mse: 474.3560\n",
      "Epoch 167/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3355 - mse: 7.3355 - val_loss: 469.5093 - val_mse: 469.5093\n",
      "Epoch 168/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.5040 - mse: 7.5040 - val_loss: 467.8126 - val_mse: 467.8126\n",
      "Epoch 169/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.6518 - mse: 7.6518 - val_loss: 466.6232 - val_mse: 466.6232\n",
      "Epoch 170/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.8290 - mse: 8.8290 - val_loss: 463.3086 - val_mse: 463.3086\n",
      "Epoch 171/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.7703 - mse: 7.7703 - val_loss: 460.7907 - val_mse: 460.7907\n",
      "Epoch 172/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.9235 - mse: 7.9235 - val_loss: 457.6689 - val_mse: 457.6689\n",
      "Epoch 173/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.6817 - mse: 7.6817 - val_loss: 458.1352 - val_mse: 458.1352\n",
      "Epoch 174/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.6025 - mse: 9.6025 - val_loss: 456.6371 - val_mse: 456.6371\n",
      "Epoch 175/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.1640 - mse: 8.1640 - val_loss: 453.4129 - val_mse: 453.4129\n",
      "Epoch 176/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9063 - mse: 8.9063 - val_loss: 455.5352 - val_mse: 455.5352\n",
      "Epoch 177/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9281 - mse: 8.9281 - val_loss: 453.3841 - val_mse: 453.3841\n",
      "Epoch 178/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.2440 - mse: 8.2440 - val_loss: 454.7194 - val_mse: 454.7194\n",
      "Epoch 179/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.7931 - mse: 8.7931 - val_loss: 453.0892 - val_mse: 453.0892\n",
      "Epoch 180/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2284 - mse: 7.2284 - val_loss: 452.7878 - val_mse: 452.7878\n",
      "Epoch 181/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.5888 - mse: 7.5888 - val_loss: 453.3953 - val_mse: 453.3953\n",
      "Epoch 182/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6021 - mse: 6.6021 - val_loss: 450.8503 - val_mse: 450.8503\n",
      "Epoch 183/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.9297 - mse: 7.9297 - val_loss: 452.1319 - val_mse: 452.1319\n",
      "Epoch 184/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.5338 - mse: 8.5338 - val_loss: 453.4677 - val_mse: 453.4677\n",
      "Epoch 185/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7975 - mse: 6.7975 - val_loss: 450.1567 - val_mse: 450.1567\n",
      "Epoch 186/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.1436 - mse: 8.1436 - val_loss: 450.6620 - val_mse: 450.6620\n",
      "Epoch 187/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.7695 - mse: 7.7695 - val_loss: 455.2264 - val_mse: 455.2264\n",
      "Epoch 188/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.9195 - mse: 7.9195 - val_loss: 450.3944 - val_mse: 450.3944\n",
      "Epoch 189/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.9779 - mse: 7.9779 - val_loss: 449.8371 - val_mse: 449.8371\n",
      "Epoch 190/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.4987 - mse: 8.4987 - val_loss: 451.4637 - val_mse: 451.4637\n",
      "Epoch 191/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.4714 - mse: 9.4714 - val_loss: 450.9795 - val_mse: 450.9795\n",
      "Epoch 192/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2121 - mse: 7.2121 - val_loss: 448.7769 - val_mse: 448.7769\n",
      "Epoch 193/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.4293 - mse: 9.4293 - val_loss: 449.9467 - val_mse: 449.9467\n",
      "Epoch 194/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.4490 - mse: 8.4490 - val_loss: 450.0089 - val_mse: 450.0089\n",
      "Epoch 195/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.8669 - mse: 9.8669 - val_loss: 453.5816 - val_mse: 453.5816\n",
      "Epoch 196/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.4656 - mse: 7.4656 - val_loss: 450.9664 - val_mse: 450.9664\n",
      "Epoch 197/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3591 - mse: 8.3591 - val_loss: 455.5599 - val_mse: 455.5599\n",
      "Epoch 198/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.0197 - mse: 7.0197 - val_loss: 448.8156 - val_mse: 448.8156\n",
      "Epoch 199/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.0213 - mse: 8.0213 - val_loss: 452.6996 - val_mse: 452.6996\n",
      "Epoch 200/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6818 - mse: 6.6818 - val_loss: 453.3818 - val_mse: 453.3818\n",
      "Epoch 201/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.3521 - mse: 9.3521 - val_loss: 451.0587 - val_mse: 451.0587\n",
      "Epoch 202/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2604 - mse: 7.2604 - val_loss: 448.1532 - val_mse: 448.1532\n",
      "Epoch 203/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9847 - mse: 8.9847 - val_loss: 456.2408 - val_mse: 456.2408\n",
      "Epoch 204/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.5119 - mse: 8.5119 - val_loss: 451.3712 - val_mse: 451.3712\n",
      "Epoch 205/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.1314 - mse: 8.1314 - val_loss: 449.6305 - val_mse: 449.6305\n",
      "Epoch 206/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1788 - mse: 7.1788 - val_loss: 448.5648 - val_mse: 448.5648\n",
      "Epoch 207/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.8751 - mse: 8.8751 - val_loss: 449.2678 - val_mse: 449.2678\n",
      "Epoch 208/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.4957 - mse: 8.4957 - val_loss: 457.1085 - val_mse: 457.1085\n",
      "Epoch 209/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.4249 - mse: 7.4249 - val_loss: 450.5231 - val_mse: 450.5231\n",
      "Epoch 210/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.0856 - mse: 8.0856 - val_loss: 451.6544 - val_mse: 451.6544\n",
      "Epoch 211/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.7591 - mse: 7.7591 - val_loss: 452.3723 - val_mse: 452.3723\n",
      "Epoch 212/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.1398 - mse: 8.1398 - val_loss: 453.7100 - val_mse: 453.7100\n",
      "Epoch 213/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8980 - mse: 7.8980 - val_loss: 449.8652 - val_mse: 449.8652\n",
      "Epoch 214/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.2321 - mse: 8.2321 - val_loss: 448.5042 - val_mse: 448.5042\n",
      "Epoch 215/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.0240 - mse: 8.0240 - val_loss: 448.9266 - val_mse: 448.9266\n",
      "Epoch 216/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7189 - mse: 6.7189 - val_loss: 451.4199 - val_mse: 451.4199\n",
      "Epoch 217/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.0386 - mse: 9.0386 - val_loss: 448.6336 - val_mse: 448.6336\n",
      "Epoch 218/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.8401 - mse: 6.8401 - val_loss: 453.2105 - val_mse: 453.2105\n",
      "Epoch 219/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8930 - mse: 7.8930 - val_loss: 450.4593 - val_mse: 450.4593\n",
      "Epoch 220/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.2505 - mse: 8.2505 - val_loss: 444.6855 - val_mse: 444.6855\n",
      "Epoch 221/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8119 - mse: 7.8119 - val_loss: 456.9870 - val_mse: 456.9870\n",
      "Epoch 222/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1051 - mse: 7.1051 - val_loss: 451.7472 - val_mse: 451.7472\n",
      "Epoch 223/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.7396 - mse: 7.7396 - val_loss: 450.1244 - val_mse: 450.1244\n",
      "Epoch 224/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.3792 - mse: 9.3792 - val_loss: 449.8423 - val_mse: 449.8423\n",
      "Epoch 225/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.8048 - mse: 9.8048 - val_loss: 442.2970 - val_mse: 442.2970\n",
      "Epoch 226/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8891 - mse: 7.8891 - val_loss: 450.9094 - val_mse: 450.9094\n",
      "Epoch 227/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.2032 - mse: 6.2032 - val_loss: 451.3694 - val_mse: 451.3694\n",
      "Epoch 228/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.7783 - mse: 7.7783 - val_loss: 452.0138 - val_mse: 452.0138\n",
      "Epoch 229/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6013 - mse: 6.6013 - val_loss: 448.1964 - val_mse: 448.1964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6081 - mse: 6.6081 - val_loss: 450.5490 - val_mse: 450.5490\n",
      "Epoch 231/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.9521 - mse: 7.9521 - val_loss: 443.9478 - val_mse: 443.9478\n",
      "Epoch 232/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.4537 - mse: 6.4537 - val_loss: 458.5381 - val_mse: 458.5381\n",
      "Epoch 233/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.2047 - mse: 8.2047 - val_loss: 442.9319 - val_mse: 442.9319\n",
      "Epoch 234/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.5309 - mse: 6.5309 - val_loss: 442.7553 - val_mse: 442.7553\n",
      "Epoch 235/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.0027 - mse: 7.0027 - val_loss: 442.0853 - val_mse: 442.0853\n",
      "Epoch 236/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9325 - mse: 5.9325 - val_loss: 447.2367 - val_mse: 447.2367\n",
      "Epoch 237/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9695 - mse: 6.9695 - val_loss: 447.5961 - val_mse: 447.5961\n",
      "Epoch 238/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.5115 - mse: 6.5115 - val_loss: 448.4512 - val_mse: 448.4512\n",
      "Epoch 239/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8699 - mse: 7.8699 - val_loss: 439.0732 - val_mse: 439.0732\n",
      "Epoch 240/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.4813 - mse: 9.4813 - val_loss: 463.4036 - val_mse: 463.4036\n",
      "Epoch 241/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.8046 - mse: 8.8046 - val_loss: 459.5164 - val_mse: 459.5164\n",
      "Epoch 242/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7122 - mse: 6.7122 - val_loss: 481.3581 - val_mse: 481.3581\n",
      "Epoch 243/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7209 - mse: 6.7209 - val_loss: 452.5055 - val_mse: 452.5055\n",
      "Epoch 244/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2730 - mse: 7.2730 - val_loss: 436.1494 - val_mse: 436.1494\n",
      "Epoch 245/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.5149 - mse: 7.5149 - val_loss: 449.9342 - val_mse: 449.9342\n",
      "Epoch 246/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.8787 - mse: 6.8787 - val_loss: 439.4608 - val_mse: 439.4608\n",
      "Epoch 247/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.8106 - mse: 6.8106 - val_loss: 445.4571 - val_mse: 445.4571\n",
      "Epoch 248/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1454 - mse: 7.1454 - val_loss: 458.6479 - val_mse: 458.6479\n",
      "Epoch 249/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1185 - mse: 7.1185 - val_loss: 463.5861 - val_mse: 463.5861\n",
      "Epoch 250/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9006 - mse: 5.9006 - val_loss: 424.4206 - val_mse: 424.4206\n",
      "Epoch 251/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.0053 - mse: 6.0053 - val_loss: 455.6278 - val_mse: 455.6278\n",
      "Epoch 252/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7612 - mse: 6.7612 - val_loss: 444.8378 - val_mse: 444.8378\n",
      "Epoch 253/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.2596 - mse: 6.2596 - val_loss: 434.6027 - val_mse: 434.6027\n",
      "Epoch 254/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2961 - mse: 7.2961 - val_loss: 512.4785 - val_mse: 512.4785\n",
      "Epoch 255/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.9024 - mse: 7.9024 - val_loss: 425.0990 - val_mse: 425.0990\n",
      "Epoch 256/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.7384 - mse: 5.7384 - val_loss: 484.4127 - val_mse: 484.4127\n",
      "Epoch 257/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9516 - mse: 5.9516 - val_loss: 452.0901 - val_mse: 452.0901\n",
      "Epoch 258/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.8503 - mse: 6.8503 - val_loss: 421.4032 - val_mse: 421.4032\n",
      "Epoch 259/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.1512 - mse: 6.1512 - val_loss: 451.1960 - val_mse: 451.1960\n",
      "Epoch 260/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1467 - mse: 5.1467 - val_loss: 436.9134 - val_mse: 436.9134\n",
      "Epoch 261/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.1938 - mse: 5.1938 - val_loss: 452.4499 - val_mse: 452.4499\n",
      "Epoch 262/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.9332 - mse: 4.9332 - val_loss: 463.9756 - val_mse: 463.9756\n",
      "Epoch 263/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8733 - mse: 7.8733 - val_loss: 427.1175 - val_mse: 427.1175\n",
      "Epoch 264/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.2654 - mse: 7.2654 - val_loss: 410.8524 - val_mse: 410.8524\n",
      "Epoch 265/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.4531 - mse: 5.4531 - val_loss: 459.0790 - val_mse: 459.0790\n",
      "Epoch 266/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3551 - mse: 6.3551 - val_loss: 467.8410 - val_mse: 467.8410\n",
      "Epoch 267/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9056 - mse: 5.9056 - val_loss: 448.2344 - val_mse: 448.2344\n",
      "Epoch 268/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.7924 - mse: 5.7924 - val_loss: 428.5282 - val_mse: 428.5282\n",
      "Epoch 269/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.2567 - mse: 6.2567 - val_loss: 463.6093 - val_mse: 463.6093\n",
      "Epoch 270/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.8596 - mse: 5.8596 - val_loss: 460.6914 - val_mse: 460.6914\n",
      "Epoch 271/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5984 - mse: 5.5984 - val_loss: 421.0853 - val_mse: 421.0853\n",
      "Epoch 272/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.9929 - mse: 4.9929 - val_loss: 466.8237 - val_mse: 466.8237\n",
      "Epoch 273/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8789 - mse: 4.8789 - val_loss: 485.8219 - val_mse: 485.8219\n",
      "Epoch 274/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9399 - mse: 8.9399 - val_loss: 492.6189 - val_mse: 492.6189\n",
      "Epoch 275/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0709 - mse: 5.0709 - val_loss: 446.2263 - val_mse: 446.2263\n",
      "Epoch 276/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.7181 - mse: 4.7181 - val_loss: 489.8708 - val_mse: 489.8708\n",
      "Epoch 277/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.8363 - mse: 5.8363 - val_loss: 465.7465 - val_mse: 465.7465\n",
      "Epoch 278/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3506 - mse: 4.3506 - val_loss: 456.8149 - val_mse: 456.8149\n",
      "Epoch 279/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6624 - mse: 3.6624 - val_loss: 444.4149 - val_mse: 444.4149\n",
      "Epoch 280/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.9744 - mse: 4.9744 - val_loss: 470.8070 - val_mse: 470.8070\n",
      "Epoch 281/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3785 - mse: 4.3785 - val_loss: 469.0034 - val_mse: 469.0034\n",
      "Epoch 282/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5378 - mse: 4.5378 - val_loss: 474.8271 - val_mse: 474.8271\n",
      "Epoch 283/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5005 - mse: 3.5005 - val_loss: 440.1670 - val_mse: 440.1670\n",
      "Epoch 284/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.5722 - mse: 4.5722 - val_loss: 494.5207 - val_mse: 494.5207\n",
      "Epoch 285/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3717 - mse: 3.3717 - val_loss: 459.3916 - val_mse: 459.3916\n",
      "Epoch 286/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8400 - mse: 2.8400 - val_loss: 455.7553 - val_mse: 455.7553\n",
      "Epoch 287/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6263 - mse: 3.6263 - val_loss: 485.6011 - val_mse: 485.6011\n",
      "Epoch 288/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5055 - mse: 3.5055 - val_loss: 471.5184 - val_mse: 471.5184\n",
      "Epoch 289/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2869 - mse: 3.2869 - val_loss: 425.6554 - val_mse: 425.6554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.2867 - mse: 3.2867 - val_loss: 501.8808 - val_mse: 501.8808\n",
      "Epoch 291/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3163 - mse: 3.3163 - val_loss: 458.5103 - val_mse: 458.5103\n",
      "Epoch 292/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7595 - mse: 2.7595 - val_loss: 422.8446 - val_mse: 422.8446\n",
      "Epoch 293/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3477 - mse: 2.3477 - val_loss: 472.8323 - val_mse: 472.8323\n",
      "Epoch 294/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4632 - mse: 2.4632 - val_loss: 442.7838 - val_mse: 442.7838\n",
      "Epoch 295/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1195 - mse: 2.1195 - val_loss: 433.8727 - val_mse: 433.8727\n",
      "Epoch 296/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1204 - mse: 2.1204 - val_loss: 409.2406 - val_mse: 409.2406\n",
      "Epoch 297/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3586 - mse: 2.3586 - val_loss: 467.9801 - val_mse: 467.9801\n",
      "Epoch 298/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2423 - mse: 2.2423 - val_loss: 319.7270 - val_mse: 319.7270\n",
      "Epoch 299/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3646 - mse: 2.3646 - val_loss: 397.1953 - val_mse: 397.1953\n",
      "Epoch 300/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0017 - mse: 2.0017 - val_loss: 462.2438 - val_mse: 462.2438\n",
      "Epoch 301/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4264 - mse: 1.4264 - val_loss: 447.0154 - val_mse: 447.0154\n",
      "Epoch 302/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8436 - mse: 1.8436 - val_loss: 446.0932 - val_mse: 446.0932\n",
      "Epoch 303/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6154 - mse: 1.6154 - val_loss: 449.7172 - val_mse: 449.7172\n",
      "Epoch 304/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5366 - mse: 1.5366 - val_loss: 504.2369 - val_mse: 504.2369\n",
      "Epoch 305/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3562 - mse: 1.3562 - val_loss: 416.1412 - val_mse: 416.1412\n",
      "Epoch 306/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3525 - mse: 1.3525 - val_loss: 456.3773 - val_mse: 456.3773\n",
      "Epoch 307/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1057 - mse: 1.1057 - val_loss: 450.9308 - val_mse: 450.9308\n",
      "Epoch 308/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2789 - mse: 1.2789 - val_loss: 446.7523 - val_mse: 446.7523\n",
      "Epoch 309/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0004 - mse: 1.0004 - val_loss: 453.0872 - val_mse: 453.0872\n",
      "Epoch 310/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1272 - mse: 1.1272 - val_loss: 455.8742 - val_mse: 455.8742\n",
      "Epoch 311/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1416 - mse: 1.1416 - val_loss: 419.2248 - val_mse: 419.2248\n",
      "Epoch 312/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.6464 - mse: 0.6464 - val_loss: 466.0851 - val_mse: 466.0851\n",
      "Epoch 313/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4441 - mse: 0.4441 - val_loss: 444.0546 - val_mse: 444.0546\n",
      "Epoch 314/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.9481 - mse: 0.9481 - val_loss: 450.0488 - val_mse: 450.0488\n",
      "Epoch 315/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5413 - mse: 0.5413 - val_loss: 468.6366 - val_mse: 468.6366\n",
      "Epoch 316/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4844 - mse: 0.4844 - val_loss: 432.7748 - val_mse: 432.7748\n",
      "Epoch 317/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3811 - mse: 0.3811 - val_loss: 461.9580 - val_mse: 461.9580\n",
      "Epoch 318/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4574 - mse: 0.4574 - val_loss: 448.2000 - val_mse: 448.2000\n",
      "Epoch 319/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3199 - mse: 0.3199 - val_loss: 469.2012 - val_mse: 469.2012\n",
      "Epoch 320/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3193 - mse: 0.3193 - val_loss: 412.4191 - val_mse: 412.4191\n",
      "Epoch 321/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2732 - mse: 0.2732 - val_loss: 428.4676 - val_mse: 428.4676\n",
      "Epoch 322/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3594 - mse: 0.3594 - val_loss: 465.5518 - val_mse: 465.5518\n",
      "Epoch 323/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2210 - mse: 0.2210 - val_loss: 412.9548 - val_mse: 412.9548\n",
      "Epoch 324/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4568 - mse: 0.4568 - val_loss: 429.2703 - val_mse: 429.2703\n",
      "Epoch 325/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0097 - mse: 1.0097 - val_loss: 488.1619 - val_mse: 488.1619\n",
      "Epoch 326/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5697 - mse: 0.5697 - val_loss: 449.8774 - val_mse: 449.8774\n",
      "Epoch 327/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 454.5670 - val_mse: 454.5670\n",
      "Epoch 328/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0713 - mse: 0.0713 - val_loss: 442.1056 - val_mse: 442.1056\n",
      "Epoch 329/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1612 - mse: 0.1612 - val_loss: 448.1633 - val_mse: 448.1633\n",
      "Epoch 330/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0511 - mse: 0.0511 - val_loss: 452.9044 - val_mse: 452.9044\n",
      "Epoch 331/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0973 - mse: 0.0973 - val_loss: 425.0975 - val_mse: 425.0975\n",
      "Epoch 332/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1631 - mse: 0.1631 - val_loss: 453.5367 - val_mse: 453.5367\n",
      "Epoch 333/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 453.3661 - val_mse: 453.3661\n",
      "Epoch 334/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 443.9131 - val_mse: 443.9131\n",
      "Epoch 335/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 455.2813 - val_mse: 455.2813\n",
      "Epoch 336/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 432.6534 - val_mse: 432.6534\n",
      "Epoch 337/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 445.8356 - val_mse: 445.8356\n",
      "Epoch 338/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 450.9057 - val_mse: 450.9057\n",
      "Epoch 339/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 459.9506 - val_mse: 459.9506\n",
      "Epoch 340/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 421.5738 - val_mse: 421.5738\n",
      "Epoch 341/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 411.8423 - val_mse: 411.8423\n",
      "Epoch 342/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 424.0063 - val_mse: 424.0063\n",
      "Epoch 343/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 430.1752 - val_mse: 430.1752\n",
      "Epoch 344/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 440.2636 - val_mse: 440.2636\n",
      "Epoch 345/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 446.0206 - val_mse: 446.0206\n",
      "Epoch 346/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 450.9628 - val_mse: 450.9628\n",
      "Epoch 347/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.4618e-04 - mse: 9.4618e-04 - val_loss: 450.9206 - val_mse: 450.9206\n",
      "Epoch 348/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0593 - mse: 0.0593 - val_loss: 444.7468 - val_mse: 444.7468\n",
      "Epoch 349/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3235 - mse: 1.3235 - val_loss: 342.7098 - val_mse: 342.7098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3013 - mse: 0.3013 - val_loss: 337.0207 - val_mse: 337.0207\n",
      "Epoch 351/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0483 - mse: 2.0483 - val_loss: 306.8644 - val_mse: 306.8644\n",
      "Epoch 352/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5894 - mse: 0.5894 - val_loss: 339.7485 - val_mse: 339.7485\n",
      "Epoch 353/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 350.0396 - val_mse: 350.0396\n",
      "Epoch 354/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 352.4367 - val_mse: 352.4367\n",
      "Epoch 355/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 355.0053 - val_mse: 355.0053\n",
      "Epoch 356/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.4635e-04 - mse: 8.4635e-04 - val_loss: 357.2796 - val_mse: 357.2796\n",
      "Epoch 357/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.9829e-04 - mse: 8.9829e-04 - val_loss: 359.6414 - val_mse: 359.6414\n",
      "Epoch 358/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.1685e-04 - mse: 7.1685e-04 - val_loss: 361.6512 - val_mse: 361.6512\n",
      "Epoch 359/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.1958e-04 - mse: 6.1958e-04 - val_loss: 363.4949 - val_mse: 363.4949\n",
      "Epoch 360/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9750e-04 - mse: 3.9750e-04 - val_loss: 365.1952 - val_mse: 365.1952\n",
      "Epoch 361/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3729e-04 - mse: 2.3729e-04 - val_loss: 366.3912 - val_mse: 366.3912\n",
      "Epoch 362/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0798e-04 - mse: 2.0798e-04 - val_loss: 367.8951 - val_mse: 367.8951\n",
      "Epoch 363/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1898e-04 - mse: 1.1898e-04 - val_loss: 368.5036 - val_mse: 368.5036\n",
      "Epoch 364/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9429e-04 - mse: 1.9429e-04 - val_loss: 369.5587 - val_mse: 369.5587\n",
      "Epoch 365/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6253e-05 - mse: 6.6253e-05 - val_loss: 370.4780 - val_mse: 370.4780\n",
      "Epoch 366/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.4717e-05 - mse: 6.4717e-05 - val_loss: 371.0935 - val_mse: 371.0935\n",
      "Epoch 367/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0153e-05 - mse: 5.0153e-05 - val_loss: 371.6309 - val_mse: 371.6309\n",
      "Epoch 368/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.4027e-05 - mse: 7.4027e-05 - val_loss: 372.4654 - val_mse: 372.4654\n",
      "Epoch 369/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.7014e-05 - mse: 2.7014e-05 - val_loss: 372.7543 - val_mse: 372.7543\n",
      "Epoch 370/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0591e-05 - mse: 2.0591e-05 - val_loss: 373.2021 - val_mse: 373.2021\n",
      "Epoch 371/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.7729e-06 - mse: 5.7729e-06 - val_loss: 373.4841 - val_mse: 373.4841\n",
      "Epoch 372/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2083e-06 - mse: 4.2083e-06 - val_loss: 373.7725 - val_mse: 373.7725\n",
      "Epoch 373/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6503e-06 - mse: 2.6503e-06 - val_loss: 374.0001 - val_mse: 374.0001\n",
      "Epoch 374/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2191e-06 - mse: 2.2191e-06 - val_loss: 374.1492 - val_mse: 374.1492\n",
      "Epoch 375/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1427e-06 - mse: 1.1427e-06 - val_loss: 374.3479 - val_mse: 374.3479\n",
      "Epoch 376/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4194e-06 - mse: 1.4194e-06 - val_loss: 374.4077 - val_mse: 374.4077\n",
      "Epoch 377/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1014e-06 - mse: 1.1014e-06 - val_loss: 374.5363 - val_mse: 374.5363\n",
      "Epoch 378/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.6198e-06 - mse: 2.6198e-06 - val_loss: 374.6359 - val_mse: 374.6359\n",
      "Epoch 379/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9335e-05 - mse: 1.9335e-05 - val_loss: 373.3517 - val_mse: 373.3517\n",
      "Epoch 380/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0631 - mse: 0.0631 - val_loss: 411.0858 - val_mse: 411.0858\n",
      "Epoch 381/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2598 - mse: 0.2598 - val_loss: 374.8708 - val_mse: 374.8708\n",
      "Epoch 382/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1845 - mse: 0.1845 - val_loss: 367.3271 - val_mse: 367.3271\n",
      "Epoch 383/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1209 - mse: 0.1209 - val_loss: 360.8096 - val_mse: 360.8096\n",
      "Epoch 384/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3081 - mse: 0.3081 - val_loss: 321.4555 - val_mse: 321.4555\n",
      "Epoch 385/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3766 - mse: 3.3766 - val_loss: 611.2101 - val_mse: 611.2101\n",
      "Epoch 386/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4983 - mse: 0.4983 - val_loss: 409.9208 - val_mse: 409.9208\n",
      "Epoch 387/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1449 - mse: 0.1449 - val_loss: 412.1190 - val_mse: 412.1190\n",
      "Epoch 388/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 414.9043 - val_mse: 414.9043\n",
      "Epoch 389/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.4060e-04 - mse: 6.4060e-04 - val_loss: 413.9313 - val_mse: 413.9313\n",
      "Epoch 390/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.9065e-04 - mse: 3.9065e-04 - val_loss: 413.9241 - val_mse: 413.9241\n",
      "Epoch 391/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8974e-05 - mse: 1.8974e-05 - val_loss: 413.4559 - val_mse: 413.4559\n",
      "Epoch 392/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5355e-05 - mse: 1.5355e-05 - val_loss: 413.1160 - val_mse: 413.1160\n",
      "Epoch 393/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1653e-05 - mse: 1.1653e-05 - val_loss: 412.7725 - val_mse: 412.7725\n",
      "Epoch 394/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3848e-06 - mse: 6.3848e-06 - val_loss: 412.4941 - val_mse: 412.4941\n",
      "Epoch 395/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.5903e-06 - mse: 5.5903e-06 - val_loss: 412.2573 - val_mse: 412.2573\n",
      "Epoch 396/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0941e-06 - mse: 3.0941e-06 - val_loss: 412.0605 - val_mse: 412.0605\n",
      "Epoch 397/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0563e-06 - mse: 2.0563e-06 - val_loss: 411.9129 - val_mse: 411.9129\n",
      "Epoch 398/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.0171e-07 - mse: 9.0171e-07 - val_loss: 411.8140 - val_mse: 411.8140\n",
      "Epoch 399/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1629e-06 - mse: 1.1629e-06 - val_loss: 411.7433 - val_mse: 411.7433\n",
      "Epoch 400/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4205e-06 - mse: 1.4205e-06 - val_loss: 411.5974 - val_mse: 411.5974\n",
      "Epoch 401/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2017e-06 - mse: 1.2017e-06 - val_loss: 411.5634 - val_mse: 411.5634\n",
      "Epoch 402/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.9106e-07 - mse: 5.9106e-07 - val_loss: 411.5145 - val_mse: 411.5145\n",
      "Epoch 403/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0389e-07 - mse: 2.0389e-07 - val_loss: 411.4509 - val_mse: 411.4509\n",
      "Epoch 404/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2300e-07 - mse: 1.2300e-07 - val_loss: 411.4410 - val_mse: 411.4410\n",
      "Epoch 405/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.8603e-07 - mse: 8.8603e-07 - val_loss: 411.3831 - val_mse: 411.3831\n",
      "Epoch 406/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.3461e-08 - mse: 8.3461e-08 - val_loss: 411.3336 - val_mse: 411.3336\n",
      "Epoch 407/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.6966e-06 - mse: 3.6966e-06 - val_loss: 411.2986 - val_mse: 411.2986\n",
      "Epoch 408/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1789e-05 - mse: 1.1789e-05 - val_loss: 411.2689 - val_mse: 411.2689\n",
      "Epoch 409/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6339e-05 - mse: 1.6339e-05 - val_loss: 411.6273 - val_mse: 411.6273\n",
      "Epoch 410/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6517e-04 - mse: 1.6517e-04 - val_loss: 411.7311 - val_mse: 411.7311\n",
      "Epoch 411/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0975 - mse: 0.0975 - val_loss: 481.5123 - val_mse: 481.5123\n",
      "Epoch 412/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4438 - mse: 3.4438 - val_loss: 369.0644 - val_mse: 369.0644\n",
      "Epoch 413/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5564 - mse: 0.5564 - val_loss: 411.1339 - val_mse: 411.1339\n",
      "Epoch 414/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 405.8741 - val_mse: 405.8741\n",
      "Epoch 415/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2307e-04 - mse: 1.2307e-04 - val_loss: 406.2953 - val_mse: 406.2953\n",
      "Epoch 416/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0025e-06 - mse: 5.0025e-06 - val_loss: 406.3553 - val_mse: 406.3553\n",
      "Epoch 417/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0951e-09 - mse: 3.0951e-09 - val_loss: 406.3590 - val_mse: 406.3590\n",
      "Epoch 418/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4444e-09 - mse: 1.4444e-09 - val_loss: 406.3611 - val_mse: 406.3611\n",
      "Epoch 419/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.4971e-09 - mse: 3.4971e-09 - val_loss: 406.3622 - val_mse: 406.3622\n",
      "Epoch 420/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.3088e-09 - mse: 2.3088e-09 - val_loss: 406.3662 - val_mse: 406.3662\n",
      "Epoch 421/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7650e-09 - mse: 3.7650e-09 - val_loss: 406.3814 - val_mse: 406.3814\n",
      "Epoch 422/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.8886e-08 - mse: 4.8886e-08 - val_loss: 406.3723 - val_mse: 406.3723\n",
      "Epoch 423/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.5806e-10 - mse: 8.5806e-10 - val_loss: 406.3731 - val_mse: 406.3731\n",
      "Epoch 424/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8009e-10 - mse: 7.8009e-10 - val_loss: 406.3743 - val_mse: 406.3743\n",
      "Epoch 425/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4850e-09 - mse: 1.4850e-09 - val_loss: 406.3733 - val_mse: 406.3733\n",
      "Epoch 426/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 8.2117e-10 - mse: 8.2117e-10 - val_loss: 406.3791 - val_mse: 406.3791\n",
      "Epoch 427/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.8167e-09 - mse: 2.8167e-09 - val_loss: 406.3784 - val_mse: 406.3784\n",
      "Epoch 428/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.5821e-10 - mse: 9.5821e-10 - val_loss: 406.3815 - val_mse: 406.3815\n",
      "Epoch 429/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.7305e-10 - mse: 6.7305e-10 - val_loss: 406.3801 - val_mse: 406.3801\n",
      "Epoch 430/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.7469e-10 - mse: 4.7469e-10 - val_loss: 406.3820 - val_mse: 406.3820\n",
      "Epoch 431/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.8202e-10 - mse: 5.8202e-10 - val_loss: 406.3831 - val_mse: 406.3831\n",
      "Epoch 432/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4612e-09 - mse: 1.4612e-09 - val_loss: 406.3836 - val_mse: 406.3836\n",
      "Epoch 433/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.6932e-09 - mse: 9.6932e-09 - val_loss: 406.3803 - val_mse: 406.3803\n",
      "Epoch 434/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3305e-09 - mse: 1.3305e-09 - val_loss: 406.3820 - val_mse: 406.3820\n",
      "Epoch 435/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4520e-07 - mse: 2.4520e-07 - val_loss: 406.3683 - val_mse: 406.3683\n",
      "Epoch 436/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8058e-06 - mse: 1.8058e-06 - val_loss: 406.3780 - val_mse: 406.3780\n",
      "Epoch 437/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.7838e-07 - mse: 9.7838e-07 - val_loss: 406.3852 - val_mse: 406.3852\n",
      "Epoch 438/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8583e-06 - mse: 1.8583e-06 - val_loss: 406.3802 - val_mse: 406.3802\n",
      "Epoch 439/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6958e-06 - mse: 6.6958e-06 - val_loss: 406.2245 - val_mse: 406.2245\n",
      "Epoch 440/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.8312e-04 - mse: 1.8312e-04 - val_loss: 405.9114 - val_mse: 405.9114\n",
      "Epoch 441/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.6254e-04 - mse: 7.6254e-04 - val_loss: 406.4236 - val_mse: 406.4236\n",
      "Epoch 442/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 399.1737 - val_mse: 399.1737\n",
      "Epoch 443/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5792 - mse: 2.5792 - val_loss: 379.3837 - val_mse: 379.3837\n",
      "Epoch 444/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4294 - mse: 0.4294 - val_loss: 415.7672 - val_mse: 415.7672\n",
      "Epoch 445/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 408.4233 - val_mse: 408.4233\n",
      "Epoch 446/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 405.1371 - val_mse: 405.1371\n",
      "Epoch 447/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 407.8840 - val_mse: 407.8840\n",
      "Epoch 448/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9896e-04 - mse: 2.9896e-04 - val_loss: 406.7830 - val_mse: 406.7830\n",
      "Epoch 449/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0026e-05 - mse: 1.0026e-05 - val_loss: 407.0771 - val_mse: 407.0771\n",
      "Epoch 450/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.7792e-06 - mse: 3.7792e-06 - val_loss: 407.1464 - val_mse: 407.1464\n",
      "Epoch 451/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.3377e-06 - mse: 3.3377e-06 - val_loss: 407.3107 - val_mse: 407.3107\n",
      "Epoch 452/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0034e-06 - mse: 4.0034e-06 - val_loss: 407.3629 - val_mse: 407.3629\n",
      "Epoch 453/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.3649e-07 - mse: 9.3649e-07 - val_loss: 407.4638 - val_mse: 407.4638\n",
      "Epoch 454/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9386e-07 - mse: 6.9386e-07 - val_loss: 407.5589 - val_mse: 407.5589\n",
      "Epoch 455/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2203e-07 - mse: 4.2203e-07 - val_loss: 407.6285 - val_mse: 407.6285\n",
      "Epoch 456/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.5362e-07 - mse: 3.5362e-07 - val_loss: 407.6887 - val_mse: 407.6887\n",
      "Epoch 457/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.1506e-07 - mse: 2.1506e-07 - val_loss: 407.7231 - val_mse: 407.7231\n",
      "Epoch 458/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.9054e-07 - mse: 4.9054e-07 - val_loss: 407.7579 - val_mse: 407.7579\n",
      "Epoch 459/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4200e-06 - mse: 1.4200e-06 - val_loss: 407.7982 - val_mse: 407.7982\n",
      "Epoch 460/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0606e-06 - mse: 1.0606e-06 - val_loss: 407.8242 - val_mse: 407.8242\n",
      "Epoch 461/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.9225e-08 - mse: 6.9225e-08 - val_loss: 407.8633 - val_mse: 407.8633\n",
      "Epoch 462/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2343e-07 - mse: 4.2343e-07 - val_loss: 407.8515 - val_mse: 407.8515\n",
      "Epoch 463/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4868e-06 - mse: 2.4868e-06 - val_loss: 407.8832 - val_mse: 407.8832\n",
      "Epoch 464/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step - loss: 5.6793e-07 - mse: 5.6793e-07 - val_loss: 407.9152 - val_mse: 407.9152\n",
      "Epoch 465/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.7948e-07 - mse: 4.7948e-07 - val_loss: 407.8741 - val_mse: 407.8741\n",
      "Epoch 466/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3810e-07 - mse: 7.3810e-07 - val_loss: 407.8737 - val_mse: 407.8737\n",
      "Epoch 467/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2917e-06 - mse: 1.2917e-06 - val_loss: 408.0135 - val_mse: 408.0135\n",
      "Epoch 468/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5995e-04 - mse: 1.5995e-04 - val_loss: 407.6402 - val_mse: 407.6402\n",
      "Epoch 469/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.7777e-05 - mse: 5.7777e-05 - val_loss: 407.8566 - val_mse: 407.8566\n",
      "Epoch 470/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.9670e-06 - mse: 1.9670e-06 - val_loss: 407.9105 - val_mse: 407.9105\n",
      "Epoch 471/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.0700e-06 - mse: 5.0700e-06 - val_loss: 407.7054 - val_mse: 407.7054\n",
      "Epoch 472/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.6624e-04 - mse: 7.6624e-04 - val_loss: 408.0162 - val_mse: 408.0162\n",
      "Epoch 473/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.1171 - mse: 0.1171 - val_loss: 370.8629 - val_mse: 370.8629\n",
      "Epoch 474/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 11.2981 - mse: 11.2981 - val_loss: 483.6751 - val_mse: 483.6751\n",
      "Epoch 475/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.4176 - mse: 0.4176 - val_loss: 332.5890 - val_mse: 332.5890\n",
      "Epoch 476/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 336.6230 - val_mse: 336.6230\n",
      "Epoch 477/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 338.1240 - val_mse: 338.1240\n",
      "Epoch 478/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.8311e-04 - mse: 7.8311e-04 - val_loss: 339.7612 - val_mse: 339.7612\n",
      "Epoch 479/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 341.6499 - val_mse: 341.6499\n",
      "Epoch 480/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.3689e-04 - mse: 9.3689e-04 - val_loss: 343.1011 - val_mse: 343.1011\n",
      "Epoch 481/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.0301e-04 - mse: 6.0301e-04 - val_loss: 344.4488 - val_mse: 344.4488\n",
      "Epoch 482/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3719e-04 - mse: 4.3719e-04 - val_loss: 345.6806 - val_mse: 345.6806\n",
      "Epoch 483/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0122e-04 - mse: 3.0122e-04 - val_loss: 346.7633 - val_mse: 346.7633\n",
      "Epoch 484/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.0048e-04 - mse: 3.0048e-04 - val_loss: 347.8235 - val_mse: 347.8235\n",
      "Epoch 485/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2793e-04 - mse: 1.2793e-04 - val_loss: 348.6964 - val_mse: 348.6964\n",
      "Epoch 486/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.0693e-04 - mse: 1.0693e-04 - val_loss: 349.4826 - val_mse: 349.4826\n",
      "Epoch 487/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1043e-04 - mse: 1.1043e-04 - val_loss: 350.1368 - val_mse: 350.1368\n",
      "Epoch 488/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 7.3159e-05 - mse: 7.3159e-05 - val_loss: 350.8404 - val_mse: 350.8404\n",
      "Epoch 489/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.2279e-05 - mse: 4.2279e-05 - val_loss: 351.3232 - val_mse: 351.3232\n",
      "Epoch 490/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 3.8854e-05 - mse: 3.8854e-05 - val_loss: 351.8789 - val_mse: 351.8789\n",
      "Epoch 491/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.9186e-05 - mse: 2.9186e-05 - val_loss: 352.3256 - val_mse: 352.3256\n",
      "Epoch 492/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.5970e-05 - mse: 2.5970e-05 - val_loss: 352.6819 - val_mse: 352.6819\n",
      "Epoch 493/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6967e-05 - mse: 1.6967e-05 - val_loss: 352.9512 - val_mse: 352.9512\n",
      "Epoch 494/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.1652e-05 - mse: 1.1652e-05 - val_loss: 353.2670 - val_mse: 353.2670\n",
      "Epoch 495/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.3294e-06 - mse: 5.3294e-06 - val_loss: 353.4915 - val_mse: 353.4915\n",
      "Epoch 496/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.0614e-06 - mse: 4.0614e-06 - val_loss: 353.6655 - val_mse: 353.6655\n",
      "Epoch 497/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.3743e-06 - mse: 4.3743e-06 - val_loss: 353.8545 - val_mse: 353.8545\n",
      "Epoch 498/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4071e-06 - mse: 2.4071e-06 - val_loss: 353.9813 - val_mse: 353.9813\n",
      "Epoch 499/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 9.2718e-07 - mse: 9.2718e-07 - val_loss: 354.0903 - val_mse: 354.0903\n",
      "Epoch 500/500\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.6080e-07 - mse: 6.6080e-07 - val_loss: 354.1785 - val_mse: 354.1785\n",
      "20/20 [==============================] - 0s 569us/step - loss: 2656.4468 - mse: 2656.4468\n",
      "mse : [2656.44677734375, 2656.44677734375]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=False, test_size=0.4)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, shuffle=False, test_size=0.5)\n",
    "\n",
    "# 2. 모델 구성\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "input_layer = Input(shape=(1, ))\n",
    "d = Dense(5, activation='relu')(input_layer)\n",
    "d = Dense(3)(d)\n",
    "d = Dense(4)(d)\n",
    "output_layer = Dense(2)(d)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# 3. 훈련\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=500, validation_data=(x_val, y_val))\n",
    "\n",
    "# 4. 평가 예측\n",
    "mse = model.evaluate(x_test, y_test, batch_size=1)\n",
    "print('mse :', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80, 81, 82, 83, 84])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff9da2ead30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[306.24152 422.13522]\n",
      " [308.52148 425.221  ]\n",
      " [310.80142 428.3068 ]\n",
      " [313.0814  431.3926 ]\n",
      " [315.36133 434.47836]\n",
      " [317.64127 437.56418]\n",
      " [319.9212  440.64996]\n",
      " [322.20117 443.73575]\n",
      " [324.48108 446.82153]\n",
      " [326.76105 449.90738]\n",
      " [329.04095 452.99313]\n",
      " [331.32092 456.07892]\n",
      " [333.60083 459.1647 ]\n",
      " [335.8808  462.25052]\n",
      " [338.16077 465.33633]\n",
      " [340.44067 468.42215]\n",
      " [342.72064 471.5079 ]\n",
      " [345.00058 474.59372]\n",
      " [347.28052 477.67947]\n",
      " [349.56042 480.76526]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  51.540733728342765\n",
      "r2_score :  -78.89314987235878\n"
     ]
    }
   ],
   "source": [
    "# RMSE \n",
    "from sklearn.metrics import mean_squared_error\n",
    "def RMSE(y_test, y_predict):\n",
    "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "print('RMSE : ', RMSE(y_test, y_predict))\n",
    "\n",
    "# r2\n",
    "from sklearn.metrics import r2_score\n",
    "print('r2_score : ', r2_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict한 부분의 값이 원하는 대로 잘 출력되지 않은 것을 알 수 있음.  \n",
    "RMSE 도 높은 수치, R2는 아예 음수임.  \n",
    "1개의 데이터에서 2개의 데이터를 예측하는데에 있어서 정보가 부족해서 그런 것일 수도 있음.  \n",
    "이러한 모델도 가능하다는 것 정도 인지하고 넘어가면 됨.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
